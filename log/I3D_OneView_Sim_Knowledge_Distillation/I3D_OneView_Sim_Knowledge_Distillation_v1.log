2024-05-02 12:24:20,255 [INFO] Step[50/1020]: training loss : 0.8371934640407562 TRAIN  loss dict:  {'mse_loss': 0.8371934640407562}
2024-05-02 12:25:51,652 [INFO] Step[100/1020]: training loss : 0.7404458749294281 TRAIN  loss dict:  {'mse_loss': 0.7404458749294281}
2024-05-02 12:27:19,667 [INFO] Step[150/1020]: training loss : 0.6498636901378632 TRAIN  loss dict:  {'mse_loss': 0.6498636901378632}
2024-05-02 12:28:55,955 [INFO] Step[200/1020]: training loss : 0.5826011312007904 TRAIN  loss dict:  {'mse_loss': 0.5826011312007904}
2024-05-02 12:30:20,796 [INFO] Step[250/1020]: training loss : 0.532302485704422 TRAIN  loss dict:  {'mse_loss': 0.532302485704422}
2024-05-02 12:31:35,190 [INFO] Step[300/1020]: training loss : 0.5146781021356582 TRAIN  loss dict:  {'mse_loss': 0.5146781021356582}
2024-05-02 12:32:51,106 [INFO] Step[350/1020]: training loss : 0.49598591923713686 TRAIN  loss dict:  {'mse_loss': 0.49598591923713686}
2024-05-02 12:34:06,553 [INFO] Step[400/1020]: training loss : 0.48796316266059875 TRAIN  loss dict:  {'mse_loss': 0.48796316266059875}
2024-05-02 12:35:23,294 [INFO] Step[450/1020]: training loss : 0.47670167744159697 TRAIN  loss dict:  {'mse_loss': 0.47670167744159697}
2024-05-02 12:36:37,373 [INFO] Step[500/1020]: training loss : 0.4751884365081787 TRAIN  loss dict:  {'mse_loss': 0.4751884365081787}
2024-05-02 12:37:58,098 [INFO] Step[550/1020]: training loss : 0.4640082883834839 TRAIN  loss dict:  {'mse_loss': 0.4640082883834839}
2024-05-02 12:39:13,847 [INFO] Step[600/1020]: training loss : 0.458048141002655 TRAIN  loss dict:  {'mse_loss': 0.458048141002655}
2024-05-02 12:40:08,429 [INFO] Step[650/1020]: training loss : 0.4585122406482697 TRAIN  loss dict:  {'mse_loss': 0.4585122406482697}
2024-05-02 12:41:19,211 [INFO] Step[700/1020]: training loss : 0.45922534763813017 TRAIN  loss dict:  {'mse_loss': 0.45922534763813017}
2024-05-02 12:42:24,318 [INFO] Step[750/1020]: training loss : 0.4505651366710663 TRAIN  loss dict:  {'mse_loss': 0.4505651366710663}
2024-05-02 12:43:42,446 [INFO] Step[800/1020]: training loss : 0.4533230555057526 TRAIN  loss dict:  {'mse_loss': 0.4533230555057526}
2024-05-02 12:45:05,467 [INFO] Step[850/1020]: training loss : 0.44702036917209625 TRAIN  loss dict:  {'mse_loss': 0.44702036917209625}
2024-05-02 12:46:18,837 [INFO] Step[900/1020]: training loss : 0.4471408975124359 TRAIN  loss dict:  {'mse_loss': 0.4471408975124359}
2024-05-02 12:47:33,090 [INFO] Step[950/1020]: training loss : 0.44447366774082187 TRAIN  loss dict:  {'mse_loss': 0.44447366774082187}
2024-05-02 12:48:44,886 [INFO] Step[1000/1020]: training loss : 0.4429942661523819 TRAIN  loss dict:  {'mse_loss': 0.4429942661523819}
2024-05-02 12:54:22,408 [INFO] Label accuracies statistics:
2024-05-02 12:54:22,410 [INFO] {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.25, 4: 0.3333333333333333, 5: 0.0, 6: 0.0, 7: 0.5, 8: 0.0, 9: 0.0, 10: 0.0, 11: 0.0, 12: 0.25, 13: 0.25, 14: 0.25, 15: 0.0, 16: 0.25, 17: 0.0, 18: 0.25, 19: 0.75, 20: 0.0, 21: 1.0, 22: 0.5, 23: 0.75, 24: 0.0, 25: 0.75, 26: 0.0, 27: 0.5, 28: 0.0, 29: 0.25, 30: 0.0, 31: 0.0, 32: 0.25, 33: 0.0, 34: 0.5, 35: 0.0, 36: 0.25, 37: 0.0, 38: 0.0, 39: 0.5, 40: 1.0, 41: 0.25, 42: 0.0, 43: 0.0, 44: 0.0, 45: 0.0, 46: 1.0, 47: 0.0, 48: 0.25, 49: 0.25, 50: 0.0, 51: 0.75, 52: 0.5, 53: 0.0, 54: 0.5, 55: 0.0, 56: 0.0, 57: 0.25, 58: 0.25, 59: 0.25, 60: 0.25, 61: 0.75, 62: 0.0, 63: 0.0, 64: 0.0, 65: 0.5, 66: 0.25, 67: 1.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.0, 72: 0.25, 73: 0.0, 74: 0.0, 75: 1.0, 76: 0.5, 77: 0.25, 78: 0.5, 79: 0.5, 80: 0.0, 81: 0.0, 82: 0.5, 83: 0.0, 84: 0.0, 85: 0.0, 86: 0.75, 87: 0.0, 88: 0.0, 89: 0.0, 90: 0.5, 91: 0.75, 92: 0.75, 93: 0.0, 94: 0.0, 95: 0.0, 96: 0.25, 97: 0.0, 98: 0.25, 99: 0.0, 100: 0.0, 101: 0.0, 102: 0.5, 103: 0.0, 104: 0.0, 105: 0.75, 106: 0.25, 107: 0.0, 108: 0.75, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.0, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.5, 118: 0.5, 119: 0.25, 120: 0.5, 121: 0.5, 122: 0.0, 123: 0.25, 124: 0.0, 125: 0.75, 126: 0.25, 127: 0.0, 128: 0.25, 129: 0.25, 130: 0.25, 131: 0.75, 132: 0.25, 133: 0.75, 134: 0.25, 135: 0.0, 136: 0.0, 137: 0.0, 138: 0.25, 139: 0.0, 140: 0.25, 141: 0.0, 142: 0.0, 143: 0.5, 144: 0.0, 145: 0.25, 146: 0.0, 147: 0.25, 148: 0.0, 149: 0.0, 150: 0.25, 151: 0.75, 152: 0.75, 153: 0.25, 154: 0.5, 155: 0.0, 156: 0.0, 157: 0.0, 158: 0.0, 159: 0.25, 160: 0.5, 161: 0.5, 162: 0.25, 163: 0.0, 164: 0.0, 165: 0.0, 166: 0.0, 167: 0.0, 168: 0.0, 169: 0.0, 170: 0.75, 171: 0.25, 172: 0.5, 173: 0.5, 174: 0.25, 175: 0.0, 176: 0.0, 177: 0.0, 178: 0.0, 179: 0.0, 180: 0.25, 181: 0.25, 182: 0.25, 183: 0.25, 184: 0.25, 185: 0.0, 186: 0.0, 187: 0.0, 188: 0.75, 189: 0.25, 190: 0.0, 191: 0.5, 192: 0.0, 193: 0.75, 194: 1.0, 195: 0.25, 196: 0.0, 197: 0.0, 198: 0.0}

2024-05-02 12:54:24,714 [INFO] [1] TRAIN  loss: 0.5145221195092389 acc: 0.0
2024-05-02 12:54:24,715 [INFO] [1] TRAIN  loss dict: {'mse_loss': 0.5145221195092389}
2024-05-02 12:54:24,716 [INFO] [1] VALIDATION loss: 4.136339504309375 VALIDATION  acc: 0.2222222222222222
2024-05-02 12:54:24,717 [INFO] [1] VALIDATION  loss dict: {'mse_loss': 0.43746622433566085, 'classification_loss': 3.698873277866479}
2024-05-02 12:54:24,718 [INFO] 
2024-05-02 12:56:40,656 [INFO] Step[50/1020]: training loss : 0.4390417069196701 TRAIN  loss dict:  {'mse_loss': 0.4390417069196701}
2024-05-02 12:57:52,853 [INFO] Step[100/1020]: training loss : 0.437041300535202 TRAIN  loss dict:  {'mse_loss': 0.437041300535202}
2024-05-02 12:59:12,492 [INFO] Step[150/1020]: training loss : 0.4371071028709412 TRAIN  loss dict:  {'mse_loss': 0.4371071028709412}
2024-05-02 13:00:24,982 [INFO] Step[200/1020]: training loss : 0.44013032615184783 TRAIN  loss dict:  {'mse_loss': 0.44013032615184783}
2024-05-02 13:01:39,588 [INFO] Step[250/1020]: training loss : 0.43222115337848666 TRAIN  loss dict:  {'mse_loss': 0.43222115337848666}
2024-05-02 13:02:56,014 [INFO] Step[300/1020]: training loss : 0.42988346934318544 TRAIN  loss dict:  {'mse_loss': 0.42988346934318544}
2024-05-02 13:04:02,585 [INFO] Step[350/1020]: training loss : 0.4242569267749786 TRAIN  loss dict:  {'mse_loss': 0.4242569267749786}
2024-05-02 13:05:22,221 [INFO] Step[400/1020]: training loss : 0.42794100880622865 TRAIN  loss dict:  {'mse_loss': 0.42794100880622865}
2024-05-02 13:06:45,229 [INFO] Step[450/1020]: training loss : 0.42455404162406923 TRAIN  loss dict:  {'mse_loss': 0.42455404162406923}
2024-05-02 13:07:51,919 [INFO] Step[500/1020]: training loss : 0.428911954164505 TRAIN  loss dict:  {'mse_loss': 0.428911954164505}
2024-05-02 13:08:56,478 [INFO] Step[550/1020]: training loss : 0.42439730823040006 TRAIN  loss dict:  {'mse_loss': 0.42439730823040006}
2024-05-02 13:10:13,044 [INFO] Step[600/1020]: training loss : 0.42195434749126437 TRAIN  loss dict:  {'mse_loss': 0.42195434749126437}
2024-05-02 13:11:26,563 [INFO] Step[650/1020]: training loss : 0.42555791676044463 TRAIN  loss dict:  {'mse_loss': 0.42555791676044463}
2024-05-02 13:12:40,064 [INFO] Step[700/1020]: training loss : 0.4222925299406052 TRAIN  loss dict:  {'mse_loss': 0.4222925299406052}
2024-05-02 13:14:00,998 [INFO] Step[750/1020]: training loss : 0.4228812336921692 TRAIN  loss dict:  {'mse_loss': 0.4228812336921692}
2024-05-02 13:15:15,010 [INFO] Step[800/1020]: training loss : 0.42309709191322326 TRAIN  loss dict:  {'mse_loss': 0.42309709191322326}
2024-05-02 13:16:34,868 [INFO] Step[850/1020]: training loss : 0.41868385672569275 TRAIN  loss dict:  {'mse_loss': 0.41868385672569275}
2024-05-02 13:17:54,231 [INFO] Step[900/1020]: training loss : 0.420605702996254 TRAIN  loss dict:  {'mse_loss': 0.420605702996254}
2024-05-02 13:19:10,901 [INFO] Step[950/1020]: training loss : 0.41907293140888213 TRAIN  loss dict:  {'mse_loss': 0.41907293140888213}
2024-05-02 13:20:03,156 [INFO] Step[1000/1020]: training loss : 0.4184016746282577 TRAIN  loss dict:  {'mse_loss': 0.4184016746282577}
2024-05-02 13:26:06,092 [INFO] Label accuracies statistics:
2024-05-02 13:26:06,117 [INFO] {0: 0.5, 1: 0.5, 2: 0.25, 3: 0.25, 4: 0.3333333333333333, 5: 0.25, 6: 0.0, 7: 0.5, 8: 0.0, 9: 0.5, 10: 0.25, 11: 0.25, 12: 0.25, 13: 0.0, 14: 0.5, 15: 0.5, 16: 0.25, 17: 0.25, 18: 0.25, 19: 0.25, 20: 0.0, 21: 0.5, 22: 0.25, 23: 0.75, 24: 0.0, 25: 0.25, 26: 0.0, 27: 0.75, 28: 0.0, 29: 0.0, 30: 0.0, 31: 0.0, 32: 0.5, 33: 0.5, 34: 0.75, 35: 0.0, 36: 0.25, 37: 0.0, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.5, 42: 0.5, 43: 0.0, 44: 0.5, 45: 0.5, 46: 0.75, 47: 0.25, 48: 0.75, 49: 0.25, 50: 0.5, 51: 0.75, 52: 0.0, 53: 0.0, 54: 0.0, 55: 0.5, 56: 0.0, 57: 0.25, 58: 0.5, 59: 0.25, 60: 0.0, 61: 0.75, 62: 0.0, 63: 0.0, 64: 0.5, 65: 0.75, 66: 0.0, 67: 1.0, 68: 0.0, 69: 0.0, 70: 0.0, 71: 0.75, 72: 0.0, 73: 0.25, 74: 0.25, 75: 1.0, 76: 1.0, 77: 0.25, 78: 0.75, 79: 0.5, 80: 0.75, 81: 0.25, 82: 0.0, 83: 0.0, 84: 0.5, 85: 1.0, 86: 0.0, 87: 0.0, 88: 0.6666666666666666, 89: 0.0, 90: 0.5, 91: 0.75, 92: 0.25, 93: 0.25, 94: 0.0, 95: 0.5, 96: 0.0, 97: 0.0, 98: 0.5, 99: 0.0, 100: 0.0, 101: 0.25, 102: 0.5, 103: 0.0, 104: 0.0, 105: 0.5, 106: 0.5, 107: 0.0, 108: 1.0, 109: 0.0, 110: 0.0, 111: 0.0, 112: 0.0, 113: 0.25, 114: 0.0, 115: 0.0, 116: 0.0, 117: 0.5, 118: 0.75, 119: 0.25, 120: 0.5, 121: 0.25, 122: 0.25, 123: 0.25, 124: 0.0, 125: 0.75, 126: 0.0, 127: 0.5, 128: 0.5, 129: 0.25, 130: 0.5, 131: 0.0, 132: 0.5, 133: 0.25, 134: 0.75, 135: 0.5, 136: 0.75, 137: 0.75, 138: 0.25, 139: 0.5, 140: 0.25, 141: 0.5, 142: 0.0, 143: 0.25, 144: 0.25, 145: 0.25, 146: 0.25, 147: 0.0, 148: 0.0, 149: 0.5, 150: 0.25, 151: 0.75, 152: 0.75, 153: 0.25, 154: 0.5, 155: 0.0, 156: 0.0, 157: 0.5, 158: 0.5, 159: 0.25, 160: 0.0, 161: 1.0, 162: 0.0, 163: 0.0, 164: 0.5, 165: 0.5, 166: 0.25, 167: 0.0, 168: 0.0, 169: 0.25, 170: 1.0, 171: 0.25, 172: 0.5, 173: 0.75, 174: 0.5, 175: 0.25, 176: 0.0, 177: 0.5, 178: 0.25, 179: 0.5, 180: 0.75, 181: 0.5, 182: 0.75, 183: 0.0, 184: 0.75, 185: 0.0, 186: 0.0, 187: 0.25, 188: 1.0, 189: 0.5, 190: 0.5, 191: 0.5, 192: 0.0, 193: 0.75, 194: 1.0, 195: 0.5, 196: 0.0, 197: 0.25, 198: 0.0}

2024-05-02 13:26:12,266 [INFO] [2] TRAIN  loss: 0.42673868104523305 acc: 0.0
2024-05-02 13:26:12,266 [INFO] [2] TRAIN  loss dict: {'mse_loss': 0.42673868104523305}
2024-05-02 13:26:12,267 [INFO] [2] VALIDATION loss: 3.49653480510519 VALIDATION  acc: 0.3333333333333333
2024-05-02 13:26:12,267 [INFO] [2] VALIDATION  loss dict: {'mse_loss': 0.40952789151307306, 'classification_loss': 3.0870069072704123}
2024-05-02 13:26:12,267 [INFO] 
2024-05-02 13:27:52,398 [INFO] Step[50/1020]: training loss : 0.41151866257190706 TRAIN  loss dict:  {'mse_loss': 0.41151866257190706}
2024-05-02 13:29:01,563 [INFO] Step[100/1020]: training loss : 0.40934676349163057 TRAIN  loss dict:  {'mse_loss': 0.40934676349163057}
2024-05-02 13:30:18,626 [INFO] Step[150/1020]: training loss : 0.40901569664478304 TRAIN  loss dict:  {'mse_loss': 0.40901569664478304}
2024-05-02 13:31:20,855 [INFO] Step[200/1020]: training loss : 0.4084349399805069 TRAIN  loss dict:  {'mse_loss': 0.4084349399805069}
2024-05-02 13:32:29,276 [INFO] Step[250/1020]: training loss : 0.41356760144233706 TRAIN  loss dict:  {'mse_loss': 0.41356760144233706}
2024-05-02 13:33:57,897 [INFO] Step[300/1020]: training loss : 0.4090973174571991 TRAIN  loss dict:  {'mse_loss': 0.4090973174571991}
2024-05-02 13:35:15,301 [INFO] Step[350/1020]: training loss : 0.40704634428024294 TRAIN  loss dict:  {'mse_loss': 0.40704634428024294}
2024-05-02 13:36:28,505 [INFO] Step[400/1020]: training loss : 0.4036233150959015 TRAIN  loss dict:  {'mse_loss': 0.4036233150959015}
2024-05-02 13:37:53,373 [INFO] Step[450/1020]: training loss : 0.4079683965444565 TRAIN  loss dict:  {'mse_loss': 0.4079683965444565}
2024-05-02 13:39:13,919 [INFO] Step[500/1020]: training loss : 0.40245543539524076 TRAIN  loss dict:  {'mse_loss': 0.40245543539524076}
2024-05-02 13:40:41,372 [INFO] Step[550/1020]: training loss : 0.4056432110071182 TRAIN  loss dict:  {'mse_loss': 0.4056432110071182}
2024-05-02 13:41:54,941 [INFO] Step[600/1020]: training loss : 0.407802060842514 TRAIN  loss dict:  {'mse_loss': 0.407802060842514}
2024-05-02 13:43:15,850 [INFO] Step[650/1020]: training loss : 0.3992712128162384 TRAIN  loss dict:  {'mse_loss': 0.3992712128162384}
2024-05-02 13:44:20,360 [INFO] Step[700/1020]: training loss : 0.40269248068332675 TRAIN  loss dict:  {'mse_loss': 0.40269248068332675}
2024-05-02 13:45:29,177 [INFO] Step[750/1020]: training loss : 0.40313454389572145 TRAIN  loss dict:  {'mse_loss': 0.40313454389572145}
2024-05-02 13:46:30,963 [INFO] Step[800/1020]: training loss : 0.4026899266242981 TRAIN  loss dict:  {'mse_loss': 0.4026899266242981}
2024-05-02 13:47:39,356 [INFO] Step[850/1020]: training loss : 0.3993877983093262 TRAIN  loss dict:  {'mse_loss': 0.3993877983093262}
2024-05-02 13:48:48,445 [INFO] Step[900/1020]: training loss : 0.39848999977111815 TRAIN  loss dict:  {'mse_loss': 0.39848999977111815}
2024-05-02 13:50:07,851 [INFO] Step[950/1020]: training loss : 0.3984015029668808 TRAIN  loss dict:  {'mse_loss': 0.3984015029668808}
2024-05-02 13:51:17,505 [INFO] Step[1000/1020]: training loss : 0.3930775910615921 TRAIN  loss dict:  {'mse_loss': 0.3930775910615921}
2024-05-02 13:56:24,783 [INFO] Label accuracies statistics:
2024-05-02 13:56:24,784 [INFO] {0: 0.5, 1: 0.5, 2: 0.0, 3: 0.75, 4: 0.3333333333333333, 5: 0.0, 6: 0.0, 7: 0.75, 8: 0.0, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.25, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.25, 22: 0.25, 23: 0.75, 24: 0.0, 25: 0.75, 26: 0.25, 27: 0.75, 28: 0.0, 29: 0.5, 30: 0.0, 31: 0.0, 32: 0.5, 33: 0.75, 34: 0.5, 35: 0.25, 36: 0.5, 37: 0.0, 38: 0.25, 39: 0.75, 40: 1.0, 41: 0.5, 42: 0.5, 43: 0.25, 44: 0.25, 45: 0.75, 46: 0.25, 47: 0.5, 48: 0.0, 49: 0.25, 50: 0.5, 51: 0.75, 52: 0.25, 53: 0.0, 54: 0.0, 55: 0.25, 56: 0.0, 57: 0.25, 58: 0.5, 59: 0.25, 60: 0.0, 61: 0.75, 62: 0.25, 63: 0.0, 64: 0.25, 65: 0.25, 66: 0.0, 67: 0.75, 68: 0.25, 69: 0.0, 70: 0.0, 71: 0.25, 72: 0.75, 73: 0.25, 74: 0.0, 75: 1.0, 76: 0.75, 77: 0.0, 78: 0.5, 79: 0.5, 80: 0.75, 81: 0.25, 82: 0.0, 83: 0.25, 84: 0.5, 85: 1.0, 86: 0.0, 87: 0.0, 88: 0.3333333333333333, 89: 0.0, 90: 1.0, 91: 1.0, 92: 0.5, 93: 0.5, 94: 0.25, 95: 0.75, 96: 0.5, 97: 0.0, 98: 0.0, 99: 0.25, 100: 0.0, 101: 0.75, 102: 0.25, 103: 0.0, 104: 0.25, 105: 0.5, 106: 0.75, 107: 0.25, 108: 0.5, 109: 0.25, 110: 0.25, 111: 0.5, 112: 0.25, 113: 0.0, 114: 0.5, 115: 0.25, 116: 0.75, 117: 0.75, 118: 0.75, 119: 0.75, 120: 0.0, 121: 0.5, 122: 0.25, 123: 0.5, 124: 0.75, 125: 0.75, 126: 0.5, 127: 0.0, 128: 0.75, 129: 0.0, 130: 0.5, 131: 0.5, 132: 0.75, 133: 0.75, 134: 1.0, 135: 0.5, 136: 0.75, 137: 1.0, 138: 0.25, 139: 1.0, 140: 0.25, 141: 0.25, 142: 0.25, 143: 0.5, 144: 0.0, 145: 0.0, 146: 0.0, 147: 0.0, 148: 0.0, 149: 0.5, 150: 0.25, 151: 0.75, 152: 0.5, 153: 0.0, 154: 0.75, 155: 0.0, 156: 0.25, 157: 0.25, 158: 0.5, 159: 0.5, 160: 0.0, 161: 1.0, 162: 0.5, 163: 0.25, 164: 0.25, 165: 0.75, 166: 0.25, 167: 0.0, 168: 0.0, 169: 0.5, 170: 0.75, 171: 0.25, 172: 0.5, 173: 0.5, 174: 0.25, 175: 0.25, 176: 0.0, 177: 0.25, 178: 0.0, 179: 0.5, 180: 0.75, 181: 0.5, 182: 0.75, 183: 0.5, 184: 0.0, 185: 0.0, 186: 0.0, 187: 0.5, 188: 1.0, 189: 0.75, 190: 0.0, 191: 0.5, 192: 0.25, 193: 0.75, 194: 1.0, 195: 0.5, 196: 0.0, 197: 0.0, 198: 0.25}

2024-05-02 13:56:31,039 [INFO] [3] TRAIN  loss: 0.40444002668647205 acc: 0.0
2024-05-02 13:56:31,042 [INFO] [3] TRAIN  loss dict: {'mse_loss': 0.40444002668647205}
2024-05-02 13:56:31,045 [INFO] [3] VALIDATION loss: 3.087684727678395 VALIDATION  acc: 0.3888888888888889
2024-05-02 13:56:31,046 [INFO] [3] VALIDATION  loss dict: {'mse_loss': 0.39228794038897813, 'classification_loss': 2.6953967869883835}
2024-05-02 13:56:31,049 [INFO] 
2024-05-02 13:58:34,843 [INFO] Step[50/1020]: training loss : 0.3932155454158783 TRAIN  loss dict:  {'mse_loss': 0.3932155454158783}
2024-05-02 13:59:42,243 [INFO] Step[100/1020]: training loss : 0.39025563359260557 TRAIN  loss dict:  {'mse_loss': 0.39025563359260557}
2024-05-02 14:00:54,381 [INFO] Step[150/1020]: training loss : 0.3972929447889328 TRAIN  loss dict:  {'mse_loss': 0.3972929447889328}
2024-05-02 14:01:56,237 [INFO] Step[200/1020]: training loss : 0.39699657082557677 TRAIN  loss dict:  {'mse_loss': 0.39699657082557677}
2024-05-02 14:03:08,733 [INFO] Step[250/1020]: training loss : 0.39146393120288847 TRAIN  loss dict:  {'mse_loss': 0.39146393120288847}
2024-05-02 14:04:10,845 [INFO] Step[300/1020]: training loss : 0.38922072649002076 TRAIN  loss dict:  {'mse_loss': 0.38922072649002076}
2024-05-02 14:05:14,850 [INFO] Step[350/1020]: training loss : 0.38680159449577334 TRAIN  loss dict:  {'mse_loss': 0.38680159449577334}
2024-05-02 14:06:17,922 [INFO] Step[400/1020]: training loss : 0.3927356058359146 TRAIN  loss dict:  {'mse_loss': 0.3927356058359146}
2024-05-02 14:07:12,911 [INFO] Step[450/1020]: training loss : 0.3864263164997101 TRAIN  loss dict:  {'mse_loss': 0.3864263164997101}
2024-05-02 14:08:15,194 [INFO] Step[500/1020]: training loss : 0.39078314542770387 TRAIN  loss dict:  {'mse_loss': 0.39078314542770387}
2024-05-02 14:09:31,247 [INFO] Step[550/1020]: training loss : 0.38360141336917875 TRAIN  loss dict:  {'mse_loss': 0.38360141336917875}
2024-05-02 14:10:49,942 [INFO] Step[600/1020]: training loss : 0.393374570608139 TRAIN  loss dict:  {'mse_loss': 0.393374570608139}
2024-05-02 14:12:10,876 [INFO] Step[650/1020]: training loss : 0.3861852872371674 TRAIN  loss dict:  {'mse_loss': 0.3861852872371674}
2024-05-02 14:13:35,098 [INFO] Step[700/1020]: training loss : 0.3857309234142303 TRAIN  loss dict:  {'mse_loss': 0.3857309234142303}
2024-05-02 14:14:51,143 [INFO] Step[750/1020]: training loss : 0.3862874734401703 TRAIN  loss dict:  {'mse_loss': 0.3862874734401703}
2024-05-02 14:15:54,791 [INFO] Step[800/1020]: training loss : 0.38589091181755064 TRAIN  loss dict:  {'mse_loss': 0.38589091181755064}
2024-05-02 14:17:02,192 [INFO] Step[850/1020]: training loss : 0.38215222299098967 TRAIN  loss dict:  {'mse_loss': 0.38215222299098967}
2024-05-02 14:18:15,106 [INFO] Step[900/1020]: training loss : 0.38460916638374326 TRAIN  loss dict:  {'mse_loss': 0.38460916638374326}
2024-05-02 14:19:32,088 [INFO] Step[950/1020]: training loss : 0.37989697337150574 TRAIN  loss dict:  {'mse_loss': 0.37989697337150574}
2024-05-02 14:20:39,602 [INFO] Step[1000/1020]: training loss : 0.38514464676380156 TRAIN  loss dict:  {'mse_loss': 0.38514464676380156}
2024-05-02 14:26:00,247 [INFO] Label accuracies statistics:
2024-05-02 14:26:00,250 [INFO] {0: 0.5, 1: 0.75, 2: 0.25, 3: 0.25, 4: 0.6666666666666666, 5: 0.25, 6: 0.0, 7: 1.0, 8: 0.0, 9: 0.25, 10: 0.25, 11: 0.5, 12: 0.5, 13: 0.25, 14: 0.5, 15: 0.25, 16: 0.25, 17: 0.25, 18: 0.5, 19: 0.5, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.5, 24: 0.0, 25: 0.5, 26: 0.0, 27: 0.5, 28: 0.25, 29: 0.75, 30: 0.75, 31: 0.25, 32: 0.5, 33: 1.0, 34: 0.5, 35: 0.25, 36: 0.25, 37: 0.0, 38: 0.0, 39: 0.75, 40: 1.0, 41: 0.5, 42: 0.5, 43: 0.25, 44: 0.75, 45: 0.75, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.25, 50: 0.75, 51: 0.5, 52: 0.25, 53: 0.0, 54: 0.25, 55: 0.5, 56: 0.0, 57: 0.75, 58: 0.5, 59: 0.25, 60: 0.0, 61: 0.75, 62: 1.0, 63: 0.5, 64: 0.5, 65: 0.75, 66: 0.25, 67: 0.75, 68: 0.25, 69: 0.0, 70: 0.25, 71: 0.5, 72: 1.0, 73: 0.25, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.25, 78: 0.5, 79: 0.5, 80: 0.5, 81: 0.25, 82: 0.0, 83: 0.25, 84: 0.5, 85: 1.0, 86: 0.25, 87: 0.0, 88: 0.6666666666666666, 89: 0.5, 90: 1.0, 91: 1.0, 92: 0.75, 93: 0.5, 94: 0.0, 95: 0.75, 96: 0.5, 97: 0.0, 98: 0.5, 99: 0.25, 100: 0.25, 101: 1.0, 102: 0.75, 103: 0.0, 104: 0.5, 105: 0.25, 106: 1.0, 107: 0.5, 108: 0.5, 109: 0.0, 110: 0.25, 111: 0.25, 112: 0.0, 113: 0.25, 114: 0.5, 115: 0.0, 116: 0.5, 117: 0.75, 118: 0.75, 119: 0.25, 120: 0.25, 121: 0.75, 122: 0.0, 123: 0.0, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.25, 128: 0.75, 129: 0.25, 130: 0.75, 131: 0.5, 132: 0.25, 133: 0.75, 134: 0.75, 135: 0.5, 136: 1.0, 137: 0.75, 138: 0.25, 139: 0.75, 140: 0.25, 141: 0.5, 142: 0.5, 143: 0.75, 144: 0.25, 145: 0.0, 146: 0.5, 147: 0.25, 148: 0.0, 149: 0.5, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.5, 154: 0.5, 155: 0.0, 156: 0.5, 157: 0.5, 158: 0.25, 159: 0.5, 160: 0.0, 161: 1.0, 162: 0.75, 163: 0.25, 164: 0.25, 165: 0.5, 166: 0.25, 167: 0.0, 168: 0.25, 169: 0.25, 170: 1.0, 171: 0.25, 172: 0.5, 173: 0.5, 174: 0.25, 175: 0.25, 176: 0.0, 177: 0.75, 178: 0.5, 179: 0.5, 180: 0.75, 181: 0.5, 182: 1.0, 183: 0.5, 184: 0.75, 185: 0.5, 186: 0.0, 187: 0.5, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.25, 192: 0.75, 193: 0.5, 194: 1.0, 195: 0.0, 196: 0.0, 197: 0.25, 198: 0.0}

2024-05-02 14:26:06,165 [INFO] [4] TRAIN  loss: 0.3884162144333709 acc: 0.0
2024-05-02 14:26:06,167 [INFO] [4] TRAIN  loss dict: {'mse_loss': 0.3884162144333709}
2024-05-02 14:26:06,257 [INFO] [4] VALIDATION loss: 2.7732850680447587 VALIDATION  acc: 0.45580808080808083
2024-05-02 14:26:06,257 [INFO] [4] VALIDATION  loss dict: {'mse_loss': 0.3768035337479428, 'classification_loss': 2.39648152662046}
2024-05-02 14:26:06,259 [INFO] 
2024-05-02 14:28:02,252 [INFO] Step[50/1020]: training loss : 0.37657699823379515 TRAIN  loss dict:  {'mse_loss': 0.37657699823379515}
2024-05-02 14:29:05,990 [INFO] Step[100/1020]: training loss : 0.3860598689317703 TRAIN  loss dict:  {'mse_loss': 0.3860598689317703}
2024-05-02 14:30:08,181 [INFO] Step[150/1020]: training loss : 0.37512108743190764 TRAIN  loss dict:  {'mse_loss': 0.37512108743190764}
2024-05-02 14:31:11,225 [INFO] Step[200/1020]: training loss : 0.3803097772598267 TRAIN  loss dict:  {'mse_loss': 0.3803097772598267}
2024-05-02 14:32:09,388 [INFO] Step[250/1020]: training loss : 0.37565890729427337 TRAIN  loss dict:  {'mse_loss': 0.37565890729427337}
2024-05-02 14:33:10,880 [INFO] Step[300/1020]: training loss : 0.3738799148797989 TRAIN  loss dict:  {'mse_loss': 0.3738799148797989}
2024-05-02 14:34:11,571 [INFO] Step[350/1020]: training loss : 0.37981746435165403 TRAIN  loss dict:  {'mse_loss': 0.37981746435165403}
2024-05-02 14:35:17,166 [INFO] Step[400/1020]: training loss : 0.37508632957935334 TRAIN  loss dict:  {'mse_loss': 0.37508632957935334}
2024-05-02 14:36:16,991 [INFO] Step[450/1020]: training loss : 0.3758904719352722 TRAIN  loss dict:  {'mse_loss': 0.3758904719352722}
2024-05-02 14:37:21,456 [INFO] Step[500/1020]: training loss : 0.3796158927679062 TRAIN  loss dict:  {'mse_loss': 0.3796158927679062}
2024-05-02 14:38:23,544 [INFO] Step[550/1020]: training loss : 0.37700419723987577 TRAIN  loss dict:  {'mse_loss': 0.37700419723987577}
2024-05-02 14:39:25,624 [INFO] Step[600/1020]: training loss : 0.38015884160995483 TRAIN  loss dict:  {'mse_loss': 0.38015884160995483}
2024-05-02 14:40:31,345 [INFO] Step[650/1020]: training loss : 0.3739016342163086 TRAIN  loss dict:  {'mse_loss': 0.3739016342163086}
2024-05-02 14:41:33,132 [INFO] Step[700/1020]: training loss : 0.3750733345746994 TRAIN  loss dict:  {'mse_loss': 0.3750733345746994}
2024-05-02 14:42:34,794 [INFO] Step[750/1020]: training loss : 0.36873997151851656 TRAIN  loss dict:  {'mse_loss': 0.36873997151851656}
2024-05-02 14:43:35,892 [INFO] Step[800/1020]: training loss : 0.3690351241827011 TRAIN  loss dict:  {'mse_loss': 0.3690351241827011}
2024-05-02 14:44:40,084 [INFO] Step[850/1020]: training loss : 0.3722242450714111 TRAIN  loss dict:  {'mse_loss': 0.3722242450714111}
2024-05-02 14:45:44,836 [INFO] Step[900/1020]: training loss : 0.36845117807388306 TRAIN  loss dict:  {'mse_loss': 0.36845117807388306}
2024-05-02 14:46:46,567 [INFO] Step[950/1020]: training loss : 0.3740548074245453 TRAIN  loss dict:  {'mse_loss': 0.3740548074245453}
2024-05-02 14:47:51,783 [INFO] Step[1000/1020]: training loss : 0.37105961084365846 TRAIN  loss dict:  {'mse_loss': 0.37105961084365846}
2024-05-02 14:53:11,674 [INFO] Label accuracies statistics:
2024-05-02 14:53:11,683 [INFO] {0: 0.5, 1: 0.75, 2: 0.25, 3: 0.75, 4: 0.6666666666666666, 5: 0.25, 6: 0.0, 7: 1.0, 8: 0.0, 9: 0.75, 10: 0.75, 11: 0.5, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.5, 16: 0.25, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.25, 22: 0.25, 23: 0.75, 24: 0.5, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.25, 29: 0.75, 30: 0.75, 31: 0.5, 32: 0.25, 33: 0.75, 34: 0.5, 35: 0.5, 36: 0.25, 37: 0.0, 38: 0.0, 39: 0.75, 40: 1.0, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.75, 45: 1.0, 46: 0.75, 47: 0.75, 48: 0.75, 49: 0.25, 50: 0.75, 51: 0.5, 52: 0.0, 53: 0.25, 54: 0.25, 55: 0.5, 56: 0.25, 57: 0.5, 58: 0.5, 59: 0.5, 60: 0.25, 61: 0.75, 62: 0.75, 63: 0.5, 64: 0.5, 65: 1.0, 66: 0.5, 67: 1.0, 68: 0.5, 69: 0.0, 70: 0.5, 71: 0.25, 72: 0.5, 73: 0.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.25, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.0, 83: 0.25, 84: 0.5, 85: 1.0, 86: 0.25, 87: 0.5, 88: 0.6666666666666666, 89: 0.5, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.5, 97: 0.0, 98: 0.0, 99: 1.0, 100: 0.25, 101: 0.75, 102: 0.75, 103: 0.25, 104: 0.5, 105: 0.5, 106: 0.75, 107: 0.25, 108: 0.5, 109: 0.5, 110: 0.5, 111: 0.5, 112: 0.0, 113: 0.0, 114: 0.75, 115: 0.5, 116: 0.5, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.5, 121: 1.0, 122: 0.25, 123: 0.5, 124: 1.0, 125: 0.75, 126: 0.75, 127: 0.25, 128: 1.0, 129: 0.5, 130: 0.75, 131: 0.5, 132: 0.5, 133: 0.75, 134: 1.0, 135: 0.75, 136: 0.75, 137: 0.25, 138: 0.5, 139: 0.5, 140: 0.5, 141: 0.75, 142: 0.0, 143: 0.5, 144: 0.25, 145: 0.0, 146: 0.5, 147: 0.0, 148: 0.0, 149: 1.0, 150: 0.25, 151: 0.5, 152: 0.5, 153: 0.5, 154: 0.25, 155: 0.0, 156: 0.75, 157: 0.5, 158: 0.0, 159: 0.5, 160: 0.0, 161: 1.0, 162: 0.25, 163: 0.25, 164: 0.75, 165: 0.75, 166: 0.25, 167: 0.0, 168: 0.5, 169: 0.25, 170: 1.0, 171: 0.0, 172: 0.5, 173: 0.75, 174: 0.25, 175: 0.25, 176: 0.0, 177: 0.25, 178: 0.5, 179: 0.75, 180: 1.0, 181: 0.5, 182: 0.75, 183: 0.75, 184: 0.25, 185: 0.75, 186: 0.25, 187: 0.5, 188: 0.75, 189: 0.75, 190: 0.25, 191: 0.5, 192: 0.25, 193: 1.0, 194: 1.0, 195: 0.5, 196: 0.25, 197: 0.75, 198: 0.25}

2024-05-02 14:53:16,576 [INFO] [5] TRAIN  loss: 0.37533915504521015 acc: 0.0
2024-05-02 14:53:16,576 [INFO] [5] TRAIN  loss dict: {'mse_loss': 0.37533915504521015}
2024-05-02 14:53:16,577 [INFO] [5] VALIDATION loss: 2.511546911615314 VALIDATION  acc: 0.5151515151515151
2024-05-02 14:53:16,577 [INFO] [5] VALIDATION  loss dict: {'mse_loss': 0.3656736932920687, 'classification_loss': 2.1458732118510238}
2024-05-02 14:53:16,577 [INFO] 
2024-05-02 14:55:34,206 [INFO] Step[50/1020]: training loss : 0.3628369730710983 TRAIN  loss dict:  {'mse_loss': 0.3628369730710983}
2024-05-02 14:56:52,997 [INFO] Step[100/1020]: training loss : 0.3629743218421936 TRAIN  loss dict:  {'mse_loss': 0.3629743218421936}
2024-05-02 14:58:04,992 [INFO] Step[150/1020]: training loss : 0.36665345907211305 TRAIN  loss dict:  {'mse_loss': 0.36665345907211305}
2024-05-02 14:59:06,047 [INFO] Step[200/1020]: training loss : 0.36575100243091585 TRAIN  loss dict:  {'mse_loss': 0.36575100243091585}
2024-05-02 15:00:12,151 [INFO] Step[250/1020]: training loss : 0.3650557005405426 TRAIN  loss dict:  {'mse_loss': 0.3650557005405426}
2024-05-02 15:01:08,551 [INFO] Step[300/1020]: training loss : 0.3612960249185562 TRAIN  loss dict:  {'mse_loss': 0.3612960249185562}
2024-05-02 15:02:24,831 [INFO] Step[350/1020]: training loss : 0.36758202373981474 TRAIN  loss dict:  {'mse_loss': 0.36758202373981474}
2024-05-02 15:03:35,269 [INFO] Step[400/1020]: training loss : 0.3666196709871292 TRAIN  loss dict:  {'mse_loss': 0.3666196709871292}
2024-05-02 15:04:44,079 [INFO] Step[450/1020]: training loss : 0.3604975211620331 TRAIN  loss dict:  {'mse_loss': 0.3604975211620331}
2024-05-02 15:05:54,428 [INFO] Step[500/1020]: training loss : 0.36145848214626314 TRAIN  loss dict:  {'mse_loss': 0.36145848214626314}
2024-05-02 15:06:57,576 [INFO] Step[550/1020]: training loss : 0.36201523065567015 TRAIN  loss dict:  {'mse_loss': 0.36201523065567015}
2024-05-02 15:08:07,850 [INFO] Step[600/1020]: training loss : 0.3596536457538605 TRAIN  loss dict:  {'mse_loss': 0.3596536457538605}
2024-05-02 15:09:13,058 [INFO] Step[650/1020]: training loss : 0.3620510643720627 TRAIN  loss dict:  {'mse_loss': 0.3620510643720627}
2024-05-02 15:10:22,418 [INFO] Step[700/1020]: training loss : 0.35740824103355406 TRAIN  loss dict:  {'mse_loss': 0.35740824103355406}
2024-05-02 15:11:33,598 [INFO] Step[750/1020]: training loss : 0.36079662084579467 TRAIN  loss dict:  {'mse_loss': 0.36079662084579467}
2024-05-02 15:12:37,459 [INFO] Step[800/1020]: training loss : 0.366051225066185 TRAIN  loss dict:  {'mse_loss': 0.366051225066185}
2024-05-02 15:13:50,093 [INFO] Step[850/1020]: training loss : 0.3585622411966324 TRAIN  loss dict:  {'mse_loss': 0.3585622411966324}
2024-05-02 15:14:57,803 [INFO] Step[900/1020]: training loss : 0.3642300999164581 TRAIN  loss dict:  {'mse_loss': 0.3642300999164581}
2024-05-02 15:16:04,795 [INFO] Step[950/1020]: training loss : 0.35673565685749054 TRAIN  loss dict:  {'mse_loss': 0.35673565685749054}
2024-05-02 15:17:13,909 [INFO] Step[1000/1020]: training loss : 0.3570000946521759 TRAIN  loss dict:  {'mse_loss': 0.3570000946521759}
2024-05-02 15:22:26,904 [INFO] Label accuracies statistics:
2024-05-02 15:22:26,906 [INFO] {0: 0.5, 1: 0.75, 2: 0.0, 3: 0.5, 4: 0.6666666666666666, 5: 0.25, 6: 0.0, 7: 0.75, 8: 0.0, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.5, 16: 0.5, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.25, 22: 1.0, 23: 0.5, 24: 0.25, 25: 0.75, 26: 0.5, 27: 0.5, 28: 0.5, 29: 0.25, 30: 0.75, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.5, 37: 0.0, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 0.5, 49: 0.75, 50: 0.5, 51: 0.5, 52: 0.25, 53: 0.25, 54: 0.25, 55: 0.75, 56: 0.25, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.0, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.25, 67: 1.0, 68: 0.5, 69: 0.0, 70: 0.5, 71: 0.5, 72: 1.0, 73: 0.25, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.0, 78: 0.75, 79: 0.5, 80: 0.75, 81: 0.5, 82: 0.0, 83: 0.25, 84: 0.25, 85: 1.0, 86: 0.0, 87: 0.0, 88: 0.3333333333333333, 89: 0.5, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.5, 94: 0.25, 95: 0.75, 96: 0.75, 97: 0.0, 98: 0.5, 99: 0.75, 100: 0.25, 101: 1.0, 102: 0.75, 103: 0.0, 104: 0.75, 105: 0.5, 106: 1.0, 107: 0.5, 108: 0.5, 109: 0.25, 110: 0.5, 111: 1.0, 112: 0.0, 113: 0.25, 114: 0.75, 115: 0.75, 116: 0.5, 117: 0.75, 118: 0.75, 119: 0.5, 120: 0.25, 121: 0.0, 122: 0.5, 123: 0.25, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.5, 128: 0.75, 129: 0.0, 130: 0.5, 131: 0.75, 132: 0.25, 133: 0.5, 134: 0.75, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.25, 139: 0.75, 140: 0.25, 141: 0.25, 142: 0.25, 143: 0.5, 144: 0.25, 145: 0.25, 146: 0.5, 147: 0.5, 148: 0.0, 149: 1.0, 150: 0.25, 151: 0.5, 152: 1.0, 153: 0.25, 154: 0.5, 155: 0.0, 156: 0.75, 157: 0.5, 158: 0.5, 159: 0.5, 160: 0.25, 161: 1.0, 162: 0.0, 163: 0.25, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.0, 168: 0.25, 169: 0.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.5, 175: 0.75, 176: 0.0, 177: 0.75, 178: 0.5, 179: 0.5, 180: 1.0, 181: 0.75, 182: 0.75, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.0, 187: 0.5, 188: 1.0, 189: 0.5, 190: 0.5, 191: 0.5, 192: 0.5, 193: 0.5, 194: 1.0, 195: 0.25, 196: 0.25, 197: 0.75, 198: 0.25}

2024-05-02 15:22:33,404 [INFO] [6] TRAIN  loss: 0.3621739452083906 acc: 0.0
2024-05-02 15:22:33,405 [INFO] [6] TRAIN  loss dict: {'mse_loss': 0.3621739452083906}
2024-05-02 15:22:33,405 [INFO] [6] VALIDATION loss: 2.3702710577935884 VALIDATION  acc: 0.5277777777777778
2024-05-02 15:22:33,405 [INFO] [6] VALIDATION  loss dict: {'mse_loss': 0.3565498387271708, 'classification_loss': 2.0137212219262364}
2024-05-02 15:22:33,405 [INFO] 
2024-05-02 15:24:40,013 [INFO] Step[50/1020]: training loss : 0.35937544345855715 TRAIN  loss dict:  {'mse_loss': 0.35937544345855715}
2024-05-02 15:25:45,325 [INFO] Step[100/1020]: training loss : 0.355957093834877 TRAIN  loss dict:  {'mse_loss': 0.355957093834877}
2024-05-02 15:27:00,543 [INFO] Step[150/1020]: training loss : 0.35193180620670317 TRAIN  loss dict:  {'mse_loss': 0.35193180620670317}
2024-05-02 15:28:05,192 [INFO] Step[200/1020]: training loss : 0.34840339064598086 TRAIN  loss dict:  {'mse_loss': 0.34840339064598086}
2024-05-02 15:29:17,104 [INFO] Step[250/1020]: training loss : 0.3523536229133606 TRAIN  loss dict:  {'mse_loss': 0.3523536229133606}
2024-05-02 15:30:21,000 [INFO] Step[300/1020]: training loss : 0.3557333016395569 TRAIN  loss dict:  {'mse_loss': 0.3557333016395569}
2024-05-02 15:31:31,929 [INFO] Step[350/1020]: training loss : 0.3504467558860779 TRAIN  loss dict:  {'mse_loss': 0.3504467558860779}
2024-05-02 15:32:42,370 [INFO] Step[400/1020]: training loss : 0.3505690228939056 TRAIN  loss dict:  {'mse_loss': 0.3505690228939056}
2024-05-02 15:33:50,750 [INFO] Step[450/1020]: training loss : 0.3530525368452072 TRAIN  loss dict:  {'mse_loss': 0.3530525368452072}
2024-05-02 15:34:58,523 [INFO] Step[500/1020]: training loss : 0.35527367770671847 TRAIN  loss dict:  {'mse_loss': 0.35527367770671847}
2024-05-02 15:36:03,236 [INFO] Step[550/1020]: training loss : 0.35460380375385286 TRAIN  loss dict:  {'mse_loss': 0.35460380375385286}
2024-05-02 15:37:10,941 [INFO] Step[600/1020]: training loss : 0.3586158299446106 TRAIN  loss dict:  {'mse_loss': 0.3586158299446106}
2024-05-02 15:38:04,570 [INFO] Step[650/1020]: training loss : 0.35106198728084564 TRAIN  loss dict:  {'mse_loss': 0.35106198728084564}
2024-05-02 15:39:00,847 [INFO] Step[700/1020]: training loss : 0.3444100475311279 TRAIN  loss dict:  {'mse_loss': 0.3444100475311279}
2024-05-02 15:40:09,634 [INFO] Step[750/1020]: training loss : 0.35737140417099 TRAIN  loss dict:  {'mse_loss': 0.35737140417099}
2024-05-02 15:41:21,870 [INFO] Step[800/1020]: training loss : 0.34903002202510836 TRAIN  loss dict:  {'mse_loss': 0.34903002202510836}
2024-05-02 15:42:31,307 [INFO] Step[850/1020]: training loss : 0.3469418215751648 TRAIN  loss dict:  {'mse_loss': 0.3469418215751648}
2024-05-02 15:43:43,862 [INFO] Step[900/1020]: training loss : 0.3488334310054779 TRAIN  loss dict:  {'mse_loss': 0.3488334310054779}
2024-05-02 15:44:51,692 [INFO] Step[950/1020]: training loss : 0.3479289150238037 TRAIN  loss dict:  {'mse_loss': 0.3479289150238037}
2024-05-02 15:45:46,369 [INFO] Step[1000/1020]: training loss : 0.3495390659570694 TRAIN  loss dict:  {'mse_loss': 0.3495390659570694}
2024-05-02 15:50:53,874 [INFO] Label accuracies statistics:
2024-05-02 15:50:53,875 [INFO] {0: 0.5, 1: 0.75, 2: 0.25, 3: 0.75, 4: 0.3333333333333333, 5: 0.75, 6: 0.0, 7: 0.75, 8: 0.0, 9: 0.5, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.25, 14: 0.5, 15: 0.25, 16: 0.5, 17: 0.25, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.0, 22: 0.5, 23: 0.75, 24: 0.25, 25: 0.75, 26: 0.0, 27: 0.5, 28: 0.5, 29: 0.5, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.25, 36: 0.25, 37: 0.0, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.75, 45: 1.0, 46: 0.75, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.5, 52: 0.25, 53: 0.25, 54: 0.0, 55: 0.5, 56: 0.25, 57: 0.75, 58: 0.75, 59: 0.5, 60: 0.0, 61: 0.75, 62: 0.75, 63: 0.75, 64: 0.25, 65: 0.75, 66: 0.5, 67: 1.0, 68: 0.75, 69: 0.0, 70: 0.5, 71: 0.5, 72: 0.5, 73: 0.5, 74: 0.25, 75: 1.0, 76: 1.0, 77: 0.5, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.0, 83: 1.0, 84: 0.25, 85: 1.0, 86: 0.25, 87: 0.0, 88: 0.6666666666666666, 89: 0.5, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.5, 94: 0.25, 95: 0.75, 96: 0.75, 97: 0.5, 98: 1.0, 99: 1.0, 100: 0.25, 101: 1.0, 102: 0.5, 103: 0.25, 104: 1.0, 105: 0.5, 106: 0.75, 107: 0.5, 108: 0.5, 109: 0.25, 110: 0.75, 111: 1.0, 112: 0.25, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 0.75, 119: 0.5, 120: 0.5, 121: 0.75, 122: 0.25, 123: 0.5, 124: 0.75, 125: 0.75, 126: 0.75, 127: 1.0, 128: 0.75, 129: 0.5, 130: 0.75, 131: 1.0, 132: 0.5, 133: 0.75, 134: 0.75, 135: 0.75, 136: 1.0, 137: 0.75, 138: 0.25, 139: 0.25, 140: 0.75, 141: 0.5, 142: 0.25, 143: 0.5, 144: 0.5, 145: 0.5, 146: 0.5, 147: 0.75, 148: 0.25, 149: 1.0, 150: 0.25, 151: 0.5, 152: 0.75, 153: 0.25, 154: 0.25, 155: 0.25, 156: 0.75, 157: 0.5, 158: 0.5, 159: 0.5, 160: 0.25, 161: 1.0, 162: 0.25, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.0, 167: 0.0, 168: 0.25, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.25, 175: 0.5, 176: 0.0, 177: 0.25, 178: 0.75, 179: 0.5, 180: 0.75, 181: 0.75, 182: 0.75, 183: 0.5, 184: 0.5, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.25, 192: 0.75, 193: 0.5, 194: 1.0, 195: 0.25, 196: 0.25, 197: 0.75, 198: 0.25}

2024-05-02 15:51:01,691 [INFO] [7] TRAIN  loss: 0.35198344307787277 acc: 0.0
2024-05-02 15:51:01,692 [INFO] [7] TRAIN  loss dict: {'mse_loss': 0.35198344307787277}
2024-05-02 15:51:01,697 [INFO] [7] VALIDATION loss: 2.2177693699345444 VALIDATION  acc: 0.5681818181818182
2024-05-02 15:51:01,701 [INFO] [7] VALIDATION  loss dict: {'mse_loss': 0.3461851748553189, 'classification_loss': 1.8715841962833597}
2024-05-02 15:51:01,704 [INFO] 
2024-05-02 15:53:00,929 [INFO] Step[50/1020]: training loss : 0.3455783271789551 TRAIN  loss dict:  {'mse_loss': 0.3455783271789551}
2024-05-02 15:54:06,113 [INFO] Step[100/1020]: training loss : 0.34451573133468627 TRAIN  loss dict:  {'mse_loss': 0.34451573133468627}
2024-05-02 15:55:11,586 [INFO] Step[150/1020]: training loss : 0.34200766623020173 TRAIN  loss dict:  {'mse_loss': 0.34200766623020173}
2024-05-02 15:56:18,791 [INFO] Step[200/1020]: training loss : 0.3420858508348465 TRAIN  loss dict:  {'mse_loss': 0.3420858508348465}
2024-05-02 15:57:17,080 [INFO] Step[250/1020]: training loss : 0.34181404292583467 TRAIN  loss dict:  {'mse_loss': 0.34181404292583467}
2024-05-02 15:58:31,138 [INFO] Step[300/1020]: training loss : 0.3447922176122665 TRAIN  loss dict:  {'mse_loss': 0.3447922176122665}
2024-05-02 15:59:37,083 [INFO] Step[350/1020]: training loss : 0.33885729014873506 TRAIN  loss dict:  {'mse_loss': 0.33885729014873506}
2024-05-02 16:00:47,812 [INFO] Step[400/1020]: training loss : 0.34517400979995727 TRAIN  loss dict:  {'mse_loss': 0.34517400979995727}
2024-05-02 16:01:57,666 [INFO] Step[450/1020]: training loss : 0.34065645456314086 TRAIN  loss dict:  {'mse_loss': 0.34065645456314086}
2024-05-02 16:03:10,791 [INFO] Step[500/1020]: training loss : 0.34404210388660433 TRAIN  loss dict:  {'mse_loss': 0.34404210388660433}
2024-05-02 16:04:17,820 [INFO] Step[550/1020]: training loss : 0.34075177788734434 TRAIN  loss dict:  {'mse_loss': 0.34075177788734434}
2024-05-02 16:05:17,749 [INFO] Step[600/1020]: training loss : 0.3375915139913559 TRAIN  loss dict:  {'mse_loss': 0.3375915139913559}
2024-05-02 16:06:22,826 [INFO] Step[650/1020]: training loss : 0.3327360302209854 TRAIN  loss dict:  {'mse_loss': 0.3327360302209854}
2024-05-02 16:07:34,967 [INFO] Step[700/1020]: training loss : 0.3413687127828598 TRAIN  loss dict:  {'mse_loss': 0.3413687127828598}
2024-05-02 16:08:52,527 [INFO] Step[750/1020]: training loss : 0.33507104218006134 TRAIN  loss dict:  {'mse_loss': 0.33507104218006134}
2024-05-02 16:09:55,828 [INFO] Step[800/1020]: training loss : 0.3336414575576782 TRAIN  loss dict:  {'mse_loss': 0.3336414575576782}
2024-05-02 16:10:55,850 [INFO] Step[850/1020]: training loss : 0.3432904171943665 TRAIN  loss dict:  {'mse_loss': 0.3432904171943665}
2024-05-02 16:12:03,792 [INFO] Step[900/1020]: training loss : 0.3414755827188492 TRAIN  loss dict:  {'mse_loss': 0.3414755827188492}
2024-05-02 16:13:06,489 [INFO] Step[950/1020]: training loss : 0.3413232398033142 TRAIN  loss dict:  {'mse_loss': 0.3413232398033142}
2024-05-02 16:14:12,728 [INFO] Step[1000/1020]: training loss : 0.3374352580308914 TRAIN  loss dict:  {'mse_loss': 0.3374352580308914}
2024-05-02 16:19:16,324 [INFO] Label accuracies statistics:
2024-05-02 16:19:16,332 [INFO] {0: 0.5, 1: 0.75, 2: 0.25, 3: 0.75, 4: 0.6666666666666666, 5: 0.25, 6: 0.0, 7: 1.0, 8: 0.0, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.25, 16: 0.25, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.0, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.75, 26: 0.75, 27: 0.75, 28: 0.5, 29: 0.25, 30: 0.75, 31: 0.5, 32: 0.75, 33: 0.75, 34: 0.75, 35: 0.0, 36: 0.25, 37: 0.0, 38: 0.25, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 0.25, 47: 0.5, 48: 0.5, 49: 0.25, 50: 0.5, 51: 0.5, 52: 0.25, 53: 0.0, 54: 0.25, 55: 0.5, 56: 0.25, 57: 0.75, 58: 0.75, 59: 0.25, 60: 0.0, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.5, 67: 1.0, 68: 0.5, 69: 0.0, 70: 0.25, 71: 0.5, 72: 1.0, 73: 0.5, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.5, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.0, 83: 0.75, 84: 0.5, 85: 1.0, 86: 0.25, 87: 0.25, 88: 0.6666666666666666, 89: 0.75, 90: 1.0, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.75, 97: 0.5, 98: 0.5, 99: 0.75, 100: 0.25, 101: 0.75, 102: 0.75, 103: 0.25, 104: 1.0, 105: 0.25, 106: 1.0, 107: 0.25, 108: 0.5, 109: 0.5, 110: 0.5, 111: 0.5, 112: 0.5, 113: 0.0, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 0.5, 119: 0.5, 120: 0.75, 121: 1.0, 122: 0.5, 123: 0.75, 124: 0.5, 125: 0.5, 126: 0.75, 127: 0.75, 128: 0.75, 129: 0.5, 130: 0.75, 131: 1.0, 132: 0.25, 133: 0.75, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.25, 138: 0.25, 139: 0.0, 140: 0.25, 141: 0.5, 142: 0.0, 143: 0.5, 144: 0.75, 145: 0.25, 146: 0.5, 147: 0.75, 148: 0.25, 149: 0.75, 150: 0.25, 151: 0.25, 152: 0.75, 153: 0.25, 154: 0.25, 155: 0.0, 156: 0.25, 157: 0.5, 158: 0.75, 159: 0.5, 160: 0.25, 161: 1.0, 162: 0.0, 163: 0.25, 164: 0.75, 165: 0.75, 166: 0.0, 167: 0.0, 168: 0.5, 169: 0.5, 170: 1.0, 171: 0.25, 172: 0.5, 173: 0.75, 174: 0.5, 175: 0.5, 176: 0.0, 177: 0.75, 178: 1.0, 179: 0.25, 180: 1.0, 181: 0.5, 182: 0.75, 183: 0.5, 184: 0.25, 185: 0.75, 186: 0.5, 187: 0.5, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.5, 192: 0.75, 193: 0.75, 194: 1.0, 195: 0.5, 196: 0.25, 197: 0.75, 198: 0.25}

2024-05-02 16:19:21,978 [INFO] [8] TRAIN  loss: 0.3407128688167123 acc: 0.0
2024-05-02 16:19:21,979 [INFO] [8] TRAIN  loss dict: {'mse_loss': 0.3407128688167123}
2024-05-02 16:19:21,981 [INFO] [8] VALIDATION loss: 2.1529984955835824 VALIDATION  acc: 0.5467171717171717
2024-05-02 16:19:21,983 [INFO] [8] VALIDATION  loss dict: {'mse_loss': 0.34022398849930424, 'classification_loss': 1.8127745055791102}
2024-05-02 16:19:21,986 [INFO] 
2024-05-02 16:21:21,481 [INFO] Step[50/1020]: training loss : 0.33807051956653594 TRAIN  loss dict:  {'mse_loss': 0.33807051956653594}
2024-05-02 16:22:16,580 [INFO] Step[100/1020]: training loss : 0.3390917736291885 TRAIN  loss dict:  {'mse_loss': 0.3390917736291885}
2024-05-02 16:23:04,478 [INFO] Step[150/1020]: training loss : 0.3311741381883621 TRAIN  loss dict:  {'mse_loss': 0.3311741381883621}
2024-05-02 16:24:08,117 [INFO] Step[200/1020]: training loss : 0.32945249855518344 TRAIN  loss dict:  {'mse_loss': 0.32945249855518344}
2024-05-02 16:25:13,267 [INFO] Step[250/1020]: training loss : 0.33240271151065826 TRAIN  loss dict:  {'mse_loss': 0.33240271151065826}
2024-05-02 16:26:33,557 [INFO] Step[300/1020]: training loss : 0.33613780081272127 TRAIN  loss dict:  {'mse_loss': 0.33613780081272127}
2024-05-02 16:27:35,022 [INFO] Step[350/1020]: training loss : 0.3363025063276291 TRAIN  loss dict:  {'mse_loss': 0.3363025063276291}
2024-05-02 16:28:38,029 [INFO] Step[400/1020]: training loss : 0.33547924101352694 TRAIN  loss dict:  {'mse_loss': 0.33547924101352694}
2024-05-02 16:29:31,723 [INFO] Step[450/1020]: training loss : 0.3376803314685822 TRAIN  loss dict:  {'mse_loss': 0.3376803314685822}
2024-05-02 16:30:30,954 [INFO] Step[500/1020]: training loss : 0.33006791830062865 TRAIN  loss dict:  {'mse_loss': 0.33006791830062865}
2024-05-02 16:31:27,925 [INFO] Step[550/1020]: training loss : 0.3381288129091263 TRAIN  loss dict:  {'mse_loss': 0.3381288129091263}
2024-05-02 16:32:37,634 [INFO] Step[600/1020]: training loss : 0.33262432396411895 TRAIN  loss dict:  {'mse_loss': 0.33262432396411895}
2024-05-02 16:33:47,821 [INFO] Step[650/1020]: training loss : 0.3333772277832031 TRAIN  loss dict:  {'mse_loss': 0.3333772277832031}
2024-05-02 16:34:52,577 [INFO] Step[700/1020]: training loss : 0.3321791684627533 TRAIN  loss dict:  {'mse_loss': 0.3321791684627533}
2024-05-02 16:36:06,218 [INFO] Step[750/1020]: training loss : 0.3315528643131256 TRAIN  loss dict:  {'mse_loss': 0.3315528643131256}
2024-05-02 16:37:06,927 [INFO] Step[800/1020]: training loss : 0.32757794082164765 TRAIN  loss dict:  {'mse_loss': 0.32757794082164765}
2024-05-02 16:38:10,943 [INFO] Step[850/1020]: training loss : 0.32761115610599517 TRAIN  loss dict:  {'mse_loss': 0.32761115610599517}
2024-05-02 16:39:15,684 [INFO] Step[900/1020]: training loss : 0.3342314463853836 TRAIN  loss dict:  {'mse_loss': 0.3342314463853836}
2024-05-02 16:40:27,107 [INFO] Step[950/1020]: training loss : 0.3298891353607178 TRAIN  loss dict:  {'mse_loss': 0.3298891353607178}
2024-05-02 16:41:30,465 [INFO] Step[1000/1020]: training loss : 0.3252187120914459 TRAIN  loss dict:  {'mse_loss': 0.3252187120914459}
2024-05-02 16:46:46,959 [INFO] Label accuracies statistics:
2024-05-02 16:46:46,962 [INFO] {0: 0.5, 1: 0.75, 2: 0.25, 3: 0.75, 4: 0.3333333333333333, 5: 0.25, 6: 0.25, 7: 1.0, 8: 0.0, 9: 0.75, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.5, 14: 0.25, 15: 0.5, 16: 0.25, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.25, 22: 0.5, 23: 0.75, 24: 0.5, 25: 0.75, 26: 0.75, 27: 0.5, 28: 0.5, 29: 0.5, 30: 0.75, 31: 0.5, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.25, 36: 0.25, 37: 0.0, 38: 0.0, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 0.5, 47: 0.75, 48: 1.0, 49: 0.25, 50: 0.75, 51: 0.5, 52: 0.25, 53: 0.0, 54: 0.25, 55: 0.5, 56: 0.25, 57: 0.5, 58: 0.75, 59: 0.25, 60: 0.0, 61: 0.75, 62: 1.0, 63: 0.5, 64: 0.5, 65: 0.25, 66: 0.25, 67: 1.0, 68: 0.75, 69: 0.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.5, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.25, 83: 0.5, 84: 0.75, 85: 1.0, 86: 0.25, 87: 0.0, 88: 0.6666666666666666, 89: 0.5, 90: 1.0, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.75, 97: 0.75, 98: 0.5, 99: 1.0, 100: 0.25, 101: 1.0, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.25, 108: 0.5, 109: 0.5, 110: 0.5, 111: 0.75, 112: 0.25, 113: 0.0, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.5, 120: 0.5, 121: 0.75, 122: 0.0, 123: 0.0, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 0.75, 129: 0.75, 130: 1.0, 131: 0.5, 132: 0.25, 133: 1.0, 134: 0.75, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.25, 139: 0.5, 140: 0.0, 141: 0.75, 142: 0.5, 143: 1.0, 144: 0.5, 145: 0.25, 146: 0.5, 147: 0.75, 148: 0.5, 149: 1.0, 150: 0.25, 151: 0.25, 152: 0.75, 153: 0.5, 154: 0.25, 155: 0.0, 156: 0.5, 157: 0.5, 158: 0.25, 159: 0.5, 160: 0.0, 161: 1.0, 162: 0.25, 163: 0.0, 164: 1.0, 165: 0.75, 166: 0.25, 167: 0.25, 168: 0.5, 169: 0.5, 170: 1.0, 171: 0.0, 172: 0.5, 173: 0.75, 174: 0.25, 175: 0.75, 176: 0.25, 177: 0.5, 178: 1.0, 179: 1.0, 180: 1.0, 181: 0.75, 182: 0.75, 183: 0.75, 184: 0.25, 185: 0.75, 186: 0.25, 187: 0.75, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.25, 192: 0.25, 193: 0.75, 194: 1.0, 195: 0.5, 196: 0.5, 197: 0.75, 198: 0.0}

2024-05-02 16:46:54,244 [INFO] [9] TRAIN  loss: 0.3329106551175024 acc: 0.0
2024-05-02 16:46:54,246 [INFO] [9] TRAIN  loss dict: {'mse_loss': 0.3329106551175024}
2024-05-02 16:46:54,248 [INFO] [9] VALIDATION loss: 2.0501961771285897 VALIDATION  acc: 0.571969696969697
2024-05-02 16:46:54,249 [INFO] [9] VALIDATION  loss dict: {'mse_loss': 0.33334370905702765, 'classification_loss': 1.7168524596426222}
2024-05-02 16:46:54,251 [INFO] 
2024-05-02 16:48:45,660 [INFO] Step[50/1020]: training loss : 0.33035621643066404 TRAIN  loss dict:  {'mse_loss': 0.33035621643066404}
2024-05-02 16:49:56,012 [INFO] Step[100/1020]: training loss : 0.3230402320623398 TRAIN  loss dict:  {'mse_loss': 0.3230402320623398}
2024-05-02 16:50:57,682 [INFO] Step[150/1020]: training loss : 0.3214876878261566 TRAIN  loss dict:  {'mse_loss': 0.3214876878261566}
2024-05-02 16:51:56,652 [INFO] Step[200/1020]: training loss : 0.32903711378574374 TRAIN  loss dict:  {'mse_loss': 0.32903711378574374}
2024-05-02 16:52:57,638 [INFO] Step[250/1020]: training loss : 0.3269545722007752 TRAIN  loss dict:  {'mse_loss': 0.3269545722007752}
2024-05-02 16:53:58,492 [INFO] Step[300/1020]: training loss : 0.32577253818511964 TRAIN  loss dict:  {'mse_loss': 0.32577253818511964}
2024-05-02 16:55:03,442 [INFO] Step[350/1020]: training loss : 0.33062313854694364 TRAIN  loss dict:  {'mse_loss': 0.33062313854694364}
2024-05-02 16:56:06,560 [INFO] Step[400/1020]: training loss : 0.32638568997383116 TRAIN  loss dict:  {'mse_loss': 0.32638568997383116}
2024-05-02 16:57:15,898 [INFO] Step[450/1020]: training loss : 0.32447266817092896 TRAIN  loss dict:  {'mse_loss': 0.32447266817092896}
2024-05-02 16:58:24,922 [INFO] Step[500/1020]: training loss : 0.3228454464673996 TRAIN  loss dict:  {'mse_loss': 0.3228454464673996}
2024-05-02 16:59:25,562 [INFO] Step[550/1020]: training loss : 0.3260365927219391 TRAIN  loss dict:  {'mse_loss': 0.3260365927219391}
2024-05-02 17:00:28,175 [INFO] Step[600/1020]: training loss : 0.3136274790763855 TRAIN  loss dict:  {'mse_loss': 0.3136274790763855}
2024-05-02 17:01:27,880 [INFO] Step[650/1020]: training loss : 0.32137754678726194 TRAIN  loss dict:  {'mse_loss': 0.32137754678726194}
2024-05-02 17:02:28,776 [INFO] Step[700/1020]: training loss : 0.32326068729162216 TRAIN  loss dict:  {'mse_loss': 0.32326068729162216}
2024-05-02 17:03:35,474 [INFO] Step[750/1020]: training loss : 0.3198118081688881 TRAIN  loss dict:  {'mse_loss': 0.3198118081688881}
2024-05-02 17:04:42,026 [INFO] Step[800/1020]: training loss : 0.31864104032516477 TRAIN  loss dict:  {'mse_loss': 0.31864104032516477}
2024-05-02 17:05:32,525 [INFO] Step[850/1020]: training loss : 0.3273259520530701 TRAIN  loss dict:  {'mse_loss': 0.3273259520530701}
2024-05-02 17:06:24,617 [INFO] Step[900/1020]: training loss : 0.32701938509941103 TRAIN  loss dict:  {'mse_loss': 0.32701938509941103}
2024-05-02 17:07:25,962 [INFO] Step[950/1020]: training loss : 0.32318425476551055 TRAIN  loss dict:  {'mse_loss': 0.32318425476551055}
2024-05-02 17:08:34,554 [INFO] Step[1000/1020]: training loss : 0.3215301752090454 TRAIN  loss dict:  {'mse_loss': 0.3215301752090454}
2024-05-02 17:14:01,659 [INFO] Label accuracies statistics:
2024-05-02 17:14:01,680 [INFO] {0: 0.5, 1: 1.0, 2: 0.5, 3: 1.0, 4: 0.6666666666666666, 5: 0.25, 6: 0.0, 7: 0.75, 8: 0.0, 9: 1.0, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.5, 14: 0.75, 15: 0.25, 16: 0.25, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.25, 21: 0.25, 22: 0.5, 23: 0.75, 24: 0.25, 25: 0.75, 26: 0.75, 27: 1.0, 28: 0.5, 29: 0.5, 30: 0.75, 31: 0.5, 32: 1.0, 33: 1.0, 34: 0.5, 35: 0.5, 36: 0.5, 37: 0.0, 38: 0.5, 39: 0.75, 40: 1.0, 41: 1.0, 42: 0.75, 43: 0.5, 44: 0.25, 45: 1.0, 46: 0.75, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.5, 51: 0.5, 52: 0.25, 53: 0.25, 54: 0.25, 55: 0.5, 56: 0.5, 57: 0.75, 58: 0.75, 59: 0.5, 60: 0.0, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.5, 67: 1.0, 68: 0.75, 69: 0.0, 70: 0.5, 71: 0.25, 72: 1.0, 73: 0.0, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.25, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.0, 83: 0.25, 84: 0.75, 85: 1.0, 86: 0.0, 87: 0.0, 88: 0.6666666666666666, 89: 0.5, 90: 1.0, 91: 1.0, 92: 0.75, 93: 0.5, 94: 0.25, 95: 0.75, 96: 0.75, 97: 0.75, 98: 0.5, 99: 0.75, 100: 0.25, 101: 1.0, 102: 0.75, 103: 0.0, 104: 1.0, 105: 0.0, 106: 1.0, 107: 0.5, 108: 0.5, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.25, 113: 0.5, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.5, 121: 1.0, 122: 0.5, 123: 0.5, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 0.75, 129: 0.75, 130: 0.5, 131: 0.75, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.25, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.0, 143: 0.75, 144: 0.5, 145: 0.25, 146: 0.75, 147: 0.75, 148: 0.5, 149: 1.0, 150: 0.25, 151: 0.5, 152: 1.0, 153: 0.25, 154: 0.25, 155: 0.0, 156: 0.75, 157: 0.5, 158: 0.5, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.25, 163: 0.0, 164: 0.5, 165: 0.75, 166: 0.25, 167: 0.25, 168: 0.25, 169: 0.75, 170: 1.0, 171: 0.0, 172: 0.5, 173: 0.75, 174: 0.25, 175: 1.0, 176: 0.0, 177: 0.0, 178: 1.0, 179: 1.0, 180: 1.0, 181: 0.5, 182: 0.75, 183: 0.5, 184: 0.5, 185: 0.75, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.5, 191: 0.0, 192: 0.25, 193: 0.25, 194: 1.0, 195: 0.25, 196: 0.25, 197: 0.75, 198: 0.75}

2024-05-02 17:14:07,773 [INFO] [10] TRAIN  loss: 0.32405978756792403 acc: 0.0
2024-05-02 17:14:07,773 [INFO] [10] TRAIN  loss dict: {'mse_loss': 0.32405978756792403}
2024-05-02 17:14:07,774 [INFO] [10] VALIDATION loss: 1.9404958387215931 VALIDATION  acc: 0.5896464646464646
2024-05-02 17:14:07,774 [INFO] [10] VALIDATION  loss dict: {'mse_loss': 0.3249860147033075, 'classification_loss': 1.6155098173955473}
2024-05-02 17:14:07,775 [INFO] 
2024-05-02 17:16:00,148 [INFO] Step[50/1020]: training loss : 0.3212963896989822 TRAIN  loss dict:  {'mse_loss': 0.3212963896989822}
2024-05-02 17:17:17,571 [INFO] Step[100/1020]: training loss : 0.30929615795612336 TRAIN  loss dict:  {'mse_loss': 0.30929615795612336}
2024-05-02 17:18:26,485 [INFO] Step[150/1020]: training loss : 0.30840798646211626 TRAIN  loss dict:  {'mse_loss': 0.30840798646211626}
2024-05-02 17:19:28,335 [INFO] Step[200/1020]: training loss : 0.31423482358455657 TRAIN  loss dict:  {'mse_loss': 0.31423482358455657}
2024-05-02 17:20:29,389 [INFO] Step[250/1020]: training loss : 0.3135877352952957 TRAIN  loss dict:  {'mse_loss': 0.3135877352952957}
2024-05-02 17:21:36,369 [INFO] Step[300/1020]: training loss : 0.3139056986570358 TRAIN  loss dict:  {'mse_loss': 0.3139056986570358}
2024-05-02 17:22:48,569 [INFO] Step[350/1020]: training loss : 0.31391362100839615 TRAIN  loss dict:  {'mse_loss': 0.31391362100839615}
2024-05-02 17:23:44,340 [INFO] Step[400/1020]: training loss : 0.31553905487060546 TRAIN  loss dict:  {'mse_loss': 0.31553905487060546}
2024-05-02 17:24:48,958 [INFO] Step[450/1020]: training loss : 0.3217742431163788 TRAIN  loss dict:  {'mse_loss': 0.3217742431163788}
2024-05-02 17:25:52,063 [INFO] Step[500/1020]: training loss : 0.31504459023475645 TRAIN  loss dict:  {'mse_loss': 0.31504459023475645}
2024-05-02 17:26:55,817 [INFO] Step[550/1020]: training loss : 0.3096874123811722 TRAIN  loss dict:  {'mse_loss': 0.3096874123811722}
2024-05-02 17:27:55,906 [INFO] Step[600/1020]: training loss : 0.3178287345170975 TRAIN  loss dict:  {'mse_loss': 0.3178287345170975}
2024-05-02 17:29:04,218 [INFO] Step[650/1020]: training loss : 0.31692352294921877 TRAIN  loss dict:  {'mse_loss': 0.31692352294921877}
2024-05-02 17:29:59,656 [INFO] Step[700/1020]: training loss : 0.3161919403076172 TRAIN  loss dict:  {'mse_loss': 0.3161919403076172}
2024-05-02 17:31:06,013 [INFO] Step[750/1020]: training loss : 0.31432154297828674 TRAIN  loss dict:  {'mse_loss': 0.31432154297828674}
2024-05-02 17:32:03,633 [INFO] Step[800/1020]: training loss : 0.31491335153579714 TRAIN  loss dict:  {'mse_loss': 0.31491335153579714}
2024-05-02 17:33:02,885 [INFO] Step[850/1020]: training loss : 0.30766165792942046 TRAIN  loss dict:  {'mse_loss': 0.30766165792942046}
2024-05-02 17:34:04,014 [INFO] Step[900/1020]: training loss : 0.31120844423770905 TRAIN  loss dict:  {'mse_loss': 0.31120844423770905}
2024-05-02 17:35:10,838 [INFO] Step[950/1020]: training loss : 0.30944683134555817 TRAIN  loss dict:  {'mse_loss': 0.30944683134555817}
2024-05-02 17:36:10,083 [INFO] Step[1000/1020]: training loss : 0.31640920996665955 TRAIN  loss dict:  {'mse_loss': 0.31640920996665955}
2024-05-02 17:41:21,242 [INFO] Label accuracies statistics:
2024-05-02 17:41:21,249 [INFO] {0: 0.5, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.6666666666666666, 5: 0.5, 6: 0.0, 7: 1.0, 8: 0.0, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.5, 14: 0.25, 15: 0.5, 16: 0.25, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.5, 22: 0.5, 23: 0.75, 24: 0.5, 25: 0.5, 26: 1.0, 27: 0.75, 28: 0.5, 29: 0.5, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.0, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 0.5, 43: 0.5, 44: 0.25, 45: 1.0, 46: 0.5, 47: 0.5, 48: 0.75, 49: 0.25, 50: 1.0, 51: 0.5, 52: 0.25, 53: 0.0, 54: 0.5, 55: 0.5, 56: 0.5, 57: 0.75, 58: 0.75, 59: 0.25, 60: 0.0, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.75, 65: 0.25, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.25, 74: 0.25, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.0, 83: 1.0, 84: 0.75, 85: 1.0, 86: 0.0, 87: 0.5, 88: 0.3333333333333333, 89: 0.75, 90: 1.0, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.75, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.5, 108: 0.5, 109: 0.25, 110: 0.5, 111: 0.75, 112: 0.25, 113: 0.5, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.75, 118: 0.75, 119: 0.75, 120: 0.5, 121: 1.0, 122: 0.5, 123: 0.5, 124: 1.0, 125: 0.75, 126: 0.75, 127: 1.0, 128: 0.75, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.5, 133: 1.0, 134: 0.75, 135: 0.75, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.25, 140: 0.5, 141: 1.0, 142: 0.5, 143: 0.75, 144: 1.0, 145: 0.25, 146: 0.5, 147: 1.0, 148: 0.75, 149: 0.5, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.5, 154: 0.25, 155: 0.5, 156: 0.75, 157: 0.5, 158: 0.25, 159: 0.5, 160: 0.25, 161: 1.0, 162: 0.0, 163: 0.0, 164: 0.5, 165: 0.75, 166: 0.25, 167: 0.25, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.0, 172: 0.75, 173: 0.75, 174: 0.25, 175: 0.75, 176: 0.25, 177: 0.0, 178: 1.0, 179: 0.75, 180: 0.75, 181: 0.75, 182: 0.75, 183: 0.5, 184: 0.5, 185: 0.75, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.25, 192: 0.25, 193: 0.5, 194: 1.0, 195: 0.25, 196: 0.25, 197: 1.0, 198: 0.0}

2024-05-02 17:41:27,183 [INFO] [11] TRAIN  loss: 0.31403009009127525 acc: 0.0
2024-05-02 17:41:27,183 [INFO] [11] TRAIN  loss dict: {'mse_loss': 0.31403009009127525}
2024-05-02 17:41:27,184 [INFO] [11] VALIDATION loss: 1.8235885919344546 VALIDATION  acc: 0.6186868686868687
2024-05-02 17:41:27,184 [INFO] [11] VALIDATION  loss dict: {'mse_loss': 0.3164771692921417, 'classification_loss': 1.5071114167721584}
2024-05-02 17:41:27,185 [INFO] 
2024-05-02 17:43:17,423 [INFO] Step[50/1020]: training loss : 0.3059298300743103 TRAIN  loss dict:  {'mse_loss': 0.3059298300743103}
2024-05-02 17:44:20,985 [INFO] Step[100/1020]: training loss : 0.3119745308160782 TRAIN  loss dict:  {'mse_loss': 0.3119745308160782}
2024-05-02 17:45:21,944 [INFO] Step[150/1020]: training loss : 0.3084893202781677 TRAIN  loss dict:  {'mse_loss': 0.3084893202781677}
2024-05-02 17:46:23,714 [INFO] Step[200/1020]: training loss : 0.3078902721405029 TRAIN  loss dict:  {'mse_loss': 0.3078902721405029}
2024-05-02 17:47:29,496 [INFO] Step[250/1020]: training loss : 0.3139252156019211 TRAIN  loss dict:  {'mse_loss': 0.3139252156019211}
2024-05-02 17:48:30,306 [INFO] Step[300/1020]: training loss : 0.3028077954053879 TRAIN  loss dict:  {'mse_loss': 0.3028077954053879}
2024-05-02 17:49:19,091 [INFO] Step[350/1020]: training loss : 0.30419685184955597 TRAIN  loss dict:  {'mse_loss': 0.30419685184955597}
2024-05-02 17:50:20,890 [INFO] Step[400/1020]: training loss : 0.31110242009162903 TRAIN  loss dict:  {'mse_loss': 0.31110242009162903}
2024-05-02 17:51:23,201 [INFO] Step[450/1020]: training loss : 0.3100039094686508 TRAIN  loss dict:  {'mse_loss': 0.3100039094686508}
2024-05-02 17:52:30,191 [INFO] Step[500/1020]: training loss : 0.31670005261898043 TRAIN  loss dict:  {'mse_loss': 0.31670005261898043}
2024-05-02 17:53:40,162 [INFO] Step[550/1020]: training loss : 0.3057111820578575 TRAIN  loss dict:  {'mse_loss': 0.3057111820578575}
2024-05-02 17:54:39,479 [INFO] Step[600/1020]: training loss : 0.30696889996528626 TRAIN  loss dict:  {'mse_loss': 0.30696889996528626}
2024-05-02 17:55:40,932 [INFO] Step[650/1020]: training loss : 0.30944119930267333 TRAIN  loss dict:  {'mse_loss': 0.30944119930267333}
2024-05-02 17:56:44,578 [INFO] Step[700/1020]: training loss : 0.3083349984884262 TRAIN  loss dict:  {'mse_loss': 0.3083349984884262}
2024-05-02 17:57:52,279 [INFO] Step[750/1020]: training loss : 0.30970162510871885 TRAIN  loss dict:  {'mse_loss': 0.30970162510871885}
2024-05-02 17:58:52,142 [INFO] Step[800/1020]: training loss : 0.30059258490800855 TRAIN  loss dict:  {'mse_loss': 0.30059258490800855}
2024-05-02 17:59:54,351 [INFO] Step[850/1020]: training loss : 0.3069613280892372 TRAIN  loss dict:  {'mse_loss': 0.3069613280892372}
2024-05-02 18:00:57,258 [INFO] Step[900/1020]: training loss : 0.3061135935783386 TRAIN  loss dict:  {'mse_loss': 0.3061135935783386}
2024-05-02 18:01:58,736 [INFO] Step[950/1020]: training loss : 0.30033852487802504 TRAIN  loss dict:  {'mse_loss': 0.30033852487802504}
2024-05-02 18:02:58,720 [INFO] Step[1000/1020]: training loss : 0.3082990935444832 TRAIN  loss dict:  {'mse_loss': 0.3082990935444832}
2024-05-02 18:07:59,996 [INFO] Label accuracies statistics:
2024-05-02 18:08:00,000 [INFO] {0: 0.5, 1: 0.75, 2: 0.5, 3: 0.75, 4: 0.6666666666666666, 5: 0.75, 6: 0.25, 7: 1.0, 8: 0.0, 9: 1.0, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.5, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.0, 22: 0.75, 23: 0.75, 24: 0.5, 25: 0.75, 26: 0.75, 27: 1.0, 28: 0.5, 29: 0.5, 30: 0.75, 31: 0.5, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.0, 38: 0.25, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.5, 52: 0.25, 53: 0.0, 54: 0.0, 55: 0.25, 56: 0.25, 57: 0.75, 58: 0.75, 59: 0.25, 60: 0.0, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.25, 66: 0.5, 67: 1.0, 68: 0.75, 69: 0.25, 70: 0.75, 71: 0.25, 72: 1.0, 73: 0.5, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.5, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.5, 83: 1.0, 84: 0.5, 85: 1.0, 86: 0.25, 87: 0.25, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.75, 97: 0.75, 98: 0.5, 99: 1.0, 100: 0.5, 101: 0.5, 102: 0.75, 103: 0.25, 104: 1.0, 105: 0.0, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.5, 110: 1.0, 111: 0.75, 112: 0.0, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 0.75, 119: 1.0, 120: 0.5, 121: 1.0, 122: 0.5, 123: 0.5, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 0.75, 135: 0.75, 136: 1.0, 137: 0.5, 138: 0.25, 139: 0.25, 140: 0.25, 141: 0.25, 142: 0.75, 143: 0.5, 144: 0.75, 145: 0.25, 146: 0.75, 147: 1.0, 148: 0.75, 149: 0.75, 150: 0.5, 151: 0.25, 152: 1.0, 153: 0.25, 154: 0.25, 155: 0.25, 156: 0.75, 157: 0.5, 158: 0.25, 159: 0.5, 160: 0.0, 161: 0.75, 162: 0.0, 163: 0.5, 164: 0.5, 165: 1.0, 166: 0.5, 167: 0.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.5, 173: 0.75, 174: 0.25, 175: 0.75, 176: 0.5, 177: 0.25, 178: 1.0, 179: 1.0, 180: 1.0, 181: 0.5, 182: 0.25, 183: 0.5, 184: 0.25, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.25, 192: 0.0, 193: 0.75, 194: 1.0, 195: 0.25, 196: 0.5, 197: 1.0, 198: 0.5}

2024-05-02 18:08:16,763 [INFO] [12] TRAIN  loss: 0.3077112015994156 acc: 0.0
2024-05-02 18:08:16,764 [INFO] [12] TRAIN  loss dict: {'mse_loss': 0.3077112015994156}
2024-05-02 18:08:16,764 [INFO] [12] VALIDATION loss: 1.785298396240581 VALIDATION  acc: 0.6136363636363636
2024-05-02 18:08:16,764 [INFO] [12] VALIDATION  loss dict: {'mse_loss': 0.3123122817187598, 'classification_loss': 1.472986116026989}
2024-05-02 18:08:16,764 [INFO] 
2024-05-02 18:10:09,902 [INFO] Step[50/1020]: training loss : 0.29937669962644575 TRAIN  loss dict:  {'mse_loss': 0.29937669962644575}
2024-05-02 18:11:14,441 [INFO] Step[100/1020]: training loss : 0.2973453015089035 TRAIN  loss dict:  {'mse_loss': 0.2973453015089035}
2024-05-02 18:12:23,166 [INFO] Step[150/1020]: training loss : 0.30156709283590316 TRAIN  loss dict:  {'mse_loss': 0.30156709283590316}
2024-05-02 18:13:36,364 [INFO] Step[200/1020]: training loss : 0.30051195234060285 TRAIN  loss dict:  {'mse_loss': 0.30051195234060285}
2024-05-02 18:14:38,759 [INFO] Step[250/1020]: training loss : 0.3071936732530594 TRAIN  loss dict:  {'mse_loss': 0.3071936732530594}
2024-05-02 18:15:42,714 [INFO] Step[300/1020]: training loss : 0.30024078994989395 TRAIN  loss dict:  {'mse_loss': 0.30024078994989395}
2024-05-02 18:16:45,384 [INFO] Step[350/1020]: training loss : 0.3009697961807251 TRAIN  loss dict:  {'mse_loss': 0.3009697961807251}
2024-05-02 18:17:48,331 [INFO] Step[400/1020]: training loss : 0.29840085834264757 TRAIN  loss dict:  {'mse_loss': 0.29840085834264757}
2024-05-02 18:18:51,321 [INFO] Step[450/1020]: training loss : 0.30540232062339784 TRAIN  loss dict:  {'mse_loss': 0.30540232062339784}
2024-05-02 18:20:05,336 [INFO] Step[500/1020]: training loss : 0.3026618757843971 TRAIN  loss dict:  {'mse_loss': 0.3026618757843971}
2024-05-02 18:21:05,911 [INFO] Step[550/1020]: training loss : 0.30047761380672455 TRAIN  loss dict:  {'mse_loss': 0.30047761380672455}
2024-05-02 18:22:16,187 [INFO] Step[600/1020]: training loss : 0.306653613448143 TRAIN  loss dict:  {'mse_loss': 0.306653613448143}
2024-05-02 18:23:16,537 [INFO] Step[650/1020]: training loss : 0.3073216271400452 TRAIN  loss dict:  {'mse_loss': 0.3073216271400452}
2024-05-02 18:24:22,401 [INFO] Step[700/1020]: training loss : 0.3019095915555954 TRAIN  loss dict:  {'mse_loss': 0.3019095915555954}
2024-05-02 18:25:40,637 [INFO] Step[750/1020]: training loss : 0.3009690478444099 TRAIN  loss dict:  {'mse_loss': 0.3009690478444099}
2024-05-02 18:26:50,096 [INFO] Step[800/1020]: training loss : 0.3031608331203461 TRAIN  loss dict:  {'mse_loss': 0.3031608331203461}
2024-05-02 18:27:54,027 [INFO] Step[850/1020]: training loss : 0.2998532342910767 TRAIN  loss dict:  {'mse_loss': 0.2998532342910767}
2024-05-02 18:29:00,418 [INFO] Step[900/1020]: training loss : 0.299988876581192 TRAIN  loss dict:  {'mse_loss': 0.299988876581192}
2024-05-02 18:30:05,445 [INFO] Step[950/1020]: training loss : 0.3075781708955765 TRAIN  loss dict:  {'mse_loss': 0.3075781708955765}
2024-05-02 18:31:00,879 [INFO] Step[1000/1020]: training loss : 0.30577878177165985 TRAIN  loss dict:  {'mse_loss': 0.30577878177165985}
2024-05-02 18:35:41,762 [INFO] Label accuracies statistics:
2024-05-02 18:35:41,763 [INFO] {0: 0.5, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.3333333333333333, 5: 0.75, 6: 0.0, 7: 1.0, 8: 0.0, 9: 1.0, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.75, 16: 0.25, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.25, 22: 0.75, 23: 0.75, 24: 0.5, 25: 0.25, 26: 1.0, 27: 0.75, 28: 0.5, 29: 0.75, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.5, 35: 0.5, 36: 0.75, 37: 0.25, 38: 0.25, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.5, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.5, 52: 0.25, 53: 0.25, 54: 0.5, 55: 0.5, 56: 0.25, 57: 0.75, 58: 0.75, 59: 0.25, 60: 0.25, 61: 0.75, 62: 1.0, 63: 0.5, 64: 0.5, 65: 0.5, 66: 0.75, 67: 1.0, 68: 0.75, 69: 0.25, 70: 0.5, 71: 0.5, 72: 1.0, 73: 0.5, 74: 0.5, 75: 1.0, 76: 0.25, 77: 1.0, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.5, 83: 1.0, 84: 0.75, 85: 1.0, 86: 0.25, 87: 0.25, 88: 0.6666666666666666, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.75, 97: 0.75, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.25, 106: 0.75, 107: 0.5, 108: 0.5, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.25, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.5, 117: 0.5, 118: 1.0, 119: 0.5, 120: 0.5, 121: 0.75, 122: 0.5, 123: 0.5, 124: 0.75, 125: 1.0, 126: 0.75, 127: 1.0, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 0.75, 135: 0.5, 136: 1.0, 137: 0.5, 138: 0.25, 139: 0.25, 140: 0.75, 141: 0.5, 142: 0.75, 143: 0.75, 144: 0.0, 145: 0.25, 146: 0.5, 147: 1.0, 148: 0.5, 149: 1.0, 150: 0.25, 151: 0.75, 152: 1.0, 153: 0.75, 154: 0.5, 155: 0.0, 156: 0.5, 157: 0.5, 158: 0.75, 159: 0.5, 160: 0.25, 161: 1.0, 162: 0.5, 163: 0.5, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.0, 168: 0.5, 169: 0.5, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 0.25, 175: 0.5, 176: 0.5, 177: 0.25, 178: 1.0, 179: 0.75, 180: 1.0, 181: 0.5, 182: 0.75, 183: 0.75, 184: 0.25, 185: 0.75, 186: 0.75, 187: 0.75, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.25, 196: 0.5, 197: 1.0, 198: 0.5}

2024-05-02 18:35:48,715 [INFO] [13] TRAIN  loss: 0.30233493875346934 acc: 0.0
2024-05-02 18:35:48,715 [INFO] [13] TRAIN  loss dict: {'mse_loss': 0.30233493875346934}
2024-05-02 18:35:48,716 [INFO] [13] VALIDATION loss: 1.7370486111954004 VALIDATION  acc: 0.6376262626262627
2024-05-02 18:35:48,716 [INFO] [13] VALIDATION  loss dict: {'mse_loss': 0.3086088013016816, 'classification_loss': 1.4284398106463028}
2024-05-02 18:35:48,716 [INFO] 
2024-05-02 18:37:41,467 [INFO] Step[50/1020]: training loss : 0.30061941474676135 TRAIN  loss dict:  {'mse_loss': 0.30061941474676135}
2024-05-02 18:38:37,283 [INFO] Step[100/1020]: training loss : 0.293165982067585 TRAIN  loss dict:  {'mse_loss': 0.293165982067585}
2024-05-02 18:39:30,219 [INFO] Step[150/1020]: training loss : 0.2927085027098656 TRAIN  loss dict:  {'mse_loss': 0.2927085027098656}
2024-05-02 18:40:29,527 [INFO] Step[200/1020]: training loss : 0.30118738412857055 TRAIN  loss dict:  {'mse_loss': 0.30118738412857055}
2024-05-02 18:41:40,568 [INFO] Step[250/1020]: training loss : 0.3009038218855858 TRAIN  loss dict:  {'mse_loss': 0.3009038218855858}
2024-05-02 18:42:41,773 [INFO] Step[300/1020]: training loss : 0.30128258854150775 TRAIN  loss dict:  {'mse_loss': 0.30128258854150775}
2024-05-02 18:43:42,390 [INFO] Step[350/1020]: training loss : 0.29631036579608916 TRAIN  loss dict:  {'mse_loss': 0.29631036579608916}
2024-05-02 18:44:46,973 [INFO] Step[400/1020]: training loss : 0.29504844844341277 TRAIN  loss dict:  {'mse_loss': 0.29504844844341277}
2024-05-02 18:45:51,616 [INFO] Step[450/1020]: training loss : 0.29554229974746704 TRAIN  loss dict:  {'mse_loss': 0.29554229974746704}
2024-05-02 18:47:00,205 [INFO] Step[500/1020]: training loss : 0.2943297839164734 TRAIN  loss dict:  {'mse_loss': 0.2943297839164734}
2024-05-02 18:48:03,063 [INFO] Step[550/1020]: training loss : 0.2926132383942604 TRAIN  loss dict:  {'mse_loss': 0.2926132383942604}
2024-05-02 18:49:14,372 [INFO] Step[600/1020]: training loss : 0.29852789133787155 TRAIN  loss dict:  {'mse_loss': 0.29852789133787155}
2024-05-02 18:50:18,038 [INFO] Step[650/1020]: training loss : 0.30448618173599246 TRAIN  loss dict:  {'mse_loss': 0.30448618173599246}
2024-05-02 18:51:18,533 [INFO] Step[700/1020]: training loss : 0.2960974341630936 TRAIN  loss dict:  {'mse_loss': 0.2960974341630936}
2024-05-02 18:52:21,939 [INFO] Step[750/1020]: training loss : 0.29447698801755906 TRAIN  loss dict:  {'mse_loss': 0.29447698801755906}
2024-05-02 18:53:21,185 [INFO] Step[800/1020]: training loss : 0.2840789559483528 TRAIN  loss dict:  {'mse_loss': 0.2840789559483528}
2024-05-02 18:54:23,644 [INFO] Step[850/1020]: training loss : 0.30092687845230104 TRAIN  loss dict:  {'mse_loss': 0.30092687845230104}
2024-05-02 18:55:28,444 [INFO] Step[900/1020]: training loss : 0.2959884193539619 TRAIN  loss dict:  {'mse_loss': 0.2959884193539619}
2024-05-02 18:56:35,507 [INFO] Step[950/1020]: training loss : 0.2982985612750053 TRAIN  loss dict:  {'mse_loss': 0.2982985612750053}
2024-05-02 18:57:46,179 [INFO] Step[1000/1020]: training loss : 0.3012381699681282 TRAIN  loss dict:  {'mse_loss': 0.3012381699681282}
2024-05-02 19:02:27,431 [INFO] Label accuracies statistics:
2024-05-02 19:02:27,437 [INFO] {0: 0.5, 1: 1.0, 2: 0.25, 3: 0.75, 4: 0.6666666666666666, 5: 0.75, 6: 0.25, 7: 0.75, 8: 0.0, 9: 0.75, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.5, 14: 0.25, 15: 0.75, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.75, 26: 1.0, 27: 0.75, 28: 0.25, 29: 0.5, 30: 0.75, 31: 0.5, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.0, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.5, 45: 1.0, 46: 1.0, 47: 0.5, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.25, 52: 0.25, 53: 0.25, 54: 0.5, 55: 0.5, 56: 0.75, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.0, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.75, 66: 0.5, 67: 1.0, 68: 0.5, 69: 0.25, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.5, 74: 0.5, 75: 1.0, 76: 0.25, 77: 0.25, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.5, 83: 0.5, 84: 0.25, 85: 1.0, 86: 0.25, 87: 0.5, 88: 0.6666666666666666, 89: 0.75, 90: 1.0, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.5, 101: 0.5, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.25, 106: 1.0, 107: 0.25, 108: 0.5, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.0, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.5, 120: 0.75, 121: 1.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 0.75, 130: 0.75, 131: 0.75, 132: 0.25, 133: 1.0, 134: 0.75, 135: 0.75, 136: 1.0, 137: 0.75, 138: 0.25, 139: 0.5, 140: 0.5, 141: 0.75, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.0, 146: 0.75, 147: 1.0, 148: 0.5, 149: 0.5, 150: 0.5, 151: 0.75, 152: 1.0, 153: 0.25, 154: 0.25, 155: 0.0, 156: 1.0, 157: 0.5, 158: 0.25, 159: 0.5, 160: 0.25, 161: 1.0, 162: 0.0, 163: 0.25, 164: 0.5, 165: 1.0, 166: 0.0, 167: 0.0, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.5, 173: 0.75, 174: 0.25, 175: 0.75, 176: 0.5, 177: 0.5, 178: 1.0, 179: 0.75, 180: 1.0, 181: 0.5, 182: 0.75, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.5, 196: 0.5, 197: 0.75, 198: 0.25}

2024-05-02 19:02:27,515 [INFO] [14] TRAIN  loss: 0.2969191078900122 acc: 0.0
2024-05-02 19:02:27,518 [INFO] [14] TRAIN  loss dict: {'mse_loss': 0.2969191078900122}
2024-05-02 19:02:27,522 [INFO] [14] VALIDATION loss: 1.7340140545910054 VALIDATION  acc: 0.6401515151515151
2024-05-02 19:02:27,523 [INFO] [14] VALIDATION  loss dict: {'mse_loss': 0.3035211025765448, 'classification_loss': 1.4304929502835178}
2024-05-02 19:02:27,526 [INFO] 
2024-05-02 19:04:15,184 [INFO] Step[50/1020]: training loss : 0.29657319247722624 TRAIN  loss dict:  {'mse_loss': 0.29657319247722624}
2024-05-02 19:05:17,543 [INFO] Step[100/1020]: training loss : 0.2940943172574043 TRAIN  loss dict:  {'mse_loss': 0.2940943172574043}
2024-05-02 19:06:23,392 [INFO] Step[150/1020]: training loss : 0.2915134960412979 TRAIN  loss dict:  {'mse_loss': 0.2915134960412979}
2024-05-02 19:07:24,348 [INFO] Step[200/1020]: training loss : 0.29607833832502367 TRAIN  loss dict:  {'mse_loss': 0.29607833832502367}
2024-05-02 19:08:22,113 [INFO] Step[250/1020]: training loss : 0.2897056952118874 TRAIN  loss dict:  {'mse_loss': 0.2897056952118874}
2024-05-02 19:09:24,491 [INFO] Step[300/1020]: training loss : 0.28930057764053346 TRAIN  loss dict:  {'mse_loss': 0.28930057764053346}
2024-05-02 19:10:25,238 [INFO] Step[350/1020]: training loss : 0.2879911783337593 TRAIN  loss dict:  {'mse_loss': 0.2879911783337593}
2024-05-02 19:11:24,669 [INFO] Step[400/1020]: training loss : 0.29590117633342744 TRAIN  loss dict:  {'mse_loss': 0.29590117633342744}
2024-05-02 19:12:32,116 [INFO] Step[450/1020]: training loss : 0.28531191259622574 TRAIN  loss dict:  {'mse_loss': 0.28531191259622574}
2024-05-02 19:13:29,956 [INFO] Step[500/1020]: training loss : 0.3001017236709595 TRAIN  loss dict:  {'mse_loss': 0.3001017236709595}
2024-05-02 19:14:26,316 [INFO] Step[550/1020]: training loss : 0.2955389153957367 TRAIN  loss dict:  {'mse_loss': 0.2955389153957367}
2024-05-02 19:15:09,217 [INFO] Step[600/1020]: training loss : 0.2905090290307999 TRAIN  loss dict:  {'mse_loss': 0.2905090290307999}
2024-05-02 19:16:14,612 [INFO] Step[650/1020]: training loss : 0.29270940721035005 TRAIN  loss dict:  {'mse_loss': 0.29270940721035005}
2024-05-02 19:17:23,762 [INFO] Step[700/1020]: training loss : 0.29492135375738143 TRAIN  loss dict:  {'mse_loss': 0.29492135375738143}
2024-05-02 19:18:34,259 [INFO] Step[750/1020]: training loss : 0.29326712965965274 TRAIN  loss dict:  {'mse_loss': 0.29326712965965274}
2024-05-02 19:19:40,592 [INFO] Step[800/1020]: training loss : 0.2957134953141212 TRAIN  loss dict:  {'mse_loss': 0.2957134953141212}
2024-05-02 19:20:44,209 [INFO] Step[850/1020]: training loss : 0.2993800711631775 TRAIN  loss dict:  {'mse_loss': 0.2993800711631775}
2024-05-02 19:21:36,737 [INFO] Step[900/1020]: training loss : 0.2926684719324112 TRAIN  loss dict:  {'mse_loss': 0.2926684719324112}
2024-05-02 19:22:31,599 [INFO] Step[950/1020]: training loss : 0.28512641876935957 TRAIN  loss dict:  {'mse_loss': 0.28512641876935957}
2024-05-02 19:23:29,690 [INFO] Step[1000/1020]: training loss : 0.2854159840941429 TRAIN  loss dict:  {'mse_loss': 0.2854159840941429}
2024-05-02 19:28:01,375 [INFO] Label accuracies statistics:
2024-05-02 19:28:01,377 [INFO] {0: 1.0, 1: 1.0, 2: 0.25, 3: 0.75, 4: 0.6666666666666666, 5: 0.75, 6: 0.0, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.5, 13: 0.5, 14: 0.25, 15: 0.5, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.5, 21: 0.25, 22: 0.75, 23: 0.5, 24: 0.5, 25: 0.5, 26: 1.0, 27: 0.75, 28: 0.5, 29: 0.5, 30: 0.75, 31: 0.5, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.0, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 0.75, 47: 0.75, 48: 0.75, 49: 0.5, 50: 1.0, 51: 0.5, 52: 0.25, 53: 0.0, 54: 0.25, 55: 0.25, 56: 0.5, 57: 0.75, 58: 0.75, 59: 0.5, 60: 0.25, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.5, 65: 0.25, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.0, 70: 0.75, 71: 0.75, 72: 0.75, 73: 0.25, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.0, 83: 1.0, 84: 0.5, 85: 1.0, 86: 0.25, 87: 0.0, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.75, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.5, 101: 0.75, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.0, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.25, 113: 0.25, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.75, 118: 0.75, 119: 0.75, 120: 0.5, 121: 1.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 0.75, 126: 0.75, 127: 1.0, 128: 1.0, 129: 0.75, 130: 0.75, 131: 0.75, 132: 0.25, 133: 0.75, 134: 1.0, 135: 0.75, 136: 0.75, 137: 0.75, 138: 0.5, 139: 0.25, 140: 0.5, 141: 0.5, 142: 0.75, 143: 0.5, 144: 1.0, 145: 0.5, 146: 0.75, 147: 1.0, 148: 0.25, 149: 0.5, 150: 0.5, 151: 0.75, 152: 0.75, 153: 0.25, 154: 0.25, 155: 0.0, 156: 0.75, 157: 0.5, 158: 0.75, 159: 0.5, 160: 0.0, 161: 1.0, 162: 0.5, 163: 0.25, 164: 0.25, 165: 1.0, 166: 0.25, 167: 0.5, 168: 0.25, 169: 0.75, 170: 1.0, 171: 0.0, 172: 0.5, 173: 0.75, 174: 0.25, 175: 1.0, 176: 0.0, 177: 0.5, 178: 0.75, 179: 1.0, 180: 1.0, 181: 0.5, 182: 0.75, 183: 0.5, 184: 0.5, 185: 0.75, 186: 0.25, 187: 0.75, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.5, 196: 0.75, 197: 0.75, 198: 0.25}

2024-05-02 19:28:08,602 [INFO] [15] TRAIN  loss: 0.2925744906213938 acc: 0.0
2024-05-02 19:28:08,604 [INFO] [15] TRAIN  loss dict: {'mse_loss': 0.2925744906213938}
2024-05-02 19:28:08,606 [INFO] [15] VALIDATION loss: 1.6679502532939718 VALIDATION  acc: 0.625
2024-05-02 19:28:08,608 [INFO] [15] VALIDATION  loss dict: {'mse_loss': 0.3004631277437162, 'classification_loss': 1.367487121561561}
2024-05-02 19:28:08,611 [INFO] 
2024-05-02 19:30:13,453 [INFO] Step[50/1020]: training loss : 0.28444838255643845 TRAIN  loss dict:  {'mse_loss': 0.28444838255643845}
2024-05-02 19:31:19,871 [INFO] Step[100/1020]: training loss : 0.28387509047985077 TRAIN  loss dict:  {'mse_loss': 0.28387509047985077}
2024-05-02 19:32:24,707 [INFO] Step[150/1020]: training loss : 0.2913541978597641 TRAIN  loss dict:  {'mse_loss': 0.2913541978597641}
2024-05-02 19:33:34,065 [INFO] Step[200/1020]: training loss : 0.28448782205581663 TRAIN  loss dict:  {'mse_loss': 0.28448782205581663}
2024-05-02 19:34:30,236 [INFO] Step[250/1020]: training loss : 0.2889730948209763 TRAIN  loss dict:  {'mse_loss': 0.2889730948209763}
2024-05-02 19:35:33,826 [INFO] Step[300/1020]: training loss : 0.29113785475492476 TRAIN  loss dict:  {'mse_loss': 0.29113785475492476}
2024-05-02 19:36:38,511 [INFO] Step[350/1020]: training loss : 0.2863692599534988 TRAIN  loss dict:  {'mse_loss': 0.2863692599534988}
2024-05-02 19:37:45,010 [INFO] Step[400/1020]: training loss : 0.2900954422354698 TRAIN  loss dict:  {'mse_loss': 0.2900954422354698}
2024-05-02 19:38:56,113 [INFO] Step[450/1020]: training loss : 0.2850117853283882 TRAIN  loss dict:  {'mse_loss': 0.2850117853283882}
2024-05-02 19:40:05,710 [INFO] Step[500/1020]: training loss : 0.28226209580898287 TRAIN  loss dict:  {'mse_loss': 0.28226209580898287}
2024-05-02 19:41:16,788 [INFO] Step[550/1020]: training loss : 0.29387018918991087 TRAIN  loss dict:  {'mse_loss': 0.29387018918991087}
2024-05-02 19:42:22,029 [INFO] Step[600/1020]: training loss : 0.2888368907570839 TRAIN  loss dict:  {'mse_loss': 0.2888368907570839}
2024-05-02 19:43:33,082 [INFO] Step[650/1020]: training loss : 0.2855871373414993 TRAIN  loss dict:  {'mse_loss': 0.2855871373414993}
2024-05-02 19:44:38,589 [INFO] Step[700/1020]: training loss : 0.2837589892745018 TRAIN  loss dict:  {'mse_loss': 0.2837589892745018}
2024-05-02 19:45:45,127 [INFO] Step[750/1020]: training loss : 0.2799153766036034 TRAIN  loss dict:  {'mse_loss': 0.2799153766036034}
2024-05-02 19:46:49,273 [INFO] Step[800/1020]: training loss : 0.281644678413868 TRAIN  loss dict:  {'mse_loss': 0.281644678413868}
2024-05-02 19:47:53,544 [INFO] Step[850/1020]: training loss : 0.28890262424945834 TRAIN  loss dict:  {'mse_loss': 0.28890262424945834}
2024-05-02 19:49:00,090 [INFO] Step[900/1020]: training loss : 0.2950125169754028 TRAIN  loss dict:  {'mse_loss': 0.2950125169754028}
2024-05-02 19:50:09,398 [INFO] Step[950/1020]: training loss : 0.2895680126547813 TRAIN  loss dict:  {'mse_loss': 0.2895680126547813}
2024-05-02 19:51:21,331 [INFO] Step[1000/1020]: training loss : 0.29301138579845426 TRAIN  loss dict:  {'mse_loss': 0.29301138579845426}
2024-05-02 19:56:25,537 [INFO] Label accuracies statistics:
2024-05-02 19:56:25,548 [INFO] {0: 0.5, 1: 1.0, 2: 0.25, 3: 0.75, 4: 0.3333333333333333, 5: 0.75, 6: 0.0, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.0, 14: 0.5, 15: 0.5, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.5, 22: 0.75, 23: 0.75, 24: 0.5, 25: 0.75, 26: 1.0, 27: 0.75, 28: 0.5, 29: 0.5, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.0, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 1.0, 51: 0.5, 52: 0.25, 53: 0.0, 54: 0.0, 55: 0.5, 56: 0.5, 57: 0.75, 58: 0.75, 59: 0.5, 60: 0.25, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.5, 65: 0.5, 66: 0.75, 67: 1.0, 68: 0.75, 69: 0.0, 70: 0.5, 71: 0.75, 72: 1.0, 73: 0.25, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.5, 83: 0.75, 84: 0.75, 85: 1.0, 86: 0.25, 87: 0.25, 88: 0.3333333333333333, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.0, 95: 0.75, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.5, 101: 0.75, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.0, 106: 1.0, 107: 1.0, 108: 0.5, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.0, 113: 0.25, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.75, 118: 0.75, 119: 0.75, 120: 0.75, 121: 0.75, 122: 0.5, 123: 0.75, 124: 1.0, 125: 0.75, 126: 0.75, 127: 0.75, 128: 1.0, 129: 0.75, 130: 0.75, 131: 0.75, 132: 0.5, 133: 1.0, 134: 0.75, 135: 0.75, 136: 0.75, 137: 0.75, 138: 0.25, 139: 0.25, 140: 0.75, 141: 0.75, 142: 0.25, 143: 0.5, 144: 1.0, 145: 0.5, 146: 0.5, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 0.75, 152: 0.75, 153: 0.25, 154: 0.5, 155: 0.0, 156: 0.75, 157: 0.5, 158: 0.5, 159: 0.5, 160: 0.0, 161: 1.0, 162: 0.25, 163: 0.25, 164: 0.25, 165: 1.0, 166: 0.25, 167: 0.25, 168: 0.25, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.5, 173: 0.75, 174: 0.25, 175: 1.0, 176: 0.5, 177: 0.0, 178: 0.75, 179: 0.75, 180: 0.75, 181: 1.0, 182: 0.75, 183: 0.5, 184: 0.25, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.25, 196: 0.5, 197: 0.75, 198: 0.5}

2024-05-02 19:56:31,056 [INFO] [16] TRAIN  loss: 0.2875232412096332 acc: 0.0
2024-05-02 19:56:31,057 [INFO] [16] TRAIN  loss dict: {'mse_loss': 0.2875232412096332}
2024-05-02 19:56:31,059 [INFO] [16] VALIDATION loss: 1.654176358622734 VALIDATION  acc: 0.6363636363636364
2024-05-02 19:56:31,061 [INFO] [16] VALIDATION  loss dict: {'mse_loss': 0.2950012646991797, 'classification_loss': 1.3591750904616684}
2024-05-02 19:56:31,063 [INFO] 
2024-05-02 19:58:48,741 [INFO] Step[50/1020]: training loss : 0.2807474333047867 TRAIN  loss dict:  {'mse_loss': 0.2807474333047867}
2024-05-02 19:59:34,636 [INFO] Step[100/1020]: training loss : 0.2840999123454094 TRAIN  loss dict:  {'mse_loss': 0.2840999123454094}
2024-05-02 20:00:19,684 [INFO] Step[150/1020]: training loss : 0.2776918444037437 TRAIN  loss dict:  {'mse_loss': 0.2776918444037437}
2024-05-02 20:01:35,761 [INFO] Step[200/1020]: training loss : 0.28280494719743726 TRAIN  loss dict:  {'mse_loss': 0.28280494719743726}
2024-05-02 20:02:36,427 [INFO] Step[250/1020]: training loss : 0.2818995088338852 TRAIN  loss dict:  {'mse_loss': 0.2818995088338852}
2024-05-02 20:03:49,227 [INFO] Step[300/1020]: training loss : 0.2848412376642227 TRAIN  loss dict:  {'mse_loss': 0.2848412376642227}
2024-05-02 20:04:57,131 [INFO] Step[350/1020]: training loss : 0.29055361956357956 TRAIN  loss dict:  {'mse_loss': 0.29055361956357956}
2024-05-02 20:05:56,537 [INFO] Step[400/1020]: training loss : 0.28410455644130705 TRAIN  loss dict:  {'mse_loss': 0.28410455644130705}
2024-05-02 20:06:47,597 [INFO] Step[450/1020]: training loss : 0.2789740219712257 TRAIN  loss dict:  {'mse_loss': 0.2789740219712257}
2024-05-02 20:07:54,205 [INFO] Step[500/1020]: training loss : 0.2829825383424759 TRAIN  loss dict:  {'mse_loss': 0.2829825383424759}
2024-05-02 20:08:53,036 [INFO] Step[550/1020]: training loss : 0.2883362132310867 TRAIN  loss dict:  {'mse_loss': 0.2883362132310867}
2024-05-02 20:09:56,104 [INFO] Step[600/1020]: training loss : 0.28479561805725095 TRAIN  loss dict:  {'mse_loss': 0.28479561805725095}
2024-05-02 20:10:59,776 [INFO] Step[650/1020]: training loss : 0.2857535833120346 TRAIN  loss dict:  {'mse_loss': 0.2857535833120346}
2024-05-02 20:12:02,031 [INFO] Step[700/1020]: training loss : 0.28150681883096695 TRAIN  loss dict:  {'mse_loss': 0.28150681883096695}
2024-05-02 20:13:02,365 [INFO] Step[750/1020]: training loss : 0.2801335313916206 TRAIN  loss dict:  {'mse_loss': 0.2801335313916206}
2024-05-02 20:14:05,745 [INFO] Step[800/1020]: training loss : 0.2852000117301941 TRAIN  loss dict:  {'mse_loss': 0.2852000117301941}
2024-05-02 20:15:09,862 [INFO] Step[850/1020]: training loss : 0.28209948778152466 TRAIN  loss dict:  {'mse_loss': 0.28209948778152466}
2024-05-02 20:16:12,790 [INFO] Step[900/1020]: training loss : 0.28525951474905015 TRAIN  loss dict:  {'mse_loss': 0.28525951474905015}
2024-05-02 20:17:15,131 [INFO] Step[950/1020]: training loss : 0.27986413151025774 TRAIN  loss dict:  {'mse_loss': 0.27986413151025774}
2024-05-02 20:18:15,376 [INFO] Step[1000/1020]: training loss : 0.2762021255493164 TRAIN  loss dict:  {'mse_loss': 0.2762021255493164}
2024-05-02 20:22:31,834 [INFO] Label accuracies statistics:
2024-05-02 20:22:31,836 [INFO] {0: 0.5, 1: 0.75, 2: 0.25, 3: 1.0, 4: 0.6666666666666666, 5: 0.75, 6: 0.25, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.5, 14: 0.25, 15: 0.5, 16: 0.25, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.75, 26: 0.75, 27: 1.0, 28: 0.5, 29: 1.0, 30: 0.75, 31: 0.5, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 0.0, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.75, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.25, 50: 1.0, 51: 0.5, 52: 0.25, 53: 0.25, 54: 0.25, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.25, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.25, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.0, 70: 0.75, 71: 0.25, 72: 1.0, 73: 0.5, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.5, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.0, 83: 0.75, 84: 0.75, 85: 1.0, 86: 0.25, 87: 0.0, 88: 0.6666666666666666, 89: 0.5, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.5, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.0, 106: 1.0, 107: 0.5, 108: 0.5, 109: 0.5, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 0.75, 119: 0.5, 120: 0.5, 121: 1.0, 122: 0.5, 123: 0.25, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 0.75, 129: 0.75, 130: 0.5, 131: 1.0, 132: 0.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.5, 139: 0.5, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.5, 144: 1.0, 145: 0.5, 146: 0.75, 147: 0.75, 148: 0.5, 149: 0.75, 150: 0.5, 151: 0.75, 152: 1.0, 153: 0.5, 154: 0.75, 155: 0.0, 156: 0.75, 157: 0.5, 158: 0.5, 159: 0.5, 160: 0.25, 161: 1.0, 162: 0.25, 163: 0.5, 164: 0.5, 165: 1.0, 166: 0.25, 167: 0.5, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.25, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.5, 180: 1.0, 181: 0.5, 182: 0.5, 183: 0.5, 184: 0.5, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.5, 196: 0.5, 197: 0.75, 198: 0.75}

2024-05-02 20:22:37,293 [INFO] [17] TRAIN  loss: 0.2829109837903696 acc: 0.0
2024-05-02 20:22:37,294 [INFO] [17] TRAIN  loss dict: {'mse_loss': 0.2829109837903696}
2024-05-02 20:22:37,295 [INFO] [17] VALIDATION loss: 1.616596157051096 VALIDATION  acc: 0.6553030303030303
2024-05-02 20:22:37,296 [INFO] [17] VALIDATION  loss dict: {'mse_loss': 0.29250072597554233, 'classification_loss': 1.3240954313389581}
2024-05-02 20:22:37,297 [INFO] 
2024-05-02 20:24:27,176 [INFO] Step[50/1020]: training loss : 0.2806894621253014 TRAIN  loss dict:  {'mse_loss': 0.2806894621253014}
2024-05-02 20:25:37,805 [INFO] Step[100/1020]: training loss : 0.2724900722503662 TRAIN  loss dict:  {'mse_loss': 0.2724900722503662}
2024-05-02 20:26:37,388 [INFO] Step[150/1020]: training loss : 0.2761072391271591 TRAIN  loss dict:  {'mse_loss': 0.2761072391271591}
2024-05-02 20:27:37,580 [INFO] Step[200/1020]: training loss : 0.27598402202129363 TRAIN  loss dict:  {'mse_loss': 0.27598402202129363}
2024-05-02 20:28:43,450 [INFO] Step[250/1020]: training loss : 0.28017420262098314 TRAIN  loss dict:  {'mse_loss': 0.28017420262098314}
2024-05-02 20:29:49,712 [INFO] Step[300/1020]: training loss : 0.2793909278512001 TRAIN  loss dict:  {'mse_loss': 0.2793909278512001}
2024-05-02 20:30:52,005 [INFO] Step[350/1020]: training loss : 0.27844531685113905 TRAIN  loss dict:  {'mse_loss': 0.27844531685113905}
2024-05-02 20:31:57,838 [INFO] Step[400/1020]: training loss : 0.2783203521370888 TRAIN  loss dict:  {'mse_loss': 0.2783203521370888}
2024-05-02 20:32:59,295 [INFO] Step[450/1020]: training loss : 0.2803794187307358 TRAIN  loss dict:  {'mse_loss': 0.2803794187307358}
2024-05-02 20:34:02,214 [INFO] Step[500/1020]: training loss : 0.2805509379506111 TRAIN  loss dict:  {'mse_loss': 0.2805509379506111}
2024-05-02 20:35:02,609 [INFO] Step[550/1020]: training loss : 0.2866368114948273 TRAIN  loss dict:  {'mse_loss': 0.2866368114948273}
2024-05-02 20:36:11,465 [INFO] Step[600/1020]: training loss : 0.2817430013418198 TRAIN  loss dict:  {'mse_loss': 0.2817430013418198}
2024-05-02 20:37:07,899 [INFO] Step[650/1020]: training loss : 0.2831641185283661 TRAIN  loss dict:  {'mse_loss': 0.2831641185283661}
2024-05-02 20:38:11,191 [INFO] Step[700/1020]: training loss : 0.2779231721162796 TRAIN  loss dict:  {'mse_loss': 0.2779231721162796}
2024-05-02 20:39:16,886 [INFO] Step[750/1020]: training loss : 0.28395975023508074 TRAIN  loss dict:  {'mse_loss': 0.28395975023508074}
2024-05-02 20:40:17,508 [INFO] Step[800/1020]: training loss : 0.2760530424118042 TRAIN  loss dict:  {'mse_loss': 0.2760530424118042}
2024-05-02 20:41:21,638 [INFO] Step[850/1020]: training loss : 0.2770961746573448 TRAIN  loss dict:  {'mse_loss': 0.2770961746573448}
2024-05-02 20:42:23,891 [INFO] Step[900/1020]: training loss : 0.27787985652685165 TRAIN  loss dict:  {'mse_loss': 0.27787985652685165}
2024-05-02 20:43:13,388 [INFO] Step[950/1020]: training loss : 0.27911363273859024 TRAIN  loss dict:  {'mse_loss': 0.27911363273859024}
2024-05-02 20:44:12,692 [INFO] Step[1000/1020]: training loss : 0.2805641907453537 TRAIN  loss dict:  {'mse_loss': 0.2805641907453537}
2024-05-02 20:49:05,401 [INFO] Label accuracies statistics:
2024-05-02 20:49:05,409 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.6666666666666666, 5: 0.75, 6: 0.25, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.75, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.25, 22: 1.0, 23: 0.5, 24: 0.5, 25: 0.5, 26: 1.0, 27: 1.0, 28: 0.5, 29: 0.5, 30: 0.75, 31: 0.5, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.25, 36: 0.75, 37: 0.0, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.5, 44: 0.5, 45: 1.0, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.25, 50: 1.0, 51: 0.5, 52: 0.25, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 0.75, 58: 0.75, 59: 0.75, 60: 0.25, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.5, 65: 0.25, 66: 0.25, 67: 1.0, 68: 0.5, 69: 0.25, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.25, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.25, 83: 0.75, 84: 0.5, 85: 1.0, 86: 0.25, 87: 0.5, 88: 0.6666666666666666, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.25, 101: 0.5, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.0, 106: 1.0, 107: 0.5, 108: 0.5, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.25, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.5, 118: 0.75, 119: 1.0, 120: 0.5, 121: 1.0, 122: 0.5, 123: 0.5, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 0.75, 130: 0.75, 131: 0.75, 132: 0.25, 133: 0.5, 134: 1.0, 135: 0.5, 136: 0.75, 137: 0.5, 138: 0.5, 139: 0.25, 140: 0.75, 141: 0.5, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.5, 146: 0.5, 147: 1.0, 148: 0.5, 149: 0.5, 150: 0.5, 151: 0.75, 152: 1.0, 153: 0.25, 154: 0.75, 155: 0.0, 156: 0.75, 157: 0.5, 158: 0.5, 159: 0.5, 160: 0.25, 161: 1.0, 162: 0.25, 163: 0.0, 164: 0.5, 165: 0.75, 166: 0.5, 167: 0.0, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.25, 175: 1.0, 176: 0.75, 177: 0.5, 178: 1.0, 179: 1.0, 180: 1.0, 181: 0.5, 182: 0.75, 183: 0.5, 184: 0.5, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.5, 196: 0.5, 197: 0.75, 198: 0.5}

2024-05-02 20:49:05,482 [INFO] [18] TRAIN  loss: 0.2792723221375662 acc: 0.0
2024-05-02 20:49:05,483 [INFO] [18] TRAIN  loss dict: {'mse_loss': 0.2792723221375662}
2024-05-02 20:49:05,483 [INFO] [18] VALIDATION loss: 1.6213707339884056 VALIDATION  acc: 0.6527777777777778
2024-05-02 20:49:05,483 [INFO] [18] VALIDATION  loss dict: {'mse_loss': 0.2913495265323706, 'classification_loss': 1.330021210447556}
2024-05-02 20:49:05,484 [INFO] 
2024-05-02 20:50:47,206 [INFO] Step[50/1020]: training loss : 0.2699606493115425 TRAIN  loss dict:  {'mse_loss': 0.2699606493115425}
2024-05-02 20:51:45,279 [INFO] Step[100/1020]: training loss : 0.2638126888871193 TRAIN  loss dict:  {'mse_loss': 0.2638126888871193}
2024-05-02 20:52:52,569 [INFO] Step[150/1020]: training loss : 0.2846828556060791 TRAIN  loss dict:  {'mse_loss': 0.2846828556060791}
2024-05-02 20:53:56,923 [INFO] Step[200/1020]: training loss : 0.2704732993245125 TRAIN  loss dict:  {'mse_loss': 0.2704732993245125}
2024-05-02 20:54:59,318 [INFO] Step[250/1020]: training loss : 0.27015120327472686 TRAIN  loss dict:  {'mse_loss': 0.27015120327472686}
2024-05-02 20:56:16,675 [INFO] Step[300/1020]: training loss : 0.2722108897566795 TRAIN  loss dict:  {'mse_loss': 0.2722108897566795}
2024-05-02 20:57:24,298 [INFO] Step[350/1020]: training loss : 0.26978078693151475 TRAIN  loss dict:  {'mse_loss': 0.26978078693151475}
2024-05-02 20:58:31,139 [INFO] Step[400/1020]: training loss : 0.27645952492952347 TRAIN  loss dict:  {'mse_loss': 0.27645952492952347}
2024-05-02 20:59:33,619 [INFO] Step[450/1020]: training loss : 0.2786502549052238 TRAIN  loss dict:  {'mse_loss': 0.2786502549052238}
2024-05-02 21:00:35,280 [INFO] Step[500/1020]: training loss : 0.26739507585763933 TRAIN  loss dict:  {'mse_loss': 0.26739507585763933}
2024-05-02 21:01:41,881 [INFO] Step[550/1020]: training loss : 0.2745576119422913 TRAIN  loss dict:  {'mse_loss': 0.2745576119422913}
2024-05-02 21:02:40,147 [INFO] Step[600/1020]: training loss : 0.2764581152796745 TRAIN  loss dict:  {'mse_loss': 0.2764581152796745}
2024-05-02 21:03:41,110 [INFO] Step[650/1020]: training loss : 0.27479457050561906 TRAIN  loss dict:  {'mse_loss': 0.27479457050561906}
2024-05-02 21:04:45,297 [INFO] Step[700/1020]: training loss : 0.28025626987218855 TRAIN  loss dict:  {'mse_loss': 0.28025626987218855}
2024-05-02 21:05:52,487 [INFO] Step[750/1020]: training loss : 0.277799913585186 TRAIN  loss dict:  {'mse_loss': 0.277799913585186}
2024-05-02 21:06:52,462 [INFO] Step[800/1020]: training loss : 0.28251640558242797 TRAIN  loss dict:  {'mse_loss': 0.28251640558242797}
2024-05-02 21:07:53,777 [INFO] Step[850/1020]: training loss : 0.2743161037564278 TRAIN  loss dict:  {'mse_loss': 0.2743161037564278}
2024-05-02 21:08:56,952 [INFO] Step[900/1020]: training loss : 0.2772444024682045 TRAIN  loss dict:  {'mse_loss': 0.2772444024682045}
2024-05-02 21:09:58,823 [INFO] Step[950/1020]: training loss : 0.27005219101905825 TRAIN  loss dict:  {'mse_loss': 0.27005219101905825}
2024-05-02 21:11:01,475 [INFO] Step[1000/1020]: training loss : 0.26282209426164627 TRAIN  loss dict:  {'mse_loss': 0.26282209426164627}
2024-05-02 21:15:24,899 [INFO] Label accuracies statistics:
2024-05-02 21:15:24,900 [INFO] {0: 0.5, 1: 1.0, 2: 0.25, 3: 1.0, 4: 0.3333333333333333, 5: 0.5, 6: 0.0, 7: 1.0, 8: 0.0, 9: 0.75, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.75, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.25, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.75, 26: 0.75, 27: 1.0, 28: 0.5, 29: 0.75, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.0, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 0.75, 47: 0.5, 48: 0.75, 49: 0.5, 50: 1.0, 51: 0.75, 52: 0.25, 53: 0.0, 54: 0.5, 55: 0.5, 56: 0.5, 57: 0.75, 58: 0.75, 59: 0.5, 60: 0.25, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.75, 66: 0.75, 67: 1.0, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.25, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.25, 83: 1.0, 84: 0.5, 85: 1.0, 86: 0.25, 87: 0.75, 88: 0.6666666666666666, 89: 0.5, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.5, 94: 0.25, 95: 0.75, 96: 0.75, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.5, 101: 0.75, 102: 0.5, 103: 0.5, 104: 1.0, 105: 0.0, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.5, 110: 1.0, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.5, 118: 0.75, 119: 0.75, 120: 0.5, 121: 1.0, 122: 0.5, 123: 0.5, 124: 0.75, 125: 0.75, 126: 0.75, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.5, 133: 0.75, 134: 0.75, 135: 0.75, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.25, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.5, 144: 1.0, 145: 0.5, 146: 0.5, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 0.5, 152: 1.0, 153: 0.5, 154: 0.75, 155: 0.0, 156: 0.75, 157: 0.5, 158: 0.5, 159: 0.5, 160: 0.0, 161: 1.0, 162: 0.0, 163: 0.5, 164: 0.5, 165: 0.75, 166: 0.5, 167: 0.25, 168: 0.25, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.25, 175: 1.0, 176: 0.75, 177: 0.25, 178: 1.0, 179: 0.75, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.25, 185: 0.75, 186: 0.75, 187: 0.75, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.5, 196: 0.75, 197: 0.75, 198: 0.25}

2024-05-02 21:15:37,014 [INFO] [19] TRAIN  loss: 0.27393801993891304 acc: 0.0
2024-05-02 21:15:37,014 [INFO] [19] TRAIN  loss dict: {'mse_loss': 0.27393801993891304}
2024-05-02 21:15:37,015 [INFO] [19] VALIDATION loss: 1.5573280924799466 VALIDATION  acc: 0.6616161616161617
2024-05-02 21:15:37,015 [INFO] [19] VALIDATION  loss dict: {'mse_loss': 0.28624694350391927, 'classification_loss': 1.2710811454012538}
2024-05-02 21:15:37,015 [INFO] 
2024-05-02 21:17:05,850 [INFO] Step[50/1020]: training loss : 0.27184035778045657 TRAIN  loss dict:  {'mse_loss': 0.27184035778045657}
2024-05-02 21:17:51,362 [INFO] Step[100/1020]: training loss : 0.2695043683052063 TRAIN  loss dict:  {'mse_loss': 0.2695043683052063}
2024-05-02 21:18:30,952 [INFO] Step[150/1020]: training loss : 0.269510435461998 TRAIN  loss dict:  {'mse_loss': 0.269510435461998}
2024-05-02 21:19:16,057 [INFO] Step[200/1020]: training loss : 0.2729581606388092 TRAIN  loss dict:  {'mse_loss': 0.2729581606388092}
2024-05-02 21:19:56,220 [INFO] Step[250/1020]: training loss : 0.266782291829586 TRAIN  loss dict:  {'mse_loss': 0.266782291829586}
2024-05-02 21:20:41,625 [INFO] Step[300/1020]: training loss : 0.27192759692668916 TRAIN  loss dict:  {'mse_loss': 0.27192759692668916}
2024-05-02 21:21:20,766 [INFO] Step[350/1020]: training loss : 0.2753233018517494 TRAIN  loss dict:  {'mse_loss': 0.2753233018517494}
2024-05-02 21:21:58,537 [INFO] Step[400/1020]: training loss : 0.2702956771850586 TRAIN  loss dict:  {'mse_loss': 0.2702956771850586}
2024-05-02 21:22:38,925 [INFO] Step[450/1020]: training loss : 0.2773244631290436 TRAIN  loss dict:  {'mse_loss': 0.2773244631290436}
2024-05-02 21:23:17,273 [INFO] Step[500/1020]: training loss : 0.27058143496513365 TRAIN  loss dict:  {'mse_loss': 0.27058143496513365}
2024-05-02 21:23:56,081 [INFO] Step[550/1020]: training loss : 0.2729783058166504 TRAIN  loss dict:  {'mse_loss': 0.2729783058166504}
2024-05-02 21:24:34,416 [INFO] Step[600/1020]: training loss : 0.26655081123113633 TRAIN  loss dict:  {'mse_loss': 0.26655081123113633}
2024-05-02 21:25:13,923 [INFO] Step[650/1020]: training loss : 0.2698308730125427 TRAIN  loss dict:  {'mse_loss': 0.2698308730125427}
2024-05-02 21:25:54,589 [INFO] Step[700/1020]: training loss : 0.27700537085533145 TRAIN  loss dict:  {'mse_loss': 0.27700537085533145}
2024-05-02 21:26:34,452 [INFO] Step[750/1020]: training loss : 0.26389754831790924 TRAIN  loss dict:  {'mse_loss': 0.26389754831790924}
2024-05-02 21:27:15,471 [INFO] Step[800/1020]: training loss : 0.2671899831295013 TRAIN  loss dict:  {'mse_loss': 0.2671899831295013}
2024-05-02 21:27:58,276 [INFO] Step[850/1020]: training loss : 0.26646270662546157 TRAIN  loss dict:  {'mse_loss': 0.26646270662546157}
2024-05-02 21:28:37,004 [INFO] Step[900/1020]: training loss : 0.2685732182860374 TRAIN  loss dict:  {'mse_loss': 0.2685732182860374}
2024-05-02 21:29:16,286 [INFO] Step[950/1020]: training loss : 0.27355958223342897 TRAIN  loss dict:  {'mse_loss': 0.27355958223342897}
2024-05-02 21:29:55,231 [INFO] Step[1000/1020]: training loss : 0.2678884598612785 TRAIN  loss dict:  {'mse_loss': 0.2678884598612785}
2024-05-02 21:32:54,111 [INFO] Label accuracies statistics:
2024-05-02 21:32:54,111 [INFO] {0: 1.0, 1: 0.75, 2: 0.25, 3: 0.75, 4: 0.6666666666666666, 5: 0.75, 6: 0.25, 7: 1.0, 8: 0.0, 9: 0.75, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.5, 16: 0.75, 17: 0.75, 18: 0.5, 19: 0.5, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.5, 29: 1.0, 30: 0.75, 31: 0.5, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.0, 38: 0.5, 39: 0.75, 40: 0.75, 41: 0.75, 42: 1.0, 43: 0.75, 44: 0.75, 45: 1.0, 46: 0.75, 47: 0.5, 48: 0.75, 49: 0.25, 50: 1.0, 51: 0.75, 52: 0.25, 53: 0.0, 54: 0.5, 55: 0.75, 56: 0.25, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.25, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.5, 66: 0.75, 67: 1.0, 68: 0.75, 69: 0.25, 70: 0.5, 71: 0.5, 72: 1.0, 73: 0.5, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.5, 83: 1.0, 84: 0.5, 85: 1.0, 86: 0.25, 87: 0.5, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.5, 101: 0.75, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.5, 109: 0.25, 110: 1.0, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.5, 118: 0.75, 119: 0.75, 120: 0.5, 121: 0.75, 122: 0.5, 123: 0.5, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.25, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.5, 146: 0.75, 147: 1.0, 148: 0.0, 149: 0.5, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.5, 154: 0.25, 155: 0.5, 156: 0.75, 157: 0.5, 158: 0.75, 159: 0.5, 160: 0.25, 161: 1.0, 162: 0.25, 163: 0.5, 164: 0.5, 165: 0.75, 166: 0.5, 167: 0.5, 168: 0.25, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.5, 175: 1.0, 176: 0.5, 177: 0.5, 178: 1.0, 179: 1.0, 180: 1.0, 181: 0.75, 182: 0.75, 183: 0.5, 184: 0.5, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.5, 196: 0.5, 197: 0.75, 198: 0.25}

2024-05-02 21:32:57,839 [INFO] [20] TRAIN  loss: 0.2704771436604799 acc: 0.0
2024-05-02 21:32:57,839 [INFO] [20] TRAIN  loss dict: {'mse_loss': 0.2704771436604799}
2024-05-02 21:32:57,840 [INFO] [20] VALIDATION loss: 1.5055548881340508 VALIDATION  acc: 0.6792929292929293
2024-05-02 21:32:57,840 [INFO] [20] VALIDATION  loss dict: {'mse_loss': 0.28103687298117264, 'classification_loss': 1.2245180098471617}
2024-05-02 21:32:57,840 [INFO] 
2024-05-02 21:34:07,339 [INFO] Step[50/1020]: training loss : 0.26043760538101196 TRAIN  loss dict:  {'mse_loss': 0.26043760538101196}
2024-05-02 21:34:45,007 [INFO] Step[100/1020]: training loss : 0.2678507277369499 TRAIN  loss dict:  {'mse_loss': 0.2678507277369499}
2024-05-02 21:35:25,377 [INFO] Step[150/1020]: training loss : 0.26105732321739195 TRAIN  loss dict:  {'mse_loss': 0.26105732321739195}
2024-05-02 21:36:07,430 [INFO] Step[200/1020]: training loss : 0.25994153171777723 TRAIN  loss dict:  {'mse_loss': 0.25994153171777723}
2024-05-02 21:36:46,755 [INFO] Step[250/1020]: training loss : 0.25481827825307846 TRAIN  loss dict:  {'mse_loss': 0.25481827825307846}
2024-05-02 21:37:26,875 [INFO] Step[300/1020]: training loss : 0.2611342689394951 TRAIN  loss dict:  {'mse_loss': 0.2611342689394951}
2024-05-02 21:38:08,635 [INFO] Step[350/1020]: training loss : 0.261465870141983 TRAIN  loss dict:  {'mse_loss': 0.261465870141983}
2024-05-02 21:38:43,349 [INFO] Step[400/1020]: training loss : 0.2678828951716423 TRAIN  loss dict:  {'mse_loss': 0.2678828951716423}
2024-05-02 21:39:22,844 [INFO] Step[450/1020]: training loss : 0.26342622220516204 TRAIN  loss dict:  {'mse_loss': 0.26342622220516204}
2024-05-02 21:39:59,214 [INFO] Step[500/1020]: training loss : 0.2662304389476776 TRAIN  loss dict:  {'mse_loss': 0.2662304389476776}
2024-05-02 21:40:38,281 [INFO] Step[550/1020]: training loss : 0.259838602244854 TRAIN  loss dict:  {'mse_loss': 0.259838602244854}
2024-05-02 21:41:17,629 [INFO] Step[600/1020]: training loss : 0.26431996017694476 TRAIN  loss dict:  {'mse_loss': 0.26431996017694476}
2024-05-02 21:41:55,025 [INFO] Step[650/1020]: training loss : 0.2598545989394188 TRAIN  loss dict:  {'mse_loss': 0.2598545989394188}
2024-05-02 21:42:34,489 [INFO] Step[700/1020]: training loss : 0.26680185526609423 TRAIN  loss dict:  {'mse_loss': 0.26680185526609423}
2024-05-02 21:43:18,043 [INFO] Step[750/1020]: training loss : 0.258328994512558 TRAIN  loss dict:  {'mse_loss': 0.258328994512558}
2024-05-02 21:43:54,550 [INFO] Step[800/1020]: training loss : 0.2592703938484192 TRAIN  loss dict:  {'mse_loss': 0.2592703938484192}
2024-05-02 21:44:30,943 [INFO] Step[850/1020]: training loss : 0.25879603207111357 TRAIN  loss dict:  {'mse_loss': 0.25879603207111357}
2024-05-02 21:45:12,895 [INFO] Step[900/1020]: training loss : 0.26506781846284866 TRAIN  loss dict:  {'mse_loss': 0.26506781846284866}
2024-05-02 21:45:50,052 [INFO] Step[950/1020]: training loss : 0.26109956741333007 TRAIN  loss dict:  {'mse_loss': 0.26109956741333007}
2024-05-02 21:46:29,714 [INFO] Step[1000/1020]: training loss : 0.26500082552433013 TRAIN  loss dict:  {'mse_loss': 0.26500082552433013}
2024-05-02 21:49:25,962 [INFO] Label accuracies statistics:
2024-05-02 21:49:25,962 [INFO] {0: 0.5, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.6666666666666666, 5: 0.5, 6: 0.0, 7: 1.0, 8: 0.0, 9: 0.75, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.5, 14: 0.25, 15: 0.75, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.25, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.5, 26: 1.0, 27: 1.0, 28: 0.5, 29: 0.75, 30: 0.75, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.0, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.5, 45: 1.0, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 1.0, 51: 0.5, 52: 0.25, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.5, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.5, 66: 0.5, 67: 1.0, 68: 0.75, 69: 0.5, 70: 0.5, 71: 0.75, 72: 1.0, 73: 0.5, 74: 0.25, 75: 1.0, 76: 0.5, 77: 0.5, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.5, 83: 0.75, 84: 0.5, 85: 1.0, 86: 0.25, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.5, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.5, 101: 0.75, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.5, 117: 0.5, 118: 1.0, 119: 0.5, 120: 0.5, 121: 1.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.5, 133: 1.0, 134: 0.75, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.5, 139: 0.5, 140: 0.75, 141: 0.75, 142: 1.0, 143: 0.75, 144: 0.75, 145: 0.75, 146: 0.5, 147: 0.75, 148: 0.25, 149: 0.75, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.75, 154: 0.75, 155: 0.25, 156: 0.75, 157: 0.5, 158: 0.25, 159: 0.5, 160: 0.25, 161: 1.0, 162: 0.25, 163: 0.25, 164: 0.75, 165: 0.75, 166: 0.5, 167: 0.5, 168: 0.25, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.25, 175: 1.0, 176: 0.5, 177: 0.0, 178: 1.0, 179: 1.0, 180: 1.0, 181: 0.5, 182: 0.75, 183: 1.0, 184: 0.5, 185: 0.75, 186: 0.25, 187: 0.75, 188: 0.5, 189: 0.5, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.75, 196: 0.5, 197: 1.0, 198: 0.5}

2024-05-02 21:49:29,737 [INFO] [21] TRAIN  loss: 0.262164072911529 acc: 0.0
2024-05-02 21:49:29,737 [INFO] [21] TRAIN  loss dict: {'mse_loss': 0.262164072911529}
2024-05-02 21:49:29,737 [INFO] [21] VALIDATION loss: 1.4922351311854642 VALIDATION  acc: 0.6830808080808081
2024-05-02 21:49:29,737 [INFO] [21] VALIDATION  loss dict: {'mse_loss': 0.2808157816679791, 'classification_loss': 1.2114193466576664}
2024-05-02 21:49:29,738 [INFO] 
2024-05-02 21:50:36,853 [INFO] Step[50/1020]: training loss : 0.26661373287439344 TRAIN  loss dict:  {'mse_loss': 0.26661373287439344}
2024-05-02 21:51:14,685 [INFO] Step[100/1020]: training loss : 0.26386192947626114 TRAIN  loss dict:  {'mse_loss': 0.26386192947626114}
2024-05-02 21:51:52,492 [INFO] Step[150/1020]: training loss : 0.25644289314746854 TRAIN  loss dict:  {'mse_loss': 0.25644289314746854}
2024-05-02 21:52:33,082 [INFO] Step[200/1020]: training loss : 0.2512716028094292 TRAIN  loss dict:  {'mse_loss': 0.2512716028094292}
2024-05-02 21:53:13,804 [INFO] Step[250/1020]: training loss : 0.2690614718198776 TRAIN  loss dict:  {'mse_loss': 0.2690614718198776}
2024-05-02 21:53:54,352 [INFO] Step[300/1020]: training loss : 0.263003930747509 TRAIN  loss dict:  {'mse_loss': 0.263003930747509}
2024-05-02 21:54:33,684 [INFO] Step[350/1020]: training loss : 0.26690763682127 TRAIN  loss dict:  {'mse_loss': 0.26690763682127}
2024-05-02 21:55:14,245 [INFO] Step[400/1020]: training loss : 0.25762016892433165 TRAIN  loss dict:  {'mse_loss': 0.25762016892433165}
2024-05-02 21:55:50,892 [INFO] Step[450/1020]: training loss : 0.26181211322546005 TRAIN  loss dict:  {'mse_loss': 0.26181211322546005}
2024-05-02 21:56:30,475 [INFO] Step[500/1020]: training loss : 0.26545913726091386 TRAIN  loss dict:  {'mse_loss': 0.26545913726091386}
2024-05-02 21:57:08,839 [INFO] Step[550/1020]: training loss : 0.2614660146832466 TRAIN  loss dict:  {'mse_loss': 0.2614660146832466}
2024-05-02 21:57:47,549 [INFO] Step[600/1020]: training loss : 0.26044290959835054 TRAIN  loss dict:  {'mse_loss': 0.26044290959835054}
2024-05-02 21:58:29,738 [INFO] Step[650/1020]: training loss : 0.2523024940490723 TRAIN  loss dict:  {'mse_loss': 0.2523024940490723}
2024-05-02 21:59:06,941 [INFO] Step[700/1020]: training loss : 0.2619930285215378 TRAIN  loss dict:  {'mse_loss': 0.2619930285215378}
2024-05-02 21:59:45,952 [INFO] Step[750/1020]: training loss : 0.2523810908198357 TRAIN  loss dict:  {'mse_loss': 0.2523810908198357}
2024-05-02 22:00:27,894 [INFO] Step[800/1020]: training loss : 0.2620297646522522 TRAIN  loss dict:  {'mse_loss': 0.2620297646522522}
2024-05-02 22:01:06,279 [INFO] Step[850/1020]: training loss : 0.26710650950670245 TRAIN  loss dict:  {'mse_loss': 0.26710650950670245}
2024-05-02 22:01:48,911 [INFO] Step[900/1020]: training loss : 0.26217267036437986 TRAIN  loss dict:  {'mse_loss': 0.26217267036437986}
2024-05-02 22:02:28,053 [INFO] Step[950/1020]: training loss : 0.2612695822119713 TRAIN  loss dict:  {'mse_loss': 0.2612695822119713}
2024-05-02 22:03:07,345 [INFO] Step[1000/1020]: training loss : 0.2641228085756302 TRAIN  loss dict:  {'mse_loss': 0.2641228085756302}
2024-05-02 22:05:59,402 [INFO] Label accuracies statistics:
2024-05-02 22:05:59,402 [INFO] {0: 0.5, 1: 1.0, 2: 0.0, 3: 0.75, 4: 0.6666666666666666, 5: 0.75, 6: 0.0, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.5, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.5, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.75, 29: 1.0, 30: 0.75, 31: 1.0, 32: 1.0, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.75, 37: 0.0, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 0.5, 47: 0.75, 48: 0.75, 49: 0.75, 50: 1.0, 51: 0.5, 52: 0.0, 53: 0.25, 54: 0.25, 55: 0.5, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.25, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.5, 65: 0.75, 66: 0.75, 67: 1.0, 68: 0.75, 69: 0.0, 70: 0.5, 71: 0.75, 72: 0.75, 73: 0.25, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.5, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.75, 83: 0.75, 84: 0.75, 85: 1.0, 86: 0.25, 87: 0.5, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.5, 103: 0.75, 104: 1.0, 105: 0.25, 106: 1.0, 107: 1.0, 108: 0.5, 109: 0.5, 110: 1.0, 111: 0.75, 112: 0.25, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.5, 120: 0.5, 121: 1.0, 122: 0.5, 123: 0.5, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.5, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.25, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.75, 145: 1.0, 146: 0.5, 147: 1.0, 148: 0.25, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.25, 154: 0.75, 155: 0.5, 156: 1.0, 157: 0.5, 158: 0.25, 159: 0.5, 160: 0.0, 161: 1.0, 162: 0.25, 163: 0.25, 164: 0.75, 165: 1.0, 166: 0.5, 167: 0.25, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.25, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 0.75, 182: 0.75, 183: 0.5, 184: 0.25, 185: 0.75, 186: 0.25, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.25, 196: 0.75, 197: 0.5, 198: 0.5}

2024-05-02 22:06:03,147 [INFO] [22] TRAIN  loss: 0.26146053251098184 acc: 0.0
2024-05-02 22:06:03,147 [INFO] [22] TRAIN  loss dict: {'mse_loss': 0.26146053251098184}
2024-05-02 22:06:03,148 [INFO] [22] VALIDATION loss: 1.4696464288716364 VALIDATION  acc: 0.6805555555555556
2024-05-02 22:06:03,148 [INFO] [22] VALIDATION  loss dict: {'mse_loss': 0.2768199686149154, 'classification_loss': 1.1928264590525868}
2024-05-02 22:06:03,148 [INFO] 
2024-05-02 22:07:13,035 [INFO] Step[50/1020]: training loss : 0.25740633577108385 TRAIN  loss dict:  {'mse_loss': 0.25740633577108385}
2024-05-02 22:07:49,347 [INFO] Step[100/1020]: training loss : 0.2567701706290245 TRAIN  loss dict:  {'mse_loss': 0.2567701706290245}
2024-05-02 22:08:27,639 [INFO] Step[150/1020]: training loss : 0.26654204428195954 TRAIN  loss dict:  {'mse_loss': 0.26654204428195954}
2024-05-02 22:09:08,115 [INFO] Step[200/1020]: training loss : 0.2632626378536224 TRAIN  loss dict:  {'mse_loss': 0.2632626378536224}
2024-05-02 22:09:46,863 [INFO] Step[250/1020]: training loss : 0.2610118895769119 TRAIN  loss dict:  {'mse_loss': 0.2610118895769119}
2024-05-02 22:10:24,647 [INFO] Step[300/1020]: training loss : 0.24884879171848298 TRAIN  loss dict:  {'mse_loss': 0.24884879171848298}
2024-05-02 22:11:06,197 [INFO] Step[350/1020]: training loss : 0.2592687013745308 TRAIN  loss dict:  {'mse_loss': 0.2592687013745308}
2024-05-02 22:11:44,188 [INFO] Step[400/1020]: training loss : 0.2578822809457779 TRAIN  loss dict:  {'mse_loss': 0.2578822809457779}
2024-05-02 22:12:24,470 [INFO] Step[450/1020]: training loss : 0.26333219826221466 TRAIN  loss dict:  {'mse_loss': 0.26333219826221466}
2024-05-02 22:13:02,705 [INFO] Step[500/1020]: training loss : 0.26333927899599074 TRAIN  loss dict:  {'mse_loss': 0.26333927899599074}
2024-05-02 22:13:44,134 [INFO] Step[550/1020]: training loss : 0.2541993322968483 TRAIN  loss dict:  {'mse_loss': 0.2541993322968483}
2024-05-02 22:14:23,858 [INFO] Step[600/1020]: training loss : 0.25525634080171583 TRAIN  loss dict:  {'mse_loss': 0.25525634080171583}
2024-05-02 22:15:02,953 [INFO] Step[650/1020]: training loss : 0.25675666898488997 TRAIN  loss dict:  {'mse_loss': 0.25675666898488997}
2024-05-02 22:15:42,428 [INFO] Step[700/1020]: training loss : 0.253464934527874 TRAIN  loss dict:  {'mse_loss': 0.253464934527874}
2024-05-02 22:16:22,531 [INFO] Step[750/1020]: training loss : 0.25548005878925323 TRAIN  loss dict:  {'mse_loss': 0.25548005878925323}
2024-05-02 22:16:55,395 [INFO] Step[800/1020]: training loss : 0.2577775377035141 TRAIN  loss dict:  {'mse_loss': 0.2577775377035141}
2024-05-02 22:17:35,090 [INFO] Step[850/1020]: training loss : 0.25360038310289384 TRAIN  loss dict:  {'mse_loss': 0.25360038310289384}
2024-05-02 22:18:16,958 [INFO] Step[900/1020]: training loss : 0.26672758400440216 TRAIN  loss dict:  {'mse_loss': 0.26672758400440216}
2024-05-02 22:18:56,669 [INFO] Step[950/1020]: training loss : 0.25956151992082593 TRAIN  loss dict:  {'mse_loss': 0.25956151992082593}
2024-05-02 22:19:39,443 [INFO] Step[1000/1020]: training loss : 0.26062765300273893 TRAIN  loss dict:  {'mse_loss': 0.26062765300273893}
2024-05-02 22:22:30,125 [INFO] Label accuracies statistics:
2024-05-02 22:22:30,125 [INFO] {0: 0.5, 1: 0.75, 2: 0.5, 3: 0.75, 4: 0.6666666666666666, 5: 0.5, 6: 0.0, 7: 1.0, 8: 0.0, 9: 0.75, 10: 1.0, 11: 1.0, 12: 0.5, 13: 0.5, 14: 0.0, 15: 0.75, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 1.0, 23: 0.5, 24: 0.5, 25: 0.5, 26: 1.0, 27: 1.0, 28: 0.5, 29: 0.5, 30: 0.75, 31: 0.5, 32: 1.0, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.5, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 0.75, 47: 0.75, 48: 0.75, 49: 0.75, 50: 1.0, 51: 0.5, 52: 0.25, 53: 0.0, 54: 0.5, 55: 0.5, 56: 0.5, 57: 0.75, 58: 0.75, 59: 0.5, 60: 0.5, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.75, 66: 0.5, 67: 1.0, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.5, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.25, 83: 0.75, 84: 0.5, 85: 1.0, 86: 0.5, 87: 0.5, 88: 0.6666666666666666, 89: 0.75, 90: 0.25, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.75, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.5, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.5, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 0.75, 119: 0.5, 120: 0.75, 121: 1.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.0, 133: 1.0, 134: 0.75, 135: 0.75, 136: 0.75, 137: 0.5, 138: 0.5, 139: 0.25, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.5, 144: 0.75, 145: 0.5, 146: 0.5, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.0, 156: 0.75, 157: 0.5, 158: 0.25, 159: 0.75, 160: 0.0, 161: 1.0, 162: 0.25, 163: 0.25, 164: 0.5, 165: 1.0, 166: 0.5, 167: 0.25, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 0.5, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 0.75, 181: 0.5, 182: 0.5, 183: 1.0, 184: 0.5, 185: 0.75, 186: 0.75, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.5, 196: 0.5, 197: 1.0, 198: 0.75}

2024-05-02 22:22:30,154 [INFO] [23] TRAIN  loss: 0.2584894663855141 acc: 0.0
2024-05-02 22:22:30,154 [INFO] [23] TRAIN  loss dict: {'mse_loss': 0.2584894663855141}
2024-05-02 22:22:30,155 [INFO] [23] VALIDATION loss: 1.470098391927854 VALIDATION  acc: 0.6843434343434344
2024-05-02 22:22:30,155 [INFO] [23] VALIDATION  loss dict: {'mse_loss': 0.27386871755424175, 'classification_loss': 1.1962296767442515}
2024-05-02 22:22:30,155 [INFO] 
2024-05-02 22:23:41,883 [INFO] Step[50/1020]: training loss : 0.24275413364171983 TRAIN  loss dict:  {'mse_loss': 0.24275413364171983}
2024-05-02 22:24:25,100 [INFO] Step[100/1020]: training loss : 0.24964236915111543 TRAIN  loss dict:  {'mse_loss': 0.24964236915111543}
2024-05-02 22:25:09,497 [INFO] Step[150/1020]: training loss : 0.25211313247680667 TRAIN  loss dict:  {'mse_loss': 0.25211313247680667}
2024-05-02 22:25:53,496 [INFO] Step[200/1020]: training loss : 0.2556494903564453 TRAIN  loss dict:  {'mse_loss': 0.2556494903564453}
2024-05-02 22:26:33,121 [INFO] Step[250/1020]: training loss : 0.25799384474754333 TRAIN  loss dict:  {'mse_loss': 0.25799384474754333}
2024-05-02 22:27:17,939 [INFO] Step[300/1020]: training loss : 0.25346446126699446 TRAIN  loss dict:  {'mse_loss': 0.25346446126699446}
2024-05-02 22:27:54,632 [INFO] Step[350/1020]: training loss : 0.25760102838277815 TRAIN  loss dict:  {'mse_loss': 0.25760102838277815}
2024-05-02 22:28:37,952 [INFO] Step[400/1020]: training loss : 0.25579835921525956 TRAIN  loss dict:  {'mse_loss': 0.25579835921525956}
2024-05-02 22:29:16,234 [INFO] Step[450/1020]: training loss : 0.2513000330328941 TRAIN  loss dict:  {'mse_loss': 0.2513000330328941}
2024-05-02 22:29:56,943 [INFO] Step[500/1020]: training loss : 0.2549648541212082 TRAIN  loss dict:  {'mse_loss': 0.2549648541212082}
2024-05-02 22:30:37,554 [INFO] Step[550/1020]: training loss : 0.259744858443737 TRAIN  loss dict:  {'mse_loss': 0.259744858443737}
2024-05-02 22:31:18,453 [INFO] Step[600/1020]: training loss : 0.25074146926403046 TRAIN  loss dict:  {'mse_loss': 0.25074146926403046}
2024-05-02 22:32:01,067 [INFO] Step[650/1020]: training loss : 0.25351944655179975 TRAIN  loss dict:  {'mse_loss': 0.25351944655179975}
2024-05-02 22:32:39,922 [INFO] Step[700/1020]: training loss : 0.25110790491104124 TRAIN  loss dict:  {'mse_loss': 0.25110790491104124}
2024-05-02 22:33:22,067 [INFO] Step[750/1020]: training loss : 0.2572750777006149 TRAIN  loss dict:  {'mse_loss': 0.2572750777006149}
2024-05-02 22:34:03,761 [INFO] Step[800/1020]: training loss : 0.25426838397979734 TRAIN  loss dict:  {'mse_loss': 0.25426838397979734}
2024-05-02 22:34:44,118 [INFO] Step[850/1020]: training loss : 0.2539724063873291 TRAIN  loss dict:  {'mse_loss': 0.2539724063873291}
2024-05-02 22:35:23,916 [INFO] Step[900/1020]: training loss : 0.25377714455127715 TRAIN  loss dict:  {'mse_loss': 0.25377714455127715}
2024-05-02 22:36:03,831 [INFO] Step[950/1020]: training loss : 0.2572767233848572 TRAIN  loss dict:  {'mse_loss': 0.2572767233848572}
2024-05-02 22:36:41,996 [INFO] Step[1000/1020]: training loss : 0.2620963028073311 TRAIN  loss dict:  {'mse_loss': 0.2620963028073311}
2024-05-02 22:39:38,928 [INFO] Label accuracies statistics:
2024-05-02 22:39:38,929 [INFO] {0: 0.5, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.3333333333333333, 5: 0.75, 6: 0.25, 7: 1.0, 8: 0.0, 9: 0.75, 10: 0.75, 11: 0.75, 12: 0.75, 13: 0.5, 14: 0.25, 15: 0.75, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.5, 26: 1.0, 27: 1.0, 28: 0.5, 29: 1.0, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 0.0, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 0.75, 43: 0.75, 44: 0.75, 45: 1.0, 46: 0.75, 47: 0.75, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.75, 52: 0.25, 53: 0.0, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.25, 60: 0.5, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.5, 74: 0.5, 75: 1.0, 76: 0.25, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.75, 83: 0.75, 84: 0.75, 85: 1.0, 86: 0.5, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.75, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.0, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.75, 110: 1.0, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.5, 117: 0.5, 118: 0.75, 119: 0.5, 120: 0.5, 121: 1.0, 122: 0.75, 123: 0.5, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.0, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.25, 140: 0.5, 141: 0.75, 142: 1.0, 143: 0.5, 144: 0.75, 145: 0.5, 146: 0.75, 147: 1.0, 148: 0.5, 149: 0.75, 150: 0.5, 151: 0.75, 152: 1.0, 153: 0.5, 154: 0.75, 155: 0.25, 156: 0.75, 157: 0.5, 158: 0.25, 159: 0.5, 160: 0.25, 161: 1.0, 162: 0.25, 163: 0.25, 164: 0.25, 165: 1.0, 166: 0.75, 167: 0.25, 168: 0.25, 169: 0.5, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.25, 175: 1.0, 176: 0.5, 177: 0.5, 178: 1.0, 179: 0.75, 180: 1.0, 181: 0.75, 182: 0.75, 183: 0.75, 184: 0.25, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.5, 196: 0.5, 197: 1.0, 198: 0.75}

2024-05-02 22:39:42,802 [INFO] [24] TRAIN  loss: 0.25407228864291137 acc: 0.0
2024-05-02 22:39:42,802 [INFO] [24] TRAIN  loss dict: {'mse_loss': 0.25407228864291137}
2024-05-02 22:39:42,802 [INFO] [24] VALIDATION loss: 1.433335105277071 VALIDATION  acc: 0.6805555555555556
2024-05-02 22:39:42,802 [INFO] [24] VALIDATION  loss dict: {'mse_loss': 0.2727592278159026, 'classification_loss': 1.1605758761441467}
2024-05-02 22:39:42,803 [INFO] 
2024-05-02 22:40:56,411 [INFO] Step[50/1020]: training loss : 0.24991427034139632 TRAIN  loss dict:  {'mse_loss': 0.24991427034139632}
2024-05-02 22:41:37,226 [INFO] Step[100/1020]: training loss : 0.2493198925256729 TRAIN  loss dict:  {'mse_loss': 0.2493198925256729}
2024-05-02 22:42:17,623 [INFO] Step[150/1020]: training loss : 0.2547427600622177 TRAIN  loss dict:  {'mse_loss': 0.2547427600622177}
2024-05-02 22:43:03,674 [INFO] Step[200/1020]: training loss : 0.2528837475180626 TRAIN  loss dict:  {'mse_loss': 0.2528837475180626}
2024-05-02 22:43:43,577 [INFO] Step[250/1020]: training loss : 0.24842924147844314 TRAIN  loss dict:  {'mse_loss': 0.24842924147844314}
2024-05-02 22:44:28,340 [INFO] Step[300/1020]: training loss : 0.24740737974643706 TRAIN  loss dict:  {'mse_loss': 0.24740737974643706}
2024-05-02 22:45:09,166 [INFO] Step[350/1020]: training loss : 0.2529976335167885 TRAIN  loss dict:  {'mse_loss': 0.2529976335167885}
2024-05-02 22:45:50,454 [INFO] Step[400/1020]: training loss : 0.25540913969278334 TRAIN  loss dict:  {'mse_loss': 0.25540913969278334}
2024-05-02 22:46:35,952 [INFO] Step[450/1020]: training loss : 0.25730126798152925 TRAIN  loss dict:  {'mse_loss': 0.25730126798152925}
2024-05-02 22:47:17,419 [INFO] Step[500/1020]: training loss : 0.2525846740603447 TRAIN  loss dict:  {'mse_loss': 0.2525846740603447}
2024-05-02 22:47:58,742 [INFO] Step[550/1020]: training loss : 0.2610254791378975 TRAIN  loss dict:  {'mse_loss': 0.2610254791378975}
2024-05-02 22:48:40,898 [INFO] Step[600/1020]: training loss : 0.24838737308979034 TRAIN  loss dict:  {'mse_loss': 0.24838737308979034}
2024-05-02 22:49:24,029 [INFO] Step[650/1020]: training loss : 0.24867033302783967 TRAIN  loss dict:  {'mse_loss': 0.24867033302783967}
2024-05-02 22:50:05,000 [INFO] Step[700/1020]: training loss : 0.24872502118349074 TRAIN  loss dict:  {'mse_loss': 0.24872502118349074}
2024-05-02 22:50:52,223 [INFO] Step[750/1020]: training loss : 0.2525917899608612 TRAIN  loss dict:  {'mse_loss': 0.2525917899608612}
2024-05-02 22:51:34,799 [INFO] Step[800/1020]: training loss : 0.25019071221351624 TRAIN  loss dict:  {'mse_loss': 0.25019071221351624}
2024-05-02 22:52:20,220 [INFO] Step[850/1020]: training loss : 0.24761397659778595 TRAIN  loss dict:  {'mse_loss': 0.24761397659778595}
2024-05-02 22:53:07,196 [INFO] Step[900/1020]: training loss : 0.24641843795776366 TRAIN  loss dict:  {'mse_loss': 0.24641843795776366}
2024-05-02 22:53:47,077 [INFO] Step[950/1020]: training loss : 0.25500581741333006 TRAIN  loss dict:  {'mse_loss': 0.25500581741333006}
2024-05-02 22:54:29,609 [INFO] Step[1000/1020]: training loss : 0.2511294484138489 TRAIN  loss dict:  {'mse_loss': 0.2511294484138489}
2024-05-02 22:57:22,589 [INFO] Label accuracies statistics:
2024-05-02 22:57:22,592 [INFO] {0: 0.5, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.6666666666666666, 5: 0.75, 6: 0.5, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.25, 14: 0.5, 15: 0.5, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.5, 29: 0.75, 30: 0.75, 31: 0.75, 32: 1.0, 33: 0.75, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.0, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 0.75, 47: 0.75, 48: 0.75, 49: 0.75, 50: 1.0, 51: 0.5, 52: 0.25, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 0.75, 58: 0.75, 59: 0.25, 60: 0.25, 61: 0.75, 62: 1.0, 63: 0.5, 64: 0.5, 65: 0.25, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.0, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.5, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.5, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.25, 83: 0.75, 84: 0.75, 85: 1.0, 86: 0.25, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.75, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.75, 108: 0.75, 109: 0.5, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.25, 115: 1.0, 116: 0.75, 117: 0.75, 118: 0.75, 119: 0.5, 120: 0.5, 121: 1.0, 122: 0.5, 123: 0.5, 124: 1.0, 125: 0.75, 126: 0.75, 127: 1.0, 128: 0.75, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.0, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.75, 146: 0.75, 147: 0.75, 148: 0.5, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 0.0, 156: 0.5, 157: 0.5, 158: 0.5, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.5, 163: 0.5, 164: 0.25, 165: 1.0, 166: 0.25, 167: 0.25, 168: 0.25, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.25, 175: 1.0, 176: 0.75, 177: 0.5, 178: 1.0, 179: 0.75, 180: 0.75, 181: 0.75, 182: 0.75, 183: 0.5, 184: 0.75, 185: 0.75, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.5, 196: 0.75, 197: 1.0, 198: 0.5}

2024-05-02 22:57:26,565 [INFO] [25] TRAIN  loss: 0.25168499718694126 acc: 0.0
2024-05-02 22:57:26,565 [INFO] [25] TRAIN  loss dict: {'mse_loss': 0.25168499718694126}
2024-05-02 22:57:26,566 [INFO] [25] VALIDATION loss: 1.426251328954793 VALIDATION  acc: 0.6843434343434344
2024-05-02 22:57:26,566 [INFO] [25] VALIDATION  loss dict: {'mse_loss': 0.2717925984450061, 'classification_loss': 1.1544587308108205}
2024-05-02 22:57:26,566 [INFO] 
2024-05-02 22:58:45,667 [INFO] Step[50/1020]: training loss : 0.23897978961467742 TRAIN  loss dict:  {'mse_loss': 0.23897978961467742}
2024-05-02 22:59:35,989 [INFO] Step[100/1020]: training loss : 0.24608483910560608 TRAIN  loss dict:  {'mse_loss': 0.24608483910560608}
2024-05-02 23:00:25,462 [INFO] Step[150/1020]: training loss : 0.2439827385544777 TRAIN  loss dict:  {'mse_loss': 0.2439827385544777}
2024-05-02 23:01:15,146 [INFO] Step[200/1020]: training loss : 0.24434243708848954 TRAIN  loss dict:  {'mse_loss': 0.24434243708848954}
2024-05-02 23:02:07,408 [INFO] Step[250/1020]: training loss : 0.24238996475934982 TRAIN  loss dict:  {'mse_loss': 0.24238996475934982}
2024-05-02 23:02:58,930 [INFO] Step[300/1020]: training loss : 0.24326081454753876 TRAIN  loss dict:  {'mse_loss': 0.24326081454753876}
2024-05-02 23:03:47,969 [INFO] Step[350/1020]: training loss : 0.25955223351716994 TRAIN  loss dict:  {'mse_loss': 0.25955223351716994}
2024-05-02 23:04:31,433 [INFO] Step[400/1020]: training loss : 0.2528899961709976 TRAIN  loss dict:  {'mse_loss': 0.2528899961709976}
2024-05-02 23:05:24,351 [INFO] Step[450/1020]: training loss : 0.2533035641908646 TRAIN  loss dict:  {'mse_loss': 0.2533035641908646}
2024-05-02 23:06:11,196 [INFO] Step[500/1020]: training loss : 0.254717278778553 TRAIN  loss dict:  {'mse_loss': 0.254717278778553}
2024-05-02 23:06:57,509 [INFO] Step[550/1020]: training loss : 0.23874118596315383 TRAIN  loss dict:  {'mse_loss': 0.23874118596315383}
2024-05-02 23:07:51,090 [INFO] Step[600/1020]: training loss : 0.25103761672973635 TRAIN  loss dict:  {'mse_loss': 0.25103761672973635}
2024-05-02 23:08:40,035 [INFO] Step[650/1020]: training loss : 0.2496041738986969 TRAIN  loss dict:  {'mse_loss': 0.2496041738986969}
2024-05-02 23:09:38,489 [INFO] Step[700/1020]: training loss : 0.25208340167999266 TRAIN  loss dict:  {'mse_loss': 0.25208340167999266}
2024-05-02 23:10:25,532 [INFO] Step[750/1020]: training loss : 0.2537471875548363 TRAIN  loss dict:  {'mse_loss': 0.2537471875548363}
2024-05-02 23:11:07,844 [INFO] Step[800/1020]: training loss : 0.2537442395091057 TRAIN  loss dict:  {'mse_loss': 0.2537442395091057}
2024-05-02 23:11:53,159 [INFO] Step[850/1020]: training loss : 0.24715915083885193 TRAIN  loss dict:  {'mse_loss': 0.24715915083885193}
2024-05-02 23:12:42,168 [INFO] Step[900/1020]: training loss : 0.255864132642746 TRAIN  loss dict:  {'mse_loss': 0.255864132642746}
2024-05-02 23:13:31,112 [INFO] Step[950/1020]: training loss : 0.25648016691207887 TRAIN  loss dict:  {'mse_loss': 0.25648016691207887}
2024-05-02 23:14:15,565 [INFO] Step[1000/1020]: training loss : 0.2557808402180672 TRAIN  loss dict:  {'mse_loss': 0.2557808402180672}
2024-05-02 23:17:04,816 [INFO] Label accuracies statistics:
2024-05-02 23:17:04,816 [INFO] {0: 0.5, 1: 0.75, 2: 0.75, 3: 0.75, 4: 0.3333333333333333, 5: 0.75, 6: 0.0, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.5, 14: 0.25, 15: 0.5, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.5, 29: 1.0, 30: 1.0, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.25, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.5, 45: 1.0, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.25, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.25, 60: 0.25, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.5, 66: 0.75, 67: 1.0, 68: 0.75, 69: 0.25, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.25, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.5, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.5, 83: 1.0, 84: 0.5, 85: 1.0, 86: 0.25, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.5, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.25, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.25, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.75, 120: 0.5, 121: 1.0, 122: 0.5, 123: 0.25, 124: 1.0, 125: 1.0, 126: 0.75, 127: 1.0, 128: 0.75, 129: 0.75, 130: 0.75, 131: 0.75, 132: 0.0, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.25, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.5, 144: 0.75, 145: 0.75, 146: 0.75, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.0, 156: 0.75, 157: 0.5, 158: 0.25, 159: 0.75, 160: 0.25, 161: 1.0, 162: 0.5, 163: 0.75, 164: 0.25, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.5, 175: 1.0, 176: 0.5, 177: 0.75, 178: 1.0, 179: 0.5, 180: 0.75, 181: 1.0, 182: 0.5, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.5}

2024-05-02 23:17:08,759 [INFO] [26] TRAIN  loss: 0.2497618956162649 acc: 0.0
2024-05-02 23:17:08,759 [INFO] [26] TRAIN  loss dict: {'mse_loss': 0.2497618956162649}
2024-05-02 23:17:08,759 [INFO] [26] VALIDATION loss: 1.4015271886430605 VALIDATION  acc: 0.6982323232323232
2024-05-02 23:17:08,759 [INFO] [26] VALIDATION  loss dict: {'mse_loss': 0.26966547845589994, 'classification_loss': 1.1318617093028744}
2024-05-02 23:17:08,759 [INFO] 
2024-05-02 23:18:36,002 [INFO] Step[50/1020]: training loss : 0.25615519762039185 TRAIN  loss dict:  {'mse_loss': 0.25615519762039185}
2024-05-02 23:19:24,534 [INFO] Step[100/1020]: training loss : 0.237808375954628 TRAIN  loss dict:  {'mse_loss': 0.237808375954628}
2024-05-02 23:20:07,353 [INFO] Step[150/1020]: training loss : 0.24113432168960572 TRAIN  loss dict:  {'mse_loss': 0.24113432168960572}
2024-05-02 23:20:47,823 [INFO] Step[200/1020]: training loss : 0.2411368077993393 TRAIN  loss dict:  {'mse_loss': 0.2411368077993393}
2024-05-02 23:21:33,592 [INFO] Step[250/1020]: training loss : 0.24461605817079543 TRAIN  loss dict:  {'mse_loss': 0.24461605817079543}
2024-05-02 23:22:15,483 [INFO] Step[300/1020]: training loss : 0.2489277669787407 TRAIN  loss dict:  {'mse_loss': 0.2489277669787407}
2024-05-02 23:22:59,488 [INFO] Step[350/1020]: training loss : 0.25096566319465635 TRAIN  loss dict:  {'mse_loss': 0.25096566319465635}
2024-05-02 23:23:47,555 [INFO] Step[400/1020]: training loss : 0.2473561692237854 TRAIN  loss dict:  {'mse_loss': 0.2473561692237854}
2024-05-02 23:24:34,131 [INFO] Step[450/1020]: training loss : 0.24537400662899017 TRAIN  loss dict:  {'mse_loss': 0.24537400662899017}
2024-05-02 23:25:14,984 [INFO] Step[500/1020]: training loss : 0.24995408475399017 TRAIN  loss dict:  {'mse_loss': 0.24995408475399017}
2024-05-02 23:26:01,156 [INFO] Step[550/1020]: training loss : 0.23851849436759948 TRAIN  loss dict:  {'mse_loss': 0.23851849436759948}
2024-05-02 23:26:53,336 [INFO] Step[600/1020]: training loss : 0.25316003054380415 TRAIN  loss dict:  {'mse_loss': 0.25316003054380415}
2024-05-02 23:27:40,336 [INFO] Step[650/1020]: training loss : 0.24782772094011307 TRAIN  loss dict:  {'mse_loss': 0.24782772094011307}
2024-05-02 23:28:30,939 [INFO] Step[700/1020]: training loss : 0.2503123673796654 TRAIN  loss dict:  {'mse_loss': 0.2503123673796654}
2024-05-02 23:29:20,672 [INFO] Step[750/1020]: training loss : 0.2520012593269348 TRAIN  loss dict:  {'mse_loss': 0.2520012593269348}
2024-05-02 23:30:02,784 [INFO] Step[800/1020]: training loss : 0.2535426416993141 TRAIN  loss dict:  {'mse_loss': 0.2535426416993141}
2024-05-02 23:30:45,893 [INFO] Step[850/1020]: training loss : 0.24647652208805085 TRAIN  loss dict:  {'mse_loss': 0.24647652208805085}
2024-05-02 23:31:30,352 [INFO] Step[900/1020]: training loss : 0.24926484018564224 TRAIN  loss dict:  {'mse_loss': 0.24926484018564224}
2024-05-02 23:32:10,865 [INFO] Step[950/1020]: training loss : 0.24784785717725755 TRAIN  loss dict:  {'mse_loss': 0.24784785717725755}
2024-05-02 23:32:56,424 [INFO] Step[1000/1020]: training loss : 0.24001017153263093 TRAIN  loss dict:  {'mse_loss': 0.24001017153263093}
2024-05-02 23:35:45,071 [INFO] Label accuracies statistics:
2024-05-02 23:35:45,072 [INFO] {0: 0.5, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.6666666666666666, 5: 0.5, 6: 0.25, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.25, 14: 0.25, 15: 0.75, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 0.25, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 1.0, 51: 0.75, 52: 0.25, 53: 0.25, 54: 0.25, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.25, 60: 0.25, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.5, 66: 0.5, 67: 1.0, 68: 0.75, 69: 0.25, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.5, 74: 0.25, 75: 1.0, 76: 0.5, 77: 0.5, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.5, 83: 0.5, 84: 0.75, 85: 1.0, 86: 0.25, 87: 0.5, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.75, 95: 0.75, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.75, 101: 1.0, 102: 0.5, 103: 0.75, 104: 1.0, 105: 0.25, 106: 1.0, 107: 1.0, 108: 0.5, 109: 0.5, 110: 0.75, 111: 1.0, 112: 0.25, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 1.0, 120: 0.5, 121: 1.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 0.5, 131: 0.75, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.5, 139: 0.25, 140: 0.5, 141: 1.0, 142: 1.0, 143: 0.5, 144: 0.75, 145: 0.5, 146: 0.75, 147: 1.0, 148: 0.25, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.25, 156: 0.75, 157: 0.5, 158: 0.5, 159: 0.5, 160: 0.25, 161: 1.0, 162: 0.5, 163: 0.5, 164: 0.5, 165: 0.75, 166: 0.25, 167: 0.25, 168: 0.25, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.5, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.5, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.25, 185: 0.75, 186: 0.75, 187: 0.75, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.5}

2024-05-02 23:35:48,909 [INFO] [27] TRAIN  loss: 0.24732108336745523 acc: 0.0
2024-05-02 23:35:48,909 [INFO] [27] TRAIN  loss dict: {'mse_loss': 0.24732108336745523}
2024-05-02 23:35:48,909 [INFO] [27] VALIDATION loss: 1.3885565707177827 VALIDATION  acc: 0.6931818181818182
2024-05-02 23:35:48,909 [INFO] [27] VALIDATION  loss dict: {'mse_loss': 0.26611654791567063, 'classification_loss': 1.1224400240626902}
2024-05-02 23:35:48,910 [INFO] 
2024-05-02 23:37:00,879 [INFO] Step[50/1020]: training loss : 0.24129412978887557 TRAIN  loss dict:  {'mse_loss': 0.24129412978887557}
2024-05-02 23:37:41,311 [INFO] Step[100/1020]: training loss : 0.23698761373758315 TRAIN  loss dict:  {'mse_loss': 0.23698761373758315}
2024-05-02 23:38:22,199 [INFO] Step[150/1020]: training loss : 0.24639167219400407 TRAIN  loss dict:  {'mse_loss': 0.24639167219400407}
2024-05-02 23:39:05,229 [INFO] Step[200/1020]: training loss : 0.24537181943655015 TRAIN  loss dict:  {'mse_loss': 0.24537181943655015}
2024-05-02 23:39:45,376 [INFO] Step[250/1020]: training loss : 0.2401099044084549 TRAIN  loss dict:  {'mse_loss': 0.2401099044084549}
2024-05-02 23:40:24,480 [INFO] Step[300/1020]: training loss : 0.24398566663265228 TRAIN  loss dict:  {'mse_loss': 0.24398566663265228}
2024-05-02 23:41:04,368 [INFO] Step[350/1020]: training loss : 0.24369996905326843 TRAIN  loss dict:  {'mse_loss': 0.24369996905326843}
2024-05-02 23:41:48,853 [INFO] Step[400/1020]: training loss : 0.24499236285686493 TRAIN  loss dict:  {'mse_loss': 0.24499236285686493}
2024-05-02 23:42:32,942 [INFO] Step[450/1020]: training loss : 0.2554721850156784 TRAIN  loss dict:  {'mse_loss': 0.2554721850156784}
2024-05-02 23:43:15,731 [INFO] Step[500/1020]: training loss : 0.25054702430963516 TRAIN  loss dict:  {'mse_loss': 0.25054702430963516}
2024-05-02 23:43:53,292 [INFO] Step[550/1020]: training loss : 0.2464418390393257 TRAIN  loss dict:  {'mse_loss': 0.2464418390393257}
2024-05-02 23:44:41,856 [INFO] Step[600/1020]: training loss : 0.2412426570057869 TRAIN  loss dict:  {'mse_loss': 0.2412426570057869}
2024-05-02 23:45:25,678 [INFO] Step[650/1020]: training loss : 0.25292450428009033 TRAIN  loss dict:  {'mse_loss': 0.25292450428009033}
2024-05-02 23:46:04,752 [INFO] Step[700/1020]: training loss : 0.24740877151489257 TRAIN  loss dict:  {'mse_loss': 0.24740877151489257}
2024-05-02 23:46:48,200 [INFO] Step[750/1020]: training loss : 0.24838820815086365 TRAIN  loss dict:  {'mse_loss': 0.24838820815086365}
2024-05-02 23:47:28,926 [INFO] Step[800/1020]: training loss : 0.24921965301036836 TRAIN  loss dict:  {'mse_loss': 0.24921965301036836}
2024-05-02 23:48:08,025 [INFO] Step[850/1020]: training loss : 0.2505583098530769 TRAIN  loss dict:  {'mse_loss': 0.2505583098530769}
2024-05-02 23:48:52,646 [INFO] Step[900/1020]: training loss : 0.2419462937116623 TRAIN  loss dict:  {'mse_loss': 0.2419462937116623}
2024-05-02 23:49:32,204 [INFO] Step[950/1020]: training loss : 0.24455773323774338 TRAIN  loss dict:  {'mse_loss': 0.24455773323774338}
2024-05-02 23:50:15,636 [INFO] Step[1000/1020]: training loss : 0.2434057155251503 TRAIN  loss dict:  {'mse_loss': 0.2434057155251503}
2024-05-02 23:53:05,184 [INFO] Label accuracies statistics:
2024-05-02 23:53:05,184 [INFO] {0: 0.5, 1: 0.5, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.5, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.5, 14: 0.25, 15: 0.75, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.5, 26: 1.0, 27: 1.0, 28: 0.5, 29: 1.0, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.25, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.75, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 1.0, 51: 0.5, 52: 0.25, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.25, 60: 0.25, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.5, 67: 0.75, 68: 0.25, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.5, 74: 0.5, 75: 1.0, 76: 0.25, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.5, 83: 0.75, 84: 0.5, 85: 1.0, 86: 0.5, 87: 0.25, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.5, 94: 0.25, 95: 0.75, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.5, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.25, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.25, 113: 0.5, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 1.0, 120: 0.5, 121: 1.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.25, 133: 1.0, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.5, 139: 0.25, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 0.5, 147: 1.0, 148: 0.5, 149: 0.75, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.0, 156: 0.5, 157: 0.5, 158: 0.75, 159: 0.5, 160: 0.25, 161: 1.0, 162: 0.5, 163: 0.5, 164: 0.25, 165: 1.0, 166: 0.5, 167: 0.25, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 0.75, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 0.75, 181: 0.75, 182: 0.75, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.5}

2024-05-02 23:53:09,193 [INFO] [28] TRAIN  loss: 0.24569881517513126 acc: 0.0
2024-05-02 23:53:09,194 [INFO] [28] TRAIN  loss dict: {'mse_loss': 0.24569881517513126}
2024-05-02 23:53:09,195 [INFO] [28] VALIDATION loss: 1.3818123361679038 VALIDATION  acc: 0.7083333333333334
2024-05-02 23:53:09,196 [INFO] [28] VALIDATION  loss dict: {'mse_loss': 0.26633174672271265, 'classification_loss': 1.1154805834809638}
2024-05-02 23:53:09,197 [INFO] 
2024-05-02 23:54:21,456 [INFO] Step[50/1020]: training loss : 0.24663335412740708 TRAIN  loss dict:  {'mse_loss': 0.24663335412740708}
2024-05-02 23:55:14,267 [INFO] Step[100/1020]: training loss : 0.2359074091911316 TRAIN  loss dict:  {'mse_loss': 0.2359074091911316}
2024-05-02 23:55:53,624 [INFO] Step[150/1020]: training loss : 0.24611181795597076 TRAIN  loss dict:  {'mse_loss': 0.24611181795597076}
2024-05-02 23:56:33,975 [INFO] Step[200/1020]: training loss : 0.24222441375255585 TRAIN  loss dict:  {'mse_loss': 0.24222441375255585}
2024-05-02 23:57:19,151 [INFO] Step[250/1020]: training loss : 0.24279750794172286 TRAIN  loss dict:  {'mse_loss': 0.24279750794172286}
2024-05-02 23:58:08,718 [INFO] Step[300/1020]: training loss : 0.24371147632598877 TRAIN  loss dict:  {'mse_loss': 0.24371147632598877}
2024-05-02 23:58:50,703 [INFO] Step[350/1020]: training loss : 0.2410253232717514 TRAIN  loss dict:  {'mse_loss': 0.2410253232717514}
2024-05-02 23:59:36,412 [INFO] Step[400/1020]: training loss : 0.24886662781238555 TRAIN  loss dict:  {'mse_loss': 0.24886662781238555}
2024-05-03 00:00:19,731 [INFO] Step[450/1020]: training loss : 0.24038944125175477 TRAIN  loss dict:  {'mse_loss': 0.24038944125175477}
2024-05-03 00:01:00,747 [INFO] Step[500/1020]: training loss : 0.24069740891456604 TRAIN  loss dict:  {'mse_loss': 0.24069740891456604}
2024-05-03 00:01:47,309 [INFO] Step[550/1020]: training loss : 0.2302556923031807 TRAIN  loss dict:  {'mse_loss': 0.2302556923031807}
2024-05-03 00:02:29,036 [INFO] Step[600/1020]: training loss : 0.23434357672929765 TRAIN  loss dict:  {'mse_loss': 0.23434357672929765}
2024-05-03 00:03:14,794 [INFO] Step[650/1020]: training loss : 0.24095054507255553 TRAIN  loss dict:  {'mse_loss': 0.24095054507255553}
2024-05-03 00:03:54,192 [INFO] Step[700/1020]: training loss : 0.24015051156282424 TRAIN  loss dict:  {'mse_loss': 0.24015051156282424}
2024-05-03 00:04:33,470 [INFO] Step[750/1020]: training loss : 0.23938383251428605 TRAIN  loss dict:  {'mse_loss': 0.23938383251428605}
2024-05-03 00:05:17,965 [INFO] Step[800/1020]: training loss : 0.24002323001623155 TRAIN  loss dict:  {'mse_loss': 0.24002323001623155}
2024-05-03 00:05:59,370 [INFO] Step[850/1020]: training loss : 0.2411269101500511 TRAIN  loss dict:  {'mse_loss': 0.2411269101500511}
2024-05-03 00:06:43,323 [INFO] Step[900/1020]: training loss : 0.2460813945531845 TRAIN  loss dict:  {'mse_loss': 0.2460813945531845}
2024-05-03 00:07:24,723 [INFO] Step[950/1020]: training loss : 0.23793617218732835 TRAIN  loss dict:  {'mse_loss': 0.23793617218732835}
2024-05-03 00:08:10,465 [INFO] Step[1000/1020]: training loss : 0.23791144102811812 TRAIN  loss dict:  {'mse_loss': 0.23791144102811812}
2024-05-03 00:11:05,539 [INFO] Label accuracies statistics:
2024-05-03 00:11:05,540 [INFO] {0: 0.5, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.3333333333333333, 5: 0.75, 6: 0.25, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.25, 14: 0.25, 15: 0.5, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.5, 29: 1.0, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 0.25, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 1.0, 51: 0.5, 52: 0.25, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.25, 60: 0.25, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.5, 66: 0.5, 67: 1.0, 68: 0.75, 69: 0.5, 70: 1.0, 71: 0.5, 72: 1.0, 73: 0.5, 74: 0.25, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.5, 83: 1.0, 84: 0.75, 85: 1.0, 86: 0.25, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.75, 95: 0.75, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.5, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.25, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.5, 120: 0.75, 121: 1.0, 122: 0.5, 123: 0.5, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.0, 133: 0.75, 134: 0.75, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.25, 139: 0.5, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.5, 146: 0.5, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.25, 156: 0.75, 157: 0.5, 158: 0.25, 159: 0.5, 160: 0.25, 161: 1.0, 162: 0.25, 163: 0.5, 164: 0.25, 165: 1.0, 166: 0.5, 167: 0.25, 168: 0.5, 169: 0.5, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 0.25, 175: 0.75, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.5, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.5, 196: 0.75, 197: 0.75, 198: 0.75}

2024-05-03 00:11:05,567 [INFO] [29] TRAIN  loss: 0.2408617568951027 acc: 0.0
2024-05-03 00:11:05,569 [INFO] [29] TRAIN  loss dict: {'mse_loss': 0.2408617568951027}
2024-05-03 00:11:05,571 [INFO] [29] VALIDATION loss: 1.4275296010603808 VALIDATION  acc: 0.6982323232323232
2024-05-03 00:11:05,573 [INFO] [29] VALIDATION  loss dict: {'mse_loss': 0.2666025480086153, 'classification_loss': 1.1609270516594854}
2024-05-03 00:11:05,575 [INFO] 
2024-05-03 00:12:15,076 [INFO] Step[50/1020]: training loss : 0.24057493597269058 TRAIN  loss dict:  {'mse_loss': 0.24057493597269058}
2024-05-03 00:13:02,257 [INFO] Step[100/1020]: training loss : 0.23348033279180527 TRAIN  loss dict:  {'mse_loss': 0.23348033279180527}
2024-05-03 00:13:45,790 [INFO] Step[150/1020]: training loss : 0.24183876276016236 TRAIN  loss dict:  {'mse_loss': 0.24183876276016236}
2024-05-03 00:14:26,312 [INFO] Step[200/1020]: training loss : 0.23991161316633225 TRAIN  loss dict:  {'mse_loss': 0.23991161316633225}
2024-05-03 00:15:04,543 [INFO] Step[250/1020]: training loss : 0.2386354923248291 TRAIN  loss dict:  {'mse_loss': 0.2386354923248291}
2024-05-03 00:15:51,802 [INFO] Step[300/1020]: training loss : 0.23703521907329558 TRAIN  loss dict:  {'mse_loss': 0.23703521907329558}
2024-05-03 00:16:36,845 [INFO] Step[350/1020]: training loss : 0.24500633984804154 TRAIN  loss dict:  {'mse_loss': 0.24500633984804154}
2024-05-03 00:17:20,431 [INFO] Step[400/1020]: training loss : 0.23757236272096635 TRAIN  loss dict:  {'mse_loss': 0.23757236272096635}
2024-05-03 00:18:09,249 [INFO] Step[450/1020]: training loss : 0.24202437043190003 TRAIN  loss dict:  {'mse_loss': 0.24202437043190003}
2024-05-03 00:18:53,002 [INFO] Step[500/1020]: training loss : 0.24344783782958984 TRAIN  loss dict:  {'mse_loss': 0.24344783782958984}
2024-05-03 00:19:39,061 [INFO] Step[550/1020]: training loss : 0.24028546273708343 TRAIN  loss dict:  {'mse_loss': 0.24028546273708343}
2024-05-03 00:20:23,614 [INFO] Step[600/1020]: training loss : 0.2487129908800125 TRAIN  loss dict:  {'mse_loss': 0.2487129908800125}
2024-05-03 00:21:06,381 [INFO] Step[650/1020]: training loss : 0.23703506350517273 TRAIN  loss dict:  {'mse_loss': 0.23703506350517273}
2024-05-03 00:21:51,662 [INFO] Step[700/1020]: training loss : 0.23231324613094329 TRAIN  loss dict:  {'mse_loss': 0.23231324613094329}
2024-05-03 00:22:33,816 [INFO] Step[750/1020]: training loss : 0.2371622547507286 TRAIN  loss dict:  {'mse_loss': 0.2371622547507286}
2024-05-03 00:23:16,134 [INFO] Step[800/1020]: training loss : 0.24501297295093535 TRAIN  loss dict:  {'mse_loss': 0.24501297295093535}
2024-05-03 00:23:59,920 [INFO] Step[850/1020]: training loss : 0.23901874363422393 TRAIN  loss dict:  {'mse_loss': 0.23901874363422393}
2024-05-03 00:24:40,297 [INFO] Step[900/1020]: training loss : 0.24340420633554458 TRAIN  loss dict:  {'mse_loss': 0.24340420633554458}
2024-05-03 00:25:22,187 [INFO] Step[950/1020]: training loss : 0.24904950767755507 TRAIN  loss dict:  {'mse_loss': 0.24904950767755507}
2024-05-03 00:26:05,659 [INFO] Step[1000/1020]: training loss : 0.23028524219989777 TRAIN  loss dict:  {'mse_loss': 0.23028524219989777}
2024-05-03 00:28:53,019 [INFO] Label accuracies statistics:
2024-05-03 00:28:53,020 [INFO] {0: 0.5, 1: 0.75, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.25, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.25, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.5, 29: 0.75, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.5, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.5, 52: 0.25, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.25, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.25, 67: 1.0, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.25, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.5, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.75, 83: 0.5, 84: 0.75, 85: 1.0, 86: 0.5, 87: 0.5, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.5, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.25, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.25, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.5, 117: 0.5, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 0.5, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.5, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.25, 139: 0.5, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.5, 144: 0.75, 145: 0.5, 146: 0.75, 147: 0.75, 148: 0.5, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.25, 156: 0.5, 157: 0.5, 158: 0.5, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.5, 167: 0.5, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.5, 173: 0.75, 174: 0.25, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.75, 183: 0.75, 184: 0.25, 185: 0.75, 186: 0.75, 187: 0.75, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.5, 196: 0.75, 197: 0.75, 198: 0.5}

2024-05-03 00:28:53,044 [INFO] [30] TRAIN  loss: 0.24018984534869006 acc: 0.0
2024-05-03 00:28:53,044 [INFO] [30] TRAIN  loss dict: {'mse_loss': 0.24018984534869006}
2024-05-03 00:28:53,045 [INFO] [30] VALIDATION loss: 1.3906622804475552 VALIDATION  acc: 0.702020202020202
2024-05-03 00:28:53,045 [INFO] [30] VALIDATION  loss dict: {'mse_loss': 0.26295481863045933, 'classification_loss': 1.127707467611992}
2024-05-03 00:28:53,045 [INFO] 
2024-05-03 00:30:12,432 [INFO] Step[50/1020]: training loss : 0.22831539213657379 TRAIN  loss dict:  {'mse_loss': 0.22831539213657379}
2024-05-03 00:30:57,231 [INFO] Step[100/1020]: training loss : 0.23733664125204088 TRAIN  loss dict:  {'mse_loss': 0.23733664125204088}
2024-05-03 00:31:40,965 [INFO] Step[150/1020]: training loss : 0.22645723402500154 TRAIN  loss dict:  {'mse_loss': 0.22645723402500154}
2024-05-03 00:32:24,682 [INFO] Step[200/1020]: training loss : 0.23655645549297333 TRAIN  loss dict:  {'mse_loss': 0.23655645549297333}
2024-05-03 00:33:09,411 [INFO] Step[250/1020]: training loss : 0.23939800173044204 TRAIN  loss dict:  {'mse_loss': 0.23939800173044204}
2024-05-03 00:33:50,458 [INFO] Step[300/1020]: training loss : 0.22776930391788483 TRAIN  loss dict:  {'mse_loss': 0.22776930391788483}
2024-05-03 00:34:32,582 [INFO] Step[350/1020]: training loss : 0.24263256341218947 TRAIN  loss dict:  {'mse_loss': 0.24263256341218947}
2024-05-03 00:35:17,521 [INFO] Step[400/1020]: training loss : 0.2376137298345566 TRAIN  loss dict:  {'mse_loss': 0.2376137298345566}
2024-05-03 00:35:55,954 [INFO] Step[450/1020]: training loss : 0.23369224071502687 TRAIN  loss dict:  {'mse_loss': 0.23369224071502687}
2024-05-03 00:36:38,426 [INFO] Step[500/1020]: training loss : 0.24219627261161805 TRAIN  loss dict:  {'mse_loss': 0.24219627261161805}
2024-05-03 00:37:19,398 [INFO] Step[550/1020]: training loss : 0.23247253388166428 TRAIN  loss dict:  {'mse_loss': 0.23247253388166428}
2024-05-03 00:37:59,118 [INFO] Step[600/1020]: training loss : 0.24359087973833085 TRAIN  loss dict:  {'mse_loss': 0.24359087973833085}
2024-05-03 00:38:44,302 [INFO] Step[650/1020]: training loss : 0.23795880049467086 TRAIN  loss dict:  {'mse_loss': 0.23795880049467086}
2024-05-03 00:39:27,734 [INFO] Step[700/1020]: training loss : 0.2411566960811615 TRAIN  loss dict:  {'mse_loss': 0.2411566960811615}
2024-05-03 00:40:11,647 [INFO] Step[750/1020]: training loss : 0.23520518451929093 TRAIN  loss dict:  {'mse_loss': 0.23520518451929093}
2024-05-03 00:40:50,544 [INFO] Step[800/1020]: training loss : 0.23486018002033235 TRAIN  loss dict:  {'mse_loss': 0.23486018002033235}
2024-05-03 00:41:33,745 [INFO] Step[850/1020]: training loss : 0.23194289743900298 TRAIN  loss dict:  {'mse_loss': 0.23194289743900298}
2024-05-03 00:42:18,642 [INFO] Step[900/1020]: training loss : 0.2381302860379219 TRAIN  loss dict:  {'mse_loss': 0.2381302860379219}
2024-05-03 00:43:03,671 [INFO] Step[950/1020]: training loss : 0.23672150522470475 TRAIN  loss dict:  {'mse_loss': 0.23672150522470475}
2024-05-03 00:43:42,243 [INFO] Step[1000/1020]: training loss : 0.237571682035923 TRAIN  loss dict:  {'mse_loss': 0.237571682035923}
2024-05-03 00:46:25,899 [INFO] Label accuracies statistics:
2024-05-03 00:46:25,899 [INFO] {0: 0.5, 1: 0.5, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.25, 7: 1.0, 8: 0.25, 9: 0.75, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.5, 15: 0.5, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.75, 26: 0.5, 27: 1.0, 28: 0.5, 29: 1.0, 30: 0.75, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.25, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.75, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.5, 52: 0.25, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.25, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.5, 67: 1.0, 68: 0.5, 69: 0.0, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.5, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.25, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.75, 83: 0.75, 84: 0.75, 85: 1.0, 86: 0.25, 87: 0.5, 88: 1.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.75, 95: 0.75, 96: 0.75, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.5, 102: 0.5, 103: 0.75, 104: 1.0, 105: 0.5, 106: 0.75, 107: 0.75, 108: 0.5, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.25, 113: 0.5, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.5, 118: 0.75, 119: 0.75, 120: 0.75, 121: 1.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 0.75, 126: 0.75, 127: 1.0, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.5, 139: 0.5, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.5, 144: 1.0, 145: 0.5, 146: 0.75, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.25, 156: 0.75, 157: 0.5, 158: 0.5, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.5, 163: 0.25, 164: 0.75, 165: 0.75, 166: 0.5, 167: 0.75, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.5, 173: 0.75, 174: 0.5, 175: 1.0, 176: 0.5, 177: 0.5, 178: 0.75, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.75, 183: 0.75, 184: 0.25, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.5, 198: 0.5}

2024-05-03 00:46:25,918 [INFO] [31] TRAIN  loss: 0.23613913373327722 acc: 0.0
2024-05-03 00:46:25,918 [INFO] [31] TRAIN  loss dict: {'mse_loss': 0.23613913373327722}
2024-05-03 00:46:25,918 [INFO] [31] VALIDATION loss: 1.406888111823737 VALIDATION  acc: 0.7045454545454546
2024-05-03 00:46:25,918 [INFO] [31] VALIDATION  loss dict: {'mse_loss': 0.2636023074237987, 'classification_loss': 1.1432858001290247}
2024-05-03 00:46:25,918 [INFO] 
2024-05-03 00:47:44,102 [INFO] Step[50/1020]: training loss : 0.2376040479540825 TRAIN  loss dict:  {'mse_loss': 0.2376040479540825}
2024-05-03 00:48:27,276 [INFO] Step[100/1020]: training loss : 0.23633132576942445 TRAIN  loss dict:  {'mse_loss': 0.23633132576942445}
2024-05-03 00:49:11,507 [INFO] Step[150/1020]: training loss : 0.2296662610769272 TRAIN  loss dict:  {'mse_loss': 0.2296662610769272}
2024-05-03 00:49:57,205 [INFO] Step[200/1020]: training loss : 0.23636455118656158 TRAIN  loss dict:  {'mse_loss': 0.23636455118656158}
2024-05-03 00:50:37,410 [INFO] Step[250/1020]: training loss : 0.22796768218278884 TRAIN  loss dict:  {'mse_loss': 0.22796768218278884}
2024-05-03 00:51:16,003 [INFO] Step[300/1020]: training loss : 0.23505467802286148 TRAIN  loss dict:  {'mse_loss': 0.23505467802286148}
2024-05-03 00:52:00,270 [INFO] Step[350/1020]: training loss : 0.2304425659775734 TRAIN  loss dict:  {'mse_loss': 0.2304425659775734}
2024-05-03 00:52:41,357 [INFO] Step[400/1020]: training loss : 0.2375529506802559 TRAIN  loss dict:  {'mse_loss': 0.2375529506802559}
2024-05-03 00:53:23,965 [INFO] Step[450/1020]: training loss : 0.23380588084459306 TRAIN  loss dict:  {'mse_loss': 0.23380588084459306}
2024-05-03 00:54:05,774 [INFO] Step[500/1020]: training loss : 0.2366835206747055 TRAIN  loss dict:  {'mse_loss': 0.2366835206747055}
2024-05-03 00:54:47,923 [INFO] Step[550/1020]: training loss : 0.23413299053907394 TRAIN  loss dict:  {'mse_loss': 0.23413299053907394}
2024-05-03 00:55:34,849 [INFO] Step[600/1020]: training loss : 0.24210636258125307 TRAIN  loss dict:  {'mse_loss': 0.24210636258125307}
2024-05-03 00:56:18,638 [INFO] Step[650/1020]: training loss : 0.2360463720560074 TRAIN  loss dict:  {'mse_loss': 0.2360463720560074}
2024-05-03 00:56:59,440 [INFO] Step[700/1020]: training loss : 0.2367339712381363 TRAIN  loss dict:  {'mse_loss': 0.2367339712381363}
2024-05-03 00:57:41,885 [INFO] Step[750/1020]: training loss : 0.24195670038461686 TRAIN  loss dict:  {'mse_loss': 0.24195670038461686}
2024-05-03 00:58:33,520 [INFO] Step[800/1020]: training loss : 0.23803161233663558 TRAIN  loss dict:  {'mse_loss': 0.23803161233663558}
2024-05-03 00:59:15,446 [INFO] Step[850/1020]: training loss : 0.23029779464006425 TRAIN  loss dict:  {'mse_loss': 0.23029779464006425}
2024-05-03 00:59:59,464 [INFO] Step[900/1020]: training loss : 0.2335457018017769 TRAIN  loss dict:  {'mse_loss': 0.2335457018017769}
2024-05-03 01:00:44,765 [INFO] Step[950/1020]: training loss : 0.24205170512199403 TRAIN  loss dict:  {'mse_loss': 0.24205170512199403}
2024-05-03 01:01:26,019 [INFO] Step[1000/1020]: training loss : 0.23740329205989838 TRAIN  loss dict:  {'mse_loss': 0.23740329205989838}
2024-05-03 01:04:07,565 [INFO] Label accuracies statistics:
2024-05-03 01:04:07,565 [INFO] {0: 0.5, 1: 0.75, 2: 0.75, 3: 1.0, 4: 0.6666666666666666, 5: 0.75, 6: 0.25, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.75, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.5, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 0.75, 47: 0.75, 48: 0.75, 49: 0.75, 50: 1.0, 51: 0.5, 52: 0.25, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.75, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.25, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.25, 70: 1.0, 71: 0.25, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.5, 83: 0.75, 84: 0.75, 85: 1.0, 86: 0.5, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.75, 108: 0.75, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.75, 120: 0.75, 121: 0.75, 122: 0.5, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.25, 133: 1.0, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.5, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.5, 144: 1.0, 145: 0.5, 146: 0.5, 147: 1.0, 148: 0.5, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.25, 156: 0.75, 157: 0.5, 158: 0.25, 159: 0.5, 160: 0.25, 161: 1.0, 162: 0.5, 163: 0.5, 164: 0.5, 165: 0.75, 166: 0.5, 167: 0.25, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 0.25, 175: 1.0, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.75, 180: 1.0, 181: 0.75, 182: 0.75, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.5, 187: 1.0, 188: 1.0, 189: 0.5, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.5, 196: 1.0, 197: 0.75, 198: 0.5}

2024-05-03 01:04:11,268 [INFO] [32] TRAIN  loss: 0.23580509091124816 acc: 0.0
2024-05-03 01:04:11,269 [INFO] [32] TRAIN  loss dict: {'mse_loss': 0.23580509091124816}
2024-05-03 01:04:11,269 [INFO] [32] VALIDATION loss: 1.355966908687895 VALIDATION  acc: 0.7108585858585859
2024-05-03 01:04:11,269 [INFO] [32] VALIDATION  loss dict: {'mse_loss': 0.25950628368541445, 'classification_loss': 1.0964606211643027}
2024-05-03 01:04:11,270 [INFO] 
2024-05-03 01:05:29,373 [INFO] Step[50/1020]: training loss : 0.23598120510578155 TRAIN  loss dict:  {'mse_loss': 0.23598120510578155}
2024-05-03 01:06:12,957 [INFO] Step[100/1020]: training loss : 0.2313758009672165 TRAIN  loss dict:  {'mse_loss': 0.2313758009672165}
2024-05-03 01:06:52,164 [INFO] Step[150/1020]: training loss : 0.2342521020770073 TRAIN  loss dict:  {'mse_loss': 0.2342521020770073}
2024-05-03 01:07:35,087 [INFO] Step[200/1020]: training loss : 0.22584971249103547 TRAIN  loss dict:  {'mse_loss': 0.22584971249103547}
2024-05-03 01:08:14,044 [INFO] Step[250/1020]: training loss : 0.2285214328765869 TRAIN  loss dict:  {'mse_loss': 0.2285214328765869}
2024-05-03 01:08:56,655 [INFO] Step[300/1020]: training loss : 0.22933730393648147 TRAIN  loss dict:  {'mse_loss': 0.22933730393648147}
2024-05-03 01:09:42,662 [INFO] Step[350/1020]: training loss : 0.22915040105581283 TRAIN  loss dict:  {'mse_loss': 0.22915040105581283}
2024-05-03 01:10:24,109 [INFO] Step[400/1020]: training loss : 0.22646795094013214 TRAIN  loss dict:  {'mse_loss': 0.22646795094013214}
2024-05-03 01:11:05,838 [INFO] Step[450/1020]: training loss : 0.2327306842803955 TRAIN  loss dict:  {'mse_loss': 0.2327306842803955}
2024-05-03 01:11:51,589 [INFO] Step[500/1020]: training loss : 0.23779306799173355 TRAIN  loss dict:  {'mse_loss': 0.23779306799173355}
2024-05-03 01:12:35,415 [INFO] Step[550/1020]: training loss : 0.23523744106292724 TRAIN  loss dict:  {'mse_loss': 0.23523744106292724}
2024-05-03 01:13:18,349 [INFO] Step[600/1020]: training loss : 0.23456122606992721 TRAIN  loss dict:  {'mse_loss': 0.23456122606992721}
2024-05-03 01:14:05,430 [INFO] Step[650/1020]: training loss : 0.23576901525259017 TRAIN  loss dict:  {'mse_loss': 0.23576901525259017}
2024-05-03 01:14:49,059 [INFO] Step[700/1020]: training loss : 0.23803729176521302 TRAIN  loss dict:  {'mse_loss': 0.23803729176521302}
2024-05-03 01:15:31,775 [INFO] Step[750/1020]: training loss : 0.23384021818637848 TRAIN  loss dict:  {'mse_loss': 0.23384021818637848}
2024-05-03 01:16:09,027 [INFO] Step[800/1020]: training loss : 0.23335297882556916 TRAIN  loss dict:  {'mse_loss': 0.23335297882556916}
2024-05-03 01:16:54,750 [INFO] Step[850/1020]: training loss : 0.23432255238294603 TRAIN  loss dict:  {'mse_loss': 0.23432255238294603}
2024-05-03 01:17:37,237 [INFO] Step[900/1020]: training loss : 0.22897524297237395 TRAIN  loss dict:  {'mse_loss': 0.22897524297237395}
2024-05-03 01:18:18,356 [INFO] Step[950/1020]: training loss : 0.226744145154953 TRAIN  loss dict:  {'mse_loss': 0.226744145154953}
2024-05-03 01:19:03,293 [INFO] Step[1000/1020]: training loss : 0.22854052871465683 TRAIN  loss dict:  {'mse_loss': 0.22854052871465683}
2024-05-03 01:21:42,474 [INFO] Label accuracies statistics:
2024-05-03 01:21:42,474 [INFO] {0: 0.5, 1: 0.5, 2: 0.25, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.25, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.0, 15: 0.5, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.25, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.5, 26: 1.0, 27: 1.0, 28: 0.75, 29: 0.75, 30: 0.75, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 0.75, 47: 0.75, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.5, 52: 0.25, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.25, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.5, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.25, 70: 1.0, 71: 0.5, 72: 1.0, 73: 0.5, 74: 0.5, 75: 1.0, 76: 0.5, 77: 1.0, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.0, 83: 0.75, 84: 0.75, 85: 1.0, 86: 0.25, 87: 0.25, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.5, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.25, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.5, 110: 1.0, 111: 1.0, 112: 0.25, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.75, 120: 0.5, 121: 0.75, 122: 0.5, 123: 0.5, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.0, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.25, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.5, 146: 0.75, 147: 1.0, 148: 0.75, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.0, 156: 0.75, 157: 0.5, 158: 0.25, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.5, 164: 0.5, 165: 1.0, 166: 0.5, 167: 0.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.5, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 0.75, 181: 0.75, 182: 0.75, 183: 0.75, 184: 0.25, 185: 0.75, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.75, 196: 0.5, 197: 1.0, 198: 0.75}

2024-05-03 01:21:42,491 [INFO] [33] TRAIN  loss: 0.2321915859393045 acc: 0.0
2024-05-03 01:21:42,491 [INFO] [33] TRAIN  loss dict: {'mse_loss': 0.2321915859393045}
2024-05-03 01:21:42,492 [INFO] [33] VALIDATION loss: 1.3636655615586224 VALIDATION  acc: 0.6931818181818182
2024-05-03 01:21:42,492 [INFO] [33] VALIDATION  loss dict: {'mse_loss': 0.2584263667313739, 'classification_loss': 1.105239194281625}
2024-05-03 01:21:42,492 [INFO] 
2024-05-03 01:22:55,855 [INFO] Step[50/1020]: training loss : 0.2361416271328926 TRAIN  loss dict:  {'mse_loss': 0.2361416271328926}
2024-05-03 01:23:38,644 [INFO] Step[100/1020]: training loss : 0.2278267887234688 TRAIN  loss dict:  {'mse_loss': 0.2278267887234688}
2024-05-03 01:24:24,595 [INFO] Step[150/1020]: training loss : 0.2317546182870865 TRAIN  loss dict:  {'mse_loss': 0.2317546182870865}
2024-05-03 01:25:09,711 [INFO] Step[200/1020]: training loss : 0.22977499336004256 TRAIN  loss dict:  {'mse_loss': 0.22977499336004256}
2024-05-03 01:25:54,694 [INFO] Step[250/1020]: training loss : 0.23139985471963884 TRAIN  loss dict:  {'mse_loss': 0.23139985471963884}
2024-05-03 01:26:37,882 [INFO] Step[300/1020]: training loss : 0.22453216075897217 TRAIN  loss dict:  {'mse_loss': 0.22453216075897217}
2024-05-03 01:27:16,955 [INFO] Step[350/1020]: training loss : 0.22828048288822175 TRAIN  loss dict:  {'mse_loss': 0.22828048288822175}
2024-05-03 01:27:58,498 [INFO] Step[400/1020]: training loss : 0.23036428153514862 TRAIN  loss dict:  {'mse_loss': 0.23036428153514862}
2024-05-03 01:28:43,338 [INFO] Step[450/1020]: training loss : 0.22750296026468278 TRAIN  loss dict:  {'mse_loss': 0.22750296026468278}
2024-05-03 01:29:23,130 [INFO] Step[500/1020]: training loss : 0.22713616907596587 TRAIN  loss dict:  {'mse_loss': 0.22713616907596587}
2024-05-03 01:30:02,677 [INFO] Step[550/1020]: training loss : 0.23794238537549972 TRAIN  loss dict:  {'mse_loss': 0.23794238537549972}
2024-05-03 01:30:49,634 [INFO] Step[600/1020]: training loss : 0.2312815707921982 TRAIN  loss dict:  {'mse_loss': 0.2312815707921982}
2024-05-03 01:31:32,673 [INFO] Step[650/1020]: training loss : 0.2217799398303032 TRAIN  loss dict:  {'mse_loss': 0.2217799398303032}
2024-05-03 01:32:16,532 [INFO] Step[700/1020]: training loss : 0.23550972193479539 TRAIN  loss dict:  {'mse_loss': 0.23550972193479539}
2024-05-03 01:32:56,066 [INFO] Step[750/1020]: training loss : 0.2336518582701683 TRAIN  loss dict:  {'mse_loss': 0.2336518582701683}
2024-05-03 01:33:37,707 [INFO] Step[800/1020]: training loss : 0.23008620440959932 TRAIN  loss dict:  {'mse_loss': 0.23008620440959932}
2024-05-03 01:34:26,854 [INFO] Step[850/1020]: training loss : 0.2294371935725212 TRAIN  loss dict:  {'mse_loss': 0.2294371935725212}
2024-05-03 01:35:10,056 [INFO] Step[900/1020]: training loss : 0.2321425512433052 TRAIN  loss dict:  {'mse_loss': 0.2321425512433052}
2024-05-03 01:35:54,219 [INFO] Step[950/1020]: training loss : 0.2265417158603668 TRAIN  loss dict:  {'mse_loss': 0.2265417158603668}
2024-05-03 01:36:37,070 [INFO] Step[1000/1020]: training loss : 0.24233787298202514 TRAIN  loss dict:  {'mse_loss': 0.24233787298202514}
2024-05-03 01:39:16,821 [INFO] Label accuracies statistics:
2024-05-03 01:39:16,821 [INFO] {0: 0.5, 1: 1.0, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 0.5, 6: 0.5, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.25, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.5, 24: 0.5, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.5, 29: 1.0, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.25, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 0.75, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.5, 52: 0.25, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.25, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.25, 67: 0.75, 68: 0.75, 69: 0.5, 70: 1.0, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.5, 83: 0.75, 84: 0.75, 85: 1.0, 86: 0.5, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.5, 109: 0.5, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.75, 120: 0.75, 121: 1.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 0.75, 129: 0.75, 130: 1.0, 131: 0.75, 132: 0.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.75, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.5, 146: 0.75, 147: 1.0, 148: 0.5, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.5, 156: 0.75, 157: 0.5, 158: 0.5, 159: 0.5, 160: 0.25, 161: 1.0, 162: 0.5, 163: 0.5, 164: 0.75, 165: 0.75, 166: 0.5, 167: 0.25, 168: 0.5, 169: 0.5, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.25, 175: 1.0, 176: 0.5, 177: 0.75, 178: 0.75, 179: 0.75, 180: 1.0, 181: 1.0, 182: 0.5, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.5, 196: 0.75, 197: 0.75, 198: 0.75}

2024-05-03 01:39:20,670 [INFO] [34] TRAIN  loss: 0.23076943966980074 acc: 0.0
2024-05-03 01:39:20,672 [INFO] [34] TRAIN  loss dict: {'mse_loss': 0.23076943966980074}
2024-05-03 01:39:20,674 [INFO] [34] VALIDATION loss: 1.309286157365399 VALIDATION  acc: 0.7196969696969697
2024-05-03 01:39:20,676 [INFO] [34] VALIDATION  loss dict: {'mse_loss': 0.2570010339370882, 'classification_loss': 1.0522851205684922}
2024-05-03 01:39:20,678 [INFO] 
2024-05-03 01:40:40,438 [INFO] Step[50/1020]: training loss : 0.23833045214414597 TRAIN  loss dict:  {'mse_loss': 0.23833045214414597}
2024-05-03 01:41:24,001 [INFO] Step[100/1020]: training loss : 0.2243464097380638 TRAIN  loss dict:  {'mse_loss': 0.2243464097380638}
2024-05-03 01:42:09,750 [INFO] Step[150/1020]: training loss : 0.22173077434301378 TRAIN  loss dict:  {'mse_loss': 0.22173077434301378}
2024-05-03 01:42:56,150 [INFO] Step[200/1020]: training loss : 0.22566246062517167 TRAIN  loss dict:  {'mse_loss': 0.22566246062517167}
2024-05-03 01:43:38,781 [INFO] Step[250/1020]: training loss : 0.22545478552579878 TRAIN  loss dict:  {'mse_loss': 0.22545478552579878}
2024-05-03 01:44:20,237 [INFO] Step[300/1020]: training loss : 0.2283458998799324 TRAIN  loss dict:  {'mse_loss': 0.2283458998799324}
2024-05-03 01:45:08,133 [INFO] Step[350/1020]: training loss : 0.22880657464265824 TRAIN  loss dict:  {'mse_loss': 0.22880657464265824}
2024-05-03 01:45:53,858 [INFO] Step[400/1020]: training loss : 0.23266611009836197 TRAIN  loss dict:  {'mse_loss': 0.23266611009836197}
2024-05-03 01:46:35,177 [INFO] Step[450/1020]: training loss : 0.22655750185251236 TRAIN  loss dict:  {'mse_loss': 0.22655750185251236}
2024-05-03 01:47:16,934 [INFO] Step[500/1020]: training loss : 0.2257192239165306 TRAIN  loss dict:  {'mse_loss': 0.2257192239165306}
2024-05-03 01:48:00,758 [INFO] Step[550/1020]: training loss : 0.22492803692817687 TRAIN  loss dict:  {'mse_loss': 0.22492803692817687}
2024-05-03 01:48:41,221 [INFO] Step[600/1020]: training loss : 0.23067510455846787 TRAIN  loss dict:  {'mse_loss': 0.23067510455846787}
2024-05-03 01:49:23,331 [INFO] Step[650/1020]: training loss : 0.23130200952291488 TRAIN  loss dict:  {'mse_loss': 0.23130200952291488}
2024-05-03 01:50:06,964 [INFO] Step[700/1020]: training loss : 0.22665241062641145 TRAIN  loss dict:  {'mse_loss': 0.22665241062641145}
2024-05-03 01:50:51,612 [INFO] Step[750/1020]: training loss : 0.22975767761468888 TRAIN  loss dict:  {'mse_loss': 0.22975767761468888}
2024-05-03 01:51:36,177 [INFO] Step[800/1020]: training loss : 0.23015523076057434 TRAIN  loss dict:  {'mse_loss': 0.23015523076057434}
2024-05-03 01:52:17,024 [INFO] Step[850/1020]: training loss : 0.23064775735139847 TRAIN  loss dict:  {'mse_loss': 0.23064775735139847}
2024-05-03 01:53:00,582 [INFO] Step[900/1020]: training loss : 0.22946122854948045 TRAIN  loss dict:  {'mse_loss': 0.22946122854948045}
2024-05-03 01:53:46,011 [INFO] Step[950/1020]: training loss : 0.23164021372795104 TRAIN  loss dict:  {'mse_loss': 0.23164021372795104}
2024-05-03 01:54:31,374 [INFO] Step[1000/1020]: training loss : 0.22096206933259965 TRAIN  loss dict:  {'mse_loss': 0.22096206933259965}
2024-05-03 01:57:14,310 [INFO] Label accuracies statistics:
2024-05-03 01:57:14,311 [INFO] {0: 1.0, 1: 0.75, 2: 0.25, 3: 0.75, 4: 0.6666666666666666, 5: 0.5, 6: 0.5, 7: 1.0, 8: 0.0, 9: 0.75, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.5, 16: 1.0, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.5, 24: 0.5, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.5, 29: 0.75, 30: 0.75, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.25, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 1.0, 51: 0.5, 52: 0.25, 53: 0.25, 54: 0.5, 55: 0.5, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.25, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.75, 66: 0.25, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.5, 74: 0.5, 75: 1.0, 76: 0.25, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.5, 83: 0.75, 84: 0.5, 85: 1.0, 86: 0.25, 87: 0.5, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.75, 95: 0.75, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.25, 106: 0.75, 107: 1.0, 108: 0.5, 109: 0.75, 110: 1.0, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.75, 120: 0.5, 121: 1.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 0.75, 126: 0.75, 127: 1.0, 128: 0.75, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.25, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.75, 140: 0.75, 141: 0.5, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.75, 146: 0.5, 147: 1.0, 148: 0.25, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.25, 156: 0.75, 157: 0.5, 158: 0.5, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.5, 163: 0.5, 164: 0.5, 165: 1.0, 166: 0.5, 167: 0.5, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.5, 175: 1.0, 176: 0.75, 177: 0.5, 178: 1.0, 179: 0.5, 180: 0.75, 181: 1.0, 182: 0.75, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.25, 187: 1.0, 188: 0.25, 189: 0.5, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.5, 196: 1.0, 197: 0.5, 198: 0.75}

2024-05-03 01:57:14,328 [INFO] [35] TRAIN  loss: 0.2280485985325832 acc: 0.0
2024-05-03 01:57:14,329 [INFO] [35] TRAIN  loss dict: {'mse_loss': 0.2280485985325832}
2024-05-03 01:57:14,329 [INFO] [35] VALIDATION loss: 1.3732196590063548 VALIDATION  acc: 0.6957070707070707
2024-05-03 01:57:14,329 [INFO] [35] VALIDATION  loss dict: {'mse_loss': 0.2592906216629828, 'classification_loss': 1.1139290342201489}
2024-05-03 01:57:14,329 [INFO] 
2024-05-03 01:58:28,399 [INFO] Step[50/1020]: training loss : 0.22299684673547746 TRAIN  loss dict:  {'mse_loss': 0.22299684673547746}
2024-05-03 01:59:17,005 [INFO] Step[100/1020]: training loss : 0.22724305033683778 TRAIN  loss dict:  {'mse_loss': 0.22724305033683778}
2024-05-03 01:59:57,622 [INFO] Step[150/1020]: training loss : 0.23139868468046187 TRAIN  loss dict:  {'mse_loss': 0.23139868468046187}
2024-05-03 02:00:38,920 [INFO] Step[200/1020]: training loss : 0.22062747359275817 TRAIN  loss dict:  {'mse_loss': 0.22062747359275817}
2024-05-03 02:01:20,379 [INFO] Step[250/1020]: training loss : 0.22496656596660614 TRAIN  loss dict:  {'mse_loss': 0.22496656596660614}
2024-05-03 02:02:08,175 [INFO] Step[300/1020]: training loss : 0.22835426837205886 TRAIN  loss dict:  {'mse_loss': 0.22835426837205886}
2024-05-03 02:02:48,436 [INFO] Step[350/1020]: training loss : 0.2283657693862915 TRAIN  loss dict:  {'mse_loss': 0.2283657693862915}
2024-05-03 02:03:28,678 [INFO] Step[400/1020]: training loss : 0.22276926577091216 TRAIN  loss dict:  {'mse_loss': 0.22276926577091216}
2024-05-03 02:04:14,480 [INFO] Step[450/1020]: training loss : 0.2182397523522377 TRAIN  loss dict:  {'mse_loss': 0.2182397523522377}
2024-05-03 02:04:54,290 [INFO] Step[500/1020]: training loss : 0.23136705338954924 TRAIN  loss dict:  {'mse_loss': 0.23136705338954924}
2024-05-03 02:05:38,750 [INFO] Step[550/1020]: training loss : 0.22569344729185103 TRAIN  loss dict:  {'mse_loss': 0.22569344729185103}
2024-05-03 02:06:28,007 [INFO] Step[600/1020]: training loss : 0.22679731309413909 TRAIN  loss dict:  {'mse_loss': 0.22679731309413909}
2024-05-03 02:07:14,459 [INFO] Step[650/1020]: training loss : 0.2316831660270691 TRAIN  loss dict:  {'mse_loss': 0.2316831660270691}
2024-05-03 02:07:57,217 [INFO] Step[700/1020]: training loss : 0.22497542291879655 TRAIN  loss dict:  {'mse_loss': 0.22497542291879655}
2024-05-03 02:08:33,446 [INFO] Step[750/1020]: training loss : 0.21913214266300202 TRAIN  loss dict:  {'mse_loss': 0.21913214266300202}
2024-05-03 02:09:15,942 [INFO] Step[800/1020]: training loss : 0.22870351791381835 TRAIN  loss dict:  {'mse_loss': 0.22870351791381835}
2024-05-03 02:09:56,804 [INFO] Step[850/1020]: training loss : 0.22350339651107787 TRAIN  loss dict:  {'mse_loss': 0.22350339651107787}
2024-05-03 02:10:42,746 [INFO] Step[900/1020]: training loss : 0.22902514576911925 TRAIN  loss dict:  {'mse_loss': 0.22902514576911925}
2024-05-03 02:11:20,418 [INFO] Step[950/1020]: training loss : 0.223640339076519 TRAIN  loss dict:  {'mse_loss': 0.223640339076519}
2024-05-03 02:12:04,241 [INFO] Step[1000/1020]: training loss : 0.22502866566181182 TRAIN  loss dict:  {'mse_loss': 0.22502866566181182}
2024-05-03 02:14:50,192 [INFO] Label accuracies statistics:
2024-05-03 02:14:50,192 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.25, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.5, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.5, 26: 0.75, 27: 1.0, 28: 0.5, 29: 1.0, 30: 0.75, 31: 1.0, 32: 1.0, 33: 0.5, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.5, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.75, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 1.0, 51: 0.5, 52: 0.25, 53: 0.25, 54: 0.5, 55: 0.5, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.0, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.5, 67: 1.0, 68: 0.75, 69: 0.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.5, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.5, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.5, 83: 1.0, 84: 0.75, 85: 1.0, 86: 0.25, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.5, 97: 1.0, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.5, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.75, 118: 0.75, 119: 0.75, 120: 0.75, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 0.75, 126: 0.75, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.25, 140: 0.75, 141: 1.0, 142: 0.75, 143: 1.0, 144: 1.0, 145: 0.5, 146: 0.75, 147: 1.0, 148: 0.25, 149: 0.5, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.0, 156: 0.5, 157: 0.5, 158: 0.5, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.5, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.25, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.25, 175: 1.0, 176: 0.75, 177: 0.75, 178: 0.75, 179: 1.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.75}

2024-05-03 02:14:50,209 [INFO] [36] TRAIN  loss: 0.22578228184697674 acc: 0.0
2024-05-03 02:14:50,209 [INFO] [36] TRAIN  loss dict: {'mse_loss': 0.22578228184697674}
2024-05-03 02:14:50,209 [INFO] [36] VALIDATION loss: 1.3300789490041107 VALIDATION  acc: 0.7095959595959596
2024-05-03 02:14:50,210 [INFO] [36] VALIDATION  loss dict: {'mse_loss': 0.25574721373391873, 'classification_loss': 1.0743317327302213}
2024-05-03 02:14:50,210 [INFO] 
2024-05-03 02:16:09,879 [INFO] Step[50/1020]: training loss : 0.22607507556676865 TRAIN  loss dict:  {'mse_loss': 0.22607507556676865}
2024-05-03 02:16:54,737 [INFO] Step[100/1020]: training loss : 0.2260097321867943 TRAIN  loss dict:  {'mse_loss': 0.2260097321867943}
2024-05-03 02:17:34,485 [INFO] Step[150/1020]: training loss : 0.23043789058923722 TRAIN  loss dict:  {'mse_loss': 0.23043789058923722}
2024-05-03 02:18:17,926 [INFO] Step[200/1020]: training loss : 0.2241015514731407 TRAIN  loss dict:  {'mse_loss': 0.2241015514731407}
2024-05-03 02:18:59,719 [INFO] Step[250/1020]: training loss : 0.21876211762428283 TRAIN  loss dict:  {'mse_loss': 0.21876211762428283}
2024-05-03 02:19:47,181 [INFO] Step[300/1020]: training loss : 0.22520686209201812 TRAIN  loss dict:  {'mse_loss': 0.22520686209201812}
2024-05-03 02:20:36,769 [INFO] Step[350/1020]: training loss : 0.22732748091220856 TRAIN  loss dict:  {'mse_loss': 0.22732748091220856}
2024-05-03 02:21:14,957 [INFO] Step[400/1020]: training loss : 0.22978683233261107 TRAIN  loss dict:  {'mse_loss': 0.22978683233261107}
2024-05-03 02:21:56,822 [INFO] Step[450/1020]: training loss : 0.23167726367712022 TRAIN  loss dict:  {'mse_loss': 0.23167726367712022}
2024-05-03 02:22:42,272 [INFO] Step[500/1020]: training loss : 0.22670947015285492 TRAIN  loss dict:  {'mse_loss': 0.22670947015285492}
2024-05-03 02:23:24,572 [INFO] Step[550/1020]: training loss : 0.22245996445417404 TRAIN  loss dict:  {'mse_loss': 0.22245996445417404}
2024-05-03 02:24:07,205 [INFO] Step[600/1020]: training loss : 0.22426583737134934 TRAIN  loss dict:  {'mse_loss': 0.22426583737134934}
2024-05-03 02:24:53,008 [INFO] Step[650/1020]: training loss : 0.23367747277021408 TRAIN  loss dict:  {'mse_loss': 0.23367747277021408}
2024-05-03 02:25:32,799 [INFO] Step[700/1020]: training loss : 0.227788704931736 TRAIN  loss dict:  {'mse_loss': 0.227788704931736}
2024-05-03 02:26:19,547 [INFO] Step[750/1020]: training loss : 0.2252419939637184 TRAIN  loss dict:  {'mse_loss': 0.2252419939637184}
2024-05-03 02:26:58,936 [INFO] Step[800/1020]: training loss : 0.22022889882326127 TRAIN  loss dict:  {'mse_loss': 0.22022889882326127}
2024-05-03 02:27:38,380 [INFO] Step[850/1020]: training loss : 0.22215465515851973 TRAIN  loss dict:  {'mse_loss': 0.22215465515851973}
2024-05-03 02:28:18,875 [INFO] Step[900/1020]: training loss : 0.22898262292146682 TRAIN  loss dict:  {'mse_loss': 0.22898262292146682}
2024-05-03 02:29:05,846 [INFO] Step[950/1020]: training loss : 0.22605573356151581 TRAIN  loss dict:  {'mse_loss': 0.22605573356151581}
2024-05-03 02:29:46,377 [INFO] Step[1000/1020]: training loss : 0.2256955799460411 TRAIN  loss dict:  {'mse_loss': 0.2256955799460411}
2024-05-03 02:32:40,305 [INFO] Label accuracies statistics:
2024-05-03 02:32:40,306 [INFO] {0: 0.5, 1: 1.0, 2: 1.0, 3: 1.0, 4: 0.6666666666666666, 5: 0.5, 6: 0.25, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.5, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.5, 26: 1.0, 27: 0.75, 28: 0.5, 29: 1.0, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.75, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.5, 52: 0.25, 53: 0.25, 54: 0.5, 55: 0.5, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.25, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.25, 67: 1.0, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.25, 77: 0.5, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.5, 83: 0.75, 84: 0.5, 85: 0.75, 86: 0.25, 87: 0.75, 88: 1.0, 89: 0.5, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.5, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.0, 113: 0.25, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.5, 118: 0.75, 119: 0.75, 120: 0.75, 121: 1.0, 122: 0.75, 123: 0.5, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.25, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.5, 144: 1.0, 145: 0.75, 146: 0.5, 147: 1.0, 148: 0.5, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.5, 156: 0.75, 157: 0.5, 158: 0.25, 159: 0.5, 160: 0.75, 161: 1.0, 162: 0.5, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.5, 167: 0.25, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 0.5, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 0.75, 181: 1.0, 182: 0.75, 183: 0.75, 184: 0.75, 185: 0.75, 186: 0.5, 187: 1.0, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.25, 196: 0.75, 197: 1.0, 198: 0.75}

2024-05-03 02:32:40,323 [INFO] [37] TRAIN  loss: 0.226141696540164 acc: 0.0
2024-05-03 02:32:40,323 [INFO] [37] TRAIN  loss dict: {'mse_loss': 0.226141696540164}
2024-05-03 02:32:40,324 [INFO] [37] VALIDATION loss: 1.3199183840793793 VALIDATION  acc: 0.7171717171717171
2024-05-03 02:32:40,324 [INFO] [37] VALIDATION  loss dict: {'mse_loss': 0.25388061052018945, 'classification_loss': 1.0660377725432015}
2024-05-03 02:32:40,324 [INFO] 
2024-05-03 02:33:55,965 [INFO] Step[50/1020]: training loss : 0.22044481188058854 TRAIN  loss dict:  {'mse_loss': 0.22044481188058854}
2024-05-03 02:34:38,594 [INFO] Step[100/1020]: training loss : 0.21262862861156465 TRAIN  loss dict:  {'mse_loss': 0.21262862861156465}
2024-05-03 02:35:20,140 [INFO] Step[150/1020]: training loss : 0.22786226630210876 TRAIN  loss dict:  {'mse_loss': 0.22786226630210876}
2024-05-03 02:36:02,179 [INFO] Step[200/1020]: training loss : 0.22629857420921326 TRAIN  loss dict:  {'mse_loss': 0.22629857420921326}
2024-05-03 02:36:47,353 [INFO] Step[250/1020]: training loss : 0.23071476697921753 TRAIN  loss dict:  {'mse_loss': 0.23071476697921753}
2024-05-03 02:37:29,078 [INFO] Step[300/1020]: training loss : 0.218887060880661 TRAIN  loss dict:  {'mse_loss': 0.218887060880661}
2024-05-03 02:38:15,817 [INFO] Step[350/1020]: training loss : 0.2149531838297844 TRAIN  loss dict:  {'mse_loss': 0.2149531838297844}
2024-05-03 02:38:57,207 [INFO] Step[400/1020]: training loss : 0.21906081974506378 TRAIN  loss dict:  {'mse_loss': 0.21906081974506378}
2024-05-03 02:39:40,682 [INFO] Step[450/1020]: training loss : 0.22306691318750382 TRAIN  loss dict:  {'mse_loss': 0.22306691318750382}
2024-05-03 02:40:24,326 [INFO] Step[500/1020]: training loss : 0.23561656177043916 TRAIN  loss dict:  {'mse_loss': 0.23561656177043916}
2024-05-03 02:41:01,156 [INFO] Step[550/1020]: training loss : 0.2272418287396431 TRAIN  loss dict:  {'mse_loss': 0.2272418287396431}
2024-05-03 02:41:44,958 [INFO] Step[600/1020]: training loss : 0.22678764790296554 TRAIN  loss dict:  {'mse_loss': 0.22678764790296554}
2024-05-03 02:42:26,878 [INFO] Step[650/1020]: training loss : 0.2215583625435829 TRAIN  loss dict:  {'mse_loss': 0.2215583625435829}
2024-05-03 02:43:11,541 [INFO] Step[700/1020]: training loss : 0.22848689138889314 TRAIN  loss dict:  {'mse_loss': 0.22848689138889314}
2024-05-03 02:43:54,245 [INFO] Step[750/1020]: training loss : 0.2178186747431755 TRAIN  loss dict:  {'mse_loss': 0.2178186747431755}
2024-05-03 02:44:37,271 [INFO] Step[800/1020]: training loss : 0.22759782016277313 TRAIN  loss dict:  {'mse_loss': 0.22759782016277313}
2024-05-03 02:45:20,958 [INFO] Step[850/1020]: training loss : 0.21552248269319535 TRAIN  loss dict:  {'mse_loss': 0.21552248269319535}
2024-05-03 02:46:06,035 [INFO] Step[900/1020]: training loss : 0.2249484756588936 TRAIN  loss dict:  {'mse_loss': 0.2249484756588936}
2024-05-03 02:46:51,069 [INFO] Step[950/1020]: training loss : 0.2196482887864113 TRAIN  loss dict:  {'mse_loss': 0.2196482887864113}
2024-05-03 02:47:33,595 [INFO] Step[1000/1020]: training loss : 0.22471200317144394 TRAIN  loss dict:  {'mse_loss': 0.22471200317144394}
2024-05-03 02:50:18,050 [INFO] Label accuracies statistics:
2024-05-03 02:50:18,052 [INFO] {0: 1.0, 1: 0.5, 2: 0.25, 3: 1.0, 4: 0.3333333333333333, 5: 0.5, 6: 0.5, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.5, 16: 1.0, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.25, 26: 1.0, 27: 1.0, 28: 0.5, 29: 0.75, 30: 0.75, 31: 0.5, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.5, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.25, 53: 0.25, 54: 0.5, 55: 1.0, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.25, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.5, 66: 0.5, 67: 1.0, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 1.0, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.5, 83: 1.0, 84: 0.75, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.75, 95: 0.75, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.25, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 0.75, 119: 0.75, 120: 0.5, 121: 1.0, 122: 1.0, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.25, 139: 0.75, 140: 0.5, 141: 1.0, 142: 0.75, 143: 0.5, 144: 1.0, 145: 0.5, 146: 0.5, 147: 1.0, 148: 0.5, 149: 0.5, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.5, 158: 0.75, 159: 0.5, 160: 0.25, 161: 1.0, 162: 0.25, 163: 0.5, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.5, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 0.75, 181: 0.75, 182: 0.75, 183: 0.5, 184: 0.75, 185: 0.75, 186: 0.25, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.75}

2024-05-03 02:50:18,080 [INFO] [38] TRAIN  loss: 0.22315072348597004 acc: 0.0
2024-05-03 02:50:18,080 [INFO] [38] TRAIN  loss dict: {'mse_loss': 0.22315072348597004}
2024-05-03 02:50:18,081 [INFO] [38] VALIDATION loss: 1.3102875558113811 VALIDATION  acc: 0.726010101010101
2024-05-03 02:50:18,081 [INFO] [38] VALIDATION  loss dict: {'mse_loss': 0.25318828669160304, 'classification_loss': 1.0570992695431065}
2024-05-03 02:50:18,081 [INFO] 
2024-05-03 02:51:36,063 [INFO] Step[50/1020]: training loss : 0.22731898337602616 TRAIN  loss dict:  {'mse_loss': 0.22731898337602616}
2024-05-03 02:52:15,931 [INFO] Step[100/1020]: training loss : 0.22434274941682816 TRAIN  loss dict:  {'mse_loss': 0.22434274941682816}
2024-05-03 02:53:00,281 [INFO] Step[150/1020]: training loss : 0.21760377287864685 TRAIN  loss dict:  {'mse_loss': 0.21760377287864685}
2024-05-03 02:53:41,725 [INFO] Step[200/1020]: training loss : 0.2186543056368828 TRAIN  loss dict:  {'mse_loss': 0.2186543056368828}
2024-05-03 02:54:21,637 [INFO] Step[250/1020]: training loss : 0.2207300665974617 TRAIN  loss dict:  {'mse_loss': 0.2207300665974617}
2024-05-03 02:55:03,500 [INFO] Step[300/1020]: training loss : 0.21943229526281358 TRAIN  loss dict:  {'mse_loss': 0.21943229526281358}
2024-05-03 02:55:48,921 [INFO] Step[350/1020]: training loss : 0.2177547624707222 TRAIN  loss dict:  {'mse_loss': 0.2177547624707222}
2024-05-03 02:56:27,886 [INFO] Step[400/1020]: training loss : 0.2171948516368866 TRAIN  loss dict:  {'mse_loss': 0.2171948516368866}
2024-05-03 02:57:10,938 [INFO] Step[450/1020]: training loss : 0.2253526294231415 TRAIN  loss dict:  {'mse_loss': 0.2253526294231415}
2024-05-03 02:57:54,847 [INFO] Step[500/1020]: training loss : 0.22105410039424897 TRAIN  loss dict:  {'mse_loss': 0.22105410039424897}
2024-05-03 02:58:40,858 [INFO] Step[550/1020]: training loss : 0.21695656418800355 TRAIN  loss dict:  {'mse_loss': 0.21695656418800355}
2024-05-03 02:59:26,034 [INFO] Step[600/1020]: training loss : 0.22430295556783675 TRAIN  loss dict:  {'mse_loss': 0.22430295556783675}
2024-05-03 03:00:08,426 [INFO] Step[650/1020]: training loss : 0.22649304658174516 TRAIN  loss dict:  {'mse_loss': 0.22649304658174516}
2024-05-03 03:00:49,240 [INFO] Step[700/1020]: training loss : 0.2257076621055603 TRAIN  loss dict:  {'mse_loss': 0.2257076621055603}
2024-05-03 03:01:29,701 [INFO] Step[750/1020]: training loss : 0.22064027607440947 TRAIN  loss dict:  {'mse_loss': 0.22064027607440947}
2024-05-03 03:02:12,540 [INFO] Step[800/1020]: training loss : 0.22398463606834412 TRAIN  loss dict:  {'mse_loss': 0.22398463606834412}
2024-05-03 03:02:54,628 [INFO] Step[850/1020]: training loss : 0.22420290142297744 TRAIN  loss dict:  {'mse_loss': 0.22420290142297744}
2024-05-03 03:03:35,619 [INFO] Step[900/1020]: training loss : 0.2213757112622261 TRAIN  loss dict:  {'mse_loss': 0.2213757112622261}
2024-05-03 03:04:14,748 [INFO] Step[950/1020]: training loss : 0.21607668548822404 TRAIN  loss dict:  {'mse_loss': 0.21607668548822404}
2024-05-03 03:04:55,613 [INFO] Step[1000/1020]: training loss : 0.2213010323047638 TRAIN  loss dict:  {'mse_loss': 0.2213010323047638}
2024-05-03 03:07:43,953 [INFO] Label accuracies statistics:
2024-05-03 03:07:43,953 [INFO] {0: 1.0, 1: 0.75, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 0.5, 6: 0.5, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.25, 16: 1.0, 17: 0.5, 18: 1.0, 19: 0.5, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.5, 29: 0.75, 30: 0.75, 31: 0.5, 32: 1.0, 33: 0.75, 34: 0.75, 35: 0.5, 36: 1.0, 37: 0.25, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.75, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 1.0, 51: 0.75, 52: 0.25, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.25, 61: 0.75, 62: 1.0, 63: 0.5, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.0, 83: 1.0, 84: 0.75, 85: 0.75, 86: 0.25, 87: 0.5, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.75, 120: 0.75, 121: 1.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.5, 133: 0.75, 134: 0.75, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.5, 139: 0.5, 140: 0.5, 141: 1.0, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.5, 146: 0.75, 147: 0.75, 148: 0.5, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.25, 156: 0.75, 157: 0.5, 158: 0.75, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.25, 163: 0.5, 164: 0.5, 165: 1.0, 166: 0.5, 167: 0.5, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.5, 175: 1.0, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.5, 180: 0.5, 181: 1.0, 182: 0.5, 183: 0.75, 184: 0.25, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.75}

2024-05-03 03:07:44,014 [INFO] [39] TRAIN  loss: 0.2213985150205154 acc: 0.0
2024-05-03 03:07:44,015 [INFO] [39] TRAIN  loss dict: {'mse_loss': 0.2213985150205154}
2024-05-03 03:07:44,015 [INFO] [39] VALIDATION loss: 1.3068818223446306 VALIDATION  acc: 0.7159090909090909
2024-05-03 03:07:44,015 [INFO] [39] VALIDATION  loss dict: {'mse_loss': 0.2537255872680683, 'classification_loss': 1.0531562301941744}
2024-05-03 03:07:44,016 [INFO] 
2024-05-03 03:08:58,173 [INFO] Step[50/1020]: training loss : 0.22606258153915404 TRAIN  loss dict:  {'mse_loss': 0.22606258153915404}
2024-05-03 03:09:39,779 [INFO] Step[100/1020]: training loss : 0.21173704624176026 TRAIN  loss dict:  {'mse_loss': 0.21173704624176026}
2024-05-03 03:10:20,962 [INFO] Step[150/1020]: training loss : 0.21348055928945542 TRAIN  loss dict:  {'mse_loss': 0.21348055928945542}
2024-05-03 03:11:06,981 [INFO] Step[200/1020]: training loss : 0.22322628378868103 TRAIN  loss dict:  {'mse_loss': 0.22322628378868103}
2024-05-03 03:11:52,757 [INFO] Step[250/1020]: training loss : 0.2227464908361435 TRAIN  loss dict:  {'mse_loss': 0.2227464908361435}
2024-05-03 03:12:36,614 [INFO] Step[300/1020]: training loss : 0.214271183013916 TRAIN  loss dict:  {'mse_loss': 0.214271183013916}
2024-05-03 03:13:16,067 [INFO] Step[350/1020]: training loss : 0.21874803751707078 TRAIN  loss dict:  {'mse_loss': 0.21874803751707078}
2024-05-03 03:13:59,960 [INFO] Step[400/1020]: training loss : 0.22418454110622407 TRAIN  loss dict:  {'mse_loss': 0.22418454110622407}
2024-05-03 03:14:41,671 [INFO] Step[450/1020]: training loss : 0.20770811527967453 TRAIN  loss dict:  {'mse_loss': 0.20770811527967453}
2024-05-03 03:15:25,237 [INFO] Step[500/1020]: training loss : 0.22015878230333327 TRAIN  loss dict:  {'mse_loss': 0.22015878230333327}
2024-05-03 03:16:04,665 [INFO] Step[550/1020]: training loss : 0.22457643032073973 TRAIN  loss dict:  {'mse_loss': 0.22457643032073973}
2024-05-03 03:16:41,094 [INFO] Step[600/1020]: training loss : 0.21713776469230653 TRAIN  loss dict:  {'mse_loss': 0.21713776469230653}
2024-05-03 03:17:20,101 [INFO] Step[650/1020]: training loss : 0.22098321050405503 TRAIN  loss dict:  {'mse_loss': 0.22098321050405503}
2024-05-03 03:18:01,848 [INFO] Step[700/1020]: training loss : 0.2157011944055557 TRAIN  loss dict:  {'mse_loss': 0.2157011944055557}
2024-05-03 03:18:42,187 [INFO] Step[750/1020]: training loss : 0.2199561071395874 TRAIN  loss dict:  {'mse_loss': 0.2199561071395874}
2024-05-03 03:19:29,127 [INFO] Step[800/1020]: training loss : 0.22786012411117554 TRAIN  loss dict:  {'mse_loss': 0.22786012411117554}
2024-05-03 03:20:04,560 [INFO] Step[850/1020]: training loss : 0.22483737111091615 TRAIN  loss dict:  {'mse_loss': 0.22483737111091615}
2024-05-03 03:20:45,644 [INFO] Step[900/1020]: training loss : 0.2183085200190544 TRAIN  loss dict:  {'mse_loss': 0.2183085200190544}
2024-05-03 03:21:28,978 [INFO] Step[950/1020]: training loss : 0.22589914590120316 TRAIN  loss dict:  {'mse_loss': 0.22589914590120316}
2024-05-03 03:22:08,303 [INFO] Step[1000/1020]: training loss : 0.22253107517957688 TRAIN  loss dict:  {'mse_loss': 0.22253107517957688}
2024-05-03 03:24:50,696 [INFO] Label accuracies statistics:
2024-05-03 03:24:50,696 [INFO] {0: 0.5, 1: 0.75, 2: 0.25, 3: 1.0, 4: 0.6666666666666666, 5: 0.75, 6: 0.25, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.5, 14: 0.25, 15: 0.25, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.5, 29: 0.75, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.5, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.5, 52: 0.25, 53: 0.0, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.25, 60: 0.25, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.5, 66: 0.5, 67: 0.75, 68: 0.75, 69: 1.0, 70: 1.0, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.5, 83: 0.75, 84: 0.5, 85: 1.0, 86: 0.25, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.0, 95: 0.75, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.5, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.25, 115: 1.0, 116: 1.0, 117: 0.75, 118: 0.75, 119: 0.75, 120: 0.75, 121: 1.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.75, 128: 0.75, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.5, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 0.75, 145: 0.75, 146: 0.5, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.5, 156: 0.75, 157: 0.5, 158: 0.25, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.5, 164: 0.75, 165: 0.75, 166: 0.5, 167: 0.0, 168: 0.5, 169: 1.0, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 0.25, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.75, 185: 0.75, 186: 0.25, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.5, 197: 0.75, 198: 0.5}

2024-05-03 03:24:50,715 [INFO] [40] TRAIN  loss: 0.21985783669001915 acc: 0.0
2024-05-03 03:24:50,715 [INFO] [40] TRAIN  loss dict: {'mse_loss': 0.21985783669001915}
2024-05-03 03:24:50,715 [INFO] [40] VALIDATION loss: 1.3246149061003116 VALIDATION  acc: 0.7070707070707071
2024-05-03 03:24:50,715 [INFO] [40] VALIDATION  loss dict: {'mse_loss': 0.2511504236044306, 'classification_loss': 1.0734644790151806}
2024-05-03 03:24:50,715 [INFO] 
2024-05-03 03:25:56,889 [INFO] Step[50/1020]: training loss : 0.21458576261997223 TRAIN  loss dict:  {'mse_loss': 0.21458576261997223}
2024-05-03 03:26:38,737 [INFO] Step[100/1020]: training loss : 0.21553210347890853 TRAIN  loss dict:  {'mse_loss': 0.21553210347890853}
2024-05-03 03:27:24,003 [INFO] Step[150/1020]: training loss : 0.22116539120674134 TRAIN  loss dict:  {'mse_loss': 0.22116539120674134}
2024-05-03 03:28:04,763 [INFO] Step[200/1020]: training loss : 0.21707555323839187 TRAIN  loss dict:  {'mse_loss': 0.21707555323839187}
2024-05-03 03:28:43,882 [INFO] Step[250/1020]: training loss : 0.22068366885185242 TRAIN  loss dict:  {'mse_loss': 0.22068366885185242}
2024-05-03 03:29:26,642 [INFO] Step[300/1020]: training loss : 0.21233040809631348 TRAIN  loss dict:  {'mse_loss': 0.21233040809631348}
2024-05-03 03:30:13,262 [INFO] Step[350/1020]: training loss : 0.21289992868900298 TRAIN  loss dict:  {'mse_loss': 0.21289992868900298}
2024-05-03 03:30:53,137 [INFO] Step[400/1020]: training loss : 0.21122315555810928 TRAIN  loss dict:  {'mse_loss': 0.21122315555810928}
2024-05-03 03:31:34,091 [INFO] Step[450/1020]: training loss : 0.22520425021648408 TRAIN  loss dict:  {'mse_loss': 0.22520425021648408}
2024-05-03 03:32:17,112 [INFO] Step[500/1020]: training loss : 0.21999781519174577 TRAIN  loss dict:  {'mse_loss': 0.21999781519174577}
2024-05-03 03:32:57,688 [INFO] Step[550/1020]: training loss : 0.22344509601593018 TRAIN  loss dict:  {'mse_loss': 0.22344509601593018}
2024-05-03 03:33:37,615 [INFO] Step[600/1020]: training loss : 0.21302378475666045 TRAIN  loss dict:  {'mse_loss': 0.21302378475666045}
2024-05-03 03:34:23,131 [INFO] Step[650/1020]: training loss : 0.21532331436872482 TRAIN  loss dict:  {'mse_loss': 0.21532331436872482}
2024-05-03 03:35:06,242 [INFO] Step[700/1020]: training loss : 0.21987005352973937 TRAIN  loss dict:  {'mse_loss': 0.21987005352973937}
2024-05-03 03:35:48,687 [INFO] Step[750/1020]: training loss : 0.21512113898992538 TRAIN  loss dict:  {'mse_loss': 0.21512113898992538}
2024-05-03 03:36:31,469 [INFO] Step[800/1020]: training loss : 0.22269993901252746 TRAIN  loss dict:  {'mse_loss': 0.22269993901252746}
2024-05-03 03:37:17,199 [INFO] Step[850/1020]: training loss : 0.21212965369224548 TRAIN  loss dict:  {'mse_loss': 0.21212965369224548}
2024-05-03 03:37:54,819 [INFO] Step[900/1020]: training loss : 0.21807642459869384 TRAIN  loss dict:  {'mse_loss': 0.21807642459869384}
2024-05-03 03:38:35,821 [INFO] Step[950/1020]: training loss : 0.22273926824331283 TRAIN  loss dict:  {'mse_loss': 0.22273926824331283}
2024-05-03 03:39:15,299 [INFO] Step[1000/1020]: training loss : 0.21376063644886018 TRAIN  loss dict:  {'mse_loss': 0.21376063644886018}
2024-05-03 03:41:52,655 [INFO] Label accuracies statistics:
2024-05-03 03:41:52,655 [INFO] {0: 0.5, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 0.5, 6: 0.5, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.5, 16: 0.75, 17: 0.75, 18: 0.75, 19: 0.0, 20: 0.5, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.5, 26: 1.0, 27: 1.0, 28: 0.75, 29: 1.0, 30: 0.5, 31: 0.5, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.0, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.5, 52: 0.25, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.25, 60: 0.25, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.5, 65: 0.5, 66: 0.25, 67: 1.0, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.25, 77: 0.25, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.5, 83: 1.0, 84: 0.75, 85: 1.0, 86: 0.25, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.5, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.5, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.0, 113: 0.25, 114: 0.25, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.75, 120: 0.75, 121: 1.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 0.5, 131: 1.0, 132: 0.5, 133: 0.75, 134: 0.75, 135: 0.75, 136: 1.0, 137: 0.5, 138: 0.5, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.5, 146: 0.5, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.5, 158: 0.25, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.5, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.25, 168: 0.25, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.5, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 0.75, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.5, 198: 0.75}

2024-05-03 03:41:52,675 [INFO] [41] TRAIN  loss: 0.21732441340299213 acc: 0.0
2024-05-03 03:41:52,675 [INFO] [41] TRAIN  loss dict: {'mse_loss': 0.21732441340299213}
2024-05-03 03:41:52,676 [INFO] [41] VALIDATION loss: 1.313003391479001 VALIDATION  acc: 0.7121212121212122
2024-05-03 03:41:52,676 [INFO] [41] VALIDATION  loss dict: {'mse_loss': 0.2502856355423879, 'classification_loss': 1.0627177600758244}
2024-05-03 03:41:52,676 [INFO] 
2024-05-03 03:43:10,137 [INFO] Step[50/1020]: training loss : 0.21207934200763703 TRAIN  loss dict:  {'mse_loss': 0.21207934200763703}
2024-05-03 03:43:49,117 [INFO] Step[100/1020]: training loss : 0.21576200067996978 TRAIN  loss dict:  {'mse_loss': 0.21576200067996978}
2024-05-03 03:44:28,840 [INFO] Step[150/1020]: training loss : 0.21735042065382004 TRAIN  loss dict:  {'mse_loss': 0.21735042065382004}
2024-05-03 03:45:07,320 [INFO] Step[200/1020]: training loss : 0.21523292481899262 TRAIN  loss dict:  {'mse_loss': 0.21523292481899262}
2024-05-03 03:45:49,801 [INFO] Step[250/1020]: training loss : 0.21687281608581543 TRAIN  loss dict:  {'mse_loss': 0.21687281608581543}
2024-05-03 03:46:28,816 [INFO] Step[300/1020]: training loss : 0.21962959825992584 TRAIN  loss dict:  {'mse_loss': 0.21962959825992584}
2024-05-03 03:47:11,293 [INFO] Step[350/1020]: training loss : 0.21343629270792008 TRAIN  loss dict:  {'mse_loss': 0.21343629270792008}
2024-05-03 03:47:55,301 [INFO] Step[400/1020]: training loss : 0.2132079619169235 TRAIN  loss dict:  {'mse_loss': 0.2132079619169235}
2024-05-03 03:48:43,145 [INFO] Step[450/1020]: training loss : 0.21564651250839234 TRAIN  loss dict:  {'mse_loss': 0.21564651250839234}
2024-05-03 03:49:23,436 [INFO] Step[500/1020]: training loss : 0.22539741307497024 TRAIN  loss dict:  {'mse_loss': 0.22539741307497024}
2024-05-03 03:50:03,038 [INFO] Step[550/1020]: training loss : 0.21311997950077058 TRAIN  loss dict:  {'mse_loss': 0.21311997950077058}
2024-05-03 03:50:43,173 [INFO] Step[600/1020]: training loss : 0.21336206436157226 TRAIN  loss dict:  {'mse_loss': 0.21336206436157226}
2024-05-03 03:51:25,188 [INFO] Step[650/1020]: training loss : 0.22209267646074296 TRAIN  loss dict:  {'mse_loss': 0.22209267646074296}
2024-05-03 03:52:06,237 [INFO] Step[700/1020]: training loss : 0.2218430781364441 TRAIN  loss dict:  {'mse_loss': 0.2218430781364441}
2024-05-03 03:52:46,052 [INFO] Step[750/1020]: training loss : 0.21792545139789582 TRAIN  loss dict:  {'mse_loss': 0.21792545139789582}
2024-05-03 03:53:26,644 [INFO] Step[800/1020]: training loss : 0.21980221182107926 TRAIN  loss dict:  {'mse_loss': 0.21980221182107926}
2024-05-03 03:54:09,020 [INFO] Step[850/1020]: training loss : 0.22021019995212554 TRAIN  loss dict:  {'mse_loss': 0.22021019995212554}
2024-05-03 03:54:51,361 [INFO] Step[900/1020]: training loss : 0.22537184566259383 TRAIN  loss dict:  {'mse_loss': 0.22537184566259383}
2024-05-03 03:55:36,930 [INFO] Step[950/1020]: training loss : 0.21320586413145065 TRAIN  loss dict:  {'mse_loss': 0.21320586413145065}
2024-05-03 03:56:14,561 [INFO] Step[1000/1020]: training loss : 0.2117018273472786 TRAIN  loss dict:  {'mse_loss': 0.2117018273472786}
2024-05-03 03:58:54,202 [INFO] Label accuracies statistics:
2024-05-03 03:58:54,202 [INFO] {0: 0.5, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.6666666666666666, 5: 0.5, 6: 0.25, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.5, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.25, 29: 0.75, 30: 0.5, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.5, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.5, 52: 0.5, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.25, 60: 0.25, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.75, 67: 1.0, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.25, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.5, 83: 0.75, 84: 0.75, 85: 1.0, 86: 0.25, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.5, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.25, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 0.75, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 0.75, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.0, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.75, 146: 0.75, 147: 1.0, 148: 0.5, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.5, 156: 0.75, 157: 0.5, 158: 0.25, 159: 0.5, 160: 0.75, 161: 1.0, 162: 0.5, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.5, 167: 0.5, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 0.5, 175: 1.0, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.5, 180: 1.0, 181: 1.0, 182: 0.75, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.75, 187: 0.75, 188: 0.5, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.5, 196: 0.5, 197: 0.5, 198: 0.75}

2024-05-03 03:58:57,919 [INFO] [42] TRAIN  loss: 0.21699154340461188 acc: 0.0
2024-05-03 03:58:57,919 [INFO] [42] TRAIN  loss dict: {'mse_loss': 0.21699154340461188}
2024-05-03 03:58:57,919 [INFO] [42] VALIDATION loss: 1.289601665629883 VALIDATION  acc: 0.7184343434343434
2024-05-03 03:58:57,920 [INFO] [42] VALIDATION  loss dict: {'mse_loss': 0.251256127474886, 'classification_loss': 1.0383455343074117}
2024-05-03 03:58:57,920 [INFO] 
2024-05-03 04:00:10,821 [INFO] Step[50/1020]: training loss : 0.2160910725593567 TRAIN  loss dict:  {'mse_loss': 0.2160910725593567}
2024-05-03 04:00:53,841 [INFO] Step[100/1020]: training loss : 0.20661162883043288 TRAIN  loss dict:  {'mse_loss': 0.20661162883043288}
2024-05-03 04:01:34,911 [INFO] Step[150/1020]: training loss : 0.21613719254732133 TRAIN  loss dict:  {'mse_loss': 0.21613719254732133}
2024-05-03 04:02:14,217 [INFO] Step[200/1020]: training loss : 0.2093298014998436 TRAIN  loss dict:  {'mse_loss': 0.2093298014998436}
2024-05-03 04:02:54,267 [INFO] Step[250/1020]: training loss : 0.2129584538936615 TRAIN  loss dict:  {'mse_loss': 0.2129584538936615}
2024-05-03 04:03:35,772 [INFO] Step[300/1020]: training loss : 0.21943262100219726 TRAIN  loss dict:  {'mse_loss': 0.21943262100219726}
2024-05-03 04:04:16,078 [INFO] Step[350/1020]: training loss : 0.22005837082862853 TRAIN  loss dict:  {'mse_loss': 0.22005837082862853}
2024-05-03 04:04:56,443 [INFO] Step[400/1020]: training loss : 0.21496511846780778 TRAIN  loss dict:  {'mse_loss': 0.21496511846780778}
2024-05-03 04:05:39,427 [INFO] Step[450/1020]: training loss : 0.21408141195774077 TRAIN  loss dict:  {'mse_loss': 0.21408141195774077}
2024-05-03 04:06:21,436 [INFO] Step[500/1020]: training loss : 0.21724821537733077 TRAIN  loss dict:  {'mse_loss': 0.21724821537733077}
2024-05-03 04:07:05,991 [INFO] Step[550/1020]: training loss : 0.21153533697128296 TRAIN  loss dict:  {'mse_loss': 0.21153533697128296}
2024-05-03 04:07:44,506 [INFO] Step[600/1020]: training loss : 0.22260723531246185 TRAIN  loss dict:  {'mse_loss': 0.22260723531246185}
2024-05-03 04:08:24,806 [INFO] Step[650/1020]: training loss : 0.21784229964017868 TRAIN  loss dict:  {'mse_loss': 0.21784229964017868}
2024-05-03 04:09:04,107 [INFO] Step[700/1020]: training loss : 0.22333175122737883 TRAIN  loss dict:  {'mse_loss': 0.22333175122737883}
2024-05-03 04:09:48,611 [INFO] Step[750/1020]: training loss : 0.2155491504073143 TRAIN  loss dict:  {'mse_loss': 0.2155491504073143}
2024-05-03 04:10:34,572 [INFO] Step[800/1020]: training loss : 0.20796949595212935 TRAIN  loss dict:  {'mse_loss': 0.20796949595212935}
2024-05-03 04:11:20,662 [INFO] Step[850/1020]: training loss : 0.21410456478595732 TRAIN  loss dict:  {'mse_loss': 0.21410456478595732}
2024-05-03 04:12:01,338 [INFO] Step[900/1020]: training loss : 0.2217076000571251 TRAIN  loss dict:  {'mse_loss': 0.2217076000571251}
2024-05-03 04:12:45,720 [INFO] Step[950/1020]: training loss : 0.2214332777261734 TRAIN  loss dict:  {'mse_loss': 0.2214332777261734}
2024-05-03 04:13:24,298 [INFO] Step[1000/1020]: training loss : 0.21708581119775772 TRAIN  loss dict:  {'mse_loss': 0.21708581119775772}
2024-05-03 04:16:05,056 [INFO] Label accuracies statistics:
2024-05-03 04:16:05,056 [INFO] {0: 0.5, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.6666666666666666, 5: 0.75, 6: 0.5, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.5, 13: 0.75, 14: 0.5, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 0.0, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.75, 26: 0.75, 27: 1.0, 28: 0.5, 29: 0.75, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.25, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 1.0, 51: 0.5, 52: 0.25, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.25, 60: 0.25, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.75, 67: 1.0, 68: 0.75, 69: 0.25, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.5, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.5, 83: 1.0, 84: 0.75, 85: 0.75, 86: 0.25, 87: 0.5, 88: 1.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.0, 95: 0.75, 96: 0.5, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.5, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.25, 106: 0.75, 107: 1.0, 108: 0.5, 109: 0.5, 110: 1.0, 111: 1.0, 112: 0.25, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 0.75, 129: 0.75, 130: 0.5, 131: 0.75, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.25, 139: 0.25, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.5, 144: 1.0, 145: 1.0, 146: 0.75, 147: 1.0, 148: 0.5, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.25, 156: 0.75, 157: 0.5, 158: 0.25, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.25, 163: 0.5, 164: 0.75, 165: 1.0, 166: 0.5, 167: 0.5, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.75, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 0.75, 181: 1.0, 182: 0.75, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.5, 198: 0.75}

2024-05-03 04:16:05,074 [INFO] [43] TRAIN  loss: 0.21614707033423816 acc: 0.0
2024-05-03 04:16:05,074 [INFO] [43] TRAIN  loss dict: {'mse_loss': 0.21614707033423816}
2024-05-03 04:16:05,074 [INFO] [43] VALIDATION loss: 1.2936643191208743 VALIDATION  acc: 0.7121212121212122
2024-05-03 04:16:05,074 [INFO] [43] VALIDATION  loss dict: {'mse_loss': 0.24813241820142726, 'classification_loss': 1.0455319019354352}
2024-05-03 04:16:05,074 [INFO] 
2024-05-03 04:17:14,603 [INFO] Step[50/1020]: training loss : 0.2118007105588913 TRAIN  loss dict:  {'mse_loss': 0.2118007105588913}
2024-05-03 04:17:54,343 [INFO] Step[100/1020]: training loss : 0.2175853481888771 TRAIN  loss dict:  {'mse_loss': 0.2175853481888771}
2024-05-03 04:18:37,317 [INFO] Step[150/1020]: training loss : 0.2223929613828659 TRAIN  loss dict:  {'mse_loss': 0.2223929613828659}
2024-05-03 04:19:21,918 [INFO] Step[200/1020]: training loss : 0.2130251085758209 TRAIN  loss dict:  {'mse_loss': 0.2130251085758209}
2024-05-03 04:20:01,452 [INFO] Step[250/1020]: training loss : 0.21036676228046416 TRAIN  loss dict:  {'mse_loss': 0.21036676228046416}
2024-05-03 04:20:43,655 [INFO] Step[300/1020]: training loss : 0.21694209724664687 TRAIN  loss dict:  {'mse_loss': 0.21694209724664687}
2024-05-03 04:21:22,232 [INFO] Step[350/1020]: training loss : 0.21442926421761513 TRAIN  loss dict:  {'mse_loss': 0.21442926421761513}
2024-05-03 04:22:08,367 [INFO] Step[400/1020]: training loss : 0.21227278411388398 TRAIN  loss dict:  {'mse_loss': 0.21227278411388398}
2024-05-03 04:22:50,897 [INFO] Step[450/1020]: training loss : 0.22341546148061753 TRAIN  loss dict:  {'mse_loss': 0.22341546148061753}
2024-05-03 04:23:30,820 [INFO] Step[500/1020]: training loss : 0.21735798984766005 TRAIN  loss dict:  {'mse_loss': 0.21735798984766005}
2024-05-03 04:24:12,925 [INFO] Step[550/1020]: training loss : 0.21396055638790132 TRAIN  loss dict:  {'mse_loss': 0.21396055638790132}
2024-05-03 04:24:58,639 [INFO] Step[600/1020]: training loss : 0.20919535368680953 TRAIN  loss dict:  {'mse_loss': 0.20919535368680953}
2024-05-03 04:25:38,959 [INFO] Step[650/1020]: training loss : 0.21021505564451218 TRAIN  loss dict:  {'mse_loss': 0.21021505564451218}
2024-05-03 04:26:20,548 [INFO] Step[700/1020]: training loss : 0.210403912961483 TRAIN  loss dict:  {'mse_loss': 0.210403912961483}
2024-05-03 04:27:02,417 [INFO] Step[750/1020]: training loss : 0.20781573712825774 TRAIN  loss dict:  {'mse_loss': 0.20781573712825774}
2024-05-03 04:27:40,870 [INFO] Step[800/1020]: training loss : 0.20607172936201096 TRAIN  loss dict:  {'mse_loss': 0.20607172936201096}
2024-05-03 04:28:21,884 [INFO] Step[850/1020]: training loss : 0.22024580508470534 TRAIN  loss dict:  {'mse_loss': 0.22024580508470534}
2024-05-03 04:29:04,965 [INFO] Step[900/1020]: training loss : 0.21638294845819472 TRAIN  loss dict:  {'mse_loss': 0.21638294845819472}
2024-05-03 04:29:48,710 [INFO] Step[950/1020]: training loss : 0.21431406944990158 TRAIN  loss dict:  {'mse_loss': 0.21431406944990158}
2024-05-03 04:30:28,324 [INFO] Step[1000/1020]: training loss : 0.21686739414930345 TRAIN  loss dict:  {'mse_loss': 0.21686739414930345}
2024-05-03 04:33:08,622 [INFO] Label accuracies statistics:
2024-05-03 04:33:08,623 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.5, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.5, 14: 0.25, 15: 0.5, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.75, 27: 1.0, 28: 0.5, 29: 0.75, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.25, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 1.0, 51: 0.5, 52: 0.25, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.5, 57: 1.0, 58: 0.5, 59: 0.75, 60: 0.25, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.5, 70: 1.0, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 1.0, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.5, 83: 1.0, 84: 0.75, 85: 1.0, 86: 0.25, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.75, 95: 0.75, 96: 0.75, 97: 1.0, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.5, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.5, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.5, 144: 1.0, 145: 0.75, 146: 0.5, 147: 1.0, 148: 0.5, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.5, 156: 1.0, 157: 0.5, 158: 0.5, 159: 0.75, 160: 0.25, 161: 1.0, 162: 0.5, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.25, 167: 0.0, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.5, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 0.5, 183: 0.75, 184: 0.25, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.5, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.5, 196: 0.75, 197: 0.75, 198: 0.5}

2024-05-03 04:33:08,640 [INFO] [44] TRAIN  loss: 0.21421572655877646 acc: 0.0
2024-05-03 04:33:08,640 [INFO] [44] TRAIN  loss dict: {'mse_loss': 0.21421572655877646}
2024-05-03 04:33:08,640 [INFO] [44] VALIDATION loss: 1.2974279764475245 VALIDATION  acc: 0.7234848484848485
2024-05-03 04:33:08,640 [INFO] [44] VALIDATION  loss dict: {'mse_loss': 0.249446751267621, 'classification_loss': 1.047981223655921}
2024-05-03 04:33:08,640 [INFO] 
2024-05-03 04:34:27,052 [INFO] Step[50/1020]: training loss : 0.20829153299331665 TRAIN  loss dict:  {'mse_loss': 0.20829153299331665}
2024-05-03 04:35:06,878 [INFO] Step[100/1020]: training loss : 0.2061546966433525 TRAIN  loss dict:  {'mse_loss': 0.2061546966433525}
2024-05-03 04:35:45,510 [INFO] Step[150/1020]: training loss : 0.20898138016462325 TRAIN  loss dict:  {'mse_loss': 0.20898138016462325}
2024-05-03 04:36:23,986 [INFO] Step[200/1020]: training loss : 0.2098240202665329 TRAIN  loss dict:  {'mse_loss': 0.2098240202665329}
2024-05-03 04:37:03,075 [INFO] Step[250/1020]: training loss : 0.2073967182636261 TRAIN  loss dict:  {'mse_loss': 0.2073967182636261}
2024-05-03 04:37:46,319 [INFO] Step[300/1020]: training loss : 0.21286296874284744 TRAIN  loss dict:  {'mse_loss': 0.21286296874284744}
2024-05-03 04:38:28,228 [INFO] Step[350/1020]: training loss : 0.2185931271314621 TRAIN  loss dict:  {'mse_loss': 0.2185931271314621}
2024-05-03 04:39:09,190 [INFO] Step[400/1020]: training loss : 0.2224212235212326 TRAIN  loss dict:  {'mse_loss': 0.2224212235212326}
2024-05-03 04:39:48,312 [INFO] Step[450/1020]: training loss : 0.21129558354616165 TRAIN  loss dict:  {'mse_loss': 0.21129558354616165}
2024-05-03 04:40:30,322 [INFO] Step[500/1020]: training loss : 0.20799367129802704 TRAIN  loss dict:  {'mse_loss': 0.20799367129802704}
2024-05-03 04:41:14,764 [INFO] Step[550/1020]: training loss : 0.21404536604881286 TRAIN  loss dict:  {'mse_loss': 0.21404536604881286}
2024-05-03 04:41:56,792 [INFO] Step[600/1020]: training loss : 0.20548536717891694 TRAIN  loss dict:  {'mse_loss': 0.20548536717891694}
2024-05-03 04:42:38,363 [INFO] Step[650/1020]: training loss : 0.21215877085924148 TRAIN  loss dict:  {'mse_loss': 0.21215877085924148}
2024-05-03 04:43:20,112 [INFO] Step[700/1020]: training loss : 0.2095837852358818 TRAIN  loss dict:  {'mse_loss': 0.2095837852358818}
2024-05-03 04:43:59,216 [INFO] Step[750/1020]: training loss : 0.2142943286895752 TRAIN  loss dict:  {'mse_loss': 0.2142943286895752}
2024-05-03 04:44:38,427 [INFO] Step[800/1020]: training loss : 0.21782736003398895 TRAIN  loss dict:  {'mse_loss': 0.21782736003398895}
2024-05-03 04:45:19,851 [INFO] Step[850/1020]: training loss : 0.22058613151311873 TRAIN  loss dict:  {'mse_loss': 0.22058613151311873}
2024-05-03 04:45:59,904 [INFO] Step[900/1020]: training loss : 0.21867063879966736 TRAIN  loss dict:  {'mse_loss': 0.21867063879966736}
2024-05-03 04:46:44,449 [INFO] Step[950/1020]: training loss : 0.22114750534296035 TRAIN  loss dict:  {'mse_loss': 0.22114750534296035}
2024-05-03 04:47:29,211 [INFO] Step[1000/1020]: training loss : 0.21799775302410127 TRAIN  loss dict:  {'mse_loss': 0.21799775302410127}
2024-05-03 04:50:14,764 [INFO] Label accuracies statistics:
2024-05-03 04:50:14,764 [INFO] {0: 0.5, 1: 1.0, 2: 0.25, 3: 1.0, 4: 0.6666666666666666, 5: 0.5, 6: 0.5, 7: 1.0, 8: 0.25, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.25, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.75, 26: 0.75, 27: 0.75, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.5, 38: 1.0, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 0.75, 47: 0.75, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.75, 52: 0.25, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.25, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.5, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 1.0, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.5, 83: 1.0, 84: 1.0, 85: 1.0, 86: 0.25, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.75, 95: 0.75, 96: 0.5, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.25, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.5, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.5, 140: 0.75, 141: 0.5, 142: 0.75, 143: 0.5, 144: 0.75, 145: 0.75, 146: 0.75, 147: 1.0, 148: 0.5, 149: 0.5, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.5, 156: 1.0, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.5, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.25, 167: 0.25, 168: 0.25, 169: 0.75, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 0.75, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 1.0}

2024-05-03 04:50:18,812 [INFO] [45] TRAIN  loss: 0.21354251788819537 acc: 0.0
2024-05-03 04:50:18,813 [INFO] [45] TRAIN  loss dict: {'mse_loss': 0.21354251788819537}
2024-05-03 04:50:18,813 [INFO] [45] VALIDATION loss: 1.2249323837082795 VALIDATION  acc: 0.7411616161616161
2024-05-03 04:50:18,813 [INFO] [45] VALIDATION  loss dict: {'mse_loss': 0.24666149718592864, 'classification_loss': 0.9782708875101173}
2024-05-03 04:50:18,814 [INFO] 
2024-05-03 04:51:32,284 [INFO] Step[50/1020]: training loss : 0.2112537717819214 TRAIN  loss dict:  {'mse_loss': 0.2112537717819214}
2024-05-03 04:52:14,927 [INFO] Step[100/1020]: training loss : 0.21254942446947098 TRAIN  loss dict:  {'mse_loss': 0.21254942446947098}
2024-05-03 04:52:53,748 [INFO] Step[150/1020]: training loss : 0.2134145215153694 TRAIN  loss dict:  {'mse_loss': 0.2134145215153694}
2024-05-03 04:53:34,893 [INFO] Step[200/1020]: training loss : 0.21405429095029832 TRAIN  loss dict:  {'mse_loss': 0.21405429095029832}
2024-05-03 04:54:18,696 [INFO] Step[250/1020]: training loss : 0.20633942425251006 TRAIN  loss dict:  {'mse_loss': 0.20633942425251006}
2024-05-03 04:55:01,188 [INFO] Step[300/1020]: training loss : 0.20991073429584503 TRAIN  loss dict:  {'mse_loss': 0.20991073429584503}
2024-05-03 04:55:39,261 [INFO] Step[350/1020]: training loss : 0.2124960708618164 TRAIN  loss dict:  {'mse_loss': 0.2124960708618164}
2024-05-03 04:56:18,985 [INFO] Step[400/1020]: training loss : 0.20705068618059158 TRAIN  loss dict:  {'mse_loss': 0.20705068618059158}
2024-05-03 04:57:04,232 [INFO] Step[450/1020]: training loss : 0.206573346555233 TRAIN  loss dict:  {'mse_loss': 0.206573346555233}
2024-05-03 04:57:44,634 [INFO] Step[500/1020]: training loss : 0.21403057217597962 TRAIN  loss dict:  {'mse_loss': 0.21403057217597962}
2024-05-03 04:58:22,673 [INFO] Step[550/1020]: training loss : 0.21226098328828813 TRAIN  loss dict:  {'mse_loss': 0.21226098328828813}
2024-05-03 04:59:04,217 [INFO] Step[600/1020]: training loss : 0.2138436233997345 TRAIN  loss dict:  {'mse_loss': 0.2138436233997345}
2024-05-03 04:59:45,138 [INFO] Step[650/1020]: training loss : 0.22047835260629653 TRAIN  loss dict:  {'mse_loss': 0.22047835260629653}
2024-05-03 05:00:30,422 [INFO] Step[700/1020]: training loss : 0.21695711553096772 TRAIN  loss dict:  {'mse_loss': 0.21695711553096772}
2024-05-03 05:01:09,436 [INFO] Step[750/1020]: training loss : 0.21192413121461867 TRAIN  loss dict:  {'mse_loss': 0.21192413121461867}
2024-05-03 05:01:54,360 [INFO] Step[800/1020]: training loss : 0.22334468811750413 TRAIN  loss dict:  {'mse_loss': 0.22334468811750413}
2024-05-03 05:02:35,966 [INFO] Step[850/1020]: training loss : 0.20786021232604981 TRAIN  loss dict:  {'mse_loss': 0.20786021232604981}
2024-05-03 05:03:18,165 [INFO] Step[900/1020]: training loss : 0.22207218825817107 TRAIN  loss dict:  {'mse_loss': 0.22207218825817107}
2024-05-03 05:04:03,582 [INFO] Step[950/1020]: training loss : 0.21322471439838409 TRAIN  loss dict:  {'mse_loss': 0.21322471439838409}
2024-05-03 05:04:40,556 [INFO] Step[1000/1020]: training loss : 0.20755223095417022 TRAIN  loss dict:  {'mse_loss': 0.20755223095417022}
2024-05-03 05:07:21,449 [INFO] Label accuracies statistics:
2024-05-03 05:07:21,449 [INFO] {0: 1.0, 1: 1.0, 2: 0.25, 3: 1.0, 4: 0.3333333333333333, 5: 0.5, 6: 0.25, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.25, 16: 1.0, 17: 0.5, 18: 1.0, 19: 0.5, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.5, 29: 1.0, 30: 0.75, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 0.75, 47: 0.75, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.5, 52: 0.25, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.25, 60: 0.25, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.5, 67: 1.0, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 1.0, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.25, 83: 1.0, 84: 0.5, 85: 1.0, 86: 0.25, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.5, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.5, 110: 1.0, 111: 1.0, 112: 0.25, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.25, 139: 1.0, 140: 0.75, 141: 0.75, 142: 1.0, 143: 0.75, 144: 0.75, 145: 0.75, 146: 0.75, 147: 0.75, 148: 0.5, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.25, 156: 0.75, 157: 0.5, 158: 0.25, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.5, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 0.25, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.5, 184: 0.25, 185: 0.75, 186: 0.75, 187: 0.75, 188: 0.5, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.75, 196: 0.5, 197: 0.75, 198: 0.5}

2024-05-03 05:07:21,467 [INFO] [46] TRAIN  loss: 0.2127283436556657 acc: 0.0
2024-05-03 05:07:21,467 [INFO] [46] TRAIN  loss dict: {'mse_loss': 0.2127283436556657}
2024-05-03 05:07:21,467 [INFO] [46] VALIDATION loss: 1.2659685494321766 VALIDATION  acc: 0.7222222222222222
2024-05-03 05:07:21,467 [INFO] [46] VALIDATION  loss dict: {'mse_loss': 0.2446801324534898, 'classification_loss': 1.0212884133098403}
2024-05-03 05:07:21,467 [INFO] 
2024-05-03 05:08:32,429 [INFO] Step[50/1020]: training loss : 0.20206911951303483 TRAIN  loss dict:  {'mse_loss': 0.20206911951303483}
2024-05-03 05:09:13,309 [INFO] Step[100/1020]: training loss : 0.2116040223836899 TRAIN  loss dict:  {'mse_loss': 0.2116040223836899}
2024-05-03 05:09:53,213 [INFO] Step[150/1020]: training loss : 0.20743690997362138 TRAIN  loss dict:  {'mse_loss': 0.20743690997362138}
2024-05-03 05:10:33,581 [INFO] Step[200/1020]: training loss : 0.21139492750167846 TRAIN  loss dict:  {'mse_loss': 0.21139492750167846}
2024-05-03 05:11:16,609 [INFO] Step[250/1020]: training loss : 0.2128845661878586 TRAIN  loss dict:  {'mse_loss': 0.2128845661878586}
2024-05-03 05:12:03,095 [INFO] Step[300/1020]: training loss : 0.21164971321821213 TRAIN  loss dict:  {'mse_loss': 0.21164971321821213}
2024-05-03 05:12:42,767 [INFO] Step[350/1020]: training loss : 0.19994465112686158 TRAIN  loss dict:  {'mse_loss': 0.19994465112686158}
2024-05-03 05:13:22,923 [INFO] Step[400/1020]: training loss : 0.20765734374523162 TRAIN  loss dict:  {'mse_loss': 0.20765734374523162}
2024-05-03 05:14:09,796 [INFO] Step[450/1020]: training loss : 0.20889711648225784 TRAIN  loss dict:  {'mse_loss': 0.20889711648225784}
2024-05-03 05:14:58,761 [INFO] Step[500/1020]: training loss : 0.21638095796108245 TRAIN  loss dict:  {'mse_loss': 0.21638095796108245}
2024-05-03 05:15:38,994 [INFO] Step[550/1020]: training loss : 0.2060616484284401 TRAIN  loss dict:  {'mse_loss': 0.2060616484284401}
2024-05-03 05:16:20,854 [INFO] Step[600/1020]: training loss : 0.21112064599990846 TRAIN  loss dict:  {'mse_loss': 0.21112064599990846}
2024-05-03 05:17:03,694 [INFO] Step[650/1020]: training loss : 0.2196736192703247 TRAIN  loss dict:  {'mse_loss': 0.2196736192703247}
2024-05-03 05:17:49,164 [INFO] Step[700/1020]: training loss : 0.21250246495008468 TRAIN  loss dict:  {'mse_loss': 0.21250246495008468}
2024-05-03 05:18:33,993 [INFO] Step[750/1020]: training loss : 0.2164042004942894 TRAIN  loss dict:  {'mse_loss': 0.2164042004942894}
2024-05-03 05:19:14,639 [INFO] Step[800/1020]: training loss : 0.20412490487098695 TRAIN  loss dict:  {'mse_loss': 0.20412490487098695}
2024-05-03 05:19:54,288 [INFO] Step[850/1020]: training loss : 0.22096712052822112 TRAIN  loss dict:  {'mse_loss': 0.22096712052822112}
2024-05-03 05:20:33,731 [INFO] Step[900/1020]: training loss : 0.2141989767551422 TRAIN  loss dict:  {'mse_loss': 0.2141989767551422}
2024-05-03 05:21:18,108 [INFO] Step[950/1020]: training loss : 0.218495614528656 TRAIN  loss dict:  {'mse_loss': 0.218495614528656}
2024-05-03 05:22:03,359 [INFO] Step[1000/1020]: training loss : 0.2063963556289673 TRAIN  loss dict:  {'mse_loss': 0.2063963556289673}
2024-05-03 05:24:48,341 [INFO] Label accuracies statistics:
2024-05-03 05:24:48,341 [INFO] {0: 1.0, 1: 0.75, 2: 0.75, 3: 1.0, 4: 0.6666666666666666, 5: 0.5, 6: 0.5, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.5, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 0.25, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.5, 29: 1.0, 30: 0.5, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.5, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.5, 52: 0.25, 53: 0.25, 54: 0.5, 55: 0.5, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.25, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.5, 67: 1.0, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.25, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.25, 83: 0.75, 84: 0.75, 85: 1.0, 86: 0.25, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.5, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.5, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.75, 120: 0.75, 121: 1.0, 122: 0.75, 123: 0.25, 124: 1.0, 125: 1.0, 126: 0.75, 127: 1.0, 128: 0.75, 129: 0.75, 130: 1.0, 131: 0.75, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.5, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.75, 143: 1.0, 144: 0.75, 145: 0.75, 146: 0.75, 147: 1.0, 148: 0.75, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.5, 156: 0.75, 157: 0.5, 158: 0.5, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.5, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.75, 168: 0.25, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.25, 175: 1.0, 176: 0.75, 177: 0.75, 178: 0.75, 179: 1.0, 180: 0.75, 181: 1.0, 182: 0.75, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.5, 196: 1.0, 197: 0.75, 198: 0.75}

2024-05-03 05:24:48,358 [INFO] [47] TRAIN  loss: 0.21097291296019274 acc: 0.0
2024-05-03 05:24:48,358 [INFO] [47] TRAIN  loss dict: {'mse_loss': 0.21097291296019274}
2024-05-03 05:24:48,358 [INFO] [47] VALIDATION loss: 1.25624439338542 VALIDATION  acc: 0.7247474747474747
2024-05-03 05:24:48,358 [INFO] [47] VALIDATION  loss dict: {'mse_loss': 0.2458867688070644, 'classification_loss': 1.0103576312857596}
2024-05-03 05:24:48,358 [INFO] 
2024-05-03 05:26:03,649 [INFO] Step[50/1020]: training loss : 0.2129429778456688 TRAIN  loss dict:  {'mse_loss': 0.2129429778456688}
2024-05-03 05:26:49,976 [INFO] Step[100/1020]: training loss : 0.20279260188341142 TRAIN  loss dict:  {'mse_loss': 0.20279260188341142}
2024-05-03 05:27:30,686 [INFO] Step[150/1020]: training loss : 0.21275194138288497 TRAIN  loss dict:  {'mse_loss': 0.21275194138288497}
2024-05-03 05:28:08,939 [INFO] Step[200/1020]: training loss : 0.20396639555692672 TRAIN  loss dict:  {'mse_loss': 0.20396639555692672}
2024-05-03 05:28:54,225 [INFO] Step[250/1020]: training loss : 0.2134519025683403 TRAIN  loss dict:  {'mse_loss': 0.2134519025683403}
2024-05-03 05:29:35,423 [INFO] Step[300/1020]: training loss : 0.20607686847448348 TRAIN  loss dict:  {'mse_loss': 0.20607686847448348}
2024-05-03 05:30:17,781 [INFO] Step[350/1020]: training loss : 0.21086450546979904 TRAIN  loss dict:  {'mse_loss': 0.21086450546979904}
2024-05-03 05:31:02,175 [INFO] Step[400/1020]: training loss : 0.21589660316705703 TRAIN  loss dict:  {'mse_loss': 0.21589660316705703}
2024-05-03 05:31:40,380 [INFO] Step[450/1020]: training loss : 0.19879905074834825 TRAIN  loss dict:  {'mse_loss': 0.19879905074834825}
2024-05-03 05:32:26,149 [INFO] Step[500/1020]: training loss : 0.20758308351039886 TRAIN  loss dict:  {'mse_loss': 0.20758308351039886}
2024-05-03 05:33:12,546 [INFO] Step[550/1020]: training loss : 0.21072452187538146 TRAIN  loss dict:  {'mse_loss': 0.21072452187538146}
2024-05-03 05:33:52,551 [INFO] Step[600/1020]: training loss : 0.21433777183294297 TRAIN  loss dict:  {'mse_loss': 0.21433777183294297}
2024-05-03 05:34:30,225 [INFO] Step[650/1020]: training loss : 0.20979690968990325 TRAIN  loss dict:  {'mse_loss': 0.20979690968990325}
2024-05-03 05:35:12,820 [INFO] Step[700/1020]: training loss : 0.2067571511864662 TRAIN  loss dict:  {'mse_loss': 0.2067571511864662}
2024-05-03 05:35:58,939 [INFO] Step[750/1020]: training loss : 0.21522394835948944 TRAIN  loss dict:  {'mse_loss': 0.21522394835948944}
2024-05-03 05:36:39,706 [INFO] Step[800/1020]: training loss : 0.20772003173828124 TRAIN  loss dict:  {'mse_loss': 0.20772003173828124}
2024-05-03 05:37:19,246 [INFO] Step[850/1020]: training loss : 0.21377552896738053 TRAIN  loss dict:  {'mse_loss': 0.21377552896738053}
2024-05-03 05:38:01,686 [INFO] Step[900/1020]: training loss : 0.20652367651462555 TRAIN  loss dict:  {'mse_loss': 0.20652367651462555}
2024-05-03 05:38:46,882 [INFO] Step[950/1020]: training loss : 0.20975205153226853 TRAIN  loss dict:  {'mse_loss': 0.20975205153226853}
2024-05-03 05:39:29,337 [INFO] Step[1000/1020]: training loss : 0.20858096420764924 TRAIN  loss dict:  {'mse_loss': 0.20858096420764924}
2024-05-03 05:42:17,103 [INFO] Label accuracies statistics:
2024-05-03 05:42:17,105 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 0.5, 6: 0.25, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.25, 16: 1.0, 17: 0.75, 18: 1.0, 19: 0.5, 20: 0.5, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.5, 26: 1.0, 27: 1.0, 28: 0.5, 29: 1.0, 30: 0.5, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.5, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.75, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 0.5, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.5, 57: 1.0, 58: 0.5, 59: 0.25, 60: 0.25, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.25, 70: 1.0, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.5, 83: 1.0, 84: 0.75, 85: 1.0, 86: 0.25, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.75, 95: 0.75, 96: 0.75, 97: 1.0, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.5, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.0, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.5, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.5, 144: 1.0, 145: 0.5, 146: 0.75, 147: 1.0, 148: 0.75, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.25, 156: 0.5, 157: 0.5, 158: 0.5, 159: 0.5, 160: 0.25, 161: 1.0, 162: 0.5, 163: 0.5, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.5, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 0.75, 181: 1.0, 182: 0.5, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.5, 197: 0.75, 198: 0.75}

2024-05-03 05:42:17,127 [INFO] [48] TRAIN  loss: 0.209337424910536 acc: 0.0
2024-05-03 05:42:17,128 [INFO] [48] TRAIN  loss dict: {'mse_loss': 0.209337424910536}
2024-05-03 05:42:17,128 [INFO] [48] VALIDATION loss: 1.2832790788526487 VALIDATION  acc: 0.726010101010101
2024-05-03 05:42:17,128 [INFO] [48] VALIDATION  loss dict: {'mse_loss': 0.24625041034787593, 'classification_loss': 1.0370286701745683}
2024-05-03 05:42:17,128 [INFO] 
2024-05-03 05:43:30,618 [INFO] Step[50/1020]: training loss : 0.2075953409075737 TRAIN  loss dict:  {'mse_loss': 0.2075953409075737}
2024-05-03 05:44:13,531 [INFO] Step[100/1020]: training loss : 0.2055321627855301 TRAIN  loss dict:  {'mse_loss': 0.2055321627855301}
2024-05-03 05:44:56,932 [INFO] Step[150/1020]: training loss : 0.20719487130641936 TRAIN  loss dict:  {'mse_loss': 0.20719487130641936}
2024-05-03 05:45:37,137 [INFO] Step[200/1020]: training loss : 0.2099486768245697 TRAIN  loss dict:  {'mse_loss': 0.2099486768245697}
2024-05-03 05:46:19,731 [INFO] Step[250/1020]: training loss : 0.20748501181602477 TRAIN  loss dict:  {'mse_loss': 0.20748501181602477}
2024-05-03 05:46:56,787 [INFO] Step[300/1020]: training loss : 0.21385943204164504 TRAIN  loss dict:  {'mse_loss': 0.21385943204164504}
2024-05-03 05:47:34,707 [INFO] Step[350/1020]: training loss : 0.2071702942252159 TRAIN  loss dict:  {'mse_loss': 0.2071702942252159}
2024-05-03 05:48:22,331 [INFO] Step[400/1020]: training loss : 0.20872584044933318 TRAIN  loss dict:  {'mse_loss': 0.20872584044933318}
2024-05-03 05:49:08,872 [INFO] Step[450/1020]: training loss : 0.19989228010177612 TRAIN  loss dict:  {'mse_loss': 0.19989228010177612}
2024-05-03 05:49:52,531 [INFO] Step[500/1020]: training loss : 0.20264945685863495 TRAIN  loss dict:  {'mse_loss': 0.20264945685863495}
2024-05-03 05:50:35,448 [INFO] Step[550/1020]: training loss : 0.20744541883468628 TRAIN  loss dict:  {'mse_loss': 0.20744541883468628}
2024-05-03 05:51:18,181 [INFO] Step[600/1020]: training loss : 0.20954883724451065 TRAIN  loss dict:  {'mse_loss': 0.20954883724451065}
2024-05-03 05:51:58,680 [INFO] Step[650/1020]: training loss : 0.2169171839952469 TRAIN  loss dict:  {'mse_loss': 0.2169171839952469}
2024-05-03 05:52:39,366 [INFO] Step[700/1020]: training loss : 0.2118065896630287 TRAIN  loss dict:  {'mse_loss': 0.2118065896630287}
2024-05-03 05:53:26,036 [INFO] Step[750/1020]: training loss : 0.20025462806224822 TRAIN  loss dict:  {'mse_loss': 0.20025462806224822}
2024-05-03 05:54:05,462 [INFO] Step[800/1020]: training loss : 0.20426810592412947 TRAIN  loss dict:  {'mse_loss': 0.20426810592412947}
2024-05-03 05:54:43,183 [INFO] Step[850/1020]: training loss : 0.21336614072322846 TRAIN  loss dict:  {'mse_loss': 0.21336614072322846}
2024-05-03 05:55:25,682 [INFO] Step[900/1020]: training loss : 0.216528380215168 TRAIN  loss dict:  {'mse_loss': 0.216528380215168}
2024-05-03 05:56:07,482 [INFO] Step[950/1020]: training loss : 0.2102478951215744 TRAIN  loss dict:  {'mse_loss': 0.2102478951215744}
2024-05-03 05:56:49,540 [INFO] Step[1000/1020]: training loss : 0.21411505699157715 TRAIN  loss dict:  {'mse_loss': 0.21411505699157715}
2024-05-03 05:59:36,768 [INFO] Label accuracies statistics:
2024-05-03 05:59:36,768 [INFO] {0: 0.5, 1: 0.5, 2: 0.25, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.5, 7: 1.0, 8: 0.25, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.75, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.5, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.25, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.25, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.5, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.5, 67: 1.0, 68: 0.75, 69: 0.25, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.5, 83: 1.0, 84: 0.75, 85: 1.0, 86: 0.5, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.75, 95: 0.75, 96: 0.5, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.5, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.25, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 0.75, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.25, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.75, 146: 0.75, 147: 1.0, 148: 0.5, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.5, 156: 0.75, 157: 0.5, 158: 0.75, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.5, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 0.5, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.5, 180: 0.75, 181: 1.0, 182: 0.75, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.75, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.75}

2024-05-03 05:59:36,784 [INFO] [49] TRAIN  loss: 0.20862049131708987 acc: 0.0
2024-05-03 05:59:36,784 [INFO] [49] TRAIN  loss dict: {'mse_loss': 0.20862049131708987}
2024-05-03 05:59:36,784 [INFO] [49] VALIDATION loss: 1.26463284253171 VALIDATION  acc: 0.7386363636363636
2024-05-03 05:59:36,784 [INFO] [49] VALIDATION  loss dict: {'mse_loss': 0.24521499864681803, 'classification_loss': 1.019417841081517}
2024-05-03 05:59:36,784 [INFO] 
2024-05-03 06:00:50,026 [INFO] Step[50/1020]: training loss : 0.20691309928894042 TRAIN  loss dict:  {'mse_loss': 0.20691309928894042}
2024-05-03 06:01:26,548 [INFO] Step[100/1020]: training loss : 0.21011509478092194 TRAIN  loss dict:  {'mse_loss': 0.21011509478092194}
2024-05-03 06:02:09,168 [INFO] Step[150/1020]: training loss : 0.19773624688386918 TRAIN  loss dict:  {'mse_loss': 0.19773624688386918}
2024-05-03 06:02:55,896 [INFO] Step[200/1020]: training loss : 0.2087483112514019 TRAIN  loss dict:  {'mse_loss': 0.2087483112514019}
2024-05-03 06:03:35,748 [INFO] Step[250/1020]: training loss : 0.19829628497362137 TRAIN  loss dict:  {'mse_loss': 0.19829628497362137}
2024-05-03 06:04:20,484 [INFO] Step[300/1020]: training loss : 0.2048583960533142 TRAIN  loss dict:  {'mse_loss': 0.2048583960533142}
2024-05-03 06:04:58,895 [INFO] Step[350/1020]: training loss : 0.20746589750051497 TRAIN  loss dict:  {'mse_loss': 0.20746589750051497}
2024-05-03 06:05:36,388 [INFO] Step[400/1020]: training loss : 0.20957905650138856 TRAIN  loss dict:  {'mse_loss': 0.20957905650138856}
2024-05-03 06:06:23,040 [INFO] Step[450/1020]: training loss : 0.21157365471124648 TRAIN  loss dict:  {'mse_loss': 0.21157365471124648}
2024-05-03 06:07:02,280 [INFO] Step[500/1020]: training loss : 0.21014592856168746 TRAIN  loss dict:  {'mse_loss': 0.21014592856168746}
2024-05-03 06:07:43,948 [INFO] Step[550/1020]: training loss : 0.20632691472768783 TRAIN  loss dict:  {'mse_loss': 0.20632691472768783}
2024-05-03 06:08:26,630 [INFO] Step[600/1020]: training loss : 0.20660944640636444 TRAIN  loss dict:  {'mse_loss': 0.20660944640636444}
2024-05-03 06:09:09,707 [INFO] Step[650/1020]: training loss : 0.21109754770994185 TRAIN  loss dict:  {'mse_loss': 0.21109754770994185}
2024-05-03 06:09:51,373 [INFO] Step[700/1020]: training loss : 0.2131034576892853 TRAIN  loss dict:  {'mse_loss': 0.2131034576892853}
2024-05-03 06:10:31,340 [INFO] Step[750/1020]: training loss : 0.21223090201616288 TRAIN  loss dict:  {'mse_loss': 0.21223090201616288}
2024-05-03 06:11:12,671 [INFO] Step[800/1020]: training loss : 0.2119690477848053 TRAIN  loss dict:  {'mse_loss': 0.2119690477848053}
2024-05-03 06:11:52,572 [INFO] Step[850/1020]: training loss : 0.21226098716259004 TRAIN  loss dict:  {'mse_loss': 0.21226098716259004}
2024-05-03 06:12:37,877 [INFO] Step[900/1020]: training loss : 0.20854207068681718 TRAIN  loss dict:  {'mse_loss': 0.20854207068681718}
2024-05-03 06:13:20,191 [INFO] Step[950/1020]: training loss : 0.20606651157140732 TRAIN  loss dict:  {'mse_loss': 0.20606651157140732}
2024-05-03 06:14:04,364 [INFO] Step[1000/1020]: training loss : 0.21002123087644578 TRAIN  loss dict:  {'mse_loss': 0.21002123087644578}
2024-05-03 06:16:57,033 [INFO] Label accuracies statistics:
2024-05-03 06:16:57,033 [INFO] {0: 0.5, 1: 0.75, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.0, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.25, 16: 1.0, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.5, 29: 0.75, 30: 0.75, 31: 0.5, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.25, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.25, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.75, 66: 0.25, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.5, 83: 1.0, 84: 0.75, 85: 1.0, 86: 0.5, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.5, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.5, 109: 0.5, 110: 0.75, 111: 1.0, 112: 0.25, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.75, 120: 0.5, 121: 1.0, 122: 1.0, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.75, 133: 0.75, 134: 0.25, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.75, 146: 0.5, 147: 1.0, 148: 0.5, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.25, 156: 0.75, 157: 0.5, 158: 0.75, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.5, 164: 1.0, 165: 1.0, 166: 1.0, 167: 0.25, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 0.75, 175: 1.0, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.75, 180: 1.0, 181: 0.75, 182: 0.75, 183: 0.75, 184: 0.25, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.5, 196: 0.5, 197: 0.75, 198: 0.75}

2024-05-03 06:16:57,050 [INFO] [50] TRAIN  loss: 0.20804540242488478 acc: 0.0
2024-05-03 06:16:57,050 [INFO] [50] TRAIN  loss dict: {'mse_loss': 0.20804540242488478}
2024-05-03 06:16:57,050 [INFO] [50] VALIDATION loss: 1.2988549084825949 VALIDATION  acc: 0.7171717171717171
2024-05-03 06:16:57,050 [INFO] [50] VALIDATION  loss dict: {'mse_loss': 0.24651752607990998, 'classification_loss': 1.0523373813208456}
2024-05-03 06:16:57,050 [INFO] 
2024-05-03 06:18:14,453 [INFO] Step[50/1020]: training loss : 0.20710730016231538 TRAIN  loss dict:  {'mse_loss': 0.20710730016231538}
2024-05-03 06:18:56,155 [INFO] Step[100/1020]: training loss : 0.20410228699445723 TRAIN  loss dict:  {'mse_loss': 0.20410228699445723}
2024-05-03 06:19:32,843 [INFO] Step[150/1020]: training loss : 0.1999339246749878 TRAIN  loss dict:  {'mse_loss': 0.1999339246749878}
2024-05-03 06:20:16,209 [INFO] Step[200/1020]: training loss : 0.1958748722076416 TRAIN  loss dict:  {'mse_loss': 0.1958748722076416}
2024-05-03 06:21:02,500 [INFO] Step[250/1020]: training loss : 0.19959663927555085 TRAIN  loss dict:  {'mse_loss': 0.19959663927555085}
2024-05-03 06:21:39,202 [INFO] Step[300/1020]: training loss : 0.20614508002996446 TRAIN  loss dict:  {'mse_loss': 0.20614508002996446}
2024-05-03 06:22:26,120 [INFO] Step[350/1020]: training loss : 0.2044970652461052 TRAIN  loss dict:  {'mse_loss': 0.2044970652461052}
2024-05-03 06:23:08,326 [INFO] Step[400/1020]: training loss : 0.20833385705947877 TRAIN  loss dict:  {'mse_loss': 0.20833385705947877}
2024-05-03 06:23:49,088 [INFO] Step[450/1020]: training loss : 0.2085061064362526 TRAIN  loss dict:  {'mse_loss': 0.2085061064362526}
2024-05-03 06:24:43,920 [INFO] Step[500/1020]: training loss : 0.2074755871295929 TRAIN  loss dict:  {'mse_loss': 0.2074755871295929}
2024-05-03 06:25:25,559 [INFO] Step[550/1020]: training loss : 0.20015406340360642 TRAIN  loss dict:  {'mse_loss': 0.20015406340360642}
2024-05-03 06:26:08,602 [INFO] Step[600/1020]: training loss : 0.20487551391124725 TRAIN  loss dict:  {'mse_loss': 0.20487551391124725}
2024-05-03 06:26:52,540 [INFO] Step[650/1020]: training loss : 0.2033413416147232 TRAIN  loss dict:  {'mse_loss': 0.2033413416147232}
2024-05-03 06:27:35,042 [INFO] Step[700/1020]: training loss : 0.20057879656553268 TRAIN  loss dict:  {'mse_loss': 0.20057879656553268}
2024-05-03 06:28:21,405 [INFO] Step[750/1020]: training loss : 0.20755808651447297 TRAIN  loss dict:  {'mse_loss': 0.20755808651447297}
2024-05-03 06:29:03,955 [INFO] Step[800/1020]: training loss : 0.2098351526260376 TRAIN  loss dict:  {'mse_loss': 0.2098351526260376}
2024-05-03 06:29:45,028 [INFO] Step[850/1020]: training loss : 0.21131546795368195 TRAIN  loss dict:  {'mse_loss': 0.21131546795368195}
2024-05-03 06:30:30,243 [INFO] Step[900/1020]: training loss : 0.20845694452524186 TRAIN  loss dict:  {'mse_loss': 0.20845694452524186}
2024-05-03 06:31:13,277 [INFO] Step[950/1020]: training loss : 0.205826396048069 TRAIN  loss dict:  {'mse_loss': 0.205826396048069}
2024-05-03 06:31:55,522 [INFO] Step[1000/1020]: training loss : 0.20699222177267074 TRAIN  loss dict:  {'mse_loss': 0.20699222177267074}
2024-05-03 06:35:00,395 [INFO] Label accuracies statistics:
2024-05-03 06:35:00,396 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 0.75, 4: 0.3333333333333333, 5: 0.5, 6: 0.5, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.5, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 0.5, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.5, 29: 0.75, 30: 0.5, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 1.0, 51: 0.75, 52: 0.25, 53: 0.5, 54: 0.5, 55: 1.0, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.25, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.5, 67: 0.5, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.25, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.25, 83: 0.75, 84: 0.75, 85: 0.75, 86: 0.25, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.5, 95: 0.75, 96: 0.25, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.5, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.25, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.75, 120: 0.75, 121: 1.0, 122: 1.0, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.25, 139: 0.5, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.75, 144: 0.75, 145: 1.0, 146: 0.75, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 0.0, 156: 0.75, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.5, 163: 0.5, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.25, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 0.5, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 0.5, 183: 1.0, 184: 0.5, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.75}

2024-05-03 06:35:00,413 [INFO] [51] TRAIN  loss: 0.20501370652049195 acc: 0.0
2024-05-03 06:35:00,413 [INFO] [51] TRAIN  loss dict: {'mse_loss': 0.20501370652049195}
2024-05-03 06:35:00,413 [INFO] [51] VALIDATION loss: 1.2470909641547636 VALIDATION  acc: 0.7386363636363636
2024-05-03 06:35:00,413 [INFO] [51] VALIDATION  loss dict: {'mse_loss': 0.24323026196222114, 'classification_loss': 1.0038607050194357}
2024-05-03 06:35:00,414 [INFO] 
2024-05-03 06:36:19,265 [INFO] Step[50/1020]: training loss : 0.213458808362484 TRAIN  loss dict:  {'mse_loss': 0.213458808362484}
2024-05-03 06:37:01,591 [INFO] Step[100/1020]: training loss : 0.2014741799235344 TRAIN  loss dict:  {'mse_loss': 0.2014741799235344}
2024-05-03 06:37:49,645 [INFO] Step[150/1020]: training loss : 0.2026924669742584 TRAIN  loss dict:  {'mse_loss': 0.2026924669742584}
2024-05-03 06:38:28,249 [INFO] Step[200/1020]: training loss : 0.1977831619977951 TRAIN  loss dict:  {'mse_loss': 0.1977831619977951}
2024-05-03 06:39:12,499 [INFO] Step[250/1020]: training loss : 0.21052717864513398 TRAIN  loss dict:  {'mse_loss': 0.21052717864513398}
2024-05-03 06:39:53,874 [INFO] Step[300/1020]: training loss : 0.2019999849796295 TRAIN  loss dict:  {'mse_loss': 0.2019999849796295}
2024-05-03 06:40:36,742 [INFO] Step[350/1020]: training loss : 0.2002736434340477 TRAIN  loss dict:  {'mse_loss': 0.2002736434340477}
2024-05-03 06:41:23,180 [INFO] Step[400/1020]: training loss : 0.20360185205936432 TRAIN  loss dict:  {'mse_loss': 0.20360185205936432}
2024-05-03 06:42:01,661 [INFO] Step[450/1020]: training loss : 0.20666491955518723 TRAIN  loss dict:  {'mse_loss': 0.20666491955518723}
2024-05-03 06:42:45,635 [INFO] Step[500/1020]: training loss : 0.20743157714605331 TRAIN  loss dict:  {'mse_loss': 0.20743157714605331}
2024-05-03 06:43:28,493 [INFO] Step[550/1020]: training loss : 0.1952657926082611 TRAIN  loss dict:  {'mse_loss': 0.1952657926082611}
2024-05-03 06:44:17,261 [INFO] Step[600/1020]: training loss : 0.2080771368741989 TRAIN  loss dict:  {'mse_loss': 0.2080771368741989}
2024-05-03 06:44:58,259 [INFO] Step[650/1020]: training loss : 0.20579173654317856 TRAIN  loss dict:  {'mse_loss': 0.20579173654317856}
2024-05-03 06:45:42,982 [INFO] Step[700/1020]: training loss : 0.207691650390625 TRAIN  loss dict:  {'mse_loss': 0.207691650390625}
2024-05-03 06:46:24,540 [INFO] Step[750/1020]: training loss : 0.20535757064819335 TRAIN  loss dict:  {'mse_loss': 0.20535757064819335}
2024-05-03 06:47:05,853 [INFO] Step[800/1020]: training loss : 0.21007282733917237 TRAIN  loss dict:  {'mse_loss': 0.21007282733917237}
2024-05-03 06:47:48,859 [INFO] Step[850/1020]: training loss : 0.20374060809612274 TRAIN  loss dict:  {'mse_loss': 0.20374060809612274}
2024-05-03 06:48:28,474 [INFO] Step[900/1020]: training loss : 0.21414217978715896 TRAIN  loss dict:  {'mse_loss': 0.21414217978715896}
2024-05-03 06:49:15,308 [INFO] Step[950/1020]: training loss : 0.20442787170410157 TRAIN  loss dict:  {'mse_loss': 0.20442787170410157}
2024-05-03 06:49:57,451 [INFO] Step[1000/1020]: training loss : 0.2074121978878975 TRAIN  loss dict:  {'mse_loss': 0.2074121978878975}
2024-05-03 06:53:00,114 [INFO] Label accuracies statistics:
2024-05-03 06:53:00,115 [INFO] {0: 0.5, 1: 1.0, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.5, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.25, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.5, 26: 1.0, 27: 1.0, 28: 0.5, 29: 1.0, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.25, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.75, 52: 0.25, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.25, 61: 0.5, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.5, 66: 0.75, 67: 0.75, 68: 0.25, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.25, 83: 0.75, 84: 0.75, 85: 1.0, 86: 0.5, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.5, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 0.75, 119: 0.75, 120: 0.75, 121: 1.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 0.75, 129: 0.75, 130: 1.0, 131: 0.75, 132: 0.25, 133: 0.75, 134: 0.75, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.25, 139: 0.5, 140: 0.5, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.5, 146: 0.75, 147: 0.75, 148: 0.75, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.5, 156: 0.75, 157: 0.5, 158: 0.75, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.5, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.75, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 0.75, 181: 1.0, 182: 0.5, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.5, 198: 0.75}

2024-05-03 06:53:00,137 [INFO] [52] TRAIN  loss: 0.20521716045982696 acc: 0.0
2024-05-03 06:53:00,137 [INFO] [52] TRAIN  loss dict: {'mse_loss': 0.20521716045982696}
2024-05-03 06:53:00,138 [INFO] [52] VALIDATION loss: 1.2680163324782343 VALIDATION  acc: 0.7285353535353535
2024-05-03 06:53:00,138 [INFO] [52] VALIDATION  loss dict: {'mse_loss': 0.2449383551273683, 'classification_loss': 1.0230779678024577}
2024-05-03 06:53:00,139 [INFO] 
2024-05-03 06:54:20,106 [INFO] Step[50/1020]: training loss : 0.1987897264957428 TRAIN  loss dict:  {'mse_loss': 0.1987897264957428}
2024-05-03 06:55:02,786 [INFO] Step[100/1020]: training loss : 0.2026936110854149 TRAIN  loss dict:  {'mse_loss': 0.2026936110854149}
2024-05-03 06:55:45,130 [INFO] Step[150/1020]: training loss : 0.19953570976853371 TRAIN  loss dict:  {'mse_loss': 0.19953570976853371}
2024-05-03 06:56:26,425 [INFO] Step[200/1020]: training loss : 0.2004653373360634 TRAIN  loss dict:  {'mse_loss': 0.2004653373360634}
2024-05-03 06:57:10,248 [INFO] Step[250/1020]: training loss : 0.20551107704639435 TRAIN  loss dict:  {'mse_loss': 0.20551107704639435}
2024-05-03 06:57:53,908 [INFO] Step[300/1020]: training loss : 0.2053658428788185 TRAIN  loss dict:  {'mse_loss': 0.2053658428788185}
2024-05-03 06:58:37,604 [INFO] Step[350/1020]: training loss : 0.21034637778997423 TRAIN  loss dict:  {'mse_loss': 0.21034637778997423}
2024-05-03 06:59:18,687 [INFO] Step[400/1020]: training loss : 0.19926247596740723 TRAIN  loss dict:  {'mse_loss': 0.19926247596740723}
2024-05-03 07:00:05,239 [INFO] Step[450/1020]: training loss : 0.2009363117814064 TRAIN  loss dict:  {'mse_loss': 0.2009363117814064}
2024-05-03 07:00:47,668 [INFO] Step[500/1020]: training loss : 0.20731626123189925 TRAIN  loss dict:  {'mse_loss': 0.20731626123189925}
2024-05-03 07:01:29,859 [INFO] Step[550/1020]: training loss : 0.20061227500438691 TRAIN  loss dict:  {'mse_loss': 0.20061227500438691}
2024-05-03 07:02:11,840 [INFO] Step[600/1020]: training loss : 0.20121972858905793 TRAIN  loss dict:  {'mse_loss': 0.20121972858905793}
2024-05-03 07:02:53,392 [INFO] Step[650/1020]: training loss : 0.2088412281870842 TRAIN  loss dict:  {'mse_loss': 0.2088412281870842}
2024-05-03 07:03:35,464 [INFO] Step[700/1020]: training loss : 0.20628273129463195 TRAIN  loss dict:  {'mse_loss': 0.20628273129463195}
2024-05-03 07:04:17,192 [INFO] Step[750/1020]: training loss : 0.2042833623290062 TRAIN  loss dict:  {'mse_loss': 0.2042833623290062}
2024-05-03 07:04:56,858 [INFO] Step[800/1020]: training loss : 0.20942169487476348 TRAIN  loss dict:  {'mse_loss': 0.20942169487476348}
2024-05-03 07:05:39,305 [INFO] Step[850/1020]: training loss : 0.2106109908223152 TRAIN  loss dict:  {'mse_loss': 0.2106109908223152}
2024-05-03 07:06:24,592 [INFO] Step[900/1020]: training loss : 0.20144778728485108 TRAIN  loss dict:  {'mse_loss': 0.20144778728485108}
2024-05-03 07:07:07,362 [INFO] Step[950/1020]: training loss : 0.2103702700138092 TRAIN  loss dict:  {'mse_loss': 0.2103702700138092}
2024-05-03 07:07:50,539 [INFO] Step[1000/1020]: training loss : 0.20802796721458436 TRAIN  loss dict:  {'mse_loss': 0.20802796721458436}
2024-05-03 07:10:51,875 [INFO] Label accuracies statistics:
2024-05-03 07:10:51,876 [INFO] {0: 1.0, 1: 0.75, 2: 0.5, 3: 1.0, 4: 0.6666666666666666, 5: 0.75, 6: 0.25, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.5, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.5, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.75, 26: 1.0, 27: 0.75, 28: 0.5, 29: 0.75, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.5, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.5, 52: 0.25, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.25, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.75, 66: 0.75, 67: 1.0, 68: 0.5, 69: 0.5, 70: 1.0, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.5, 83: 1.0, 84: 1.0, 85: 0.75, 86: 0.25, 87: 0.75, 88: 0.6666666666666666, 89: 0.5, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.75, 95: 0.75, 96: 0.5, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.5, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.0, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.75, 120: 0.75, 121: 1.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.25, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.25, 139: 0.75, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 0.75, 146: 0.75, 147: 1.0, 148: 0.5, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 0.25, 156: 0.5, 157: 0.5, 158: 0.75, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.5, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.25, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 0.25, 175: 0.75, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.75, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.25, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.75}

2024-05-03 07:10:51,903 [INFO] [53] TRAIN  loss: 0.20438800602420873 acc: 0.0
2024-05-03 07:10:51,903 [INFO] [53] TRAIN  loss dict: {'mse_loss': 0.20438800602420873}
2024-05-03 07:10:51,904 [INFO] [53] VALIDATION loss: 1.2468256392713748 VALIDATION  acc: 0.7310606060606061
2024-05-03 07:10:51,904 [INFO] [53] VALIDATION  loss dict: {'mse_loss': 0.2425942797251422, 'classification_loss': 1.0042313613712486}
2024-05-03 07:10:51,904 [INFO] 
2024-05-03 07:12:11,514 [INFO] Step[50/1020]: training loss : 0.20024488776922225 TRAIN  loss dict:  {'mse_loss': 0.20024488776922225}
2024-05-03 07:12:54,888 [INFO] Step[100/1020]: training loss : 0.1996128824353218 TRAIN  loss dict:  {'mse_loss': 0.1996128824353218}
2024-05-03 07:13:40,083 [INFO] Step[150/1020]: training loss : 0.19734935492277145 TRAIN  loss dict:  {'mse_loss': 0.19734935492277145}
2024-05-03 07:14:24,859 [INFO] Step[200/1020]: training loss : 0.20581380635499955 TRAIN  loss dict:  {'mse_loss': 0.20581380635499955}
2024-05-03 07:15:11,389 [INFO] Step[250/1020]: training loss : 0.197258852571249 TRAIN  loss dict:  {'mse_loss': 0.197258852571249}
2024-05-03 07:15:56,756 [INFO] Step[300/1020]: training loss : 0.20724687248468399 TRAIN  loss dict:  {'mse_loss': 0.20724687248468399}
2024-05-03 07:16:44,006 [INFO] Step[350/1020]: training loss : 0.20335955053567886 TRAIN  loss dict:  {'mse_loss': 0.20335955053567886}
2024-05-03 07:17:27,923 [INFO] Step[400/1020]: training loss : 0.19728765726089478 TRAIN  loss dict:  {'mse_loss': 0.19728765726089478}
2024-05-03 07:18:16,457 [INFO] Step[450/1020]: training loss : 0.2050604021549225 TRAIN  loss dict:  {'mse_loss': 0.2050604021549225}
2024-05-03 07:19:03,151 [INFO] Step[500/1020]: training loss : 0.2063410010933876 TRAIN  loss dict:  {'mse_loss': 0.2063410010933876}
2024-05-03 07:19:47,914 [INFO] Step[550/1020]: training loss : 0.20434378445148468 TRAIN  loss dict:  {'mse_loss': 0.20434378445148468}
2024-05-03 07:20:32,595 [INFO] Step[600/1020]: training loss : 0.20341232746839524 TRAIN  loss dict:  {'mse_loss': 0.20341232746839524}
2024-05-03 07:21:21,029 [INFO] Step[650/1020]: training loss : 0.21035095751285554 TRAIN  loss dict:  {'mse_loss': 0.21035095751285554}
2024-05-03 07:22:07,585 [INFO] Step[700/1020]: training loss : 0.2072771042585373 TRAIN  loss dict:  {'mse_loss': 0.2072771042585373}
2024-05-03 07:22:57,016 [INFO] Step[750/1020]: training loss : 0.1986667624115944 TRAIN  loss dict:  {'mse_loss': 0.1986667624115944}
2024-05-03 07:23:48,670 [INFO] Step[800/1020]: training loss : 0.20509404808282852 TRAIN  loss dict:  {'mse_loss': 0.20509404808282852}
2024-05-03 07:24:31,383 [INFO] Step[850/1020]: training loss : 0.20000714361667632 TRAIN  loss dict:  {'mse_loss': 0.20000714361667632}
2024-05-03 07:25:17,747 [INFO] Step[900/1020]: training loss : 0.20069686323404312 TRAIN  loss dict:  {'mse_loss': 0.20069686323404312}
2024-05-03 07:26:06,633 [INFO] Step[950/1020]: training loss : 0.20949432164430618 TRAIN  loss dict:  {'mse_loss': 0.20949432164430618}
2024-05-03 07:26:54,692 [INFO] Step[1000/1020]: training loss : 0.2062494045495987 TRAIN  loss dict:  {'mse_loss': 0.2062494045495987}
2024-05-03 07:30:04,824 [INFO] Label accuracies statistics:
2024-05-03 07:30:04,825 [INFO] {0: 1.0, 1: 0.75, 2: 0.75, 3: 0.75, 4: 0.6666666666666666, 5: 0.75, 6: 0.75, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.25, 16: 1.0, 17: 0.5, 18: 1.0, 19: 0.25, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.5, 29: 0.75, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.25, 38: 0.75, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 0.75, 47: 1.0, 48: 0.75, 49: 0.75, 50: 1.0, 51: 0.5, 52: 0.5, 53: 0.25, 54: 0.75, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.5, 59: 0.75, 60: 0.25, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.5, 66: 0.75, 67: 1.0, 68: 0.75, 69: 0.25, 70: 1.0, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.5, 83: 1.0, 84: 0.5, 85: 1.0, 86: 0.25, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.5, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.5, 110: 1.0, 111: 1.0, 112: 0.0, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 0.5, 124: 1.0, 125: 0.75, 126: 0.75, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.25, 133: 0.75, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.75, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 0.75, 147: 1.0, 148: 0.5, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.25, 156: 0.75, 157: 0.5, 158: 0.75, 159: 0.5, 160: 0.75, 161: 1.0, 162: 0.25, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.5, 167: 0.5, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.25, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 0.75, 182: 0.75, 183: 0.75, 184: 0.75, 185: 0.75, 186: 0.75, 187: 0.75, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.75}

2024-05-03 07:30:04,859 [INFO] [54] TRAIN  loss: 0.20298561255867575 acc: 0.0
2024-05-03 07:30:04,860 [INFO] [54] TRAIN  loss dict: {'mse_loss': 0.20298561255867575}
2024-05-03 07:30:04,860 [INFO] [54] VALIDATION loss: 1.2403591865993508 VALIDATION  acc: 0.7335858585858586
2024-05-03 07:30:04,861 [INFO] [54] VALIDATION  loss dict: {'mse_loss': 0.24324395469944887, 'classification_loss': 0.9971152368669558}
2024-05-03 07:30:04,861 [INFO] 
2024-05-03 07:31:30,598 [INFO] Step[50/1020]: training loss : 0.2031953389942646 TRAIN  loss dict:  {'mse_loss': 0.2031953389942646}
2024-05-03 07:32:15,662 [INFO] Step[100/1020]: training loss : 0.20930962562561034 TRAIN  loss dict:  {'mse_loss': 0.20930962562561034}
2024-05-03 07:33:05,591 [INFO] Step[150/1020]: training loss : 0.20152226716279983 TRAIN  loss dict:  {'mse_loss': 0.20152226716279983}
2024-05-03 07:33:51,372 [INFO] Step[200/1020]: training loss : 0.20221738487482072 TRAIN  loss dict:  {'mse_loss': 0.20221738487482072}
2024-05-03 07:34:36,765 [INFO] Step[250/1020]: training loss : 0.20360392183065415 TRAIN  loss dict:  {'mse_loss': 0.20360392183065415}
2024-05-03 07:35:21,866 [INFO] Step[300/1020]: training loss : 0.19878099828958512 TRAIN  loss dict:  {'mse_loss': 0.19878099828958512}
2024-05-03 07:36:10,612 [INFO] Step[350/1020]: training loss : 0.20424695700407028 TRAIN  loss dict:  {'mse_loss': 0.20424695700407028}
2024-05-03 07:36:55,458 [INFO] Step[400/1020]: training loss : 0.20218243420124055 TRAIN  loss dict:  {'mse_loss': 0.20218243420124055}
2024-05-03 07:37:44,160 [INFO] Step[450/1020]: training loss : 0.20007372587919237 TRAIN  loss dict:  {'mse_loss': 0.20007372587919237}
2024-05-03 07:38:28,338 [INFO] Step[500/1020]: training loss : 0.20063158124685287 TRAIN  loss dict:  {'mse_loss': 0.20063158124685287}
2024-05-03 07:39:18,656 [INFO] Step[550/1020]: training loss : 0.20856871366500854 TRAIN  loss dict:  {'mse_loss': 0.20856871366500854}
2024-05-03 07:40:03,378 [INFO] Step[600/1020]: training loss : 0.19499859124422073 TRAIN  loss dict:  {'mse_loss': 0.19499859124422073}
2024-05-03 07:40:53,727 [INFO] Step[650/1020]: training loss : 0.20324684113264083 TRAIN  loss dict:  {'mse_loss': 0.20324684113264083}
2024-05-03 07:41:40,766 [INFO] Step[700/1020]: training loss : 0.20016562610864638 TRAIN  loss dict:  {'mse_loss': 0.20016562610864638}
2024-05-03 07:42:25,446 [INFO] Step[750/1020]: training loss : 0.2017770940065384 TRAIN  loss dict:  {'mse_loss': 0.2017770940065384}
2024-05-03 07:43:11,643 [INFO] Step[800/1020]: training loss : 0.20345356374979018 TRAIN  loss dict:  {'mse_loss': 0.20345356374979018}
2024-05-03 07:43:56,498 [INFO] Step[850/1020]: training loss : 0.20717312067747115 TRAIN  loss dict:  {'mse_loss': 0.20717312067747115}
2024-05-03 07:44:42,390 [INFO] Step[900/1020]: training loss : 0.20782259374856948 TRAIN  loss dict:  {'mse_loss': 0.20782259374856948}
2024-05-03 07:45:26,077 [INFO] Step[950/1020]: training loss : 0.20374977290630342 TRAIN  loss dict:  {'mse_loss': 0.20374977290630342}
2024-05-03 07:46:10,700 [INFO] Step[1000/1020]: training loss : 0.20031095951795577 TRAIN  loss dict:  {'mse_loss': 0.20031095951795577}
2024-05-03 07:49:16,283 [INFO] Label accuracies statistics:
2024-05-03 07:49:16,283 [INFO] {0: 1.0, 1: 0.75, 2: 0.25, 3: 1.0, 4: 0.6666666666666666, 5: 0.75, 6: 0.5, 7: 1.0, 8: 0.25, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.25, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.5, 26: 1.0, 27: 1.0, 28: 0.5, 29: 1.0, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.5, 52: 0.25, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.25, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.5, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.5, 83: 1.0, 84: 0.5, 85: 1.0, 86: 0.25, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.75, 95: 0.75, 96: 0.5, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.25, 113: 0.5, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.25, 139: 0.75, 140: 0.75, 141: 0.75, 142: 1.0, 143: 0.5, 144: 0.75, 145: 0.5, 146: 0.75, 147: 1.0, 148: 0.5, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.5, 156: 0.5, 157: 0.5, 158: 0.75, 159: 0.5, 160: 0.25, 161: 0.75, 162: 0.5, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.25, 169: 1.0, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 0.75, 175: 0.75, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.75, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.25, 185: 0.75, 186: 0.75, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.5, 198: 0.75}

2024-05-03 07:49:16,310 [INFO] [55] TRAIN  loss: 0.20301293244987142 acc: 0.0
2024-05-03 07:49:16,310 [INFO] [55] TRAIN  loss dict: {'mse_loss': 0.20301293244987142}
2024-05-03 07:49:16,310 [INFO] [55] VALIDATION loss: 1.2391118721076937 VALIDATION  acc: 0.7348484848484849
2024-05-03 07:49:16,310 [INFO] [55] VALIDATION  loss dict: {'mse_loss': 0.2429012048124063, 'classification_loss': 0.9962106697458887}
2024-05-03 07:49:16,311 [INFO] 
2024-05-03 07:50:34,927 [INFO] Step[50/1020]: training loss : 0.19867810279130935 TRAIN  loss dict:  {'mse_loss': 0.19867810279130935}
2024-05-03 07:51:17,023 [INFO] Step[100/1020]: training loss : 0.19821103662252426 TRAIN  loss dict:  {'mse_loss': 0.19821103662252426}
2024-05-03 07:52:00,007 [INFO] Step[150/1020]: training loss : 0.19990402936935425 TRAIN  loss dict:  {'mse_loss': 0.19990402936935425}
2024-05-03 07:52:44,104 [INFO] Step[200/1020]: training loss : 0.20191196233034134 TRAIN  loss dict:  {'mse_loss': 0.20191196233034134}
2024-05-03 07:53:28,895 [INFO] Step[250/1020]: training loss : 0.20536841154098512 TRAIN  loss dict:  {'mse_loss': 0.20536841154098512}
2024-05-03 07:54:11,579 [INFO] Step[300/1020]: training loss : 0.1997271931171417 TRAIN  loss dict:  {'mse_loss': 0.1997271931171417}
2024-05-03 07:54:57,966 [INFO] Step[350/1020]: training loss : 0.20533898919820787 TRAIN  loss dict:  {'mse_loss': 0.20533898919820787}
2024-05-03 07:55:38,556 [INFO] Step[400/1020]: training loss : 0.20215629130601884 TRAIN  loss dict:  {'mse_loss': 0.20215629130601884}
2024-05-03 07:56:20,200 [INFO] Step[450/1020]: training loss : 0.19911662265658378 TRAIN  loss dict:  {'mse_loss': 0.19911662265658378}
2024-05-03 07:56:55,218 [INFO] Step[500/1020]: training loss : 0.20144894272089003 TRAIN  loss dict:  {'mse_loss': 0.20144894272089003}
2024-05-03 07:57:32,720 [INFO] Step[550/1020]: training loss : 0.2040528628230095 TRAIN  loss dict:  {'mse_loss': 0.2040528628230095}
2024-05-03 07:58:17,742 [INFO] Step[600/1020]: training loss : 0.19601731151342391 TRAIN  loss dict:  {'mse_loss': 0.19601731151342391}
2024-05-03 07:59:02,393 [INFO] Step[650/1020]: training loss : 0.20109640419483185 TRAIN  loss dict:  {'mse_loss': 0.20109640419483185}
2024-05-03 07:59:45,857 [INFO] Step[700/1020]: training loss : 0.19658306896686553 TRAIN  loss dict:  {'mse_loss': 0.19658306896686553}
2024-05-03 08:00:25,467 [INFO] Step[750/1020]: training loss : 0.2085131013393402 TRAIN  loss dict:  {'mse_loss': 0.2085131013393402}
2024-05-03 08:01:08,765 [INFO] Step[800/1020]: training loss : 0.20225942820310594 TRAIN  loss dict:  {'mse_loss': 0.20225942820310594}
2024-05-03 08:02:00,357 [INFO] Step[850/1020]: training loss : 0.20544688373804093 TRAIN  loss dict:  {'mse_loss': 0.20544688373804093}
2024-05-03 08:02:47,866 [INFO] Step[900/1020]: training loss : 0.20021186232566834 TRAIN  loss dict:  {'mse_loss': 0.20021186232566834}
2024-05-03 08:03:29,662 [INFO] Step[950/1020]: training loss : 0.2018864247202873 TRAIN  loss dict:  {'mse_loss': 0.2018864247202873}
2024-05-03 08:04:18,216 [INFO] Step[1000/1020]: training loss : 0.20315919905900956 TRAIN  loss dict:  {'mse_loss': 0.20315919905900956}
2024-05-03 08:07:33,233 [INFO] Label accuracies statistics:
2024-05-03 08:07:33,234 [INFO] {0: 1.0, 1: 0.75, 2: 0.25, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.5, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.25, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.75, 29: 1.0, 30: 0.75, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.5, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 0.5, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.25, 60: 0.25, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.75, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.25, 83: 0.75, 84: 0.75, 85: 1.0, 86: 0.25, 87: 0.5, 88: 1.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.5, 95: 0.75, 96: 0.5, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.5, 110: 0.75, 111: 1.0, 112: 0.25, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 1.0, 119: 0.75, 120: 0.75, 121: 1.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.25, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.75, 146: 0.75, 147: 1.0, 148: 0.75, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.5, 158: 0.75, 159: 0.5, 160: 0.75, 161: 1.0, 162: 0.5, 163: 0.5, 164: 1.0, 165: 1.0, 166: 0.5, 167: 0.75, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.25, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 0.75, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.75, 187: 0.75, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.75}

2024-05-03 08:07:37,172 [INFO] [56] TRAIN  loss: 0.20144947637968202 acc: 0.0
2024-05-03 08:07:37,173 [INFO] [56] TRAIN  loss dict: {'mse_loss': 0.20144947637968202}
2024-05-03 08:07:37,174 [INFO] [56] VALIDATION loss: 1.195587669734401 VALIDATION  acc: 0.7411616161616161
2024-05-03 08:07:37,175 [INFO] [56] VALIDATION  loss dict: {'mse_loss': 0.24028316606776884, 'classification_loss': 0.9553045042781065}
2024-05-03 08:07:37,175 [INFO] 
2024-05-03 08:08:54,538 [INFO] Step[50/1020]: training loss : 0.19708206623792648 TRAIN  loss dict:  {'mse_loss': 0.19708206623792648}
2024-05-03 08:09:38,879 [INFO] Step[100/1020]: training loss : 0.20245550096035003 TRAIN  loss dict:  {'mse_loss': 0.20245550096035003}
2024-05-03 08:10:21,592 [INFO] Step[150/1020]: training loss : 0.20599528789520263 TRAIN  loss dict:  {'mse_loss': 0.20599528789520263}
2024-05-03 08:11:08,712 [INFO] Step[200/1020]: training loss : 0.1980879047513008 TRAIN  loss dict:  {'mse_loss': 0.1980879047513008}
2024-05-03 08:11:53,143 [INFO] Step[250/1020]: training loss : 0.21306528240442277 TRAIN  loss dict:  {'mse_loss': 0.21306528240442277}
2024-05-03 08:12:40,274 [INFO] Step[300/1020]: training loss : 0.201702880859375 TRAIN  loss dict:  {'mse_loss': 0.201702880859375}
2024-05-03 08:13:27,158 [INFO] Step[350/1020]: training loss : 0.1990177784860134 TRAIN  loss dict:  {'mse_loss': 0.1990177784860134}
2024-05-03 08:14:15,540 [INFO] Step[400/1020]: training loss : 0.20340557783842086 TRAIN  loss dict:  {'mse_loss': 0.20340557783842086}
2024-05-03 08:15:03,321 [INFO] Step[450/1020]: training loss : 0.2046597582101822 TRAIN  loss dict:  {'mse_loss': 0.2046597582101822}
2024-05-03 08:15:50,474 [INFO] Step[500/1020]: training loss : 0.20778833597898483 TRAIN  loss dict:  {'mse_loss': 0.20778833597898483}
2024-05-03 08:16:35,811 [INFO] Step[550/1020]: training loss : 0.1918931321799755 TRAIN  loss dict:  {'mse_loss': 0.1918931321799755}
2024-05-03 08:17:30,485 [INFO] Step[600/1020]: training loss : 0.2001047232747078 TRAIN  loss dict:  {'mse_loss': 0.2001047232747078}
2024-05-03 08:18:21,704 [INFO] Step[650/1020]: training loss : 0.2022264438867569 TRAIN  loss dict:  {'mse_loss': 0.2022264438867569}
2024-05-03 08:19:07,307 [INFO] Step[700/1020]: training loss : 0.19991082459688186 TRAIN  loss dict:  {'mse_loss': 0.19991082459688186}
2024-05-03 08:19:57,796 [INFO] Step[750/1020]: training loss : 0.20585254728794097 TRAIN  loss dict:  {'mse_loss': 0.20585254728794097}
2024-05-03 08:20:48,036 [INFO] Step[800/1020]: training loss : 0.1978219997882843 TRAIN  loss dict:  {'mse_loss': 0.1978219997882843}
2024-05-03 08:21:33,571 [INFO] Step[850/1020]: training loss : 0.20185376912355424 TRAIN  loss dict:  {'mse_loss': 0.20185376912355424}
2024-05-03 08:22:22,860 [INFO] Step[900/1020]: training loss : 0.19061781644821166 TRAIN  loss dict:  {'mse_loss': 0.19061781644821166}
2024-05-03 08:23:14,888 [INFO] Step[950/1020]: training loss : 0.1993002113699913 TRAIN  loss dict:  {'mse_loss': 0.1993002113699913}
2024-05-03 08:24:01,594 [INFO] Step[1000/1020]: training loss : 0.19807008147239685 TRAIN  loss dict:  {'mse_loss': 0.19807008147239685}
2024-05-03 08:26:46,788 [INFO] Label accuracies statistics:
2024-05-03 08:26:46,789 [INFO] {0: 0.5, 1: 0.75, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 0.5, 6: 0.5, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.5, 13: 0.75, 14: 0.25, 15: 0.5, 16: 1.0, 17: 0.5, 18: 1.0, 19: 0.5, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.75, 27: 1.0, 28: 0.5, 29: 1.0, 30: 0.5, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.25, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.25, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.75, 66: 0.75, 67: 1.0, 68: 0.75, 69: 0.25, 70: 1.0, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.25, 83: 1.0, 84: 0.75, 85: 1.0, 86: 0.5, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.0, 95: 0.75, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.5, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.75, 120: 0.75, 121: 1.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.75, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 0.75, 147: 1.0, 148: 0.75, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.5, 158: 0.5, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.5, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.25, 175: 0.75, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.5, 180: 0.5, 181: 1.0, 182: 0.5, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.5, 196: 0.75, 197: 0.75, 198: 0.75}

2024-05-03 08:26:46,815 [INFO] [57] TRAIN  loss: 0.20114497871083373 acc: 0.0
2024-05-03 08:26:46,815 [INFO] [57] TRAIN  loss dict: {'mse_loss': 0.20114497871083373}
2024-05-03 08:26:46,816 [INFO] [57] VALIDATION loss: 1.238715847860081 VALIDATION  acc: 0.7373737373737373
2024-05-03 08:26:46,816 [INFO] [57] VALIDATION  loss dict: {'mse_loss': 0.23977034463725908, 'classification_loss': 0.9989455046433241}
2024-05-03 08:26:46,817 [INFO] 
2024-05-03 08:28:02,933 [INFO] Step[50/1020]: training loss : 0.19970143765211104 TRAIN  loss dict:  {'mse_loss': 0.19970143765211104}
2024-05-03 08:28:47,049 [INFO] Step[100/1020]: training loss : 0.2058331286907196 TRAIN  loss dict:  {'mse_loss': 0.2058331286907196}
2024-05-03 08:29:33,031 [INFO] Step[150/1020]: training loss : 0.20197687417268753 TRAIN  loss dict:  {'mse_loss': 0.20197687417268753}
2024-05-03 08:30:13,227 [INFO] Step[200/1020]: training loss : 0.19645201086997985 TRAIN  loss dict:  {'mse_loss': 0.19645201086997985}
2024-05-03 08:30:56,542 [INFO] Step[250/1020]: training loss : 0.19687525540590287 TRAIN  loss dict:  {'mse_loss': 0.19687525540590287}
2024-05-03 08:31:38,690 [INFO] Step[300/1020]: training loss : 0.19711386322975158 TRAIN  loss dict:  {'mse_loss': 0.19711386322975158}
2024-05-03 08:32:18,009 [INFO] Step[350/1020]: training loss : 0.20430543512105942 TRAIN  loss dict:  {'mse_loss': 0.20430543512105942}
2024-05-03 08:33:00,701 [INFO] Step[400/1020]: training loss : 0.20024836033582688 TRAIN  loss dict:  {'mse_loss': 0.20024836033582688}
2024-05-03 08:33:38,643 [INFO] Step[450/1020]: training loss : 0.19963823541998862 TRAIN  loss dict:  {'mse_loss': 0.19963823541998862}
2024-05-03 08:34:16,918 [INFO] Step[500/1020]: training loss : 0.1976329654455185 TRAIN  loss dict:  {'mse_loss': 0.1976329654455185}
2024-05-03 08:34:54,305 [INFO] Step[550/1020]: training loss : 0.20316903173923492 TRAIN  loss dict:  {'mse_loss': 0.20316903173923492}
2024-05-03 08:35:33,991 [INFO] Step[600/1020]: training loss : 0.20336250990629196 TRAIN  loss dict:  {'mse_loss': 0.20336250990629196}
2024-05-03 08:36:11,837 [INFO] Step[650/1020]: training loss : 0.19326373308897019 TRAIN  loss dict:  {'mse_loss': 0.19326373308897019}
2024-05-03 08:36:50,465 [INFO] Step[700/1020]: training loss : 0.20017340064048766 TRAIN  loss dict:  {'mse_loss': 0.20017340064048766}
2024-05-03 08:37:32,841 [INFO] Step[750/1020]: training loss : 0.1989304468035698 TRAIN  loss dict:  {'mse_loss': 0.1989304468035698}
2024-05-03 08:38:15,493 [INFO] Step[800/1020]: training loss : 0.19738384038209916 TRAIN  loss dict:  {'mse_loss': 0.19738384038209916}
2024-05-03 08:38:51,549 [INFO] Step[850/1020]: training loss : 0.19979650840163232 TRAIN  loss dict:  {'mse_loss': 0.19979650840163232}
2024-05-03 08:39:27,377 [INFO] Step[900/1020]: training loss : 0.19859213829040528 TRAIN  loss dict:  {'mse_loss': 0.19859213829040528}
2024-05-03 08:40:09,758 [INFO] Step[950/1020]: training loss : 0.19616673350334168 TRAIN  loss dict:  {'mse_loss': 0.19616673350334168}
2024-05-03 08:40:46,119 [INFO] Step[1000/1020]: training loss : 0.20023141741752626 TRAIN  loss dict:  {'mse_loss': 0.20023141741752626}
2024-05-03 08:43:29,650 [INFO] Label accuracies statistics:
2024-05-03 08:43:29,651 [INFO] {0: 1.0, 1: 0.75, 2: 0.75, 3: 0.75, 4: 0.3333333333333333, 5: 0.5, 6: 0.75, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.25, 16: 1.0, 17: 0.75, 18: 1.0, 19: 0.25, 20: 0.5, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.75, 26: 0.75, 27: 1.0, 28: 0.75, 29: 0.75, 30: 0.5, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.25, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.75, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.75, 50: 0.75, 51: 0.5, 52: 0.25, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.25, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.5, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.25, 83: 0.75, 84: 1.0, 85: 0.75, 86: 0.25, 87: 0.5, 88: 0.6666666666666666, 89: 0.75, 90: 0.25, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.75, 95: 0.75, 96: 0.5, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.75, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 0.75, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.0, 133: 0.75, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.5, 144: 1.0, 145: 0.75, 146: 0.75, 147: 1.0, 148: 0.5, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.5, 156: 1.0, 157: 0.5, 158: 0.75, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 0.5, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.75, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.25, 196: 0.75, 197: 0.75, 198: 0.75}

2024-05-03 08:43:29,670 [INFO] [58] TRAIN  loss: 0.1993595179389505 acc: 0.0
2024-05-03 08:43:29,671 [INFO] [58] TRAIN  loss dict: {'mse_loss': 0.1993595179389505}
2024-05-03 08:43:29,671 [INFO] [58] VALIDATION loss: 1.2709799812297629 VALIDATION  acc: 0.7297979797979798
2024-05-03 08:43:29,671 [INFO] [58] VALIDATION  loss dict: {'mse_loss': 0.24203490285259305, 'classification_loss': 1.0289450755079437}
2024-05-03 08:43:29,671 [INFO] 
2024-05-03 08:44:35,851 [INFO] Step[50/1020]: training loss : 0.20029475510120393 TRAIN  loss dict:  {'mse_loss': 0.20029475510120393}
2024-05-03 08:45:18,617 [INFO] Step[100/1020]: training loss : 0.19712807685136796 TRAIN  loss dict:  {'mse_loss': 0.19712807685136796}
2024-05-03 08:46:03,963 [INFO] Step[150/1020]: training loss : 0.19982753694057465 TRAIN  loss dict:  {'mse_loss': 0.19982753694057465}
2024-05-03 08:46:54,681 [INFO] Step[200/1020]: training loss : 0.18990496218204497 TRAIN  loss dict:  {'mse_loss': 0.18990496218204497}
2024-05-03 08:47:39,137 [INFO] Step[250/1020]: training loss : 0.20385950952768325 TRAIN  loss dict:  {'mse_loss': 0.20385950952768325}
2024-05-03 08:48:21,197 [INFO] Step[300/1020]: training loss : 0.19937899842858314 TRAIN  loss dict:  {'mse_loss': 0.19937899842858314}
2024-05-03 08:49:04,177 [INFO] Step[350/1020]: training loss : 0.19973992973566054 TRAIN  loss dict:  {'mse_loss': 0.19973992973566054}
2024-05-03 08:50:24,280 [INFO] Step[400/1020]: training loss : 0.20180951863527297 TRAIN  loss dict:  {'mse_loss': 0.20180951863527297}
2024-05-03 08:51:38,821 [INFO] Step[450/1020]: training loss : 0.20010835379362107 TRAIN  loss dict:  {'mse_loss': 0.20010835379362107}
2024-05-03 08:53:07,757 [INFO] Step[500/1020]: training loss : 0.20467749118804932 TRAIN  loss dict:  {'mse_loss': 0.20467749118804932}
2024-05-03 08:54:38,413 [INFO] Step[550/1020]: training loss : 0.2078619560599327 TRAIN  loss dict:  {'mse_loss': 0.2078619560599327}
2024-05-03 08:55:55,608 [INFO] Step[600/1020]: training loss : 0.2020681083202362 TRAIN  loss dict:  {'mse_loss': 0.2020681083202362}
2024-05-03 08:57:29,426 [INFO] Step[650/1020]: training loss : 0.19136864379048346 TRAIN  loss dict:  {'mse_loss': 0.19136864379048346}
2024-05-03 08:58:55,463 [INFO] Step[700/1020]: training loss : 0.1966911706328392 TRAIN  loss dict:  {'mse_loss': 0.1966911706328392}
2024-05-03 09:00:22,112 [INFO] Step[750/1020]: training loss : 0.19912520676851272 TRAIN  loss dict:  {'mse_loss': 0.19912520676851272}
2024-05-03 09:01:50,554 [INFO] Step[800/1020]: training loss : 0.19908029943704605 TRAIN  loss dict:  {'mse_loss': 0.19908029943704605}
2024-05-03 09:03:07,658 [INFO] Step[850/1020]: training loss : 0.19649976283311843 TRAIN  loss dict:  {'mse_loss': 0.19649976283311843}
2024-05-03 09:04:28,791 [INFO] Step[900/1020]: training loss : 0.1951312267780304 TRAIN  loss dict:  {'mse_loss': 0.1951312267780304}
2024-05-03 09:06:04,700 [INFO] Step[950/1020]: training loss : 0.20681858092546462 TRAIN  loss dict:  {'mse_loss': 0.20681858092546462}
2024-05-03 09:07:24,524 [INFO] Step[1000/1020]: training loss : 0.20757241547107697 TRAIN  loss dict:  {'mse_loss': 0.20757241547107697}
2024-05-03 09:13:12,943 [INFO] Label accuracies statistics:
2024-05-03 09:13:12,944 [INFO] {0: 1.0, 1: 0.75, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.75, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.5, 16: 1.0, 17: 0.5, 18: 1.0, 19: 0.5, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.5, 26: 1.0, 27: 1.0, 28: 0.5, 29: 0.75, 30: 0.5, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.25, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.5, 52: 0.5, 53: 0.25, 54: 0.5, 55: 0.5, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.25, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.5, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.5, 83: 1.0, 84: 0.5, 85: 1.0, 86: 0.5, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.5, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.25, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 0.75, 120: 0.75, 121: 1.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.25, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.5, 144: 1.0, 145: 0.5, 146: 0.75, 147: 1.0, 148: 0.75, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.5, 157: 0.5, 158: 0.5, 159: 0.5, 160: 0.75, 161: 0.75, 162: 0.5, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.5, 175: 1.0, 176: 0.75, 177: 0.75, 178: 0.75, 179: 1.0, 180: 0.75, 181: 1.0, 182: 0.5, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.25, 196: 0.75, 197: 1.0, 198: 0.75}

2024-05-03 09:13:12,996 [INFO] [59] TRAIN  loss: 0.19986266587294785 acc: 0.0
2024-05-03 09:13:12,997 [INFO] [59] TRAIN  loss dict: {'mse_loss': 0.19986266587294785}
2024-05-03 09:13:13,000 [INFO] [59] VALIDATION loss: 1.2587235399869958 VALIDATION  acc: 0.7310606060606061
2024-05-03 09:13:13,001 [INFO] [59] VALIDATION  loss dict: {'mse_loss': 0.2396807519323898, 'classification_loss': 1.0190427867752132}
2024-05-03 09:13:13,014 [INFO] 
2024-05-03 09:15:44,453 [INFO] Step[50/1020]: training loss : 0.2047286882996559 TRAIN  loss dict:  {'mse_loss': 0.2047286882996559}
2024-05-03 09:17:04,143 [INFO] Step[100/1020]: training loss : 0.20329440981149674 TRAIN  loss dict:  {'mse_loss': 0.20329440981149674}
2024-05-03 09:18:19,871 [INFO] Step[150/1020]: training loss : 0.19409677967429162 TRAIN  loss dict:  {'mse_loss': 0.19409677967429162}
2024-05-03 09:19:41,976 [INFO] Step[200/1020]: training loss : 0.20310759752988816 TRAIN  loss dict:  {'mse_loss': 0.20310759752988816}
2024-05-03 09:21:04,536 [INFO] Step[250/1020]: training loss : 0.19259154200553893 TRAIN  loss dict:  {'mse_loss': 0.19259154200553893}
2024-05-03 09:22:36,366 [INFO] Step[300/1020]: training loss : 0.19616872996091841 TRAIN  loss dict:  {'mse_loss': 0.19616872996091841}
2024-05-03 09:23:51,521 [INFO] Step[350/1020]: training loss : 0.19813168287277222 TRAIN  loss dict:  {'mse_loss': 0.19813168287277222}
2024-05-03 09:25:18,207 [INFO] Step[400/1020]: training loss : 0.2072773516178131 TRAIN  loss dict:  {'mse_loss': 0.2072773516178131}
2024-05-03 09:26:42,942 [INFO] Step[450/1020]: training loss : 0.20550561517477037 TRAIN  loss dict:  {'mse_loss': 0.20550561517477037}
2024-05-03 09:28:08,375 [INFO] Step[500/1020]: training loss : 0.2002086478471756 TRAIN  loss dict:  {'mse_loss': 0.2002086478471756}
2024-05-03 09:29:27,401 [INFO] Step[550/1020]: training loss : 0.20029118806123733 TRAIN  loss dict:  {'mse_loss': 0.20029118806123733}
2024-05-03 09:30:49,743 [INFO] Step[600/1020]: training loss : 0.19809461265802383 TRAIN  loss dict:  {'mse_loss': 0.19809461265802383}
2024-05-03 09:32:07,663 [INFO] Step[650/1020]: training loss : 0.20348379909992217 TRAIN  loss dict:  {'mse_loss': 0.20348379909992217}
2024-05-03 09:33:21,902 [INFO] Step[700/1020]: training loss : 0.20011593371629716 TRAIN  loss dict:  {'mse_loss': 0.20011593371629716}
2024-05-03 09:34:48,612 [INFO] Step[750/1020]: training loss : 0.20291157245635985 TRAIN  loss dict:  {'mse_loss': 0.20291157245635985}
2024-05-03 09:36:19,693 [INFO] Step[800/1020]: training loss : 0.1947631749510765 TRAIN  loss dict:  {'mse_loss': 0.1947631749510765}
2024-05-03 09:37:37,217 [INFO] Step[850/1020]: training loss : 0.19287831962108612 TRAIN  loss dict:  {'mse_loss': 0.19287831962108612}
2024-05-03 09:39:02,147 [INFO] Step[900/1020]: training loss : 0.2004630210995674 TRAIN  loss dict:  {'mse_loss': 0.2004630210995674}
2024-05-03 09:40:28,694 [INFO] Step[950/1020]: training loss : 0.19170947164297103 TRAIN  loss dict:  {'mse_loss': 0.19170947164297103}
2024-05-03 09:41:56,880 [INFO] Step[1000/1020]: training loss : 0.19875391840934753 TRAIN  loss dict:  {'mse_loss': 0.19875391840934753}
2024-05-03 09:47:44,149 [INFO] Label accuracies statistics:
2024-05-03 09:47:44,168 [INFO] {0: 0.5, 1: 0.75, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.0, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.5, 16: 0.5, 17: 0.75, 18: 1.0, 19: 0.5, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.5, 24: 0.5, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.5, 29: 1.0, 30: 0.5, 31: 0.75, 32: 1.0, 33: 1.0, 34: 1.0, 35: 0.75, 36: 0.75, 37: 0.5, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.5, 52: 0.5, 53: 0.5, 54: 0.5, 55: 0.5, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.25, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 1.0, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.25, 83: 0.5, 84: 0.75, 85: 1.0, 86: 0.5, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.5, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 0.75, 126: 0.75, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.0, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.75, 146: 0.75, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.5, 156: 0.5, 157: 0.5, 158: 0.5, 159: 0.5, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.5, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 0.5, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 0.75, 181: 0.75, 182: 0.5, 183: 0.75, 184: 0.75, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.5, 196: 0.75, 197: 0.5, 198: 0.75}

2024-05-03 09:47:44,243 [INFO] [60] TRAIN  loss: 0.1992632342685087 acc: 0.0
2024-05-03 09:47:44,244 [INFO] [60] TRAIN  loss dict: {'mse_loss': 0.1992632342685087}
2024-05-03 09:47:44,247 [INFO] [60] VALIDATION loss: 1.262049680406397 VALIDATION  acc: 0.7335858585858586
2024-05-03 09:47:44,248 [INFO] [60] VALIDATION  loss dict: {'mse_loss': 0.2409647221517081, 'classification_loss': 1.0210849524786074}
2024-05-03 09:47:44,249 [INFO] 
2024-05-03 09:50:13,138 [INFO] Step[50/1020]: training loss : 0.19296087950468063 TRAIN  loss dict:  {'mse_loss': 0.19296087950468063}
2024-05-03 09:51:34,765 [INFO] Step[100/1020]: training loss : 0.19378139615058898 TRAIN  loss dict:  {'mse_loss': 0.19378139615058898}
2024-05-03 09:52:48,224 [INFO] Step[150/1020]: training loss : 0.19916464298963546 TRAIN  loss dict:  {'mse_loss': 0.19916464298963546}
2024-05-03 09:54:01,912 [INFO] Step[200/1020]: training loss : 0.19750785395503045 TRAIN  loss dict:  {'mse_loss': 0.19750785395503045}
2024-05-03 09:55:27,547 [INFO] Step[250/1020]: training loss : 0.20116373062133788 TRAIN  loss dict:  {'mse_loss': 0.20116373062133788}
2024-05-03 09:56:45,911 [INFO] Step[300/1020]: training loss : 0.1987111359834671 TRAIN  loss dict:  {'mse_loss': 0.1987111359834671}
2024-05-03 09:58:10,816 [INFO] Step[350/1020]: training loss : 0.19639334827661514 TRAIN  loss dict:  {'mse_loss': 0.19639334827661514}
2024-05-03 09:59:35,578 [INFO] Step[400/1020]: training loss : 0.20155545383691786 TRAIN  loss dict:  {'mse_loss': 0.20155545383691786}
2024-05-03 10:00:56,628 [INFO] Step[450/1020]: training loss : 0.2060041344165802 TRAIN  loss dict:  {'mse_loss': 0.2060041344165802}
2024-05-03 10:02:16,696 [INFO] Step[500/1020]: training loss : 0.19230813324451446 TRAIN  loss dict:  {'mse_loss': 0.19230813324451446}
2024-05-03 10:03:32,491 [INFO] Step[550/1020]: training loss : 0.2065676775574684 TRAIN  loss dict:  {'mse_loss': 0.2065676775574684}
2024-05-03 10:04:59,723 [INFO] Step[600/1020]: training loss : 0.20053079098463059 TRAIN  loss dict:  {'mse_loss': 0.20053079098463059}
2024-05-03 10:06:24,957 [INFO] Step[650/1020]: training loss : 0.20640899509191513 TRAIN  loss dict:  {'mse_loss': 0.20640899509191513}
2024-05-03 10:07:45,454 [INFO] Step[700/1020]: training loss : 0.19185897320508957 TRAIN  loss dict:  {'mse_loss': 0.19185897320508957}
2024-05-03 10:09:25,410 [INFO] Step[750/1020]: training loss : 0.19091464161872865 TRAIN  loss dict:  {'mse_loss': 0.19091464161872865}
2024-05-03 10:10:41,237 [INFO] Step[800/1020]: training loss : 0.1955714237689972 TRAIN  loss dict:  {'mse_loss': 0.1955714237689972}
2024-05-03 10:12:01,662 [INFO] Step[850/1020]: training loss : 0.19985293835401535 TRAIN  loss dict:  {'mse_loss': 0.19985293835401535}
2024-05-03 10:13:26,631 [INFO] Step[900/1020]: training loss : 0.20502662032842636 TRAIN  loss dict:  {'mse_loss': 0.20502662032842636}
2024-05-03 10:14:50,359 [INFO] Step[950/1020]: training loss : 0.19605690002441406 TRAIN  loss dict:  {'mse_loss': 0.19605690002441406}
2024-05-03 10:16:09,673 [INFO] Step[1000/1020]: training loss : 0.1980900889635086 TRAIN  loss dict:  {'mse_loss': 0.1980900889635086}
2024-05-03 10:21:55,673 [INFO] Label accuracies statistics:
2024-05-03 10:21:55,674 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 0.5, 6: 0.5, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.5, 14: 0.25, 15: 0.5, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.5, 29: 0.75, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.5, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.75, 52: 0.5, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.25, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.75, 65: 0.5, 66: 0.5, 67: 0.75, 68: 0.25, 69: 0.75, 70: 0.5, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.25, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.75, 83: 1.0, 84: 0.75, 85: 1.0, 86: 0.25, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.0, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 1.0, 120: 0.5, 121: 1.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.25, 133: 0.75, 134: 0.25, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.25, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.75, 146: 0.75, 147: 1.0, 148: 0.75, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.25, 156: 0.5, 157: 0.5, 158: 0.5, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.5, 167: 0.5, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.75, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 0.5, 183: 0.75, 184: 0.25, 185: 0.75, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.5, 198: 0.75}

2024-05-03 10:21:55,777 [INFO] [61] TRAIN  loss: 0.19842403374027973 acc: 0.0
2024-05-03 10:21:55,778 [INFO] [61] TRAIN  loss dict: {'mse_loss': 0.19842403374027973}
2024-05-03 10:21:55,781 [INFO] [61] VALIDATION loss: 1.2474991807883435 VALIDATION  acc: 0.7222222222222222
2024-05-03 10:21:55,782 [INFO] [61] VALIDATION  loss dict: {'mse_loss': 0.23937779070452006, 'classification_loss': 1.0081213892889067}
2024-05-03 10:21:55,784 [INFO] 
2024-05-03 10:24:18,142 [INFO] Step[50/1020]: training loss : 0.1980890589952469 TRAIN  loss dict:  {'mse_loss': 0.1980890589952469}
2024-05-03 10:25:39,730 [INFO] Step[100/1020]: training loss : 0.1953968659043312 TRAIN  loss dict:  {'mse_loss': 0.1953968659043312}
2024-05-03 10:27:05,339 [INFO] Step[150/1020]: training loss : 0.19133031994104385 TRAIN  loss dict:  {'mse_loss': 0.19133031994104385}
2024-05-03 10:28:20,735 [INFO] Step[200/1020]: training loss : 0.20150687247514726 TRAIN  loss dict:  {'mse_loss': 0.20150687247514726}
2024-05-03 10:29:43,571 [INFO] Step[250/1020]: training loss : 0.19543600216507911 TRAIN  loss dict:  {'mse_loss': 0.19543600216507911}
2024-05-03 10:31:10,666 [INFO] Step[300/1020]: training loss : 0.19853103563189506 TRAIN  loss dict:  {'mse_loss': 0.19853103563189506}
2024-05-03 10:32:46,730 [INFO] Step[350/1020]: training loss : 0.19949816912412643 TRAIN  loss dict:  {'mse_loss': 0.19949816912412643}
2024-05-03 10:34:05,139 [INFO] Step[400/1020]: training loss : 0.20348973959684372 TRAIN  loss dict:  {'mse_loss': 0.20348973959684372}
2024-05-03 10:35:26,968 [INFO] Step[450/1020]: training loss : 0.19408153474330903 TRAIN  loss dict:  {'mse_loss': 0.19408153474330903}
2024-05-03 10:36:51,262 [INFO] Step[500/1020]: training loss : 0.18876566708087922 TRAIN  loss dict:  {'mse_loss': 0.18876566708087922}
2024-05-03 10:38:15,552 [INFO] Step[550/1020]: training loss : 0.19444705665111542 TRAIN  loss dict:  {'mse_loss': 0.19444705665111542}
2024-05-03 10:39:43,060 [INFO] Step[600/1020]: training loss : 0.19755779653787614 TRAIN  loss dict:  {'mse_loss': 0.19755779653787614}
2024-05-03 10:41:05,551 [INFO] Step[650/1020]: training loss : 0.19352364152669907 TRAIN  loss dict:  {'mse_loss': 0.19352364152669907}
2024-05-03 10:42:16,668 [INFO] Step[700/1020]: training loss : 0.19835587382316588 TRAIN  loss dict:  {'mse_loss': 0.19835587382316588}
2024-05-03 10:43:31,318 [INFO] Step[750/1020]: training loss : 0.19923975735902785 TRAIN  loss dict:  {'mse_loss': 0.19923975735902785}
2024-05-03 10:44:56,828 [INFO] Step[800/1020]: training loss : 0.2029910498857498 TRAIN  loss dict:  {'mse_loss': 0.2029910498857498}
2024-05-03 10:46:14,422 [INFO] Step[850/1020]: training loss : 0.20708012580871582 TRAIN  loss dict:  {'mse_loss': 0.20708012580871582}
2024-05-03 10:47:38,948 [INFO] Step[900/1020]: training loss : 0.19150994688272477 TRAIN  loss dict:  {'mse_loss': 0.19150994688272477}
2024-05-03 10:48:53,766 [INFO] Step[950/1020]: training loss : 0.20141948953270913 TRAIN  loss dict:  {'mse_loss': 0.20141948953270913}
2024-05-03 10:50:16,911 [INFO] Step[1000/1020]: training loss : 0.19675520658493043 TRAIN  loss dict:  {'mse_loss': 0.19675520658493043}
2024-05-03 10:56:01,385 [INFO] Label accuracies statistics:
2024-05-03 10:56:01,398 [INFO] {0: 0.5, 1: 0.5, 2: 0.0, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.5, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.0, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 0.5, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.75, 26: 0.75, 27: 1.0, 28: 0.5, 29: 0.75, 30: 0.75, 31: 0.5, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.5, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.5, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.25, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.5, 66: 0.75, 67: 1.0, 68: 0.5, 69: 0.5, 70: 1.0, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.25, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.5, 83: 1.0, 84: 0.75, 85: 1.0, 86: 0.5, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.75, 95: 0.75, 96: 0.5, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.5, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.25, 113: 0.25, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.75, 118: 0.75, 119: 0.75, 120: 0.75, 121: 1.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.75, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.5, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 0.75, 147: 0.75, 148: 0.75, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.0, 154: 1.0, 155: 0.5, 156: 1.0, 157: 0.5, 158: 0.5, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.5, 163: 1.0, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.5, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.25, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.5, 180: 1.0, 181: 1.0, 182: 0.25, 183: 0.75, 184: 0.75, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.75}

2024-05-03 10:56:01,435 [INFO] [62] TRAIN  loss: 0.19760436360888622 acc: 0.0
2024-05-03 10:56:01,437 [INFO] [62] TRAIN  loss dict: {'mse_loss': 0.19760436360888622}
2024-05-03 10:56:01,439 [INFO] [62] VALIDATION loss: 1.2293293853901854 VALIDATION  acc: 0.7424242424242424
2024-05-03 10:56:01,440 [INFO] [62] VALIDATION  loss dict: {'mse_loss': 0.24082042194075054, 'classification_loss': 0.9885089651286376}
2024-05-03 10:56:01,442 [INFO] 
2024-05-03 10:58:37,509 [INFO] Step[50/1020]: training loss : 0.19229692757129668 TRAIN  loss dict:  {'mse_loss': 0.19229692757129668}
2024-05-03 11:00:02,358 [INFO] Step[100/1020]: training loss : 0.19380539298057556 TRAIN  loss dict:  {'mse_loss': 0.19380539298057556}
2024-05-03 11:01:26,144 [INFO] Step[150/1020]: training loss : 0.19314247727394104 TRAIN  loss dict:  {'mse_loss': 0.19314247727394104}
2024-05-03 11:02:51,854 [INFO] Step[200/1020]: training loss : 0.20128745406866075 TRAIN  loss dict:  {'mse_loss': 0.20128745406866075}
2024-05-03 11:04:19,551 [INFO] Step[250/1020]: training loss : 0.1909019210934639 TRAIN  loss dict:  {'mse_loss': 0.1909019210934639}
2024-05-03 11:05:41,246 [INFO] Step[300/1020]: training loss : 0.20041945964097976 TRAIN  loss dict:  {'mse_loss': 0.20041945964097976}
2024-05-03 11:07:04,082 [INFO] Step[350/1020]: training loss : 0.18982778310775758 TRAIN  loss dict:  {'mse_loss': 0.18982778310775758}
2024-05-03 11:08:19,980 [INFO] Step[400/1020]: training loss : 0.19648440375924112 TRAIN  loss dict:  {'mse_loss': 0.19648440375924112}
2024-05-03 11:09:35,394 [INFO] Step[450/1020]: training loss : 0.1940177184343338 TRAIN  loss dict:  {'mse_loss': 0.1940177184343338}
2024-05-03 11:10:54,148 [INFO] Step[500/1020]: training loss : 0.18804756224155425 TRAIN  loss dict:  {'mse_loss': 0.18804756224155425}
2024-05-03 11:12:08,674 [INFO] Step[550/1020]: training loss : 0.19882068604230882 TRAIN  loss dict:  {'mse_loss': 0.19882068604230882}
2024-05-03 11:13:27,726 [INFO] Step[600/1020]: training loss : 0.19723972529172898 TRAIN  loss dict:  {'mse_loss': 0.19723972529172898}
2024-05-03 11:14:49,316 [INFO] Step[650/1020]: training loss : 0.19603652119636536 TRAIN  loss dict:  {'mse_loss': 0.19603652119636536}
2024-05-03 11:16:16,113 [INFO] Step[700/1020]: training loss : 0.19518907189369203 TRAIN  loss dict:  {'mse_loss': 0.19518907189369203}
2024-05-03 11:17:30,095 [INFO] Step[750/1020]: training loss : 0.19355572193861006 TRAIN  loss dict:  {'mse_loss': 0.19355572193861006}
2024-05-03 11:18:58,343 [INFO] Step[800/1020]: training loss : 0.19961101919412613 TRAIN  loss dict:  {'mse_loss': 0.19961101919412613}
2024-05-03 11:20:17,886 [INFO] Step[850/1020]: training loss : 0.19705399602651597 TRAIN  loss dict:  {'mse_loss': 0.19705399602651597}
2024-05-03 11:21:39,747 [INFO] Step[900/1020]: training loss : 0.19724270313978196 TRAIN  loss dict:  {'mse_loss': 0.19724270313978196}
2024-05-03 11:22:54,080 [INFO] Step[950/1020]: training loss : 0.19738396808505057 TRAIN  loss dict:  {'mse_loss': 0.19738396808505057}
2024-05-03 11:24:20,477 [INFO] Step[1000/1020]: training loss : 0.20014118164777756 TRAIN  loss dict:  {'mse_loss': 0.20014118164777756}
2024-05-03 11:29:39,103 [INFO] Label accuracies statistics:
2024-05-03 11:29:39,105 [INFO] {0: 1.0, 1: 0.5, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.5, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.5, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 0.25, 20: 0.5, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.5, 26: 0.75, 27: 1.0, 28: 0.75, 29: 0.75, 30: 0.5, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.5, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.5, 52: 0.25, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.25, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.5, 66: 0.25, 67: 1.0, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.5, 83: 1.0, 84: 0.5, 85: 1.0, 86: 0.25, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.75, 97: 0.75, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.5, 109: 0.5, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.75, 121: 0.75, 122: 0.5, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 0.75, 129: 0.75, 130: 1.0, 131: 0.75, 132: 0.25, 133: 0.75, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 0.75, 147: 0.75, 148: 0.5, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.5, 156: 0.75, 157: 0.5, 158: 0.5, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.5, 175: 0.75, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.5, 180: 1.0, 181: 1.0, 182: 0.5, 183: 0.75, 184: 0.75, 185: 0.75, 186: 0.75, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.5, 196: 1.0, 197: 1.0, 198: 0.75}

2024-05-03 11:29:39,133 [INFO] [63] TRAIN  loss: 0.19560922077473472 acc: 0.0
2024-05-03 11:29:39,135 [INFO] [63] TRAIN  loss dict: {'mse_loss': 0.19560922077473472}
2024-05-03 11:29:39,137 [INFO] [63] VALIDATION loss: 1.2378695519885632 VALIDATION  acc: 0.73989898989899
2024-05-03 11:29:39,139 [INFO] [63] VALIDATION  loss dict: {'mse_loss': 0.2384097543027666, 'classification_loss': 0.9994597944779077}
2024-05-03 11:29:39,141 [INFO] 
2024-05-03 11:31:53,937 [INFO] Step[50/1020]: training loss : 0.19700582891702653 TRAIN  loss dict:  {'mse_loss': 0.19700582891702653}
2024-05-03 11:33:16,377 [INFO] Step[100/1020]: training loss : 0.19036121010780335 TRAIN  loss dict:  {'mse_loss': 0.19036121010780335}
2024-05-03 11:34:29,803 [INFO] Step[150/1020]: training loss : 0.20491964548826216 TRAIN  loss dict:  {'mse_loss': 0.20491964548826216}
2024-05-03 11:35:40,232 [INFO] Step[200/1020]: training loss : 0.20120714277029036 TRAIN  loss dict:  {'mse_loss': 0.20120714277029036}
2024-05-03 11:36:50,650 [INFO] Step[250/1020]: training loss : 0.2005300435423851 TRAIN  loss dict:  {'mse_loss': 0.2005300435423851}
2024-05-03 11:38:05,875 [INFO] Step[300/1020]: training loss : 0.19361848413944244 TRAIN  loss dict:  {'mse_loss': 0.19361848413944244}
2024-05-03 11:39:12,203 [INFO] Step[350/1020]: training loss : 0.2004321327805519 TRAIN  loss dict:  {'mse_loss': 0.2004321327805519}
2024-05-03 11:40:23,518 [INFO] Step[400/1020]: training loss : 0.20074236154556274 TRAIN  loss dict:  {'mse_loss': 0.20074236154556274}
2024-05-03 11:41:36,511 [INFO] Step[450/1020]: training loss : 0.19850443601608275 TRAIN  loss dict:  {'mse_loss': 0.19850443601608275}
2024-05-03 11:42:56,344 [INFO] Step[500/1020]: training loss : 0.1907483696937561 TRAIN  loss dict:  {'mse_loss': 0.1907483696937561}
2024-05-03 11:44:07,997 [INFO] Step[550/1020]: training loss : 0.19367557615041733 TRAIN  loss dict:  {'mse_loss': 0.19367557615041733}
2024-05-03 11:45:28,736 [INFO] Step[600/1020]: training loss : 0.20046916753053665 TRAIN  loss dict:  {'mse_loss': 0.20046916753053665}
2024-05-03 11:46:36,903 [INFO] Step[650/1020]: training loss : 0.19689323812723158 TRAIN  loss dict:  {'mse_loss': 0.19689323812723158}
2024-05-03 11:47:50,330 [INFO] Step[700/1020]: training loss : 0.19828898400068284 TRAIN  loss dict:  {'mse_loss': 0.19828898400068284}
2024-05-03 11:48:57,639 [INFO] Step[750/1020]: training loss : 0.19963672250509262 TRAIN  loss dict:  {'mse_loss': 0.19963672250509262}
2024-05-03 11:50:11,862 [INFO] Step[800/1020]: training loss : 0.1886940896511078 TRAIN  loss dict:  {'mse_loss': 0.1886940896511078}
2024-05-03 11:51:18,764 [INFO] Step[850/1020]: training loss : 0.1969776603579521 TRAIN  loss dict:  {'mse_loss': 0.1969776603579521}
2024-05-03 11:52:36,522 [INFO] Step[900/1020]: training loss : 0.19623267084360121 TRAIN  loss dict:  {'mse_loss': 0.19623267084360121}
2024-05-03 11:53:41,679 [INFO] Step[950/1020]: training loss : 0.19451419591903688 TRAIN  loss dict:  {'mse_loss': 0.19451419591903688}
2024-05-03 11:54:43,669 [INFO] Step[1000/1020]: training loss : 0.20369846135377884 TRAIN  loss dict:  {'mse_loss': 0.20369846135377884}
2024-05-03 11:59:23,525 [INFO] Label accuracies statistics:
2024-05-03 11:59:23,526 [INFO] {0: 0.5, 1: 0.5, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 0.5, 6: 0.5, 7: 1.0, 8: 0.0, 9: 0.75, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 0.5, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.5, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.5, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 0.75, 47: 0.75, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.5, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.25, 60: 0.25, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.5, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.25, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.25, 83: 1.0, 84: 0.75, 85: 0.75, 86: 0.5, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.75, 95: 0.75, 96: 0.5, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.0, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.75, 120: 0.75, 121: 1.0, 122: 0.5, 123: 0.5, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 0.75, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.75, 144: 0.75, 145: 0.5, 146: 0.75, 147: 1.0, 148: 0.5, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.5, 156: 0.75, 157: 0.5, 158: 0.75, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.5, 167: 0.75, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.75, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 0.75, 183: 0.75, 184: 0.75, 185: 0.75, 186: 0.25, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.75}

2024-05-03 11:59:23,573 [INFO] [64] TRAIN  loss: 0.19716160608565106 acc: 0.0
2024-05-03 11:59:23,575 [INFO] [64] TRAIN  loss dict: {'mse_loss': 0.19716160608565106}
2024-05-03 11:59:23,578 [INFO] [64] VALIDATION loss: 1.2150968645106663 VALIDATION  acc: 0.7310606060606061
2024-05-03 11:59:23,579 [INFO] [64] VALIDATION  loss dict: {'mse_loss': 0.23903193324804306, 'classification_loss': 0.9760649313943254}
2024-05-03 11:59:23,581 [INFO] 
2024-05-03 12:01:05,803 [INFO] Step[50/1020]: training loss : 0.1967226645350456 TRAIN  loss dict:  {'mse_loss': 0.1967226645350456}
2024-05-03 12:02:06,923 [INFO] Step[100/1020]: training loss : 0.19529705256223678 TRAIN  loss dict:  {'mse_loss': 0.19529705256223678}
2024-05-03 12:03:01,327 [INFO] Step[150/1020]: training loss : 0.18892590701580048 TRAIN  loss dict:  {'mse_loss': 0.18892590701580048}
2024-05-03 12:04:06,001 [INFO] Step[200/1020]: training loss : 0.20402200937271117 TRAIN  loss dict:  {'mse_loss': 0.20402200937271117}
2024-05-03 12:05:08,109 [INFO] Step[250/1020]: training loss : 0.19667961597442626 TRAIN  loss dict:  {'mse_loss': 0.19667961597442626}
2024-05-03 12:06:06,917 [INFO] Step[300/1020]: training loss : 0.19545314371585845 TRAIN  loss dict:  {'mse_loss': 0.19545314371585845}
2024-05-03 12:07:06,074 [INFO] Step[350/1020]: training loss : 0.19475042074918747 TRAIN  loss dict:  {'mse_loss': 0.19475042074918747}
2024-05-03 12:08:06,441 [INFO] Step[400/1020]: training loss : 0.1950203362107277 TRAIN  loss dict:  {'mse_loss': 0.1950203362107277}
2024-05-03 12:09:01,326 [INFO] Step[450/1020]: training loss : 0.19791835084557532 TRAIN  loss dict:  {'mse_loss': 0.19791835084557532}
2024-05-03 12:09:56,808 [INFO] Step[500/1020]: training loss : 0.19114768296480178 TRAIN  loss dict:  {'mse_loss': 0.19114768296480178}
2024-05-03 12:10:55,654 [INFO] Step[550/1020]: training loss : 0.20302132219076158 TRAIN  loss dict:  {'mse_loss': 0.20302132219076158}
2024-05-03 12:11:58,882 [INFO] Step[600/1020]: training loss : 0.19665148556232454 TRAIN  loss dict:  {'mse_loss': 0.19665148556232454}
2024-05-03 12:13:01,150 [INFO] Step[650/1020]: training loss : 0.19263266116380692 TRAIN  loss dict:  {'mse_loss': 0.19263266116380692}
2024-05-03 12:14:06,328 [INFO] Step[700/1020]: training loss : 0.18783634543418884 TRAIN  loss dict:  {'mse_loss': 0.18783634543418884}
2024-05-03 12:15:04,316 [INFO] Step[750/1020]: training loss : 0.19341873943805696 TRAIN  loss dict:  {'mse_loss': 0.19341873943805696}
2024-05-03 12:15:59,952 [INFO] Step[800/1020]: training loss : 0.19170643091201783 TRAIN  loss dict:  {'mse_loss': 0.19170643091201783}
2024-05-03 12:17:01,634 [INFO] Step[850/1020]: training loss : 0.20568707317113877 TRAIN  loss dict:  {'mse_loss': 0.20568707317113877}
2024-05-03 12:17:59,839 [INFO] Step[900/1020]: training loss : 0.19603798300027847 TRAIN  loss dict:  {'mse_loss': 0.19603798300027847}
2024-05-03 12:18:59,645 [INFO] Step[950/1020]: training loss : 0.19448654234409332 TRAIN  loss dict:  {'mse_loss': 0.19448654234409332}
2024-05-03 12:19:57,862 [INFO] Step[1000/1020]: training loss : 0.18818155199289321 TRAIN  loss dict:  {'mse_loss': 0.18818155199289321}
2024-05-03 12:24:15,337 [INFO] Label accuracies statistics:
2024-05-03 12:24:15,338 [INFO] {0: 0.5, 1: 0.75, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 0.5, 6: 0.5, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.25, 16: 1.0, 17: 0.75, 18: 1.0, 19: 0.0, 20: 0.5, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.5, 26: 1.0, 27: 1.0, 28: 0.5, 29: 0.75, 30: 0.5, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.5, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.75, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 1.0, 51: 0.75, 52: 0.5, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.25, 60: 0.5, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.75, 66: 0.25, 67: 0.75, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.75, 83: 0.75, 84: 0.5, 85: 1.0, 86: 0.5, 87: 0.5, 88: 0.6666666666666666, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.5, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.25, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.25, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 1.0, 120: 0.5, 121: 1.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 0.75, 126: 0.75, 127: 1.0, 128: 0.75, 129: 0.75, 130: 0.75, 131: 0.75, 132: 0.0, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.75, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.5, 146: 0.75, 147: 1.0, 148: 0.5, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.0, 156: 0.75, 157: 0.5, 158: 0.5, 159: 0.75, 160: 0.25, 161: 1.0, 162: 0.5, 163: 0.75, 164: 0.5, 165: 1.0, 166: 0.5, 167: 0.5, 168: 0.25, 169: 1.0, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 0.5, 175: 1.0, 176: 0.75, 177: 0.75, 178: 0.75, 179: 1.0, 180: 1.0, 181: 0.75, 182: 0.75, 183: 1.0, 184: 0.5, 185: 0.75, 186: 0.75, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.75}

2024-05-03 12:24:15,391 [INFO] [65] TRAIN  loss: 0.19531096223668726 acc: 0.0
2024-05-03 12:24:15,392 [INFO] [65] TRAIN  loss dict: {'mse_loss': 0.19531096223668726}
2024-05-03 12:24:15,393 [INFO] [65] VALIDATION loss: 1.238620806598302 VALIDATION  acc: 0.7133838383838383
2024-05-03 12:24:15,394 [INFO] [65] VALIDATION  loss dict: {'mse_loss': 0.23796953614613023, 'classification_loss': 1.0006512662565166}
2024-05-03 12:24:15,395 [INFO] 
2024-05-03 12:25:55,286 [INFO] Step[50/1020]: training loss : 0.1972768384218216 TRAIN  loss dict:  {'mse_loss': 0.1972768384218216}
2024-05-03 12:26:49,873 [INFO] Step[100/1020]: training loss : 0.1874450120329857 TRAIN  loss dict:  {'mse_loss': 0.1874450120329857}
2024-05-03 12:27:49,080 [INFO] Step[150/1020]: training loss : 0.19772192656993867 TRAIN  loss dict:  {'mse_loss': 0.19772192656993867}
2024-05-03 12:28:40,033 [INFO] Step[200/1020]: training loss : 0.19220160692930222 TRAIN  loss dict:  {'mse_loss': 0.19220160692930222}
2024-05-03 12:29:34,548 [INFO] Step[250/1020]: training loss : 0.20005904495716095 TRAIN  loss dict:  {'mse_loss': 0.20005904495716095}
2024-05-03 12:30:24,073 [INFO] Step[300/1020]: training loss : 0.19876981079578399 TRAIN  loss dict:  {'mse_loss': 0.19876981079578399}
2024-05-03 12:31:20,556 [INFO] Step[350/1020]: training loss : 0.19222061604261398 TRAIN  loss dict:  {'mse_loss': 0.19222061604261398}
2024-05-03 12:32:15,787 [INFO] Step[400/1020]: training loss : 0.19030738323926927 TRAIN  loss dict:  {'mse_loss': 0.19030738323926927}
2024-05-03 12:33:11,571 [INFO] Step[450/1020]: training loss : 0.19537559568881988 TRAIN  loss dict:  {'mse_loss': 0.19537559568881988}
2024-05-03 12:34:07,148 [INFO] Step[500/1020]: training loss : 0.19801882937550544 TRAIN  loss dict:  {'mse_loss': 0.19801882937550544}
2024-05-03 12:35:05,935 [INFO] Step[550/1020]: training loss : 0.1929100200533867 TRAIN  loss dict:  {'mse_loss': 0.1929100200533867}
2024-05-03 12:35:55,209 [INFO] Step[600/1020]: training loss : 0.19496817529201507 TRAIN  loss dict:  {'mse_loss': 0.19496817529201507}
2024-05-03 12:36:43,276 [INFO] Step[650/1020]: training loss : 0.19377318203449248 TRAIN  loss dict:  {'mse_loss': 0.19377318203449248}
2024-05-03 12:37:44,564 [INFO] Step[700/1020]: training loss : 0.19512987345457078 TRAIN  loss dict:  {'mse_loss': 0.19512987345457078}
2024-05-03 12:38:38,784 [INFO] Step[750/1020]: training loss : 0.1957279062271118 TRAIN  loss dict:  {'mse_loss': 0.1957279062271118}
2024-05-03 12:39:39,691 [INFO] Step[800/1020]: training loss : 0.19629166632890702 TRAIN  loss dict:  {'mse_loss': 0.19629166632890702}
2024-05-03 12:40:34,458 [INFO] Step[850/1020]: training loss : 0.18948035836219787 TRAIN  loss dict:  {'mse_loss': 0.18948035836219787}
2024-05-03 12:41:28,693 [INFO] Step[900/1020]: training loss : 0.19681413531303404 TRAIN  loss dict:  {'mse_loss': 0.19681413531303404}
2024-05-03 12:42:22,593 [INFO] Step[950/1020]: training loss : 0.19388026207685471 TRAIN  loss dict:  {'mse_loss': 0.19388026207685471}
2024-05-03 12:43:11,513 [INFO] Step[1000/1020]: training loss : 0.19991661548614503 TRAIN  loss dict:  {'mse_loss': 0.19991661548614503}
2024-05-03 12:47:00,327 [INFO] Label accuracies statistics:
2024-05-03 12:47:00,328 [INFO] {0: 0.5, 1: 0.75, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.5, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.5, 16: 1.0, 17: 0.5, 18: 1.0, 19: 0.25, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.5, 26: 1.0, 27: 1.0, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.5, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 1.0, 51: 0.5, 52: 0.5, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.25, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.5, 66: 0.5, 67: 0.5, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.75, 83: 0.75, 84: 0.75, 85: 1.0, 86: 0.5, 87: 0.5, 88: 0.6666666666666666, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.75, 95: 0.75, 96: 0.5, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.5, 103: 0.5, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.5, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.5, 118: 0.75, 119: 1.0, 120: 0.75, 121: 0.75, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 0.75, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.5, 146: 0.75, 147: 0.75, 148: 0.75, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.5, 156: 0.75, 157: 0.5, 158: 0.5, 159: 0.5, 160: 0.25, 161: 1.0, 162: 0.5, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.25, 167: 0.5, 168: 0.25, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 0.25, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.75, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.5, 196: 1.0, 197: 1.0, 198: 0.5}

2024-05-03 12:47:00,360 [INFO] [66] TRAIN  loss: 0.1948681594621317 acc: 0.0
2024-05-03 12:47:00,361 [INFO] [66] TRAIN  loss dict: {'mse_loss': 0.1948681594621317}
2024-05-03 12:47:00,363 [INFO] [66] VALIDATION loss: 1.2313102129282374 VALIDATION  acc: 0.7272727272727273
2024-05-03 12:47:00,364 [INFO] [66] VALIDATION  loss dict: {'mse_loss': 0.23858134836109, 'classification_loss': 0.9927288586311419}
2024-05-03 12:47:00,366 [INFO] 
2024-05-03 12:48:30,244 [INFO] Step[50/1020]: training loss : 0.20083405077457428 TRAIN  loss dict:  {'mse_loss': 0.20083405077457428}
2024-05-03 12:49:23,184 [INFO] Step[100/1020]: training loss : 0.18764382630586623 TRAIN  loss dict:  {'mse_loss': 0.18764382630586623}
2024-05-03 12:50:17,710 [INFO] Step[150/1020]: training loss : 0.19498776882886887 TRAIN  loss dict:  {'mse_loss': 0.19498776882886887}
2024-05-03 12:51:11,698 [INFO] Step[200/1020]: training loss : 0.18983131483197213 TRAIN  loss dict:  {'mse_loss': 0.18983131483197213}
2024-05-03 12:52:05,211 [INFO] Step[250/1020]: training loss : 0.2004215705394745 TRAIN  loss dict:  {'mse_loss': 0.2004215705394745}
2024-05-03 12:52:53,745 [INFO] Step[300/1020]: training loss : 0.1985572248697281 TRAIN  loss dict:  {'mse_loss': 0.1985572248697281}
2024-05-03 12:53:48,177 [INFO] Step[350/1020]: training loss : 0.19624711334705353 TRAIN  loss dict:  {'mse_loss': 0.19624711334705353}
2024-05-03 12:54:36,306 [INFO] Step[400/1020]: training loss : 0.20123569667339325 TRAIN  loss dict:  {'mse_loss': 0.20123569667339325}
2024-05-03 12:55:28,169 [INFO] Step[450/1020]: training loss : 0.19998750418424607 TRAIN  loss dict:  {'mse_loss': 0.19998750418424607}
2024-05-03 12:56:16,141 [INFO] Step[500/1020]: training loss : 0.20135449051856993 TRAIN  loss dict:  {'mse_loss': 0.20135449051856993}
2024-05-03 12:57:04,957 [INFO] Step[550/1020]: training loss : 0.1937720149755478 TRAIN  loss dict:  {'mse_loss': 0.1937720149755478}
2024-05-03 12:58:00,562 [INFO] Step[600/1020]: training loss : 0.19448364526033401 TRAIN  loss dict:  {'mse_loss': 0.19448364526033401}
2024-05-03 12:58:55,505 [INFO] Step[650/1020]: training loss : 0.18850407555699347 TRAIN  loss dict:  {'mse_loss': 0.18850407555699347}
2024-05-03 12:59:48,302 [INFO] Step[700/1020]: training loss : 0.19976666808128357 TRAIN  loss dict:  {'mse_loss': 0.19976666808128357}
2024-05-03 13:00:37,782 [INFO] Step[750/1020]: training loss : 0.19370418131351472 TRAIN  loss dict:  {'mse_loss': 0.19370418131351472}
2024-05-03 13:01:25,558 [INFO] Step[800/1020]: training loss : 0.191189194470644 TRAIN  loss dict:  {'mse_loss': 0.191189194470644}
2024-05-03 13:02:19,841 [INFO] Step[850/1020]: training loss : 0.18647695660591126 TRAIN  loss dict:  {'mse_loss': 0.18647695660591126}
2024-05-03 13:03:08,893 [INFO] Step[900/1020]: training loss : 0.194224691092968 TRAIN  loss dict:  {'mse_loss': 0.194224691092968}
2024-05-03 13:04:02,248 [INFO] Step[950/1020]: training loss : 0.1880597484111786 TRAIN  loss dict:  {'mse_loss': 0.1880597484111786}
2024-05-03 13:04:53,896 [INFO] Step[1000/1020]: training loss : 0.19795313537120818 TRAIN  loss dict:  {'mse_loss': 0.19795313537120818}
2024-05-03 13:08:44,266 [INFO] Label accuracies statistics:
2024-05-03 13:08:44,267 [INFO] {0: 0.5, 1: 1.0, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.25, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.5, 14: 0.25, 15: 0.25, 16: 1.0, 17: 0.5, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.5, 26: 0.75, 27: 1.0, 28: 0.5, 29: 0.75, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.5, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.75, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.5, 52: 0.25, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.5, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.5, 69: 0.5, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.75, 83: 0.75, 84: 0.75, 85: 1.0, 86: 0.5, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.5, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.75, 110: 1.0, 111: 0.75, 112: 0.25, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.5, 118: 1.0, 119: 0.75, 120: 0.75, 121: 1.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 0.75, 126: 0.75, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.5, 133: 0.75, 134: 0.5, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.75, 146: 0.75, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.5, 156: 0.75, 157: 0.5, 158: 0.75, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 0.5, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.5, 175: 0.75, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.75, 180: 0.75, 181: 1.0, 182: 0.75, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.5, 197: 0.5, 198: 0.75}

2024-05-03 13:08:44,295 [INFO] [67] TRAIN  loss: 0.19499603581486963 acc: 0.0
2024-05-03 13:08:44,296 [INFO] [67] TRAIN  loss dict: {'mse_loss': 0.19499603581486963}
2024-05-03 13:08:44,297 [INFO] [67] VALIDATION loss: 1.2285663468970194 VALIDATION  acc: 0.7310606060606061
2024-05-03 13:08:44,297 [INFO] [67] VALIDATION  loss dict: {'mse_loss': 0.23833505301312966, 'classification_loss': 0.9902312962545289}
2024-05-03 13:08:44,298 [INFO] 
2024-05-03 13:10:13,029 [INFO] Step[50/1020]: training loss : 0.19103195130825043 TRAIN  loss dict:  {'mse_loss': 0.19103195130825043}
2024-05-03 13:11:09,318 [INFO] Step[100/1020]: training loss : 0.1923361051082611 TRAIN  loss dict:  {'mse_loss': 0.1923361051082611}
2024-05-03 13:12:01,749 [INFO] Step[150/1020]: training loss : 0.190037362575531 TRAIN  loss dict:  {'mse_loss': 0.190037362575531}
2024-05-03 13:12:50,319 [INFO] Step[200/1020]: training loss : 0.19452804431319237 TRAIN  loss dict:  {'mse_loss': 0.19452804431319237}
2024-05-03 13:13:42,325 [INFO] Step[250/1020]: training loss : 0.19518682599067688 TRAIN  loss dict:  {'mse_loss': 0.19518682599067688}
2024-05-03 13:14:35,140 [INFO] Step[300/1020]: training loss : 0.1971333172917366 TRAIN  loss dict:  {'mse_loss': 0.1971333172917366}
2024-05-03 13:15:24,856 [INFO] Step[350/1020]: training loss : 0.19498434096574782 TRAIN  loss dict:  {'mse_loss': 0.19498434096574782}
2024-05-03 13:16:18,864 [INFO] Step[400/1020]: training loss : 0.1952718749642372 TRAIN  loss dict:  {'mse_loss': 0.1952718749642372}
2024-05-03 13:17:11,127 [INFO] Step[450/1020]: training loss : 0.19223861575126647 TRAIN  loss dict:  {'mse_loss': 0.19223861575126647}
2024-05-03 13:18:01,549 [INFO] Step[500/1020]: training loss : 0.19758362010121344 TRAIN  loss dict:  {'mse_loss': 0.19758362010121344}
2024-05-03 13:18:54,399 [INFO] Step[550/1020]: training loss : 0.19930571138858796 TRAIN  loss dict:  {'mse_loss': 0.19930571138858796}
2024-05-03 13:19:47,570 [INFO] Step[600/1020]: training loss : 0.1935517284274101 TRAIN  loss dict:  {'mse_loss': 0.1935517284274101}
2024-05-03 13:20:38,863 [INFO] Step[650/1020]: training loss : 0.19789728581905364 TRAIN  loss dict:  {'mse_loss': 0.19789728581905364}
2024-05-03 13:21:30,072 [INFO] Step[700/1020]: training loss : 0.1914938732981682 TRAIN  loss dict:  {'mse_loss': 0.1914938732981682}
2024-05-03 13:22:24,040 [INFO] Step[750/1020]: training loss : 0.186474267244339 TRAIN  loss dict:  {'mse_loss': 0.186474267244339}
2024-05-03 13:23:19,450 [INFO] Step[800/1020]: training loss : 0.19477421507239343 TRAIN  loss dict:  {'mse_loss': 0.19477421507239343}
2024-05-03 13:24:11,556 [INFO] Step[850/1020]: training loss : 0.19041294634342193 TRAIN  loss dict:  {'mse_loss': 0.19041294634342193}
2024-05-03 13:25:02,727 [INFO] Step[900/1020]: training loss : 0.19572532743215562 TRAIN  loss dict:  {'mse_loss': 0.19572532743215562}
2024-05-03 13:25:56,620 [INFO] Step[950/1020]: training loss : 0.19568418353796005 TRAIN  loss dict:  {'mse_loss': 0.19568418353796005}
2024-05-03 13:26:43,314 [INFO] Step[1000/1020]: training loss : 0.1881223464012146 TRAIN  loss dict:  {'mse_loss': 0.1881223464012146}
2024-05-03 13:30:22,167 [INFO] Label accuracies statistics:
2024-05-03 13:30:22,167 [INFO] {0: 1.0, 1: 0.75, 2: 0.25, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.5, 7: 1.0, 8: 0.25, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.25, 16: 1.0, 17: 0.5, 18: 1.0, 19: 0.75, 20: 0.5, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.75, 26: 0.75, 27: 1.0, 28: 1.0, 29: 0.75, 30: 0.75, 31: 0.5, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.5, 37: 0.5, 38: 0.75, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 0.75, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.75, 52: 0.25, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.25, 61: 1.0, 62: 1.0, 63: 0.75, 64: 0.75, 65: 0.75, 66: 0.25, 67: 0.5, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.5, 83: 0.75, 84: 1.0, 85: 0.75, 86: 0.25, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.75, 95: 0.75, 96: 0.5, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.75, 120: 0.75, 121: 1.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 0.75, 129: 0.75, 130: 1.0, 131: 0.75, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 1.0, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.75, 144: 1.0, 145: 0.5, 146: 0.75, 147: 1.0, 148: 0.5, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.5, 156: 0.5, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.25, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.25, 167: 0.75, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 0.25, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.5, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.75}

2024-05-03 13:30:22,195 [INFO] [68] TRAIN  loss: 0.19352985369954623 acc: 0.0
2024-05-03 13:30:22,196 [INFO] [68] TRAIN  loss dict: {'mse_loss': 0.19352985369954623}
2024-05-03 13:30:22,198 [INFO] [68] VALIDATION loss: 1.1911759174833394 VALIDATION  acc: 0.7411616161616161
2024-05-03 13:30:22,199 [INFO] [68] VALIDATION  loss dict: {'mse_loss': 0.23534219207787754, 'classification_loss': 0.9558337298880397}
2024-05-03 13:30:22,201 [INFO] 
2024-05-03 13:31:48,957 [INFO] Step[50/1020]: training loss : 0.19090174674987792 TRAIN  loss dict:  {'mse_loss': 0.19090174674987792}
2024-05-03 13:32:41,553 [INFO] Step[100/1020]: training loss : 0.1879982218146324 TRAIN  loss dict:  {'mse_loss': 0.1879982218146324}
2024-05-03 13:33:31,994 [INFO] Step[150/1020]: training loss : 0.1936859369277954 TRAIN  loss dict:  {'mse_loss': 0.1936859369277954}
2024-05-03 13:34:19,515 [INFO] Step[200/1020]: training loss : 0.19692331165075302 TRAIN  loss dict:  {'mse_loss': 0.19692331165075302}
2024-05-03 13:35:05,078 [INFO] Step[250/1020]: training loss : 0.19554245680570603 TRAIN  loss dict:  {'mse_loss': 0.19554245680570603}
2024-05-03 13:36:00,784 [INFO] Step[300/1020]: training loss : 0.19341528967022895 TRAIN  loss dict:  {'mse_loss': 0.19341528967022895}
2024-05-03 13:36:56,520 [INFO] Step[350/1020]: training loss : 0.20568485230207442 TRAIN  loss dict:  {'mse_loss': 0.20568485230207442}
2024-05-03 13:37:54,067 [INFO] Step[400/1020]: training loss : 0.19107143491506576 TRAIN  loss dict:  {'mse_loss': 0.19107143491506576}
2024-05-03 13:38:49,187 [INFO] Step[450/1020]: training loss : 0.18285490453243256 TRAIN  loss dict:  {'mse_loss': 0.18285490453243256}
2024-05-03 13:39:38,367 [INFO] Step[500/1020]: training loss : 0.19308423846960068 TRAIN  loss dict:  {'mse_loss': 0.19308423846960068}
2024-05-03 13:40:29,118 [INFO] Step[550/1020]: training loss : 0.18600619077682495 TRAIN  loss dict:  {'mse_loss': 0.18600619077682495}
2024-05-03 13:41:15,752 [INFO] Step[600/1020]: training loss : 0.18969272077083588 TRAIN  loss dict:  {'mse_loss': 0.18969272077083588}
2024-05-03 13:42:06,906 [INFO] Step[650/1020]: training loss : 0.1918094825744629 TRAIN  loss dict:  {'mse_loss': 0.1918094825744629}
2024-05-03 13:42:54,526 [INFO] Step[700/1020]: training loss : 0.19367275565862654 TRAIN  loss dict:  {'mse_loss': 0.19367275565862654}
2024-05-03 13:43:44,066 [INFO] Step[750/1020]: training loss : 0.1907883244752884 TRAIN  loss dict:  {'mse_loss': 0.1907883244752884}
2024-05-03 13:44:35,527 [INFO] Step[800/1020]: training loss : 0.20341200560331343 TRAIN  loss dict:  {'mse_loss': 0.20341200560331343}
2024-05-03 13:45:23,670 [INFO] Step[850/1020]: training loss : 0.19281891375780105 TRAIN  loss dict:  {'mse_loss': 0.19281891375780105}
2024-05-03 13:46:11,199 [INFO] Step[900/1020]: training loss : 0.1950513206422329 TRAIN  loss dict:  {'mse_loss': 0.1950513206422329}
2024-05-03 13:47:02,939 [INFO] Step[950/1020]: training loss : 0.1902823516726494 TRAIN  loss dict:  {'mse_loss': 0.1902823516726494}
2024-05-03 13:47:54,687 [INFO] Step[1000/1020]: training loss : 0.1986625050008297 TRAIN  loss dict:  {'mse_loss': 0.1986625050008297}
2024-05-03 13:51:27,528 [INFO] Label accuracies statistics:
2024-05-03 13:51:27,531 [INFO] {0: 1.0, 1: 0.5, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 0.5, 6: 0.5, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.5, 15: 0.5, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.25, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.5, 26: 1.0, 27: 1.0, 28: 0.75, 29: 1.0, 30: 0.5, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.5, 37: 1.0, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.75, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.75, 52: 0.25, 53: 0.0, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.5, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.75, 66: 0.5, 67: 1.0, 68: 0.75, 69: 0.5, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 1.0, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.5, 83: 1.0, 84: 0.75, 85: 0.75, 86: 0.5, 87: 0.5, 88: 1.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.25, 95: 0.75, 96: 0.5, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.5, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.75, 128: 0.75, 129: 0.75, 130: 0.75, 131: 0.75, 132: 0.5, 133: 0.75, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.25, 139: 0.75, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.5, 144: 0.75, 145: 0.75, 146: 0.5, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.5, 158: 0.5, 159: 0.5, 160: 0.5, 161: 1.0, 162: 0.75, 163: 1.0, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.75, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 0.75, 175: 0.75, 176: 0.75, 177: 0.75, 178: 0.75, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.5, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.75, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.5, 196: 0.75, 197: 0.75, 198: 0.75}

2024-05-03 13:51:27,564 [INFO] [69] TRAIN  loss: 0.19286710771129412 acc: 0.0
2024-05-03 13:51:27,565 [INFO] [69] TRAIN  loss dict: {'mse_loss': 0.19286710771129412}
2024-05-03 13:51:27,567 [INFO] [69] VALIDATION loss: 1.2102960646152496 VALIDATION  acc: 0.7512626262626263
2024-05-03 13:51:27,568 [INFO] [69] VALIDATION  loss dict: {'mse_loss': 0.2361409098210961, 'classification_loss': 0.9741551516709304}
2024-05-03 13:51:27,570 [INFO] 
2024-05-03 13:52:48,347 [INFO] Step[50/1020]: training loss : 0.19329851865768433 TRAIN  loss dict:  {'mse_loss': 0.19329851865768433}
2024-05-03 13:53:41,452 [INFO] Step[100/1020]: training loss : 0.18625160470604896 TRAIN  loss dict:  {'mse_loss': 0.18625160470604896}
2024-05-03 13:54:33,078 [INFO] Step[150/1020]: training loss : 0.19022103279829025 TRAIN  loss dict:  {'mse_loss': 0.19022103279829025}
2024-05-03 13:55:20,190 [INFO] Step[200/1020]: training loss : 0.19174526244401932 TRAIN  loss dict:  {'mse_loss': 0.19174526244401932}
2024-05-03 13:56:12,986 [INFO] Step[250/1020]: training loss : 0.19733532801270484 TRAIN  loss dict:  {'mse_loss': 0.19733532801270484}
2024-05-03 13:56:55,810 [INFO] Step[300/1020]: training loss : 0.19318111568689347 TRAIN  loss dict:  {'mse_loss': 0.19318111568689347}
2024-05-03 13:57:43,048 [INFO] Step[350/1020]: training loss : 0.18781829938292505 TRAIN  loss dict:  {'mse_loss': 0.18781829938292505}
2024-05-03 13:58:30,698 [INFO] Step[400/1020]: training loss : 0.19324370086193085 TRAIN  loss dict:  {'mse_loss': 0.19324370086193085}
2024-05-03 13:59:29,632 [INFO] Step[450/1020]: training loss : 0.1997161802649498 TRAIN  loss dict:  {'mse_loss': 0.1997161802649498}
2024-05-03 14:00:19,919 [INFO] Step[500/1020]: training loss : 0.19229880273342131 TRAIN  loss dict:  {'mse_loss': 0.19229880273342131}
2024-05-03 14:01:10,285 [INFO] Step[550/1020]: training loss : 0.19170286059379577 TRAIN  loss dict:  {'mse_loss': 0.19170286059379577}
2024-05-03 14:01:57,858 [INFO] Step[600/1020]: training loss : 0.19354842752218246 TRAIN  loss dict:  {'mse_loss': 0.19354842752218246}
2024-05-03 14:02:50,354 [INFO] Step[650/1020]: training loss : 0.1973004361987114 TRAIN  loss dict:  {'mse_loss': 0.1973004361987114}
2024-05-03 14:03:41,970 [INFO] Step[700/1020]: training loss : 0.2005836072564125 TRAIN  loss dict:  {'mse_loss': 0.2005836072564125}
2024-05-03 14:04:38,093 [INFO] Step[750/1020]: training loss : 0.18341163873672486 TRAIN  loss dict:  {'mse_loss': 0.18341163873672486}
2024-05-03 14:05:30,262 [INFO] Step[800/1020]: training loss : 0.19532706961035728 TRAIN  loss dict:  {'mse_loss': 0.19532706961035728}
2024-05-03 14:06:17,688 [INFO] Step[850/1020]: training loss : 0.19399601072072983 TRAIN  loss dict:  {'mse_loss': 0.19399601072072983}
2024-05-03 14:07:11,413 [INFO] Step[900/1020]: training loss : 0.19392870873212814 TRAIN  loss dict:  {'mse_loss': 0.19392870873212814}
2024-05-03 14:07:54,563 [INFO] Step[950/1020]: training loss : 0.2028501908481121 TRAIN  loss dict:  {'mse_loss': 0.2028501908481121}
2024-05-03 14:08:36,552 [INFO] Step[1000/1020]: training loss : 0.19676198482513427 TRAIN  loss dict:  {'mse_loss': 0.19676198482513427}
2024-05-03 14:11:31,346 [INFO] Label accuracies statistics:
2024-05-03 14:11:31,346 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 0.5, 6: 0.5, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.5, 15: 0.5, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.5, 25: 0.75, 26: 0.5, 27: 1.0, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.5, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 1.0, 51: 0.75, 52: 0.5, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.5, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.25, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.75, 83: 1.0, 84: 0.75, 85: 1.0, 86: 0.25, 87: 0.75, 88: 0.6666666666666666, 89: 0.5, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.5, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.5, 110: 1.0, 111: 1.0, 112: 0.0, 113: 0.25, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.25, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.75, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 0.75, 145: 0.75, 146: 0.75, 147: 1.0, 148: 0.5, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.5, 156: 0.5, 157: 0.5, 158: 0.75, 159: 0.5, 160: 0.25, 161: 1.0, 162: 0.5, 163: 0.75, 164: 0.5, 165: 0.75, 166: 0.5, 167: 0.5, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 0.5, 175: 1.0, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.5, 180: 1.0, 181: 1.0, 182: 0.5, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.25, 196: 0.75, 197: 0.5, 198: 0.75}

2024-05-03 14:11:31,386 [INFO] [70] TRAIN  loss: 0.19368598738721773 acc: 0.0
2024-05-03 14:11:31,388 [INFO] [70] TRAIN  loss dict: {'mse_loss': 0.19368598738721773}
2024-05-03 14:11:31,391 [INFO] [70] VALIDATION loss: 1.1991620763684765 VALIDATION  acc: 0.7386363636363636
2024-05-03 14:11:31,393 [INFO] [70] VALIDATION  loss dict: {'mse_loss': 0.2347352837372308, 'classification_loss': 0.9644267875889335}
2024-05-03 14:11:31,394 [INFO] 
2024-05-03 14:12:43,140 [INFO] Step[50/1020]: training loss : 0.18460520789027213 TRAIN  loss dict:  {'mse_loss': 0.18460520789027213}
2024-05-03 14:13:27,149 [INFO] Step[100/1020]: training loss : 0.18783180445432662 TRAIN  loss dict:  {'mse_loss': 0.18783180445432662}
2024-05-03 14:14:05,151 [INFO] Step[150/1020]: training loss : 0.1944008392095566 TRAIN  loss dict:  {'mse_loss': 0.1944008392095566}
2024-05-03 14:14:53,205 [INFO] Step[200/1020]: training loss : 0.1943679055571556 TRAIN  loss dict:  {'mse_loss': 0.1943679055571556}
2024-05-03 14:15:32,884 [INFO] Step[250/1020]: training loss : 0.19260660767555238 TRAIN  loss dict:  {'mse_loss': 0.19260660767555238}
2024-05-03 14:16:19,025 [INFO] Step[300/1020]: training loss : 0.1884731924533844 TRAIN  loss dict:  {'mse_loss': 0.1884731924533844}
2024-05-03 14:16:59,111 [INFO] Step[350/1020]: training loss : 0.19838526576757431 TRAIN  loss dict:  {'mse_loss': 0.19838526576757431}
2024-05-03 14:17:42,520 [INFO] Step[400/1020]: training loss : 0.19123236060142518 TRAIN  loss dict:  {'mse_loss': 0.19123236060142518}
2024-05-03 14:18:28,513 [INFO] Step[450/1020]: training loss : 0.18858935698866844 TRAIN  loss dict:  {'mse_loss': 0.18858935698866844}
2024-05-03 14:19:10,765 [INFO] Step[500/1020]: training loss : 0.1900320328772068 TRAIN  loss dict:  {'mse_loss': 0.1900320328772068}
2024-05-03 14:19:59,163 [INFO] Step[550/1020]: training loss : 0.17961032822728157 TRAIN  loss dict:  {'mse_loss': 0.17961032822728157}
2024-05-03 14:20:51,535 [INFO] Step[600/1020]: training loss : 0.19341068774461745 TRAIN  loss dict:  {'mse_loss': 0.19341068774461745}
2024-05-03 14:21:39,654 [INFO] Step[650/1020]: training loss : 0.19268872261047362 TRAIN  loss dict:  {'mse_loss': 0.19268872261047362}
2024-05-03 14:22:27,714 [INFO] Step[700/1020]: training loss : 0.19509523391723632 TRAIN  loss dict:  {'mse_loss': 0.19509523391723632}
2024-05-03 14:23:11,548 [INFO] Step[750/1020]: training loss : 0.18799324512481688 TRAIN  loss dict:  {'mse_loss': 0.18799324512481688}
2024-05-03 14:23:57,441 [INFO] Step[800/1020]: training loss : 0.1951091009378433 TRAIN  loss dict:  {'mse_loss': 0.1951091009378433}
2024-05-03 14:24:39,895 [INFO] Step[850/1020]: training loss : 0.19059787958860397 TRAIN  loss dict:  {'mse_loss': 0.19059787958860397}
2024-05-03 14:25:27,262 [INFO] Step[900/1020]: training loss : 0.193843395113945 TRAIN  loss dict:  {'mse_loss': 0.193843395113945}
2024-05-03 14:26:15,193 [INFO] Step[950/1020]: training loss : 0.1916915413737297 TRAIN  loss dict:  {'mse_loss': 0.1916915413737297}
2024-05-03 14:27:02,445 [INFO] Step[1000/1020]: training loss : 0.1964226108789444 TRAIN  loss dict:  {'mse_loss': 0.1964226108789444}
2024-05-03 14:29:58,327 [INFO] Label accuracies statistics:
2024-05-03 14:29:58,328 [INFO] {0: 1.0, 1: 0.5, 2: 0.75, 3: 1.0, 4: 0.6666666666666666, 5: 0.5, 6: 0.5, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.25, 15: 0.75, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.5, 24: 0.5, 25: 0.75, 26: 1.0, 27: 0.75, 28: 0.5, 29: 1.0, 30: 0.5, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.5, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.75, 44: 0.75, 45: 1.0, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 1.0, 51: 0.75, 52: 0.5, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.5, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.75, 66: 0.5, 67: 0.5, 68: 0.75, 69: 0.25, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.5, 74: 0.5, 75: 1.0, 76: 0.5, 77: 1.0, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.5, 83: 0.75, 84: 0.75, 85: 1.0, 86: 0.25, 87: 0.5, 88: 1.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.5, 95: 0.75, 96: 0.5, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.5, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.75, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.25, 113: 0.25, 114: 0.5, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 0.75, 120: 0.75, 121: 1.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.5, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.5, 139: 0.5, 140: 0.75, 141: 1.0, 142: 0.75, 143: 0.5, 144: 1.0, 145: 0.5, 146: 0.75, 147: 1.0, 148: 0.75, 149: 0.75, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.25, 156: 0.75, 157: 0.5, 158: 0.75, 159: 0.5, 160: 0.25, 161: 1.0, 162: 0.5, 163: 1.0, 164: 0.5, 165: 1.0, 166: 0.75, 167: 0.75, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 0.25, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 0.75, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.5, 187: 1.0, 188: 0.75, 189: 0.5, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.75}

2024-05-03 14:29:58,360 [INFO] [71] TRAIN  loss: 0.19135613879736732 acc: 0.0
2024-05-03 14:29:58,360 [INFO] [71] TRAIN  loss dict: {'mse_loss': 0.19135613879736732}
2024-05-03 14:29:58,361 [INFO] [71] VALIDATION loss: 1.2426184865109848 VALIDATION  acc: 0.7348484848484849
2024-05-03 14:29:58,361 [INFO] [71] VALIDATION  loss dict: {'mse_loss': 0.236474274573001, 'classification_loss': 1.0061442092757182}
2024-05-03 14:29:58,361 [INFO] 
2024-05-03 14:29:58,361 [INFO] 

***Stop training***


2024-05-03 14:29:58,362 [INFO] 
Testing checkpointed models starting...

2024-05-03 14:34:42,929 [INFO] Label accuracies statistics:
2024-05-03 14:34:42,965 [INFO] {0: 0.75, 1: 1.0, 2: 0.5, 3: 1.0, 4: 1.0, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.75, 10: 1.0, 11: 1.0, 12: 0.25, 13: 0.5, 14: 0.25, 15: 0.25, 16: 0.75, 17: 0.3333333333333333, 18: 1.0, 19: 0.0, 20: 0.25, 21: 0.25, 22: 1.0, 23: 1.0, 24: 0.25, 25: 0.5, 26: 0.5, 27: 0.75, 28: 0.75, 29: 0.75, 30: 1.0, 31: 1.0, 32: 1.0, 33: 0.75, 34: 0.75, 35: 0.25, 36: 0.75, 37: 0.75, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.25, 42: 1.0, 43: 0.5, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 0.5, 51: 0.5, 52: 0.5, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.5, 57: 1.0, 58: 0.5, 59: 0.75, 60: 1.0, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.5, 66: 0.75, 67: 0.75, 68: 0.25, 69: 0.5, 70: 0.25, 71: 0.75, 72: 1.0, 73: 0.5, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 0.75, 79: 0.5, 80: 0.75, 81: 1.0, 82: 0.0, 83: 0.25, 84: 0.75, 85: 0.75, 86: 0.5, 87: 0.5, 88: 0.25, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 1.0, 95: 0.75, 96: 0.5, 97: 0.75, 98: 0.5, 99: 1.0, 100: 0.75, 101: 0.5, 102: 0.75, 103: 0.25, 104: 0.75, 105: 0.25, 106: 0.5, 107: 0.5, 108: 0.75, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.25, 113: 0.0, 114: 1.0, 115: 1.0, 116: 0.5, 117: 1.0, 118: 0.5, 119: 0.75, 120: 0.5, 121: 0.25, 122: 1.0, 123: 0.5, 124: 1.0, 125: 1.0, 126: 0.75, 127: 0.25, 128: 0.75, 129: 0.5, 130: 0.5, 131: 1.0, 132: 0.5, 133: 0.75, 134: 0.75, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.25, 139: 0.75, 140: 0.5, 141: 0.75, 142: 0.5, 143: 1.0, 144: 1.0, 145: 0.5, 146: 0.5, 147: 0.5, 148: 0.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.75, 158: 0.25, 159: 0.5, 160: 0.5, 161: 0.5, 162: 0.75, 163: 0.25, 164: 0.5, 165: 0.75, 166: 0.5, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 0.0, 175: 0.25, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.25, 180: 0.25, 181: 0.5, 182: 0.5, 183: 0.5, 184: 0.5, 185: 0.75, 186: 0.5, 187: 0.75, 188: 0.25, 189: 0.75, 190: 0.5, 191: 0.25, 192: 0.5, 193: 0.5, 194: 0.5, 195: 0.5, 196: 0.75, 197: 0.75, 198: 0.75}

2024-05-03 14:34:42,986 [INFO] 
Testing accuracy: 0.6485461441213654
