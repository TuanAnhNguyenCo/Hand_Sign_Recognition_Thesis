

2024-05-04 06:09:43,760 [INFO] Step[50/1020]: training loss : 0.5764830684661866 TRAIN  loss dict:  {'mse_loss': 0.5764830684661866}
2024-05-04 06:10:20,564 [INFO] Step[100/1020]: training loss : 0.4868653446435928 TRAIN  loss dict:  {'mse_loss': 0.4868653446435928}
2024-05-04 06:10:57,611 [INFO] Step[150/1020]: training loss : 0.46384697675704956 TRAIN  loss dict:  {'mse_loss': 0.46384697675704956}
2024-05-04 06:11:35,215 [INFO] Step[200/1020]: training loss : 0.4509935414791107 TRAIN  loss dict:  {'mse_loss': 0.4509935414791107}
2024-05-04 06:12:13,595 [INFO] Step[250/1020]: training loss : 0.4354244256019592 TRAIN  loss dict:  {'mse_loss': 0.4354244256019592}
2024-05-04 06:12:52,142 [INFO] Step[300/1020]: training loss : 0.4266618210077286 TRAIN  loss dict:  {'mse_loss': 0.4266618210077286}
2024-05-04 06:13:31,725 [INFO] Step[350/1020]: training loss : 0.42437479972839354 TRAIN  loss dict:  {'mse_loss': 0.42437479972839354}
2024-05-04 06:14:09,737 [INFO] Step[400/1020]: training loss : 0.41920861005783083 TRAIN  loss dict:  {'mse_loss': 0.41920861005783083}
2024-05-04 06:14:49,858 [INFO] Step[450/1020]: training loss : 0.4094714069366455 TRAIN  loss dict:  {'mse_loss': 0.4094714069366455}
2024-05-04 06:15:26,718 [INFO] Step[500/1020]: training loss : 0.40540912091732023 TRAIN  loss dict:  {'mse_loss': 0.40540912091732023}
2024-05-04 06:16:05,322 [INFO] Step[550/1020]: training loss : 0.40042840361595156 TRAIN  loss dict:  {'mse_loss': 0.40042840361595156}
2024-05-04 06:16:44,977 [INFO] Step[600/1020]: training loss : 0.39478586554527284 TRAIN  loss dict:  {'mse_loss': 0.39478586554527284}
2024-05-04 06:17:25,769 [INFO] Step[650/1020]: training loss : 0.3904141592979431 TRAIN  loss dict:  {'mse_loss': 0.3904141592979431}
2024-05-04 06:18:04,928 [INFO] Step[700/1020]: training loss : 0.38511882185935975 TRAIN  loss dict:  {'mse_loss': 0.38511882185935975}
2024-05-04 06:18:45,075 [INFO] Step[750/1020]: training loss : 0.3836758428812027 TRAIN  loss dict:  {'mse_loss': 0.3836758428812027}
2024-05-04 06:19:22,608 [INFO] Step[800/1020]: training loss : 0.37969443321228025 TRAIN  loss dict:  {'mse_loss': 0.37969443321228025}
2024-05-04 06:19:59,818 [INFO] Step[850/1020]: training loss : 0.37642381370067596 TRAIN  loss dict:  {'mse_loss': 0.37642381370067596}
2024-05-04 06:20:37,917 [INFO] Step[900/1020]: training loss : 0.3713278478384018 TRAIN  loss dict:  {'mse_loss': 0.3713278478384018}
2024-05-04 06:21:15,936 [INFO] Step[950/1020]: training loss : 0.3623997682332993 TRAIN  loss dict:  {'mse_loss': 0.3623997682332993}
2024-05-04 06:21:53,288 [INFO] Step[1000/1020]: training loss : 0.3616542911529541 TRAIN  loss dict:  {'mse_loss': 0.3616542911529541}
2024-05-04 06:24:39,693 [INFO] Label accuracies statistics:
2024-05-04 06:24:39,693 [INFO] {0: 0.5, 1: 1.0, 2: 0.5, 3: 0.5, 4: 0.3333333333333333, 5: 0.5, 6: 0.25, 7: 0.5, 8: 0.25, 9: 0.25, 10: 0.0, 11: 0.75, 12: 0.75, 13: 0.0, 14: 0.5, 15: 0.25, 16: 0.0, 17: 0.75, 18: 1.0, 19: 0.5, 20: 0.75, 21: 1.0, 22: 0.5, 23: 0.75, 24: 0.5, 25: 0.25, 26: 1.0, 27: 0.75, 28: 0.25, 29: 0.75, 30: 0.0, 31: 0.75, 32: 0.75, 33: 1.0, 34: 1.0, 35: 0.75, 36: 0.5, 37: 0.25, 38: 0.0, 39: 0.75, 40: 1.0, 41: 0.0, 42: 0.75, 43: 0.75, 44: 0.5, 45: 1.0, 46: 0.75, 47: 0.75, 48: 0.25, 49: 0.25, 50: 0.75, 51: 0.5, 52: 0.25, 53: 0.0, 54: 0.5, 55: 0.5, 56: 0.75, 57: 0.5, 58: 0.75, 59: 0.25, 60: 0.5, 61: 0.75, 62: 0.75, 63: 0.25, 64: 0.5, 65: 0.75, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.75, 70: 1.0, 71: 0.5, 72: 0.75, 73: 0.25, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.0, 78: 1.0, 79: 0.0, 80: 0.5, 81: 0.75, 82: 0.0, 83: 0.75, 84: 1.0, 85: 1.0, 86: 0.5, 87: 0.25, 88: 1.0, 89: 0.25, 90: 1.0, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.0, 95: 1.0, 96: 0.75, 97: 0.0, 98: 0.75, 99: 1.0, 100: 0.25, 101: 1.0, 102: 0.0, 103: 0.0, 104: 0.75, 105: 0.75, 106: 0.5, 107: 0.0, 108: 0.75, 109: 0.25, 110: 0.75, 111: 0.5, 112: 0.5, 113: 0.0, 114: 0.25, 115: 0.5, 116: 0.5, 117: 0.75, 118: 0.75, 119: 0.5, 120: 0.75, 121: 1.0, 122: 0.0, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 0.75, 129: 0.75, 130: 0.5, 131: 0.5, 132: 0.75, 133: 0.75, 134: 1.0, 135: 0.75, 136: 0.5, 137: 0.5, 138: 0.5, 139: 0.25, 140: 0.5, 141: 1.0, 142: 0.75, 143: 0.5, 144: 1.0, 145: 0.5, 146: 0.5, 147: 0.25, 148: 0.25, 149: 0.75, 150: 1.0, 151: 0.75, 152: 0.25, 153: 0.75, 154: 0.5, 155: 0.25, 156: 0.5, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.25, 161: 1.0, 162: 1.0, 163: 0.5, 164: 0.0, 165: 0.75, 166: 0.0, 167: 0.25, 168: 0.5, 169: 0.0, 170: 0.5, 171: 0.5, 172: 0.5, 173: 0.5, 174: 0.25, 175: 0.75, 176: 0.0, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 0.75, 182: 0.75, 183: 0.5, 184: 0.75, 185: 0.75, 186: 1.0, 187: 1.0, 188: 0.5, 189: 0.5, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.25, 194: 0.75, 195: 0.0, 196: 0.75, 197: 0.75, 198: 1.0}

2024-05-04 06:24:40,616 [INFO] [1] TRAIN  loss: 0.41423823754577077 acc: 0.0
2024-05-04 06:24:40,617 [INFO] [1] TRAIN  loss dict: {'mse_loss': 0.41423823754577077}
2024-05-04 06:24:40,617 [INFO] [1] VALIDATION loss: 2.320825159549713 VALIDATION  acc: 0.5782828282828283
2024-05-04 06:24:40,617 [INFO] [1] VALIDATION  loss dict: {'mse_loss': 0.354461252388328, 'classification_loss': 1.966363901140714}
2024-05-04 06:24:40,617 [INFO] 
2024-05-04 06:25:55,495 [INFO] Step[50/1020]: training loss : 0.356256029009819 TRAIN  loss dict:  {'mse_loss': 0.356256029009819}
2024-05-04 06:26:34,924 [INFO] Step[100/1020]: training loss : 0.35153779566287996 TRAIN  loss dict:  {'mse_loss': 0.35153779566287996}
2024-05-04 06:27:14,075 [INFO] Step[150/1020]: training loss : 0.34305035829544067 TRAIN  loss dict:  {'mse_loss': 0.34305035829544067}
2024-05-04 06:27:55,647 [INFO] Step[200/1020]: training loss : 0.3504052805900574 TRAIN  loss dict:  {'mse_loss': 0.3504052805900574}
2024-05-04 06:28:36,371 [INFO] Step[250/1020]: training loss : 0.3394376450777054 TRAIN  loss dict:  {'mse_loss': 0.3394376450777054}
2024-05-04 06:29:18,064 [INFO] Step[300/1020]: training loss : 0.34661574244499205 TRAIN  loss dict:  {'mse_loss': 0.34661574244499205}
2024-05-04 06:29:58,303 [INFO] Step[350/1020]: training loss : 0.34286564588546753 TRAIN  loss dict:  {'mse_loss': 0.34286564588546753}
2024-05-04 06:30:39,604 [INFO] Step[400/1020]: training loss : 0.33633517563343046 TRAIN  loss dict:  {'mse_loss': 0.33633517563343046}
2024-05-04 06:31:22,995 [INFO] Step[450/1020]: training loss : 0.3401553428173065 TRAIN  loss dict:  {'mse_loss': 0.3401553428173065}
2024-05-04 06:32:03,583 [INFO] Step[500/1020]: training loss : 0.32702088356018066 TRAIN  loss dict:  {'mse_loss': 0.32702088356018066}
2024-05-04 06:32:43,959 [INFO] Step[550/1020]: training loss : 0.33301310658454897 TRAIN  loss dict:  {'mse_loss': 0.33301310658454897}
2024-05-04 06:33:23,798 [INFO] Step[600/1020]: training loss : 0.33038601636886594 TRAIN  loss dict:  {'mse_loss': 0.33038601636886594}
2024-05-04 06:34:07,703 [INFO] Step[650/1020]: training loss : 0.3291431960463524 TRAIN  loss dict:  {'mse_loss': 0.3291431960463524}
2024-05-04 06:34:49,227 [INFO] Step[700/1020]: training loss : 0.32805132150650024 TRAIN  loss dict:  {'mse_loss': 0.32805132150650024}
2024-05-04 06:35:34,876 [INFO] Step[750/1020]: training loss : 0.3161038592457771 TRAIN  loss dict:  {'mse_loss': 0.3161038592457771}
2024-05-04 06:36:17,137 [INFO] Step[800/1020]: training loss : 0.32565759003162387 TRAIN  loss dict:  {'mse_loss': 0.32565759003162387}
2024-05-04 06:37:00,663 [INFO] Step[850/1020]: training loss : 0.3214809900522232 TRAIN  loss dict:  {'mse_loss': 0.3214809900522232}
2024-05-04 06:37:43,637 [INFO] Step[900/1020]: training loss : 0.31927980601787564 TRAIN  loss dict:  {'mse_loss': 0.31927980601787564}
2024-05-04 06:38:27,882 [INFO] Step[950/1020]: training loss : 0.31641814559698106 TRAIN  loss dict:  {'mse_loss': 0.31641814559698106}
2024-05-04 06:39:08,900 [INFO] Step[1000/1020]: training loss : 0.31590079963207246 TRAIN  loss dict:  {'mse_loss': 0.31590079963207246}
2024-05-04 06:42:02,697 [INFO] Label accuracies statistics:
2024-05-04 06:42:02,697 [INFO] {0: 0.0, 1: 0.75, 2: 0.0, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.0, 7: 0.75, 8: 0.25, 9: 0.75, 10: 0.75, 11: 1.0, 12: 0.5, 13: 0.5, 14: 0.5, 15: 0.5, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.25, 28: 0.75, 29: 0.5, 30: 0.5, 31: 0.5, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.25, 36: 0.75, 37: 0.25, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 0.75, 47: 0.75, 48: 1.0, 49: 0.25, 50: 0.5, 51: 0.75, 52: 0.25, 53: 0.0, 54: 0.25, 55: 0.5, 56: 0.75, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.5, 61: 0.5, 62: 1.0, 63: 0.75, 64: 0.25, 65: 0.75, 66: 0.75, 67: 0.75, 68: 1.0, 69: 0.5, 70: 1.0, 71: 0.75, 72: 0.5, 73: 0.75, 74: 0.5, 75: 0.75, 76: 1.0, 77: 0.5, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.0, 83: 0.75, 84: 1.0, 85: 1.0, 86: 0.5, 87: 0.25, 88: 1.0, 89: 0.5, 90: 1.0, 91: 0.75, 92: 0.75, 93: 0.75, 94: 1.0, 95: 0.75, 96: 0.25, 97: 1.0, 98: 0.75, 99: 1.0, 100: 0.5, 101: 0.75, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 0.25, 112: 0.75, 113: 0.0, 114: 1.0, 115: 0.75, 116: 0.75, 117: 1.0, 118: 0.75, 119: 0.5, 120: 0.5, 121: 0.5, 122: 0.5, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.75, 128: 0.75, 129: 0.25, 130: 0.5, 131: 0.75, 132: 0.75, 133: 0.75, 134: 1.0, 135: 0.75, 136: 0.75, 137: 0.5, 138: 0.5, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.75, 143: 0.25, 144: 0.5, 145: 0.5, 146: 0.5, 147: 0.5, 148: 0.25, 149: 1.0, 150: 0.5, 151: 0.75, 152: 0.75, 153: 0.75, 154: 0.75, 155: 0.75, 156: 0.75, 157: 0.75, 158: 0.25, 159: 0.75, 160: 0.25, 161: 1.0, 162: 0.25, 163: 0.25, 164: 0.5, 165: 0.75, 166: 0.75, 167: 0.5, 168: 0.5, 169: 0.5, 170: 0.75, 171: 0.25, 172: 1.0, 173: 0.5, 174: 0.75, 175: 0.75, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 0.75, 182: 0.5, 183: 0.25, 184: 0.0, 185: 0.75, 186: 1.0, 187: 0.75, 188: 0.25, 189: 0.75, 190: 0.75, 191: 0.5, 192: 0.75, 193: 0.75, 194: 0.75, 195: 0.25, 196: 0.75, 197: 1.0, 198: 0.5}

2024-05-04 06:42:07,367 [INFO] [2] TRAIN  loss: 0.3328423202329991 acc: 0.0
2024-05-04 06:42:07,367 [INFO] [2] TRAIN  loss dict: {'mse_loss': 0.3328423202329991}
2024-05-04 06:42:07,367 [INFO] [2] VALIDATION loss: 1.6236387244378678 VALIDATION  acc: 0.6603535353535354
2024-05-04 06:42:07,367 [INFO] [2] VALIDATION  loss dict: {'mse_loss': 0.30287171697074716, 'classification_loss': 1.3207670101011642}
2024-05-04 06:42:07,367 [INFO] 
2024-05-04 06:43:22,604 [INFO] Step[50/1020]: training loss : 0.30099306046962737 TRAIN  loss dict:  {'mse_loss': 0.30099306046962737}
2024-05-04 06:44:04,292 [INFO] Step[100/1020]: training loss : 0.3014778745174408 TRAIN  loss dict:  {'mse_loss': 0.3014778745174408}
2024-05-04 06:44:46,005 [INFO] Step[150/1020]: training loss : 0.29928634971380236 TRAIN  loss dict:  {'mse_loss': 0.29928634971380236}
2024-05-04 06:45:29,545 [INFO] Step[200/1020]: training loss : 0.29935956478118897 TRAIN  loss dict:  {'mse_loss': 0.29935956478118897}
2024-05-04 06:46:10,261 [INFO] Step[250/1020]: training loss : 0.29966811954975126 TRAIN  loss dict:  {'mse_loss': 0.29966811954975126}
2024-05-04 06:46:54,532 [INFO] Step[300/1020]: training loss : 0.29121522784233095 TRAIN  loss dict:  {'mse_loss': 0.29121522784233095}
2024-05-04 06:47:35,887 [INFO] Step[350/1020]: training loss : 0.29990059047937395 TRAIN  loss dict:  {'mse_loss': 0.29990059047937395}
2024-05-04 06:48:16,478 [INFO] Step[400/1020]: training loss : 0.3013746213912964 TRAIN  loss dict:  {'mse_loss': 0.3013746213912964}
2024-05-04 06:48:58,674 [INFO] Step[450/1020]: training loss : 0.29347450613975523 TRAIN  loss dict:  {'mse_loss': 0.29347450613975523}
2024-05-04 06:49:41,954 [INFO] Step[500/1020]: training loss : 0.2849089676141739 TRAIN  loss dict:  {'mse_loss': 0.2849089676141739}
2024-05-04 06:50:26,133 [INFO] Step[550/1020]: training loss : 0.2932095834612846 TRAIN  loss dict:  {'mse_loss': 0.2932095834612846}
2024-05-04 06:51:06,721 [INFO] Step[600/1020]: training loss : 0.2945745640993118 TRAIN  loss dict:  {'mse_loss': 0.2945745640993118}
2024-05-04 06:51:46,720 [INFO] Step[650/1020]: training loss : 0.2987375730276108 TRAIN  loss dict:  {'mse_loss': 0.2987375730276108}
2024-05-04 06:52:28,762 [INFO] Step[700/1020]: training loss : 0.2910750466585159 TRAIN  loss dict:  {'mse_loss': 0.2910750466585159}
2024-05-04 06:53:12,054 [INFO] Step[750/1020]: training loss : 0.28675569742918017 TRAIN  loss dict:  {'mse_loss': 0.28675569742918017}
2024-05-04 06:53:53,483 [INFO] Step[800/1020]: training loss : 0.2884525147080421 TRAIN  loss dict:  {'mse_loss': 0.2884525147080421}
2024-05-04 06:54:37,014 [INFO] Step[850/1020]: training loss : 0.28444695353508 TRAIN  loss dict:  {'mse_loss': 0.28444695353508}
2024-05-04 06:55:19,533 [INFO] Step[900/1020]: training loss : 0.2835760354995728 TRAIN  loss dict:  {'mse_loss': 0.2835760354995728}
2024-05-04 06:56:02,924 [INFO] Step[950/1020]: training loss : 0.27722628980875014 TRAIN  loss dict:  {'mse_loss': 0.27722628980875014}
2024-05-04 06:56:45,118 [INFO] Step[1000/1020]: training loss : 0.2784524571895599 TRAIN  loss dict:  {'mse_loss': 0.2784524571895599}
2024-05-04 06:59:35,872 [INFO] Label accuracies statistics:
2024-05-04 06:59:35,873 [INFO] {0: 0.5, 1: 0.75, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 0.75, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.5, 14: 0.5, 15: 0.75, 16: 0.0, 17: 0.75, 18: 1.0, 19: 0.5, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.5, 29: 1.0, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.25, 38: 0.25, 39: 0.75, 40: 1.0, 41: 0.5, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 1.0, 51: 0.75, 52: 0.0, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.75, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.75, 61: 0.25, 62: 1.0, 63: 1.0, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.5, 68: 1.0, 69: 1.0, 70: 0.25, 71: 0.75, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.5, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.5, 83: 0.75, 84: 1.0, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.3333333333333333, 89: 0.75, 90: 0.25, 91: 1.0, 92: 1.0, 93: 0.75, 94: 1.0, 95: 0.75, 96: 0.5, 97: 1.0, 98: 1.0, 99: 1.0, 100: 0.5, 101: 0.5, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.5, 106: 0.75, 107: 0.75, 108: 0.75, 109: 0.5, 110: 0.75, 111: 0.5, 112: 0.25, 113: 0.0, 114: 1.0, 115: 1.0, 116: 0.5, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.0, 121: 1.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 0.5, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 0.75, 131: 0.75, 132: 0.5, 133: 0.75, 134: 1.0, 135: 0.75, 136: 0.5, 137: 1.0, 138: 0.75, 139: 0.25, 140: 0.75, 141: 1.0, 142: 0.25, 143: 0.75, 144: 1.0, 145: 0.5, 146: 0.25, 147: 0.75, 148: 0.25, 149: 1.0, 150: 1.0, 151: 0.75, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.75, 158: 0.5, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.0, 163: 0.5, 164: 0.0, 165: 1.0, 166: 0.25, 167: 1.0, 168: 0.5, 169: 0.5, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 0.75, 175: 0.75, 176: 0.75, 177: 0.0, 178: 1.0, 179: 1.0, 180: 0.75, 181: 0.75, 182: 0.75, 183: 1.0, 184: 1.0, 185: 0.75, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.0, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 0.5}

2024-05-04 06:59:40,506 [INFO] [3] TRAIN  loss: 0.2921078005403865 acc: 0.0
2024-05-04 06:59:40,506 [INFO] [3] TRAIN  loss dict: {'mse_loss': 0.2921078005403865}
2024-05-04 06:59:40,507 [INFO] [3] VALIDATION loss: 1.3273471690940135 VALIDATION  acc: 0.7234848484848485
2024-05-04 06:59:40,507 [INFO] [3] VALIDATION  loss dict: {'mse_loss': 0.27420536428689957, 'classification_loss': 1.05314180499526}
2024-05-04 06:59:40,507 [INFO] 
2024-05-04 07:00:57,143 [INFO] Step[50/1020]: training loss : 0.2656530037522316 TRAIN  loss dict:  {'mse_loss': 0.2656530037522316}
2024-05-04 07:01:39,642 [INFO] Step[100/1020]: training loss : 0.26723515421152116 TRAIN  loss dict:  {'mse_loss': 0.26723515421152116}
2024-05-04 07:02:22,903 [INFO] Step[150/1020]: training loss : 0.27876357913017275 TRAIN  loss dict:  {'mse_loss': 0.27876357913017275}
2024-05-04 07:03:02,759 [INFO] Step[200/1020]: training loss : 0.2679008129239082 TRAIN  loss dict:  {'mse_loss': 0.2679008129239082}
2024-05-04 07:03:45,692 [INFO] Step[250/1020]: training loss : 0.26905300676822663 TRAIN  loss dict:  {'mse_loss': 0.26905300676822663}
2024-05-04 07:04:27,413 [INFO] Step[300/1020]: training loss : 0.26796030879020694 TRAIN  loss dict:  {'mse_loss': 0.26796030879020694}
2024-05-04 07:05:09,149 [INFO] Step[350/1020]: training loss : 0.26589244782924654 TRAIN  loss dict:  {'mse_loss': 0.26589244782924654}
2024-05-04 07:05:48,839 [INFO] Step[400/1020]: training loss : 0.2634662202000618 TRAIN  loss dict:  {'mse_loss': 0.2634662202000618}
2024-05-04 07:06:30,898 [INFO] Step[450/1020]: training loss : 0.2644103166460991 TRAIN  loss dict:  {'mse_loss': 0.2644103166460991}
2024-05-04 07:07:14,022 [INFO] Step[500/1020]: training loss : 0.25956800431013105 TRAIN  loss dict:  {'mse_loss': 0.25956800431013105}
2024-05-04 07:07:56,430 [INFO] Step[550/1020]: training loss : 0.2589187729358673 TRAIN  loss dict:  {'mse_loss': 0.2589187729358673}
2024-05-04 07:08:40,752 [INFO] Step[600/1020]: training loss : 0.2667652294039726 TRAIN  loss dict:  {'mse_loss': 0.2667652294039726}
2024-05-04 07:09:24,493 [INFO] Step[650/1020]: training loss : 0.27072575747966765 TRAIN  loss dict:  {'mse_loss': 0.27072575747966765}
2024-05-04 07:10:08,217 [INFO] Step[700/1020]: training loss : 0.26477197617292403 TRAIN  loss dict:  {'mse_loss': 0.26477197617292403}
2024-05-04 07:10:50,163 [INFO] Step[750/1020]: training loss : 0.2644409921765327 TRAIN  loss dict:  {'mse_loss': 0.2644409921765327}
2024-05-04 07:11:29,281 [INFO] Step[800/1020]: training loss : 0.26473606526851656 TRAIN  loss dict:  {'mse_loss': 0.26473606526851656}
2024-05-04 07:12:11,550 [INFO] Step[850/1020]: training loss : 0.26252626448869704 TRAIN  loss dict:  {'mse_loss': 0.26252626448869704}
2024-05-04 07:12:51,180 [INFO] Step[900/1020]: training loss : 0.26306015729904175 TRAIN  loss dict:  {'mse_loss': 0.26306015729904175}
2024-05-04 07:13:34,605 [INFO] Step[950/1020]: training loss : 0.2704704427719116 TRAIN  loss dict:  {'mse_loss': 0.2704704427719116}
2024-05-04 07:14:16,641 [INFO] Step[1000/1020]: training loss : 0.2565585222840309 TRAIN  loss dict:  {'mse_loss': 0.2565585222840309}
2024-05-04 07:17:08,884 [INFO] Label accuracies statistics:
2024-05-04 07:17:08,884 [INFO] {0: 1.0, 1: 0.75, 2: 0.25, 3: 0.75, 4: 0.6666666666666666, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.0, 9: 1.0, 10: 0.75, 11: 1.0, 12: 1.0, 13: 0.75, 14: 0.5, 15: 0.0, 16: 0.5, 17: 0.75, 18: 0.75, 19: 0.0, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.75, 28: 0.5, 29: 0.75, 30: 1.0, 31: 0.25, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.25, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 0.75, 47: 0.75, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.5, 52: 0.25, 53: 0.0, 54: 0.75, 55: 0.75, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.25, 60: 1.0, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.75, 66: 0.25, 67: 1.0, 68: 1.0, 69: 0.25, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.5, 83: 0.75, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.0, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.75, 95: 1.0, 96: 0.25, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.5, 102: 0.75, 103: 0.25, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 0.25, 112: 0.5, 113: 0.25, 114: 1.0, 115: 0.75, 116: 0.75, 117: 0.75, 118: 0.75, 119: 0.75, 120: 0.75, 121: 0.5, 122: 0.75, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.5, 128: 0.75, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.5, 138: 0.75, 139: 0.75, 140: 0.75, 141: 0.75, 142: 1.0, 143: 0.5, 144: 1.0, 145: 0.75, 146: 0.5, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 0.75, 152: 1.0, 153: 0.25, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.5, 158: 0.25, 159: 0.75, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.75, 164: 1.0, 165: 0.75, 166: 0.75, 167: 1.0, 168: 0.5, 169: 0.5, 170: 0.75, 171: 0.25, 172: 0.5, 173: 0.5, 174: 0.5, 175: 1.0, 176: 0.25, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 0.75, 182: 0.75, 183: 0.75, 184: 1.0, 185: 0.75, 186: 1.0, 187: 1.0, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.75, 192: 0.75, 193: 0.75, 194: 1.0, 195: 0.25, 196: 0.75, 197: 1.0, 198: 0.5}

2024-05-04 07:17:13,479 [INFO] [4] TRAIN  loss: 0.26566207273041503 acc: 0.0
2024-05-04 07:17:13,479 [INFO] [4] TRAIN  loss dict: {'mse_loss': 0.26566207273041503}
2024-05-04 07:17:13,480 [INFO] [4] VALIDATION loss: 1.2140406346832864 VALIDATION  acc: 0.7449494949494949
2024-05-04 07:17:13,480 [INFO] [4] VALIDATION  loss dict: {'mse_loss': 0.25422886202130657, 'classification_loss': 0.9598117741295183}
2024-05-04 07:17:13,480 [INFO] 
2024-05-04 07:18:24,439 [INFO] Step[50/1020]: training loss : 0.2401608085632324 TRAIN  loss dict:  {'mse_loss': 0.2401608085632324}
2024-05-04 07:19:06,156 [INFO] Step[100/1020]: training loss : 0.25041859596967697 TRAIN  loss dict:  {'mse_loss': 0.25041859596967697}
2024-05-04 07:19:47,146 [INFO] Step[150/1020]: training loss : 0.2474597203731537 TRAIN  loss dict:  {'mse_loss': 0.2474597203731537}
2024-05-04 07:20:32,124 [INFO] Step[200/1020]: training loss : 0.25657842189073565 TRAIN  loss dict:  {'mse_loss': 0.25657842189073565}
2024-05-04 07:21:12,639 [INFO] Step[250/1020]: training loss : 0.2534854155778885 TRAIN  loss dict:  {'mse_loss': 0.2534854155778885}
2024-05-04 07:21:54,889 [INFO] Step[300/1020]: training loss : 0.2554703429341316 TRAIN  loss dict:  {'mse_loss': 0.2554703429341316}
2024-05-04 07:22:39,603 [INFO] Step[350/1020]: training loss : 0.25827311366796496 TRAIN  loss dict:  {'mse_loss': 0.25827311366796496}
2024-05-04 07:23:23,289 [INFO] Step[400/1020]: training loss : 0.24846633434295654 TRAIN  loss dict:  {'mse_loss': 0.24846633434295654}
2024-05-04 07:24:04,243 [INFO] Step[450/1020]: training loss : 0.24362030684947966 TRAIN  loss dict:  {'mse_loss': 0.24362030684947966}
2024-05-04 07:24:47,461 [INFO] Step[500/1020]: training loss : 0.24691384881734849 TRAIN  loss dict:  {'mse_loss': 0.24691384881734849}
2024-05-04 07:25:31,188 [INFO] Step[550/1020]: training loss : 0.24756837278604507 TRAIN  loss dict:  {'mse_loss': 0.24756837278604507}
2024-05-04 07:26:10,337 [INFO] Step[600/1020]: training loss : 0.2513730189204216 TRAIN  loss dict:  {'mse_loss': 0.2513730189204216}
2024-05-04 07:26:51,043 [INFO] Step[650/1020]: training loss : 0.24245923280715942 TRAIN  loss dict:  {'mse_loss': 0.24245923280715942}
2024-05-04 07:27:37,684 [INFO] Step[700/1020]: training loss : 0.24631076365709303 TRAIN  loss dict:  {'mse_loss': 0.24631076365709303}
2024-05-04 07:28:22,535 [INFO] Step[750/1020]: training loss : 0.23943781226873398 TRAIN  loss dict:  {'mse_loss': 0.23943781226873398}
2024-05-04 07:29:03,270 [INFO] Step[800/1020]: training loss : 0.24117942482233048 TRAIN  loss dict:  {'mse_loss': 0.24117942482233048}
2024-05-04 07:29:46,312 [INFO] Step[850/1020]: training loss : 0.2515804785490036 TRAIN  loss dict:  {'mse_loss': 0.2515804785490036}
2024-05-04 07:30:27,311 [INFO] Step[900/1020]: training loss : 0.23939780563116073 TRAIN  loss dict:  {'mse_loss': 0.23939780563116073}
2024-05-04 07:31:10,403 [INFO] Step[950/1020]: training loss : 0.25207279324531556 TRAIN  loss dict:  {'mse_loss': 0.25207279324531556}
2024-05-04 07:31:52,150 [INFO] Step[1000/1020]: training loss : 0.23819755285978317 TRAIN  loss dict:  {'mse_loss': 0.23819755285978317}
2024-05-04 07:34:42,422 [INFO] Label accuracies statistics:
2024-05-04 07:34:42,422 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.75, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 0.75, 14: 0.5, 15: 0.5, 16: 0.75, 17: 0.25, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.5, 29: 0.25, 30: 0.75, 31: 1.0, 32: 1.0, 33: 1.0, 34: 1.0, 35: 0.5, 36: 0.75, 37: 0.25, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.5, 52: 0.25, 53: 0.5, 54: 0.5, 55: 0.75, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.5, 60: 1.0, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.5, 65: 1.0, 66: 0.25, 67: 1.0, 68: 0.0, 69: 0.5, 70: 1.0, 71: 0.75, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 0.75, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.25, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.75, 95: 0.75, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.75, 101: 1.0, 102: 0.25, 103: 0.25, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 0.75, 112: 0.5, 113: 0.25, 114: 1.0, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.25, 139: 0.75, 140: 0.75, 141: 0.75, 142: 1.0, 143: 0.5, 144: 1.0, 145: 0.75, 146: 0.5, 147: 0.75, 148: 1.0, 149: 1.0, 150: 0.25, 151: 0.75, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.5, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.25, 163: 0.5, 164: 1.0, 165: 1.0, 166: 0.75, 167: 1.0, 168: 0.5, 169: 0.5, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 0.75, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 0.75, 181: 0.75, 182: 0.75, 183: 0.75, 184: 1.0, 185: 0.75, 186: 1.0, 187: 1.0, 188: 0.75, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.25, 194: 1.0, 195: 0.5, 196: 0.75, 197: 1.0, 198: 0.75}

2024-05-04 07:34:47,098 [INFO] [5] TRAIN  loss: 0.24736420459607067 acc: 0.0
2024-05-04 07:34:47,098 [INFO] [5] TRAIN  loss dict: {'mse_loss': 0.24736420459607067}
2024-05-04 07:34:47,099 [INFO] [5] VALIDATION loss: 1.1366201874734176 VALIDATION  acc: 0.7664141414141414
2024-05-04 07:34:47,099 [INFO] [5] VALIDATION  loss dict: {'mse_loss': 0.24211930265330306, 'classification_loss': 0.8945008846978196}
2024-05-04 07:34:47,099 [INFO] 
2024-05-04 07:36:01,664 [INFO] Step[50/1020]: training loss : 0.23058672964572907 TRAIN  loss dict:  {'mse_loss': 0.23058672964572907}
2024-05-04 07:36:41,483 [INFO] Step[100/1020]: training loss : 0.22345333755016328 TRAIN  loss dict:  {'mse_loss': 0.22345333755016328}
2024-05-04 07:37:20,398 [INFO] Step[150/1020]: training loss : 0.23922742128372193 TRAIN  loss dict:  {'mse_loss': 0.23922742128372193}
2024-05-04 07:38:00,120 [INFO] Step[200/1020]: training loss : 0.22953364580869676 TRAIN  loss dict:  {'mse_loss': 0.22953364580869676}
2024-05-04 07:38:41,018 [INFO] Step[250/1020]: training loss : 0.2276807287335396 TRAIN  loss dict:  {'mse_loss': 0.2276807287335396}
2024-05-04 07:39:25,323 [INFO] Step[300/1020]: training loss : 0.2364284500479698 TRAIN  loss dict:  {'mse_loss': 0.2364284500479698}
2024-05-04 07:40:07,068 [INFO] Step[350/1020]: training loss : 0.2328391832113266 TRAIN  loss dict:  {'mse_loss': 0.2328391832113266}
2024-05-04 07:40:49,576 [INFO] Step[400/1020]: training loss : 0.23341138422489166 TRAIN  loss dict:  {'mse_loss': 0.23341138422489166}
2024-05-04 07:41:32,802 [INFO] Step[450/1020]: training loss : 0.236454339325428 TRAIN  loss dict:  {'mse_loss': 0.236454339325428}
2024-05-04 07:42:12,907 [INFO] Step[500/1020]: training loss : 0.24117741584777833 TRAIN  loss dict:  {'mse_loss': 0.24117741584777833}
2024-05-04 07:42:54,174 [INFO] Step[550/1020]: training loss : 0.23036080092191696 TRAIN  loss dict:  {'mse_loss': 0.23036080092191696}
2024-05-04 07:43:33,816 [INFO] Step[600/1020]: training loss : 0.23028090000152587 TRAIN  loss dict:  {'mse_loss': 0.23028090000152587}
2024-05-04 07:44:15,140 [INFO] Step[650/1020]: training loss : 0.24061573475599288 TRAIN  loss dict:  {'mse_loss': 0.24061573475599288}
2024-05-04 07:44:58,206 [INFO] Step[700/1020]: training loss : 0.23938776761293412 TRAIN  loss dict:  {'mse_loss': 0.23938776761293412}
2024-05-04 07:45:41,329 [INFO] Step[750/1020]: training loss : 0.24352994412183762 TRAIN  loss dict:  {'mse_loss': 0.24352994412183762}
2024-05-04 07:46:21,328 [INFO] Step[800/1020]: training loss : 0.2341092684864998 TRAIN  loss dict:  {'mse_loss': 0.2341092684864998}
2024-05-04 07:47:06,596 [INFO] Step[850/1020]: training loss : 0.23040495276451112 TRAIN  loss dict:  {'mse_loss': 0.23040495276451112}
2024-05-04 07:47:48,687 [INFO] Step[900/1020]: training loss : 0.23294126331806184 TRAIN  loss dict:  {'mse_loss': 0.23294126331806184}
2024-05-04 07:48:31,751 [INFO] Step[950/1020]: training loss : 0.2397885262966156 TRAIN  loss dict:  {'mse_loss': 0.2397885262966156}
2024-05-04 07:49:11,083 [INFO] Step[1000/1020]: training loss : 0.23182468503713607 TRAIN  loss dict:  {'mse_loss': 0.23182468503713607}
2024-05-04 07:52:00,890 [INFO] Label accuracies statistics:
2024-05-04 07:52:00,890 [INFO] {0: 0.5, 1: 1.0, 2: 0.25, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.25, 9: 0.5, 10: 1.0, 11: 1.0, 12: 1.0, 13: 0.75, 14: 0.75, 15: 0.5, 16: 0.75, 17: 1.0, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.75, 29: 1.0, 30: 1.0, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.5, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.25, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 0.75, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.25, 61: 0.5, 62: 1.0, 63: 1.0, 64: 0.5, 65: 1.0, 66: 0.75, 67: 0.75, 68: 1.0, 69: 0.75, 70: 0.75, 71: 1.0, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.25, 97: 1.0, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.25, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 0.75, 112: 0.25, 113: 0.5, 114: 0.5, 115: 0.75, 116: 0.5, 117: 0.75, 118: 0.5, 119: 1.0, 120: 0.75, 121: 0.25, 122: 1.0, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 0.75, 137: 0.75, 138: 0.5, 139: 0.75, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 0.75, 145: 0.5, 146: 0.5, 147: 1.0, 148: 0.75, 149: 0.75, 150: 1.0, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.25, 158: 0.5, 159: 0.75, 160: 0.25, 161: 1.0, 162: 0.5, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 1.0, 168: 0.5, 169: 0.5, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.75, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 0.75, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.5, 185: 0.75, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.75}

2024-05-04 07:52:05,671 [INFO] [6] TRAIN  loss: 0.2340425423985603 acc: 0.0
2024-05-04 07:52:05,672 [INFO] [6] TRAIN  loss dict: {'mse_loss': 0.2340425423985603}
2024-05-04 07:52:05,673 [INFO] [6] VALIDATION loss: 1.041942884298888 VALIDATION  acc: 0.7904040404040404
2024-05-04 07:52:05,673 [INFO] [6] VALIDATION  loss dict: {'mse_loss': 0.2322833218207263, 'classification_loss': 0.8096595634941501}
2024-05-04 07:52:05,673 [INFO] 
2024-05-04 07:53:21,476 [INFO] Step[50/1020]: training loss : 0.21793610334396363 TRAIN  loss dict:  {'mse_loss': 0.21793610334396363}
2024-05-04 07:54:06,123 [INFO] Step[100/1020]: training loss : 0.2192374175786972 TRAIN  loss dict:  {'mse_loss': 0.2192374175786972}
2024-05-04 07:54:47,882 [INFO] Step[150/1020]: training loss : 0.2240395388007164 TRAIN  loss dict:  {'mse_loss': 0.2240395388007164}
2024-05-04 07:55:28,801 [INFO] Step[200/1020]: training loss : 0.22507596135139465 TRAIN  loss dict:  {'mse_loss': 0.22507596135139465}
2024-05-04 07:56:09,304 [INFO] Step[250/1020]: training loss : 0.22921242117881774 TRAIN  loss dict:  {'mse_loss': 0.22921242117881774}
2024-05-04 07:56:49,552 [INFO] Step[300/1020]: training loss : 0.22702612698078156 TRAIN  loss dict:  {'mse_loss': 0.22702612698078156}
2024-05-04 07:57:30,492 [INFO] Step[350/1020]: training loss : 0.21097021341323852 TRAIN  loss dict:  {'mse_loss': 0.21097021341323852}
2024-05-04 07:58:12,083 [INFO] Step[400/1020]: training loss : 0.21756196022033691 TRAIN  loss dict:  {'mse_loss': 0.21756196022033691}
2024-05-04 07:58:53,828 [INFO] Step[450/1020]: training loss : 0.220157430768013 TRAIN  loss dict:  {'mse_loss': 0.220157430768013}
2024-05-04 07:59:39,114 [INFO] Step[500/1020]: training loss : 0.22221822291612625 TRAIN  loss dict:  {'mse_loss': 0.22221822291612625}
2024-05-04 08:00:23,202 [INFO] Step[550/1020]: training loss : 0.23292091578245164 TRAIN  loss dict:  {'mse_loss': 0.23292091578245164}
2024-05-04 08:01:04,547 [INFO] Step[600/1020]: training loss : 0.22491558343172074 TRAIN  loss dict:  {'mse_loss': 0.22491558343172074}
2024-05-04 08:01:45,905 [INFO] Step[650/1020]: training loss : 0.21965729653835298 TRAIN  loss dict:  {'mse_loss': 0.21965729653835298}
2024-05-04 08:02:25,439 [INFO] Step[700/1020]: training loss : 0.2195494595170021 TRAIN  loss dict:  {'mse_loss': 0.2195494595170021}
2024-05-04 08:03:10,113 [INFO] Step[750/1020]: training loss : 0.22432992473244667 TRAIN  loss dict:  {'mse_loss': 0.22432992473244667}
2024-05-04 08:03:53,154 [INFO] Step[800/1020]: training loss : 0.2160427576303482 TRAIN  loss dict:  {'mse_loss': 0.2160427576303482}
2024-05-04 08:04:36,655 [INFO] Step[850/1020]: training loss : 0.21794282600283624 TRAIN  loss dict:  {'mse_loss': 0.21794282600283624}
2024-05-04 08:05:19,675 [INFO] Step[900/1020]: training loss : 0.2230418211221695 TRAIN  loss dict:  {'mse_loss': 0.2230418211221695}
2024-05-04 08:06:00,445 [INFO] Step[950/1020]: training loss : 0.21160230696201324 TRAIN  loss dict:  {'mse_loss': 0.21160230696201324}
2024-05-04 08:06:43,074 [INFO] Step[1000/1020]: training loss : 0.2168703034520149 TRAIN  loss dict:  {'mse_loss': 0.2168703034520149}
2024-05-04 08:09:34,864 [INFO] Label accuracies statistics:
2024-05-04 08:09:34,864 [INFO] {0: 0.5, 1: 0.75, 2: 0.25, 3: 0.75, 4: 0.0, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 0.75, 14: 0.5, 15: 1.0, 16: 0.75, 17: 1.0, 18: 0.75, 19: 0.75, 20: 0.5, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.75, 29: 0.75, 30: 1.0, 31: 0.5, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 0.5, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 0.5, 51: 0.75, 52: 0.5, 53: 0.0, 54: 0.25, 55: 0.25, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.5, 61: 1.0, 62: 1.0, 63: 1.0, 64: 1.0, 65: 0.75, 66: 0.5, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.75, 71: 1.0, 72: 1.0, 73: 0.75, 74: 0.75, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.5, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.25, 97: 1.0, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.5, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.75, 108: 0.75, 109: 0.75, 110: 1.0, 111: 0.75, 112: 0.5, 113: 0.0, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.75, 118: 0.75, 119: 1.0, 120: 0.75, 121: 0.75, 122: 0.25, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 1.0, 139: 0.5, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 0.25, 149: 1.0, 150: 0.5, 151: 0.75, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.0, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.5, 163: 0.75, 164: 1.0, 165: 1.0, 166: 0.75, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.5, 175: 1.0, 176: 0.25, 177: 0.75, 178: 1.0, 179: 0.75, 180: 0.75, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.25, 185: 0.75, 186: 1.0, 187: 0.75, 188: 0.75, 189: 0.5, 190: 0.75, 191: 0.5, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.75}

2024-05-04 08:09:39,551 [INFO] [7] TRAIN  loss: 0.22132334966285555 acc: 0.0
2024-05-04 08:09:39,551 [INFO] [7] TRAIN  loss dict: {'mse_loss': 0.22132334966285555}
2024-05-04 08:09:39,552 [INFO] [7] VALIDATION loss: 1.02802489660304 VALIDATION  acc: 0.7815656565656566
2024-05-04 08:09:39,552 [INFO] [7] VALIDATION  loss dict: {'mse_loss': 0.2277231811348236, 'classification_loss': 0.8003017118134809}
2024-05-04 08:09:39,552 [INFO] 
2024-05-04 08:10:52,639 [INFO] Step[50/1020]: training loss : 0.2233881250023842 TRAIN  loss dict:  {'mse_loss': 0.2233881250023842}
2024-05-04 08:11:38,388 [INFO] Step[100/1020]: training loss : 0.20587593257427217 TRAIN  loss dict:  {'mse_loss': 0.20587593257427217}
2024-05-04 08:12:22,001 [INFO] Step[150/1020]: training loss : 0.20397389948368072 TRAIN  loss dict:  {'mse_loss': 0.20397389948368072}
2024-05-04 08:13:02,881 [INFO] Step[200/1020]: training loss : 0.20589860945940017 TRAIN  loss dict:  {'mse_loss': 0.20589860945940017}
2024-05-04 08:13:44,823 [INFO] Step[250/1020]: training loss : 0.22325172603130342 TRAIN  loss dict:  {'mse_loss': 0.22325172603130342}
2024-05-04 08:14:29,310 [INFO] Step[300/1020]: training loss : 0.21426535457372664 TRAIN  loss dict:  {'mse_loss': 0.21426535457372664}
2024-05-04 08:15:08,457 [INFO] Step[350/1020]: training loss : 0.22097477078437805 TRAIN  loss dict:  {'mse_loss': 0.22097477078437805}
2024-05-04 08:15:52,045 [INFO] Step[400/1020]: training loss : 0.2125422812998295 TRAIN  loss dict:  {'mse_loss': 0.2125422812998295}
2024-05-04 08:16:35,646 [INFO] Step[450/1020]: training loss : 0.20998185515403747 TRAIN  loss dict:  {'mse_loss': 0.20998185515403747}
2024-05-04 08:17:23,000 [INFO] Step[500/1020]: training loss : 0.20530488342046738 TRAIN  loss dict:  {'mse_loss': 0.20530488342046738}
2024-05-04 08:18:04,833 [INFO] Step[550/1020]: training loss : 0.2087467961013317 TRAIN  loss dict:  {'mse_loss': 0.2087467961013317}
2024-05-04 08:18:44,721 [INFO] Step[600/1020]: training loss : 0.210219624042511 TRAIN  loss dict:  {'mse_loss': 0.210219624042511}
2024-05-04 08:19:24,455 [INFO] Step[650/1020]: training loss : 0.20935839027166367 TRAIN  loss dict:  {'mse_loss': 0.20935839027166367}
2024-05-04 08:20:05,467 [INFO] Step[700/1020]: training loss : 0.21323604136705399 TRAIN  loss dict:  {'mse_loss': 0.21323604136705399}
2024-05-04 08:20:44,934 [INFO] Step[750/1020]: training loss : 0.21645068973302842 TRAIN  loss dict:  {'mse_loss': 0.21645068973302842}
2024-05-04 08:21:25,836 [INFO] Step[800/1020]: training loss : 0.2186380597949028 TRAIN  loss dict:  {'mse_loss': 0.2186380597949028}
2024-05-04 08:22:07,189 [INFO] Step[850/1020]: training loss : 0.21622006744146346 TRAIN  loss dict:  {'mse_loss': 0.21622006744146346}
2024-05-04 08:22:48,914 [INFO] Step[900/1020]: training loss : 0.21251140296459198 TRAIN  loss dict:  {'mse_loss': 0.21251140296459198}
2024-05-04 08:23:32,698 [INFO] Step[950/1020]: training loss : 0.21792939454317092 TRAIN  loss dict:  {'mse_loss': 0.21792939454317092}
2024-05-04 08:24:15,175 [INFO] Step[1000/1020]: training loss : 0.2128275778889656 TRAIN  loss dict:  {'mse_loss': 0.2128275778889656}
2024-05-04 08:27:06,921 [INFO] Label accuracies statistics:
2024-05-04 08:27:06,922 [INFO] {0: 0.5, 1: 0.75, 2: 0.0, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.5, 7: 1.0, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.5, 15: 0.5, 16: 0.75, 17: 0.75, 18: 1.0, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.75, 28: 0.5, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.25, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 0.75, 47: 1.0, 48: 0.75, 49: 0.25, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.25, 55: 0.75, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.5, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.5, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 0.5, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 0.5, 112: 0.5, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.75, 121: 0.75, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 1.0, 146: 0.5, 147: 1.0, 148: 0.5, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.5, 158: 0.25, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.5, 163: 0.75, 164: 1.0, 165: 1.0, 166: 0.75, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.5, 174: 0.75, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.25, 185: 0.75, 186: 1.0, 187: 0.75, 188: 0.75, 189: 1.0, 190: 1.0, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-04 08:27:11,583 [INFO] [8] TRAIN  loss: 0.21329639258922314 acc: 0.0
2024-05-04 08:27:11,584 [INFO] [8] TRAIN  loss dict: {'mse_loss': 0.21329639258922314}
2024-05-04 08:27:11,585 [INFO] [8] VALIDATION loss: 0.9864344038069248 VALIDATION  acc: 0.8017676767676768
2024-05-04 08:27:11,586 [INFO] [8] VALIDATION  loss dict: {'mse_loss': 0.21963156315714422, 'classification_loss': 0.7668028423101688}
2024-05-04 08:27:11,587 [INFO] 
2024-05-04 08:28:27,478 [INFO] Step[50/1020]: training loss : 0.19621345192193984 TRAIN  loss dict:  {'mse_loss': 0.19621345192193984}
2024-05-04 08:29:10,578 [INFO] Step[100/1020]: training loss : 0.20874230682849884 TRAIN  loss dict:  {'mse_loss': 0.20874230682849884}
2024-05-04 08:29:53,609 [INFO] Step[150/1020]: training loss : 0.20762290954589843 TRAIN  loss dict:  {'mse_loss': 0.20762290954589843}
2024-05-04 08:30:38,369 [INFO] Step[200/1020]: training loss : 0.19473708748817445 TRAIN  loss dict:  {'mse_loss': 0.19473708748817445}
2024-05-04 08:31:20,493 [INFO] Step[250/1020]: training loss : 0.20781517565250396 TRAIN  loss dict:  {'mse_loss': 0.20781517565250396}
2024-05-04 08:32:03,938 [INFO] Step[300/1020]: training loss : 0.20588909685611725 TRAIN  loss dict:  {'mse_loss': 0.20588909685611725}
2024-05-04 08:32:45,178 [INFO] Step[350/1020]: training loss : 0.20814449429512025 TRAIN  loss dict:  {'mse_loss': 0.20814449429512025}
2024-05-04 08:33:29,639 [INFO] Step[400/1020]: training loss : 0.197139590382576 TRAIN  loss dict:  {'mse_loss': 0.197139590382576}
2024-05-04 08:34:10,148 [INFO] Step[450/1020]: training loss : 0.2141209077835083 TRAIN  loss dict:  {'mse_loss': 0.2141209077835083}
2024-05-04 08:34:49,353 [INFO] Step[500/1020]: training loss : 0.20328175395727158 TRAIN  loss dict:  {'mse_loss': 0.20328175395727158}
2024-05-04 08:35:29,499 [INFO] Step[550/1020]: training loss : 0.19720183119177817 TRAIN  loss dict:  {'mse_loss': 0.19720183119177817}
2024-05-04 08:36:12,247 [INFO] Step[600/1020]: training loss : 0.20259377717971802 TRAIN  loss dict:  {'mse_loss': 0.20259377717971802}
2024-05-04 08:36:57,286 [INFO] Step[650/1020]: training loss : 0.19803792715072632 TRAIN  loss dict:  {'mse_loss': 0.19803792715072632}
2024-05-04 08:37:42,829 [INFO] Step[700/1020]: training loss : 0.20986803233623505 TRAIN  loss dict:  {'mse_loss': 0.20986803233623505}
2024-05-04 08:38:23,556 [INFO] Step[750/1020]: training loss : 0.20974812388420105 TRAIN  loss dict:  {'mse_loss': 0.20974812388420105}
2024-05-04 08:39:03,806 [INFO] Step[800/1020]: training loss : 0.21689185589551926 TRAIN  loss dict:  {'mse_loss': 0.21689185589551926}
2024-05-04 08:39:42,380 [INFO] Step[850/1020]: training loss : 0.20705476373434067 TRAIN  loss dict:  {'mse_loss': 0.20705476373434067}
2024-05-04 08:40:22,281 [INFO] Step[900/1020]: training loss : 0.21294535756111144 TRAIN  loss dict:  {'mse_loss': 0.21294535756111144}
2024-05-04 08:41:03,101 [INFO] Step[950/1020]: training loss : 0.20493801236152648 TRAIN  loss dict:  {'mse_loss': 0.20493801236152648}
2024-05-04 08:41:44,061 [INFO] Step[1000/1020]: training loss : 0.19918369144201278 TRAIN  loss dict:  {'mse_loss': 0.19918369144201278}
2024-05-04 08:44:37,546 [INFO] Label accuracies statistics:
2024-05-04 08:44:37,547 [INFO] {0: 0.5, 1: 0.75, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.5, 7: 0.75, 8: 0.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.75, 15: 0.75, 16: 0.75, 17: 1.0, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.75, 36: 1.0, 37: 0.75, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 0.75, 47: 1.0, 48: 0.75, 49: 0.5, 50: 1.0, 51: 0.5, 52: 0.5, 53: 0.5, 54: 0.5, 55: 1.0, 56: 0.75, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.75, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.75, 66: 0.75, 67: 1.0, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 0.75, 81: 0.75, 82: 0.5, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.5, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.5, 101: 1.0, 102: 0.5, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.75, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 0.75, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 0.25, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 1.0, 151: 0.75, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.5, 158: 0.5, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 1.0, 174: 0.75, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 0.75, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.0, 185: 0.75, 186: 1.0, 187: 0.75, 188: 0.75, 189: 1.0, 190: 0.5, 191: 0.5, 192: 1.0, 193: 1.0, 194: 1.0, 195: 0.5, 196: 0.75, 197: 1.0, 198: 0.75}

2024-05-04 08:44:42,285 [INFO] [9] TRAIN  loss: 0.20500630932841815 acc: 0.0
2024-05-04 08:44:42,285 [INFO] [9] TRAIN  loss dict: {'mse_loss': 0.20500630932841815}
2024-05-04 08:44:42,285 [INFO] [9] VALIDATION loss: 0.9441668780313598 VALIDATION  acc: 0.803030303030303
2024-05-04 08:44:42,285 [INFO] [9] VALIDATION  loss dict: {'mse_loss': 0.21375598194021167, 'classification_loss': 0.7304108959335759}
2024-05-04 08:44:42,286 [INFO] 
2024-05-04 08:46:00,330 [INFO] Step[50/1020]: training loss : 0.19056221276521682 TRAIN  loss dict:  {'mse_loss': 0.19056221276521682}
2024-05-04 08:46:42,044 [INFO] Step[100/1020]: training loss : 0.19891406431794167 TRAIN  loss dict:  {'mse_loss': 0.19891406431794167}
2024-05-04 08:47:28,716 [INFO] Step[150/1020]: training loss : 0.1965445190668106 TRAIN  loss dict:  {'mse_loss': 0.1965445190668106}
2024-05-04 08:48:08,678 [INFO] Step[200/1020]: training loss : 0.20043293312191962 TRAIN  loss dict:  {'mse_loss': 0.20043293312191962}
2024-05-04 08:48:53,655 [INFO] Step[250/1020]: training loss : 0.19915846094489098 TRAIN  loss dict:  {'mse_loss': 0.19915846094489098}
2024-05-04 08:49:35,599 [INFO] Step[300/1020]: training loss : 0.20202484160661696 TRAIN  loss dict:  {'mse_loss': 0.20202484160661696}
2024-05-04 08:50:15,536 [INFO] Step[350/1020]: training loss : 0.19039506375789642 TRAIN  loss dict:  {'mse_loss': 0.19039506375789642}
2024-05-04 08:50:56,060 [INFO] Step[400/1020]: training loss : 0.19334156975150107 TRAIN  loss dict:  {'mse_loss': 0.19334156975150107}
2024-05-04 08:51:35,208 [INFO] Step[450/1020]: training loss : 0.20075486868619918 TRAIN  loss dict:  {'mse_loss': 0.20075486868619918}
2024-05-04 08:52:17,564 [INFO] Step[500/1020]: training loss : 0.1897720903158188 TRAIN  loss dict:  {'mse_loss': 0.1897720903158188}
2024-05-04 08:52:57,543 [INFO] Step[550/1020]: training loss : 0.19649561494588852 TRAIN  loss dict:  {'mse_loss': 0.19649561494588852}
2024-05-04 08:53:39,573 [INFO] Step[600/1020]: training loss : 0.2054387879371643 TRAIN  loss dict:  {'mse_loss': 0.2054387879371643}
2024-05-04 08:54:19,045 [INFO] Step[650/1020]: training loss : 0.20898369044065476 TRAIN  loss dict:  {'mse_loss': 0.20898369044065476}
2024-05-04 08:54:57,792 [INFO] Step[700/1020]: training loss : 0.2087105070054531 TRAIN  loss dict:  {'mse_loss': 0.2087105070054531}
2024-05-04 08:55:47,018 [INFO] Step[750/1020]: training loss : 0.1989724324643612 TRAIN  loss dict:  {'mse_loss': 0.1989724324643612}
2024-05-04 08:56:34,128 [INFO] Step[800/1020]: training loss : 0.20242724418640137 TRAIN  loss dict:  {'mse_loss': 0.20242724418640137}
2024-05-04 08:57:20,948 [INFO] Step[850/1020]: training loss : 0.20339956268668175 TRAIN  loss dict:  {'mse_loss': 0.20339956268668175}
2024-05-04 08:58:05,631 [INFO] Step[900/1020]: training loss : 0.20332792669534683 TRAIN  loss dict:  {'mse_loss': 0.20332792669534683}
2024-05-04 08:58:49,664 [INFO] Step[950/1020]: training loss : 0.20165527373552322 TRAIN  loss dict:  {'mse_loss': 0.20165527373552322}
2024-05-04 08:59:35,311 [INFO] Step[1000/1020]: training loss : 0.19729395359754562 TRAIN  loss dict:  {'mse_loss': 0.19729395359754562}
2024-05-04 09:02:50,628 [INFO] Label accuracies statistics:
2024-05-04 09:02:50,629 [INFO] {0: 0.5, 1: 0.75, 2: 0.25, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.25, 7: 1.0, 8: 0.25, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 0.75, 14: 0.75, 15: 0.5, 16: 1.0, 17: 1.0, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 1.0, 23: 1.0, 24: 0.75, 25: 1.0, 26: 1.0, 27: 1.0, 28: 0.75, 29: 0.75, 30: 1.0, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 0.5, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.25, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.5, 52: 0.5, 53: 1.0, 54: 0.5, 55: 0.75, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 1.0, 66: 0.5, 67: 1.0, 68: 0.75, 69: 1.0, 70: 0.5, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.75, 83: 0.75, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.75, 95: 1.0, 96: 0.5, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 0.75, 112: 0.5, 113: 0.0, 114: 0.75, 115: 1.0, 116: 0.5, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.75, 121: 0.75, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 1.0, 146: 0.5, 147: 1.0, 148: 0.75, 149: 1.0, 150: 1.0, 151: 0.75, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.0, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.0, 185: 0.75, 186: 0.75, 187: 0.75, 188: 0.75, 189: 0.75, 190: 1.0, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-04 09:02:55,398 [INFO] [10] TRAIN  loss: 0.19953584503747668 acc: 0.0
2024-05-04 09:02:55,399 [INFO] [10] TRAIN  loss dict: {'mse_loss': 0.19953584503747668}
2024-05-04 09:02:55,399 [INFO] [10] VALIDATION loss: 0.9251623074665214 VALIDATION  acc: 0.8093434343434344
2024-05-04 09:02:55,399 [INFO] [10] VALIDATION  loss dict: {'mse_loss': 0.21444351952334847, 'classification_loss': 0.7107187858382898}
2024-05-04 09:02:55,400 [INFO] 
2024-05-04 09:04:18,605 [INFO] Step[50/1020]: training loss : 0.1843316611647606 TRAIN  loss dict:  {'mse_loss': 0.1843316611647606}
2024-05-04 09:05:03,978 [INFO] Step[100/1020]: training loss : 0.1838834199309349 TRAIN  loss dict:  {'mse_loss': 0.1838834199309349}
2024-05-04 09:05:54,209 [INFO] Step[150/1020]: training loss : 0.18975651144981384 TRAIN  loss dict:  {'mse_loss': 0.18975651144981384}
2024-05-04 09:06:41,403 [INFO] Step[200/1020]: training loss : 0.18184759050607682 TRAIN  loss dict:  {'mse_loss': 0.18184759050607682}
2024-05-04 09:07:28,548 [INFO] Step[250/1020]: training loss : 0.18643035620450973 TRAIN  loss dict:  {'mse_loss': 0.18643035620450973}
2024-05-04 09:08:14,820 [INFO] Step[300/1020]: training loss : 0.19838148802518846 TRAIN  loss dict:  {'mse_loss': 0.19838148802518846}
2024-05-04 09:09:02,556 [INFO] Step[350/1020]: training loss : 0.1910007329285145 TRAIN  loss dict:  {'mse_loss': 0.1910007329285145}
2024-05-04 09:09:45,453 [INFO] Step[400/1020]: training loss : 0.18936472073197363 TRAIN  loss dict:  {'mse_loss': 0.18936472073197363}
2024-05-04 09:10:34,157 [INFO] Step[450/1020]: training loss : 0.19124331593513488 TRAIN  loss dict:  {'mse_loss': 0.19124331593513488}
2024-05-04 09:11:19,216 [INFO] Step[500/1020]: training loss : 0.19278670221567154 TRAIN  loss dict:  {'mse_loss': 0.19278670221567154}
2024-05-04 09:12:06,679 [INFO] Step[550/1020]: training loss : 0.1939720869064331 TRAIN  loss dict:  {'mse_loss': 0.1939720869064331}
2024-05-04 09:12:52,058 [INFO] Step[600/1020]: training loss : 0.19543915033340453 TRAIN  loss dict:  {'mse_loss': 0.19543915033340453}
2024-05-04 09:13:34,423 [INFO] Step[650/1020]: training loss : 0.19717019230127333 TRAIN  loss dict:  {'mse_loss': 0.19717019230127333}
2024-05-04 09:14:15,321 [INFO] Step[700/1020]: training loss : 0.19463327318429946 TRAIN  loss dict:  {'mse_loss': 0.19463327318429946}
2024-05-04 09:15:02,905 [INFO] Step[750/1020]: training loss : 0.1909119802713394 TRAIN  loss dict:  {'mse_loss': 0.1909119802713394}
2024-05-04 09:15:47,719 [INFO] Step[800/1020]: training loss : 0.18476939365267753 TRAIN  loss dict:  {'mse_loss': 0.18476939365267753}
2024-05-04 09:16:32,459 [INFO] Step[850/1020]: training loss : 0.19263255894184111 TRAIN  loss dict:  {'mse_loss': 0.19263255894184111}
2024-05-04 09:17:18,632 [INFO] Step[900/1020]: training loss : 0.19402296379208564 TRAIN  loss dict:  {'mse_loss': 0.19402296379208564}
2024-05-04 09:18:03,265 [INFO] Step[950/1020]: training loss : 0.18860962450504304 TRAIN  loss dict:  {'mse_loss': 0.18860962450504304}
2024-05-04 09:18:45,253 [INFO] Step[1000/1020]: training loss : 0.18123524099588395 TRAIN  loss dict:  {'mse_loss': 0.18123524099588395}
2024-05-04 09:21:59,174 [INFO] Label accuracies statistics:
2024-05-04 09:21:59,175 [INFO] {0: 0.5, 1: 0.75, 2: 0.0, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.5, 7: 1.0, 8: 0.25, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 0.75, 14: 0.5, 15: 0.25, 16: 1.0, 17: 1.0, 18: 1.0, 19: 0.5, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.75, 28: 0.75, 29: 0.75, 30: 1.0, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.75, 38: 1.0, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.5, 52: 0.5, 53: 0.25, 54: 0.5, 55: 0.75, 56: 0.75, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.75, 61: 0.5, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.75, 66: 0.5, 67: 1.0, 68: 1.0, 69: 0.75, 70: 0.5, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.5, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.75, 95: 1.0, 96: 0.75, 97: 1.0, 98: 1.0, 99: 1.0, 100: 0.5, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 0.75, 108: 0.75, 109: 0.75, 110: 1.0, 111: 0.75, 112: 1.0, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 0.75, 119: 0.75, 120: 0.75, 121: 0.75, 122: 0.25, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 0.75, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 1.0, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.75, 158: 0.5, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 1.0, 168: 0.5, 169: 0.5, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 0.75, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 1.0, 185: 0.75, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-04 09:22:04,029 [INFO] [11] TRAIN  loss: 0.1897946059703827 acc: 0.0
2024-05-04 09:22:04,029 [INFO] [11] TRAIN  loss dict: {'mse_loss': 0.1897946059703827}
2024-05-04 09:22:04,029 [INFO] [11] VALIDATION loss: 0.9048831732661435 VALIDATION  acc: 0.8118686868686869
2024-05-04 09:22:04,029 [INFO] [11] VALIDATION  loss dict: {'mse_loss': 0.20466316167754356, 'classification_loss': 0.7002200131067028}
2024-05-04 09:22:04,029 [INFO] 
2024-05-04 09:23:23,431 [INFO] Step[50/1020]: training loss : 0.18770256027579307 TRAIN  loss dict:  {'mse_loss': 0.18770256027579307}
2024-05-04 09:24:03,150 [INFO] Step[100/1020]: training loss : 0.18825977936387062 TRAIN  loss dict:  {'mse_loss': 0.18825977936387062}
2024-05-04 09:24:45,180 [INFO] Step[150/1020]: training loss : 0.1872599482536316 TRAIN  loss dict:  {'mse_loss': 0.1872599482536316}
2024-05-04 09:25:30,691 [INFO] Step[200/1020]: training loss : 0.18315658435225488 TRAIN  loss dict:  {'mse_loss': 0.18315658435225488}
2024-05-04 09:26:14,249 [INFO] Step[250/1020]: training loss : 0.18676311433315276 TRAIN  loss dict:  {'mse_loss': 0.18676311433315276}
2024-05-04 09:26:54,173 [INFO] Step[300/1020]: training loss : 0.18783553957939148 TRAIN  loss dict:  {'mse_loss': 0.18783553957939148}
2024-05-04 09:27:37,505 [INFO] Step[350/1020]: training loss : 0.17533734798431397 TRAIN  loss dict:  {'mse_loss': 0.17533734798431397}
2024-05-04 09:28:21,415 [INFO] Step[400/1020]: training loss : 0.1818929570913315 TRAIN  loss dict:  {'mse_loss': 0.1818929570913315}
2024-05-04 09:29:05,369 [INFO] Step[450/1020]: training loss : 0.18871258378028868 TRAIN  loss dict:  {'mse_loss': 0.18871258378028868}
2024-05-04 09:29:51,803 [INFO] Step[500/1020]: training loss : 0.18061153441667557 TRAIN  loss dict:  {'mse_loss': 0.18061153441667557}
2024-05-04 09:30:37,550 [INFO] Step[550/1020]: training loss : 0.18775652453303338 TRAIN  loss dict:  {'mse_loss': 0.18775652453303338}
2024-05-04 09:31:21,716 [INFO] Step[600/1020]: training loss : 0.19161903470754624 TRAIN  loss dict:  {'mse_loss': 0.19161903470754624}
2024-05-04 09:32:00,729 [INFO] Step[650/1020]: training loss : 0.18912049740552903 TRAIN  loss dict:  {'mse_loss': 0.18912049740552903}
2024-05-04 09:32:47,624 [INFO] Step[700/1020]: training loss : 0.1887943847477436 TRAIN  loss dict:  {'mse_loss': 0.1887943847477436}
2024-05-04 09:33:40,899 [INFO] Step[750/1020]: training loss : 0.18884874731302262 TRAIN  loss dict:  {'mse_loss': 0.18884874731302262}
2024-05-04 09:34:26,900 [INFO] Step[800/1020]: training loss : 0.18188109695911409 TRAIN  loss dict:  {'mse_loss': 0.18188109695911409}
2024-05-04 09:35:11,897 [INFO] Step[850/1020]: training loss : 0.18179542943835258 TRAIN  loss dict:  {'mse_loss': 0.18179542943835258}
2024-05-04 09:35:51,602 [INFO] Step[900/1020]: training loss : 0.18811917722225188 TRAIN  loss dict:  {'mse_loss': 0.18811917722225188}
2024-05-04 09:36:36,325 [INFO] Step[950/1020]: training loss : 0.18670133233070374 TRAIN  loss dict:  {'mse_loss': 0.18670133233070374}
2024-05-04 09:37:20,652 [INFO] Step[1000/1020]: training loss : 0.18927153542637826 TRAIN  loss dict:  {'mse_loss': 0.18927153542637826}
2024-05-04 09:40:40,481 [INFO] Label accuracies statistics:
2024-05-04 09:40:40,495 [INFO] {0: 0.5, 1: 0.75, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.5, 7: 1.0, 8: 0.25, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 0.75, 14: 0.75, 15: 0.75, 16: 1.0, 17: 0.5, 18: 1.0, 19: 0.5, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.75, 29: 0.75, 30: 1.0, 31: 0.75, 32: 1.0, 33: 1.0, 34: 1.0, 35: 0.5, 36: 1.0, 37: 0.75, 38: 1.0, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 0.75, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.75, 65: 1.0, 66: 0.5, 67: 1.0, 68: 0.75, 69: 1.0, 70: 1.0, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.5, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 0.75, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 0.75, 145: 1.0, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.5, 159: 0.75, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.0, 172: 1.0, 173: 1.0, 174: 0.75, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 0.75, 182: 0.75, 183: 1.0, 184: 1.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 1.0, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-04 09:40:45,520 [INFO] [12] TRAIN  loss: 0.18619207952390698 acc: 0.0
2024-05-04 09:40:45,520 [INFO] [12] TRAIN  loss dict: {'mse_loss': 0.18619207952390698}
2024-05-04 09:40:45,520 [INFO] [12] VALIDATION loss: 0.8733155012808063 VALIDATION  acc: 0.8434343434343434
2024-05-04 09:40:45,520 [INFO] [12] VALIDATION  loss dict: {'mse_loss': 0.2002833355406318, 'classification_loss': 0.6730321630685017}
2024-05-04 09:40:45,521 [INFO] 
2024-05-04 09:42:22,591 [INFO] Step[50/1020]: training loss : 0.17591316252946854 TRAIN  loss dict:  {'mse_loss': 0.17591316252946854}
2024-05-04 09:43:26,595 [INFO] Step[100/1020]: training loss : 0.18269815444946289 TRAIN  loss dict:  {'mse_loss': 0.18269815444946289}
2024-05-04 09:44:22,906 [INFO] Step[150/1020]: training loss : 0.17736843913793565 TRAIN  loss dict:  {'mse_loss': 0.17736843913793565}
2024-05-04 09:45:23,347 [INFO] Step[200/1020]: training loss : 0.18183244422078132 TRAIN  loss dict:  {'mse_loss': 0.18183244422078132}
2024-05-04 09:46:12,784 [INFO] Step[250/1020]: training loss : 0.18758680671453476 TRAIN  loss dict:  {'mse_loss': 0.18758680671453476}
2024-05-04 09:46:59,539 [INFO] Step[300/1020]: training loss : 0.18409115344285965 TRAIN  loss dict:  {'mse_loss': 0.18409115344285965}
2024-05-04 09:47:52,208 [INFO] Step[350/1020]: training loss : 0.18469572231173514 TRAIN  loss dict:  {'mse_loss': 0.18469572231173514}
2024-05-04 09:48:38,151 [INFO] Step[400/1020]: training loss : 0.18622791081666945 TRAIN  loss dict:  {'mse_loss': 0.18622791081666945}
2024-05-04 09:49:22,069 [INFO] Step[450/1020]: training loss : 0.1819806344807148 TRAIN  loss dict:  {'mse_loss': 0.1819806344807148}
2024-05-04 09:50:11,394 [INFO] Step[500/1020]: training loss : 0.18308600842952727 TRAIN  loss dict:  {'mse_loss': 0.18308600842952727}
2024-05-04 09:51:00,048 [INFO] Step[550/1020]: training loss : 0.18913734942674637 TRAIN  loss dict:  {'mse_loss': 0.18913734942674637}
2024-05-04 09:51:49,032 [INFO] Step[600/1020]: training loss : 0.17435545682907105 TRAIN  loss dict:  {'mse_loss': 0.17435545682907105}
2024-05-04 09:52:51,262 [INFO] Step[650/1020]: training loss : 0.1775481466948986 TRAIN  loss dict:  {'mse_loss': 0.1775481466948986}
2024-05-04 09:53:57,510 [INFO] Step[700/1020]: training loss : 0.18051143556833268 TRAIN  loss dict:  {'mse_loss': 0.18051143556833268}
2024-05-04 09:54:50,277 [INFO] Step[750/1020]: training loss : 0.18656664162874223 TRAIN  loss dict:  {'mse_loss': 0.18656664162874223}
2024-05-04 09:55:48,326 [INFO] Step[800/1020]: training loss : 0.17956432357430457 TRAIN  loss dict:  {'mse_loss': 0.17956432357430457}
2024-05-04 09:56:46,259 [INFO] Step[850/1020]: training loss : 0.17669436559081078 TRAIN  loss dict:  {'mse_loss': 0.17669436559081078}
2024-05-04 09:57:39,276 [INFO] Step[900/1020]: training loss : 0.18646569937467575 TRAIN  loss dict:  {'mse_loss': 0.18646569937467575}
2024-05-04 09:58:31,910 [INFO] Step[950/1020]: training loss : 0.1882161784172058 TRAIN  loss dict:  {'mse_loss': 0.1882161784172058}
2024-05-04 09:59:14,708 [INFO] Step[1000/1020]: training loss : 0.1865929938852787 TRAIN  loss dict:  {'mse_loss': 0.1865929938852787}
2024-05-04 10:02:34,706 [INFO] Label accuracies statistics:
2024-05-04 10:02:34,716 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.5, 7: 1.0, 8: 0.25, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.75, 15: 0.5, 16: 0.75, 17: 0.5, 18: 1.0, 19: 0.75, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.75, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 0.5, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 1.0, 48: 0.5, 49: 0.25, 50: 1.0, 51: 0.75, 52: 0.5, 53: 0.5, 54: 0.5, 55: 0.75, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.75, 65: 1.0, 66: 0.75, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.5, 71: 1.0, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 0.75, 92: 1.0, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.5, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.75, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 0.75, 112: 0.5, 113: 0.0, 114: 1.0, 115: 1.0, 116: 0.75, 117: 0.75, 118: 0.75, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 1.0, 146: 0.25, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.75, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.75, 173: 1.0, 174: 0.75, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.5, 183: 1.0, 184: 0.5, 185: 0.75, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.5, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.75}

2024-05-04 10:02:39,430 [INFO] [13] TRAIN  loss: 0.18252992146447594 acc: 0.0
2024-05-04 10:02:39,430 [INFO] [13] TRAIN  loss dict: {'mse_loss': 0.18252992146447594}
2024-05-04 10:02:39,430 [INFO] [13] VALIDATION loss: 0.8687524135516147 VALIDATION  acc: 0.8320707070707071
2024-05-04 10:02:39,431 [INFO] [13] VALIDATION  loss dict: {'mse_loss': 0.201157576658509, 'classification_loss': 0.6675948359170985}
2024-05-04 10:02:39,431 [INFO] 
2024-05-04 10:04:04,999 [INFO] Step[50/1020]: training loss : 0.1848864211142063 TRAIN  loss dict:  {'mse_loss': 0.1848864211142063}
2024-05-04 10:04:48,536 [INFO] Step[100/1020]: training loss : 0.17184201195836069 TRAIN  loss dict:  {'mse_loss': 0.17184201195836069}
2024-05-04 10:05:43,162 [INFO] Step[150/1020]: training loss : 0.17080675646662713 TRAIN  loss dict:  {'mse_loss': 0.17080675646662713}
2024-05-04 10:06:39,601 [INFO] Step[200/1020]: training loss : 0.16934761881828309 TRAIN  loss dict:  {'mse_loss': 0.16934761881828309}
2024-05-04 10:07:43,046 [INFO] Step[250/1020]: training loss : 0.17743413239717484 TRAIN  loss dict:  {'mse_loss': 0.17743413239717484}
2024-05-04 10:08:41,669 [INFO] Step[300/1020]: training loss : 0.17825556695461273 TRAIN  loss dict:  {'mse_loss': 0.17825556695461273}
2024-05-04 10:09:30,113 [INFO] Step[350/1020]: training loss : 0.1854605033993721 TRAIN  loss dict:  {'mse_loss': 0.1854605033993721}
2024-05-04 10:10:25,396 [INFO] Step[400/1020]: training loss : 0.18348710358142853 TRAIN  loss dict:  {'mse_loss': 0.18348710358142853}
2024-05-04 10:11:14,577 [INFO] Step[450/1020]: training loss : 0.17483777284622193 TRAIN  loss dict:  {'mse_loss': 0.17483777284622193}
2024-05-04 10:12:05,547 [INFO] Step[500/1020]: training loss : 0.1850753679871559 TRAIN  loss dict:  {'mse_loss': 0.1850753679871559}
2024-05-04 10:13:01,416 [INFO] Step[550/1020]: training loss : 0.17385445684194564 TRAIN  loss dict:  {'mse_loss': 0.17385445684194564}
2024-05-04 10:14:01,195 [INFO] Step[600/1020]: training loss : 0.18441280707716942 TRAIN  loss dict:  {'mse_loss': 0.18441280707716942}
2024-05-04 10:14:52,044 [INFO] Step[650/1020]: training loss : 0.18517813622951507 TRAIN  loss dict:  {'mse_loss': 0.18517813622951507}
2024-05-04 10:15:39,093 [INFO] Step[700/1020]: training loss : 0.1743221801519394 TRAIN  loss dict:  {'mse_loss': 0.1743221801519394}
2024-05-04 10:16:32,068 [INFO] Step[750/1020]: training loss : 0.1792955319583416 TRAIN  loss dict:  {'mse_loss': 0.1792955319583416}
2024-05-04 10:17:20,303 [INFO] Step[800/1020]: training loss : 0.17876518830657007 TRAIN  loss dict:  {'mse_loss': 0.17876518830657007}
2024-05-04 10:18:21,430 [INFO] Step[850/1020]: training loss : 0.17445720195770265 TRAIN  loss dict:  {'mse_loss': 0.17445720195770265}
2024-05-04 10:19:16,191 [INFO] Step[900/1020]: training loss : 0.17694838389754294 TRAIN  loss dict:  {'mse_loss': 0.17694838389754294}
2024-05-04 10:20:14,346 [INFO] Step[950/1020]: training loss : 0.177410352230072 TRAIN  loss dict:  {'mse_loss': 0.177410352230072}
2024-05-04 10:21:09,639 [INFO] Step[1000/1020]: training loss : 0.18018746867775917 TRAIN  loss dict:  {'mse_loss': 0.18018746867775917}
2024-05-04 10:25:02,721 [INFO] Label accuracies statistics:
2024-05-04 10:25:02,722 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.5, 7: 1.0, 8: 0.5, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.5, 15: 0.75, 16: 0.75, 17: 1.0, 18: 1.0, 19: 0.25, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.75, 29: 0.75, 30: 1.0, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 0.5, 38: 1.0, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 1.0, 51: 0.5, 52: 0.5, 53: 0.5, 54: 0.5, 55: 0.75, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.75, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.75, 66: 0.5, 67: 1.0, 68: 0.25, 69: 1.0, 70: 1.0, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.5, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 0.75, 92: 0.75, 93: 0.75, 94: 1.0, 95: 1.0, 96: 1.0, 97: 1.0, 98: 1.0, 99: 1.0, 100: 0.5, 101: 0.75, 102: 0.5, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.25, 113: 0.0, 114: 1.0, 115: 0.75, 116: 0.75, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 0.75, 130: 0.75, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 1.0, 146: 0.25, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.0, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.75, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 1.0, 165: 1.0, 166: 0.75, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 0.75, 182: 0.75, 183: 1.0, 184: 0.5, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 1.0, 190: 1.0, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-04 10:25:08,679 [INFO] [14] TRAIN  loss: 0.17864510434515335 acc: 0.0
2024-05-04 10:25:08,680 [INFO] [14] TRAIN  loss dict: {'mse_loss': 0.17864510434515335}
2024-05-04 10:25:08,681 [INFO] [14] VALIDATION loss: 0.8453728635278013 VALIDATION  acc: 0.8295454545454546
2024-05-04 10:25:08,681 [INFO] [14] VALIDATION  loss dict: {'mse_loss': 0.19931735941255935, 'classification_loss': 0.6460555020327012}
2024-05-04 10:25:08,683 [INFO] 
2024-05-04 10:26:39,171 [INFO] Step[50/1020]: training loss : 0.17974104076623917 TRAIN  loss dict:  {'mse_loss': 0.17974104076623917}
2024-05-04 10:27:32,860 [INFO] Step[100/1020]: training loss : 0.17833594024181365 TRAIN  loss dict:  {'mse_loss': 0.17833594024181365}
2024-05-04 10:28:28,367 [INFO] Step[150/1020]: training loss : 0.17773537799715997 TRAIN  loss dict:  {'mse_loss': 0.17773537799715997}
2024-05-04 10:29:20,466 [INFO] Step[200/1020]: training loss : 0.18033817917108536 TRAIN  loss dict:  {'mse_loss': 0.18033817917108536}
2024-05-04 10:30:13,298 [INFO] Step[250/1020]: training loss : 0.18761747792363168 TRAIN  loss dict:  {'mse_loss': 0.18761747792363168}
2024-05-04 10:31:09,938 [INFO] Step[300/1020]: training loss : 0.17402928113937377 TRAIN  loss dict:  {'mse_loss': 0.17402928113937377}
2024-05-04 10:32:13,331 [INFO] Step[350/1020]: training loss : 0.17368756845593453 TRAIN  loss dict:  {'mse_loss': 0.17368756845593453}
2024-05-04 10:33:08,067 [INFO] Step[400/1020]: training loss : 0.17059160232543946 TRAIN  loss dict:  {'mse_loss': 0.17059160232543946}
2024-05-04 10:34:06,936 [INFO] Step[450/1020]: training loss : 0.18090119674801827 TRAIN  loss dict:  {'mse_loss': 0.18090119674801827}
2024-05-04 10:35:11,857 [INFO] Step[500/1020]: training loss : 0.1784818534553051 TRAIN  loss dict:  {'mse_loss': 0.1784818534553051}
2024-05-04 10:36:09,156 [INFO] Step[550/1020]: training loss : 0.18062792479991913 TRAIN  loss dict:  {'mse_loss': 0.18062792479991913}
2024-05-04 10:37:11,907 [INFO] Step[600/1020]: training loss : 0.16864006355404854 TRAIN  loss dict:  {'mse_loss': 0.16864006355404854}
2024-05-04 10:38:15,242 [INFO] Step[650/1020]: training loss : 0.17958321705460548 TRAIN  loss dict:  {'mse_loss': 0.17958321705460548}
2024-05-04 10:39:15,822 [INFO] Step[700/1020]: training loss : 0.16592242434620857 TRAIN  loss dict:  {'mse_loss': 0.16592242434620857}
2024-05-04 10:40:13,735 [INFO] Step[750/1020]: training loss : 0.17146188855171204 TRAIN  loss dict:  {'mse_loss': 0.17146188855171204}
2024-05-04 10:41:11,870 [INFO] Step[800/1020]: training loss : 0.1747882190346718 TRAIN  loss dict:  {'mse_loss': 0.1747882190346718}
2024-05-04 10:42:10,982 [INFO] Step[850/1020]: training loss : 0.1743856419622898 TRAIN  loss dict:  {'mse_loss': 0.1743856419622898}
2024-05-04 10:43:08,088 [INFO] Step[900/1020]: training loss : 0.1777560855448246 TRAIN  loss dict:  {'mse_loss': 0.1777560855448246}
2024-05-04 10:43:57,436 [INFO] Step[950/1020]: training loss : 0.1761577333509922 TRAIN  loss dict:  {'mse_loss': 0.1761577333509922}
2024-05-04 10:44:55,854 [INFO] Step[1000/1020]: training loss : 0.17404396891593932 TRAIN  loss dict:  {'mse_loss': 0.17404396891593932}
2024-05-04 10:49:05,220 [INFO] Label accuracies statistics:
2024-05-04 10:49:05,240 [INFO] {0: 1.0, 1: 1.0, 2: 0.25, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.5, 7: 1.0, 8: 0.25, 9: 0.75, 10: 1.0, 11: 1.0, 12: 0.75, 13: 1.0, 14: 0.5, 15: 0.25, 16: 1.0, 17: 0.75, 18: 1.0, 19: 0.5, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 1.0, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.25, 55: 0.75, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.75, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.75, 65: 1.0, 66: 0.75, 67: 1.0, 68: 0.75, 69: 1.0, 70: 1.0, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 0.75, 92: 0.75, 93: 1.0, 94: 0.5, 95: 1.0, 96: 0.5, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.5, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 0.75, 112: 0.75, 113: 0.0, 114: 1.0, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.75, 121: 0.5, 122: 1.0, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.5, 144: 1.0, 145: 1.0, 146: 0.75, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.75, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.5, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 0.75, 181: 0.75, 182: 0.75, 183: 1.0, 184: 0.75, 185: 0.75, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.75}

2024-05-04 10:49:11,442 [INFO] [15] TRAIN  loss: 0.1763057854026556 acc: 0.0
2024-05-04 10:49:11,444 [INFO] [15] TRAIN  loss dict: {'mse_loss': 0.1763057854026556}
2024-05-04 10:49:11,446 [INFO] [15] VALIDATION loss: 0.8363053649287633 VALIDATION  acc: 0.8282828282828283
2024-05-04 10:49:11,447 [INFO] [15] VALIDATION  loss dict: {'mse_loss': 0.1972141967277334, 'classification_loss': 0.6390911721544472}
2024-05-04 10:49:11,448 [INFO] 
2024-05-04 10:50:58,807 [INFO] Step[50/1020]: training loss : 0.17091944932937622 TRAIN  loss dict:  {'mse_loss': 0.17091944932937622}
2024-05-04 10:51:53,970 [INFO] Step[100/1020]: training loss : 0.16703373417258263 TRAIN  loss dict:  {'mse_loss': 0.16703373417258263}
2024-05-04 10:52:50,281 [INFO] Step[150/1020]: training loss : 0.17572978109121323 TRAIN  loss dict:  {'mse_loss': 0.17572978109121323}
2024-05-04 10:53:50,514 [INFO] Step[200/1020]: training loss : 0.17631186321377754 TRAIN  loss dict:  {'mse_loss': 0.17631186321377754}
2024-05-04 10:54:58,397 [INFO] Step[250/1020]: training loss : 0.16676327377557754 TRAIN  loss dict:  {'mse_loss': 0.16676327377557754}
2024-05-04 10:55:54,269 [INFO] Step[300/1020]: training loss : 0.16982636824250222 TRAIN  loss dict:  {'mse_loss': 0.16982636824250222}
2024-05-04 10:56:47,161 [INFO] Step[350/1020]: training loss : 0.1742405539751053 TRAIN  loss dict:  {'mse_loss': 0.1742405539751053}
2024-05-04 10:57:50,710 [INFO] Step[400/1020]: training loss : 0.16916797056794167 TRAIN  loss dict:  {'mse_loss': 0.16916797056794167}
2024-05-04 10:58:45,197 [INFO] Step[450/1020]: training loss : 0.1821748934686184 TRAIN  loss dict:  {'mse_loss': 0.1821748934686184}
2024-05-04 10:59:38,624 [INFO] Step[500/1020]: training loss : 0.1812622457742691 TRAIN  loss dict:  {'mse_loss': 0.1812622457742691}
2024-05-04 11:00:26,143 [INFO] Step[550/1020]: training loss : 0.1700898154079914 TRAIN  loss dict:  {'mse_loss': 0.1700898154079914}
2024-05-04 11:01:18,275 [INFO] Step[600/1020]: training loss : 0.18336941197514534 TRAIN  loss dict:  {'mse_loss': 0.18336941197514534}
2024-05-04 11:02:13,546 [INFO] Step[650/1020]: training loss : 0.18268145456910134 TRAIN  loss dict:  {'mse_loss': 0.18268145456910134}
2024-05-04 11:03:06,478 [INFO] Step[700/1020]: training loss : 0.17820187881588936 TRAIN  loss dict:  {'mse_loss': 0.17820187881588936}
2024-05-04 11:03:57,063 [INFO] Step[750/1020]: training loss : 0.18233154237270355 TRAIN  loss dict:  {'mse_loss': 0.18233154237270355}
2024-05-04 11:04:56,060 [INFO] Step[800/1020]: training loss : 0.17944576010107993 TRAIN  loss dict:  {'mse_loss': 0.17944576010107993}
2024-05-04 11:05:46,927 [INFO] Step[850/1020]: training loss : 0.18628722324967384 TRAIN  loss dict:  {'mse_loss': 0.18628722324967384}
2024-05-04 11:06:36,768 [INFO] Step[900/1020]: training loss : 0.17488463550806047 TRAIN  loss dict:  {'mse_loss': 0.17488463550806047}
2024-05-04 11:07:27,636 [INFO] Step[950/1020]: training loss : 0.17389197617769242 TRAIN  loss dict:  {'mse_loss': 0.17389197617769242}
2024-05-04 11:08:30,565 [INFO] Step[1000/1020]: training loss : 0.16440468341112136 TRAIN  loss dict:  {'mse_loss': 0.16440468341112136}
2024-05-04 11:12:24,165 [INFO] Label accuracies statistics:
2024-05-04 11:12:24,180 [INFO] {0: 0.5, 1: 1.0, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.5, 7: 1.0, 8: 0.5, 9: 0.75, 10: 1.0, 11: 1.0, 12: 0.75, 13: 1.0, 14: 0.75, 15: 0.5, 16: 0.75, 17: 0.75, 18: 1.0, 19: 1.0, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 1.0, 25: 0.75, 26: 0.75, 27: 1.0, 28: 0.75, 29: 0.75, 30: 1.0, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 0.5, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 1.0, 51: 0.75, 52: 0.5, 53: 0.25, 54: 0.5, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.75, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.75, 69: 1.0, 70: 1.0, 71: 1.0, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 0.75, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 0.75, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.75, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.25, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 0.75, 112: 1.0, 113: 0.0, 114: 1.0, 115: 1.0, 116: 0.5, 117: 0.75, 118: 0.75, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.5, 128: 0.75, 129: 0.75, 130: 0.75, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 1.0, 146: 0.75, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.75, 161: 0.75, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 0.75, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.75, 185: 0.75, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-04 11:12:24,219 [INFO] [16] TRAIN  loss: 0.17536138979827656 acc: 0.0
2024-05-04 11:12:24,220 [INFO] [16] TRAIN  loss dict: {'mse_loss': 0.17536138979827656}
2024-05-04 11:12:24,220 [INFO] [16] VALIDATION loss: 0.8372098890067351 VALIDATION  acc: 0.8396464646464646
2024-05-04 11:12:24,220 [INFO] [16] VALIDATION  loss dict: {'mse_loss': 0.1920867958905721, 'classification_loss': 0.6451230939099039}
2024-05-04 11:12:24,220 [INFO] 
2024-05-04 11:14:00,363 [INFO] Step[50/1020]: training loss : 0.16378586307168008 TRAIN  loss dict:  {'mse_loss': 0.16378586307168008}
2024-05-04 11:15:01,424 [INFO] Step[100/1020]: training loss : 0.16933466657996177 TRAIN  loss dict:  {'mse_loss': 0.16933466657996177}
2024-05-04 11:15:55,727 [INFO] Step[150/1020]: training loss : 0.16397449776530265 TRAIN  loss dict:  {'mse_loss': 0.16397449776530265}
2024-05-04 11:16:51,742 [INFO] Step[200/1020]: training loss : 0.16548009142279624 TRAIN  loss dict:  {'mse_loss': 0.16548009142279624}
2024-05-04 11:17:49,506 [INFO] Step[250/1020]: training loss : 0.16410917565226554 TRAIN  loss dict:  {'mse_loss': 0.16410917565226554}
2024-05-04 11:19:00,037 [INFO] Step[300/1020]: training loss : 0.17223836585879326 TRAIN  loss dict:  {'mse_loss': 0.17223836585879326}
2024-05-04 11:19:55,359 [INFO] Step[350/1020]: training loss : 0.16976281225681306 TRAIN  loss dict:  {'mse_loss': 0.16976281225681306}
2024-05-04 11:20:41,120 [INFO] Step[400/1020]: training loss : 0.17289328768849374 TRAIN  loss dict:  {'mse_loss': 0.17289328768849374}
2024-05-04 11:21:28,929 [INFO] Step[450/1020]: training loss : 0.16920193657279015 TRAIN  loss dict:  {'mse_loss': 0.16920193657279015}
2024-05-04 11:22:16,312 [INFO] Step[500/1020]: training loss : 0.1701347939670086 TRAIN  loss dict:  {'mse_loss': 0.1701347939670086}
2024-05-04 11:23:06,521 [INFO] Step[550/1020]: training loss : 0.16574870854616164 TRAIN  loss dict:  {'mse_loss': 0.16574870854616164}
2024-05-04 11:23:51,719 [INFO] Step[600/1020]: training loss : 0.17939052388072013 TRAIN  loss dict:  {'mse_loss': 0.17939052388072013}
2024-05-04 11:24:32,109 [INFO] Step[650/1020]: training loss : 0.17366437137126922 TRAIN  loss dict:  {'mse_loss': 0.17366437137126922}
2024-05-04 11:25:14,962 [INFO] Step[700/1020]: training loss : 0.1665823967754841 TRAIN  loss dict:  {'mse_loss': 0.1665823967754841}
2024-05-04 11:25:56,433 [INFO] Step[750/1020]: training loss : 0.17698913633823396 TRAIN  loss dict:  {'mse_loss': 0.17698913633823396}
2024-05-04 11:26:43,369 [INFO] Step[800/1020]: training loss : 0.17551408872008323 TRAIN  loss dict:  {'mse_loss': 0.17551408872008323}
2024-05-04 11:27:30,664 [INFO] Step[850/1020]: training loss : 0.16925100713968277 TRAIN  loss dict:  {'mse_loss': 0.16925100713968277}
2024-05-04 11:28:20,242 [INFO] Step[900/1020]: training loss : 0.18018479406833648 TRAIN  loss dict:  {'mse_loss': 0.18018479406833648}
2024-05-04 11:29:10,488 [INFO] Step[950/1020]: training loss : 0.1686853913962841 TRAIN  loss dict:  {'mse_loss': 0.1686853913962841}
2024-05-04 11:29:59,194 [INFO] Step[1000/1020]: training loss : 0.16684819921851157 TRAIN  loss dict:  {'mse_loss': 0.16684819921851157}
2024-05-04 11:33:29,801 [INFO] Label accuracies statistics:
2024-05-04 11:33:29,822 [INFO] {0: 0.5, 1: 1.0, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.5, 7: 1.0, 8: 0.75, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.5, 13: 1.0, 14: 0.5, 15: 0.5, 16: 1.0, 17: 0.5, 18: 0.75, 19: 0.75, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.75, 28: 0.5, 29: 0.75, 30: 0.75, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 0.75, 44: 1.0, 45: 1.0, 46: 0.75, 47: 1.0, 48: 0.75, 49: 0.25, 50: 1.0, 51: 0.75, 52: 0.25, 53: 0.5, 54: 0.5, 55: 0.75, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 1.0, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.75, 65: 1.0, 66: 0.5, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.75, 71: 1.0, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 1.0, 95: 1.0, 96: 0.5, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.5, 101: 0.75, 102: 0.75, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.0, 114: 1.0, 115: 1.0, 116: 0.75, 117: 1.0, 118: 0.75, 119: 0.75, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 0.75, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 1.0, 146: 0.25, 147: 1.0, 148: 0.75, 149: 0.75, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.0, 154: 1.0, 155: 1.0, 156: 1.0, 157: 1.0, 158: 0.75, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.5, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 0.75, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 0.75, 189: 1.0, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 1.0}

2024-05-04 11:33:29,851 [INFO] [17] TRAIN  loss: 0.17024067025266443 acc: 0.0
2024-05-04 11:33:29,852 [INFO] [17] TRAIN  loss dict: {'mse_loss': 0.17024067025266443}
2024-05-04 11:33:29,852 [INFO] [17] VALIDATION loss: 0.8577874019139945 VALIDATION  acc: 0.8295454545454546
2024-05-04 11:33:29,852 [INFO] [17] VALIDATION  loss dict: {'mse_loss': 0.19486579859648087, 'classification_loss': 0.6629216011291408}
2024-05-04 11:33:29,852 [INFO] 
2024-05-04 11:35:15,788 [INFO] Step[50/1020]: training loss : 0.1689489886164665 TRAIN  loss dict:  {'mse_loss': 0.1689489886164665}
2024-05-04 11:36:06,197 [INFO] Step[100/1020]: training loss : 0.16961683616042136 TRAIN  loss dict:  {'mse_loss': 0.16961683616042136}
2024-05-04 11:36:55,541 [INFO] Step[150/1020]: training loss : 0.1663017025589943 TRAIN  loss dict:  {'mse_loss': 0.1663017025589943}
2024-05-04 11:37:39,513 [INFO] Step[200/1020]: training loss : 0.1660550780594349 TRAIN  loss dict:  {'mse_loss': 0.1660550780594349}
2024-05-04 11:38:27,194 [INFO] Step[250/1020]: training loss : 0.16408330097794532 TRAIN  loss dict:  {'mse_loss': 0.16408330097794532}
2024-05-04 11:39:13,493 [INFO] Step[300/1020]: training loss : 0.16335573002696038 TRAIN  loss dict:  {'mse_loss': 0.16335573002696038}
2024-05-04 11:39:55,386 [INFO] Step[350/1020]: training loss : 0.16754427373409272 TRAIN  loss dict:  {'mse_loss': 0.16754427373409272}
2024-05-04 11:40:45,493 [INFO] Step[400/1020]: training loss : 0.16878536179661752 TRAIN  loss dict:  {'mse_loss': 0.16878536179661752}
2024-05-04 11:41:37,671 [INFO] Step[450/1020]: training loss : 0.17124544128775596 TRAIN  loss dict:  {'mse_loss': 0.17124544128775596}
2024-05-04 11:42:21,196 [INFO] Step[500/1020]: training loss : 0.17010660827159882 TRAIN  loss dict:  {'mse_loss': 0.17010660827159882}
2024-05-04 11:43:05,737 [INFO] Step[550/1020]: training loss : 0.17226248905062674 TRAIN  loss dict:  {'mse_loss': 0.17226248905062674}
2024-05-04 11:43:55,433 [INFO] Step[600/1020]: training loss : 0.16591916739940643 TRAIN  loss dict:  {'mse_loss': 0.16591916739940643}
2024-05-04 11:44:53,565 [INFO] Step[650/1020]: training loss : 0.17133329629898073 TRAIN  loss dict:  {'mse_loss': 0.17133329629898073}
2024-05-04 11:45:45,725 [INFO] Step[700/1020]: training loss : 0.16923028960824013 TRAIN  loss dict:  {'mse_loss': 0.16923028960824013}
2024-05-04 11:46:35,841 [INFO] Step[750/1020]: training loss : 0.16944694131612778 TRAIN  loss dict:  {'mse_loss': 0.16944694131612778}
2024-05-04 11:47:21,500 [INFO] Step[800/1020]: training loss : 0.1770782920718193 TRAIN  loss dict:  {'mse_loss': 0.1770782920718193}
2024-05-04 11:48:15,375 [INFO] Step[850/1020]: training loss : 0.17053295329213142 TRAIN  loss dict:  {'mse_loss': 0.17053295329213142}
2024-05-04 11:49:00,205 [INFO] Step[900/1020]: training loss : 0.17034528881311417 TRAIN  loss dict:  {'mse_loss': 0.17034528881311417}
2024-05-04 11:49:44,248 [INFO] Step[950/1020]: training loss : 0.1694482359290123 TRAIN  loss dict:  {'mse_loss': 0.1694482359290123}
2024-05-04 11:50:36,643 [INFO] Step[1000/1020]: training loss : 0.16851076140999793 TRAIN  loss dict:  {'mse_loss': 0.16851076140999793}
2024-05-04 11:54:01,303 [INFO] Label accuracies statistics:
2024-05-04 11:54:01,303 [INFO] {0: 0.5, 1: 0.75, 2: 0.75, 3: 0.75, 4: 0.3333333333333333, 5: 1.0, 6: 0.5, 7: 1.0, 8: 0.5, 9: 1.0, 10: 0.75, 11: 0.75, 12: 1.0, 13: 1.0, 14: 0.5, 15: 0.5, 16: 0.75, 17: 0.75, 18: 1.0, 19: 0.75, 20: 0.5, 21: 0.75, 22: 1.0, 23: 1.0, 24: 1.0, 25: 0.5, 26: 1.0, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.75, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 1.0, 51: 0.5, 52: 0.75, 53: 0.75, 54: 0.5, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 1.0, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.75, 65: 1.0, 66: 0.5, 67: 1.0, 68: 1.0, 69: 1.0, 70: 1.0, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.75, 97: 1.0, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.75, 140: 0.5, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 1.0, 157: 1.0, 158: 0.5, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.75, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.5, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 1.0, 185: 0.75, 186: 1.0, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-05-04 11:54:06,067 [INFO] [18] TRAIN  loss: 0.1691252787469649 acc: 0.0
2024-05-04 11:54:06,068 [INFO] [18] TRAIN  loss dict: {'mse_loss': 0.1691252787469649}
2024-05-04 11:54:06,068 [INFO] [18] VALIDATION loss: 0.8100520803245029 VALIDATION  acc: 0.8522727272727273
2024-05-04 11:54:06,068 [INFO] [18] VALIDATION  loss dict: {'mse_loss': 0.1912889201758486, 'classification_loss': 0.6187631575534158}
2024-05-04 11:54:06,069 [INFO] 
2024-05-04 11:55:27,836 [INFO] Step[50/1020]: training loss : 0.1653084483742714 TRAIN  loss dict:  {'mse_loss': 0.1653084483742714}
2024-05-04 11:56:16,707 [INFO] Step[100/1020]: training loss : 0.17069856584072113 TRAIN  loss dict:  {'mse_loss': 0.17069856584072113}
2024-05-04 11:57:03,632 [INFO] Step[150/1020]: training loss : 0.16227003529667855 TRAIN  loss dict:  {'mse_loss': 0.16227003529667855}
2024-05-04 11:57:47,164 [INFO] Step[200/1020]: training loss : 0.16309634044766427 TRAIN  loss dict:  {'mse_loss': 0.16309634044766427}
2024-05-04 11:58:29,556 [INFO] Step[250/1020]: training loss : 0.16558494433760643 TRAIN  loss dict:  {'mse_loss': 0.16558494433760643}
2024-05-04 11:59:13,146 [INFO] Step[300/1020]: training loss : 0.17606304153800012 TRAIN  loss dict:  {'mse_loss': 0.17606304153800012}
2024-05-04 11:59:57,920 [INFO] Step[350/1020]: training loss : 0.16766858905553816 TRAIN  loss dict:  {'mse_loss': 0.16766858905553816}
2024-05-04 12:00:40,436 [INFO] Step[400/1020]: training loss : 0.16993296429514884 TRAIN  loss dict:  {'mse_loss': 0.16993296429514884}
2024-05-04 12:01:27,466 [INFO] Step[450/1020]: training loss : 0.16649153634905814 TRAIN  loss dict:  {'mse_loss': 0.16649153634905814}
2024-05-04 12:02:17,501 [INFO] Step[500/1020]: training loss : 0.17070795103907585 TRAIN  loss dict:  {'mse_loss': 0.17070795103907585}
2024-05-04 12:03:00,064 [INFO] Step[550/1020]: training loss : 0.15871062204241754 TRAIN  loss dict:  {'mse_loss': 0.15871062204241754}
2024-05-04 12:03:41,682 [INFO] Step[600/1020]: training loss : 0.16857290610671044 TRAIN  loss dict:  {'mse_loss': 0.16857290610671044}
2024-05-04 12:04:26,880 [INFO] Step[650/1020]: training loss : 0.166176615357399 TRAIN  loss dict:  {'mse_loss': 0.166176615357399}
2024-05-04 12:05:23,929 [INFO] Step[700/1020]: training loss : 0.17260255351662634 TRAIN  loss dict:  {'mse_loss': 0.17260255351662634}
2024-05-04 12:06:21,315 [INFO] Step[750/1020]: training loss : 0.17221230655908584 TRAIN  loss dict:  {'mse_loss': 0.17221230655908584}
2024-05-04 12:07:10,233 [INFO] Step[800/1020]: training loss : 0.1690394462645054 TRAIN  loss dict:  {'mse_loss': 0.1690394462645054}
2024-05-04 12:07:51,501 [INFO] Step[850/1020]: training loss : 0.17140496537089348 TRAIN  loss dict:  {'mse_loss': 0.17140496537089348}
2024-05-04 12:08:33,452 [INFO] Step[900/1020]: training loss : 0.1809667432308197 TRAIN  loss dict:  {'mse_loss': 0.1809667432308197}
2024-05-04 12:09:16,862 [INFO] Step[950/1020]: training loss : 0.170371353328228 TRAIN  loss dict:  {'mse_loss': 0.170371353328228}
2024-05-04 12:09:55,778 [INFO] Step[1000/1020]: training loss : 0.17039693787693977 TRAIN  loss dict:  {'mse_loss': 0.17039693787693977}
2024-05-04 12:12:55,371 [INFO] Label accuracies statistics:
2024-05-04 12:12:55,381 [INFO] {0: 0.5, 1: 1.0, 2: 0.5, 3: 1.0, 4: 0.6666666666666666, 5: 1.0, 6: 0.25, 7: 1.0, 8: 0.5, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.5, 13: 0.75, 14: 0.75, 15: 0.75, 16: 1.0, 17: 0.5, 18: 1.0, 19: 0.5, 20: 0.75, 21: 0.75, 22: 1.0, 23: 1.0, 24: 0.75, 25: 0.5, 26: 1.0, 27: 1.0, 28: 0.5, 29: 1.0, 30: 0.75, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 1.0, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 1.0, 51: 1.0, 52: 0.75, 53: 0.75, 54: 0.5, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 1.0, 66: 0.75, 67: 1.0, 68: 0.5, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.0, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.75, 95: 1.0, 96: 0.25, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 0.75, 112: 0.5, 113: 0.0, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.75, 118: 0.75, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.25, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 0.75, 129: 0.75, 130: 0.75, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 0.75, 145: 1.0, 146: 0.75, 147: 1.0, 148: 0.5, 149: 0.75, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.75, 159: 0.75, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.75, 185: 0.75, 186: 1.0, 187: 1.0, 188: 0.75, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-04 12:12:55,438 [INFO] [19] TRAIN  loss: 0.1689091124663166 acc: 0.0
2024-05-04 12:12:55,438 [INFO] [19] TRAIN  loss dict: {'mse_loss': 0.1689091124663166}
2024-05-04 12:12:55,439 [INFO] [19] VALIDATION loss: 0.9137179820676042 VALIDATION  acc: 0.8257575757575758
2024-05-04 12:12:55,439 [INFO] [19] VALIDATION  loss dict: {'mse_loss': 0.19860342017026864, 'classification_loss': 0.7151145623771079}
2024-05-04 12:12:55,439 [INFO] 
2024-05-04 12:14:14,260 [INFO] Step[50/1020]: training loss : 0.16002416238188744 TRAIN  loss dict:  {'mse_loss': 0.16002416238188744}
2024-05-04 12:14:54,154 [INFO] Step[100/1020]: training loss : 0.16569785624742508 TRAIN  loss dict:  {'mse_loss': 0.16569785624742508}
2024-05-04 12:15:33,228 [INFO] Step[150/1020]: training loss : 0.16384421914815903 TRAIN  loss dict:  {'mse_loss': 0.16384421914815903}
2024-05-04 12:16:17,813 [INFO] Step[200/1020]: training loss : 0.1746318131685257 TRAIN  loss dict:  {'mse_loss': 0.1746318131685257}
2024-05-04 12:17:01,459 [INFO] Step[250/1020]: training loss : 0.17035168111324311 TRAIN  loss dict:  {'mse_loss': 0.17035168111324311}
2024-05-04 12:17:45,179 [INFO] Step[300/1020]: training loss : 0.1634032815694809 TRAIN  loss dict:  {'mse_loss': 0.1634032815694809}
2024-05-04 12:18:30,172 [INFO] Step[350/1020]: training loss : 0.16015993013978005 TRAIN  loss dict:  {'mse_loss': 0.16015993013978005}
2024-05-04 12:19:12,438 [INFO] Step[400/1020]: training loss : 0.1720930153131485 TRAIN  loss dict:  {'mse_loss': 0.1720930153131485}
2024-05-04 12:19:52,452 [INFO] Step[450/1020]: training loss : 0.1672786058485508 TRAIN  loss dict:  {'mse_loss': 0.1672786058485508}
2024-05-04 12:20:33,781 [INFO] Step[500/1020]: training loss : 0.16714467018842696 TRAIN  loss dict:  {'mse_loss': 0.16714467018842696}
2024-05-04 12:21:18,987 [INFO] Step[550/1020]: training loss : 0.16428600311279296 TRAIN  loss dict:  {'mse_loss': 0.16428600311279296}
2024-05-04 12:22:01,500 [INFO] Step[600/1020]: training loss : 0.17051127165555954 TRAIN  loss dict:  {'mse_loss': 0.17051127165555954}
2024-05-04 12:22:43,921 [INFO] Step[650/1020]: training loss : 0.16552550956606865 TRAIN  loss dict:  {'mse_loss': 0.16552550956606865}
2024-05-04 12:23:30,380 [INFO] Step[700/1020]: training loss : 0.17455213740468026 TRAIN  loss dict:  {'mse_loss': 0.17455213740468026}
2024-05-04 12:24:12,429 [INFO] Step[750/1020]: training loss : 0.1749618673324585 TRAIN  loss dict:  {'mse_loss': 0.1749618673324585}
2024-05-04 12:24:54,884 [INFO] Step[800/1020]: training loss : 0.16930595487356187 TRAIN  loss dict:  {'mse_loss': 0.16930595487356187}
2024-05-04 12:25:35,717 [INFO] Step[850/1020]: training loss : 0.16884002476930618 TRAIN  loss dict:  {'mse_loss': 0.16884002476930618}
2024-05-04 12:26:17,963 [INFO] Step[900/1020]: training loss : 0.17004670932888985 TRAIN  loss dict:  {'mse_loss': 0.17004670932888985}
2024-05-04 12:27:00,251 [INFO] Step[950/1020]: training loss : 0.1708194972574711 TRAIN  loss dict:  {'mse_loss': 0.1708194972574711}
2024-05-04 12:27:42,333 [INFO] Step[1000/1020]: training loss : 0.16720664978027344 TRAIN  loss dict:  {'mse_loss': 0.16720664978027344}
2024-05-04 12:30:43,837 [INFO] Label accuracies statistics:
2024-05-04 12:30:43,850 [INFO] {0: 0.5, 1: 0.75, 2: 0.25, 3: 0.75, 4: 0.3333333333333333, 5: 1.0, 6: 0.5, 7: 1.0, 8: 0.75, 9: 1.0, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.5, 15: 0.5, 16: 1.0, 17: 0.5, 18: 1.0, 19: 0.5, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.75, 29: 0.75, 30: 1.0, 31: 0.75, 32: 1.0, 33: 1.0, 34: 1.0, 35: 0.75, 36: 1.0, 37: 0.5, 38: 0.75, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 0.5, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 1.0, 58: 0.75, 59: 0.5, 60: 1.0, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.75, 65: 1.0, 66: 0.75, 67: 1.0, 68: 1.0, 69: 0.75, 70: 1.0, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.5, 97: 1.0, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.25, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 0.75, 140: 0.75, 141: 0.75, 142: 1.0, 143: 1.0, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 0.75, 149: 0.75, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.75, 159: 0.75, 160: 0.5, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 1.0, 174: 0.75, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 0.75, 183: 0.75, 184: 0.75, 185: 0.75, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-04 12:30:43,872 [INFO] [20] TRAIN  loss: 0.16828491662208941 acc: 0.0
2024-05-04 12:30:43,873 [INFO] [20] TRAIN  loss dict: {'mse_loss': 0.16828491662208941}
2024-05-04 12:30:43,873 [INFO] [20] VALIDATION loss: 0.8802398694585069 VALIDATION  acc: 0.827020202020202
2024-05-04 12:30:43,873 [INFO] [20] VALIDATION  loss dict: {'mse_loss': 0.1940942732523186, 'classification_loss': 0.6861455965136892}
2024-05-04 12:30:43,873 [INFO] 
2024-05-04 12:32:03,549 [INFO] Step[50/1020]: training loss : 0.1622988161444664 TRAIN  loss dict:  {'mse_loss': 0.1622988161444664}
2024-05-04 12:32:52,766 [INFO] Step[100/1020]: training loss : 0.15875552207231522 TRAIN  loss dict:  {'mse_loss': 0.15875552207231522}
2024-05-04 12:33:36,234 [INFO] Step[150/1020]: training loss : 0.16919413283467294 TRAIN  loss dict:  {'mse_loss': 0.16919413283467294}
2024-05-04 12:34:15,816 [INFO] Step[200/1020]: training loss : 0.16209694400429725 TRAIN  loss dict:  {'mse_loss': 0.16209694400429725}
2024-05-04 12:35:00,838 [INFO] Step[250/1020]: training loss : 0.16682032719254494 TRAIN  loss dict:  {'mse_loss': 0.16682032719254494}
2024-05-04 12:35:42,417 [INFO] Step[300/1020]: training loss : 0.1611009208858013 TRAIN  loss dict:  {'mse_loss': 0.1611009208858013}
2024-05-04 12:36:31,269 [INFO] Step[350/1020]: training loss : 0.163708920776844 TRAIN  loss dict:  {'mse_loss': 0.163708920776844}
2024-05-04 12:37:13,948 [INFO] Step[400/1020]: training loss : 0.1612239420413971 TRAIN  loss dict:  {'mse_loss': 0.1612239420413971}
2024-05-04 12:37:56,267 [INFO] Step[450/1020]: training loss : 0.16696436569094658 TRAIN  loss dict:  {'mse_loss': 0.16696436569094658}
2024-05-04 12:38:40,201 [INFO] Step[500/1020]: training loss : 0.16673837900161742 TRAIN  loss dict:  {'mse_loss': 0.16673837900161742}
2024-05-04 12:39:21,657 [INFO] Step[550/1020]: training loss : 0.16270691081881522 TRAIN  loss dict:  {'mse_loss': 0.16270691081881522}
2024-05-04 12:40:01,588 [INFO] Step[600/1020]: training loss : 0.15724987864494325 TRAIN  loss dict:  {'mse_loss': 0.15724987864494325}
2024-05-04 12:40:43,767 [INFO] Step[650/1020]: training loss : 0.1659615282714367 TRAIN  loss dict:  {'mse_loss': 0.1659615282714367}
2024-05-04 12:41:26,615 [INFO] Step[700/1020]: training loss : 0.16022979587316513 TRAIN  loss dict:  {'mse_loss': 0.16022979587316513}
2024-05-04 12:42:14,349 [INFO] Step[750/1020]: training loss : 0.1614001189172268 TRAIN  loss dict:  {'mse_loss': 0.1614001189172268}
2024-05-04 12:42:55,493 [INFO] Step[800/1020]: training loss : 0.15588502064347268 TRAIN  loss dict:  {'mse_loss': 0.15588502064347268}
2024-05-04 12:43:36,044 [INFO] Step[850/1020]: training loss : 0.16482436239719392 TRAIN  loss dict:  {'mse_loss': 0.16482436239719392}
2024-05-04 12:44:19,150 [INFO] Step[900/1020]: training loss : 0.16178720265626909 TRAIN  loss dict:  {'mse_loss': 0.16178720265626909}
2024-05-04 12:45:00,428 [INFO] Step[950/1020]: training loss : 0.1643705789744854 TRAIN  loss dict:  {'mse_loss': 0.1643705789744854}
2024-05-04 12:45:45,177 [INFO] Step[1000/1020]: training loss : 0.16401941373944282 TRAIN  loss dict:  {'mse_loss': 0.16401941373944282}
2024-05-04 12:48:57,814 [INFO] Label accuracies statistics:
2024-05-04 12:48:57,829 [INFO] {0: 0.5, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.75, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.5, 18: 1.0, 19: 1.0, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.75, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.75, 66: 0.5, 67: 0.5, 68: 0.75, 69: 1.0, 70: 0.75, 71: 1.0, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.5, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.75, 88: 1.0, 89: 1.0, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 1.0, 95: 0.75, 96: 1.0, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.75, 109: 1.0, 110: 1.0, 111: 0.75, 112: 0.75, 113: 0.0, 114: 1.0, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.75, 121: 0.75, 122: 0.25, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.75, 140: 0.5, 141: 1.0, 142: 1.0, 143: 1.0, 144: 0.75, 145: 1.0, 146: 0.25, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.75, 159: 0.75, 160: 0.75, 161: 1.0, 162: 1.0, 163: 0.75, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 0.75, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.75, 185: 0.75, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 0.75, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-04 12:48:57,869 [INFO] [21] TRAIN  loss: 0.16253136145133598 acc: 0.0
2024-05-04 12:48:57,869 [INFO] [21] TRAIN  loss dict: {'mse_loss': 0.16253136145133598}
2024-05-04 12:48:57,870 [INFO] [21] VALIDATION loss: 0.8389574197506664 VALIDATION  acc: 0.8396464646464646
2024-05-04 12:48:57,870 [INFO] [21] VALIDATION  loss dict: {'mse_loss': 0.18841737151296453, 'classification_loss': 0.6505400469906468}
2024-05-04 12:48:57,871 [INFO] 
2024-05-04 12:50:16,866 [INFO] Step[50/1020]: training loss : 0.16078537553548813 TRAIN  loss dict:  {'mse_loss': 0.16078537553548813}
2024-05-04 12:51:02,814 [INFO] Step[100/1020]: training loss : 0.16249239772558213 TRAIN  loss dict:  {'mse_loss': 0.16249239772558213}
2024-05-04 12:51:48,533 [INFO] Step[150/1020]: training loss : 0.15943252936005592 TRAIN  loss dict:  {'mse_loss': 0.15943252936005592}
2024-05-04 12:52:33,753 [INFO] Step[200/1020]: training loss : 0.16463959753513335 TRAIN  loss dict:  {'mse_loss': 0.16463959753513335}
2024-05-04 12:53:21,248 [INFO] Step[250/1020]: training loss : 0.16156310975551605 TRAIN  loss dict:  {'mse_loss': 0.16156310975551605}
2024-05-04 12:54:03,057 [INFO] Step[300/1020]: training loss : 0.16115262866020202 TRAIN  loss dict:  {'mse_loss': 0.16115262866020202}
2024-05-04 12:54:43,926 [INFO] Step[350/1020]: training loss : 0.16172736793756484 TRAIN  loss dict:  {'mse_loss': 0.16172736793756484}
2024-05-04 12:55:27,166 [INFO] Step[400/1020]: training loss : 0.15477202981710433 TRAIN  loss dict:  {'mse_loss': 0.15477202981710433}
2024-05-04 12:56:11,291 [INFO] Step[450/1020]: training loss : 0.1518571475148201 TRAIN  loss dict:  {'mse_loss': 0.1518571475148201}
2024-05-04 12:56:54,290 [INFO] Step[500/1020]: training loss : 0.1580202028155327 TRAIN  loss dict:  {'mse_loss': 0.1580202028155327}
2024-05-04 12:57:37,272 [INFO] Step[550/1020]: training loss : 0.1588376908004284 TRAIN  loss dict:  {'mse_loss': 0.1588376908004284}
2024-05-04 12:58:18,206 [INFO] Step[600/1020]: training loss : 0.16028287068009375 TRAIN  loss dict:  {'mse_loss': 0.16028287068009375}
2024-05-04 12:59:05,012 [INFO] Step[650/1020]: training loss : 0.15884434044361115 TRAIN  loss dict:  {'mse_loss': 0.15884434044361115}
2024-05-04 12:59:46,467 [INFO] Step[700/1020]: training loss : 0.16289674401283263 TRAIN  loss dict:  {'mse_loss': 0.16289674401283263}
2024-05-04 13:00:32,433 [INFO] Step[750/1020]: training loss : 0.16197889134287835 TRAIN  loss dict:  {'mse_loss': 0.16197889134287835}
2024-05-04 13:01:19,046 [INFO] Step[800/1020]: training loss : 0.15851874738931657 TRAIN  loss dict:  {'mse_loss': 0.15851874738931657}
2024-05-04 13:02:05,044 [INFO] Step[850/1020]: training loss : 0.16818755194544793 TRAIN  loss dict:  {'mse_loss': 0.16818755194544793}
2024-05-04 13:02:47,937 [INFO] Step[900/1020]: training loss : 0.16369329243898392 TRAIN  loss dict:  {'mse_loss': 0.16369329243898392}
2024-05-04 13:03:29,209 [INFO] Step[950/1020]: training loss : 0.16106752172112465 TRAIN  loss dict:  {'mse_loss': 0.16106752172112465}
2024-05-04 13:04:14,356 [INFO] Step[1000/1020]: training loss : 0.16514354988932609 TRAIN  loss dict:  {'mse_loss': 0.16514354988932609}
2024-05-04 13:07:32,517 [INFO] Label accuracies statistics:
2024-05-04 13:07:32,517 [INFO] {0: 0.5, 1: 0.75, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.5, 7: 1.0, 8: 0.75, 9: 0.75, 10: 1.0, 11: 0.75, 12: 0.75, 13: 1.0, 14: 0.5, 15: 1.0, 16: 1.0, 17: 0.75, 18: 1.0, 19: 0.5, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.75, 28: 0.75, 29: 0.75, 30: 1.0, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.75, 36: 1.0, 37: 1.0, 38: 0.75, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 0.75, 51: 0.75, 52: 0.25, 53: 0.25, 54: 0.5, 55: 0.75, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 1.0, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.5, 65: 1.0, 66: 0.25, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.5, 71: 0.75, 72: 1.0, 73: 0.5, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 1.0, 95: 1.0, 96: 1.0, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.75, 106: 0.75, 107: 1.0, 108: 0.75, 109: 0.75, 110: 0.75, 111: 0.75, 112: 1.0, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.5, 117: 0.5, 118: 0.75, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 0.75, 145: 1.0, 146: 0.75, 147: 1.0, 148: 0.75, 149: 0.75, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.5, 159: 0.75, 160: 1.0, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.75, 165: 0.75, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 0.75, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.75, 185: 0.75, 186: 1.0, 187: 0.75, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-05-04 13:07:32,538 [INFO] [22] TRAIN  loss: 0.16078251432262214 acc: 0.0
2024-05-04 13:07:32,538 [INFO] [22] TRAIN  loss dict: {'mse_loss': 0.16078251432262214}
2024-05-04 13:07:32,538 [INFO] [22] VALIDATION loss: 0.9128825777407849 VALIDATION  acc: 0.8232323232323232
2024-05-04 13:07:32,538 [INFO] [22] VALIDATION  loss dict: {'mse_loss': 0.18682177944315803, 'classification_loss': 0.7260608011298116}
2024-05-04 13:07:32,538 [INFO] 
2024-05-04 13:08:48,962 [INFO] Step[50/1020]: training loss : 0.16062094241380692 TRAIN  loss dict:  {'mse_loss': 0.16062094241380692}
2024-05-04 13:09:39,290 [INFO] Step[100/1020]: training loss : 0.1572649921476841 TRAIN  loss dict:  {'mse_loss': 0.1572649921476841}
2024-05-04 13:10:21,733 [INFO] Step[150/1020]: training loss : 0.1587643964588642 TRAIN  loss dict:  {'mse_loss': 0.1587643964588642}
2024-05-04 13:11:07,320 [INFO] Step[200/1020]: training loss : 0.15942447543144225 TRAIN  loss dict:  {'mse_loss': 0.15942447543144225}
2024-05-04 13:11:56,481 [INFO] Step[250/1020]: training loss : 0.1605508357286453 TRAIN  loss dict:  {'mse_loss': 0.1605508357286453}
2024-05-04 13:12:42,779 [INFO] Step[300/1020]: training loss : 0.16662450268864631 TRAIN  loss dict:  {'mse_loss': 0.16662450268864631}
2024-05-04 13:13:26,349 [INFO] Step[350/1020]: training loss : 0.16389315351843833 TRAIN  loss dict:  {'mse_loss': 0.16389315351843833}
2024-05-04 13:14:09,573 [INFO] Step[400/1020]: training loss : 0.15720966711640358 TRAIN  loss dict:  {'mse_loss': 0.15720966711640358}
2024-05-04 13:14:52,743 [INFO] Step[450/1020]: training loss : 0.15710499703884126 TRAIN  loss dict:  {'mse_loss': 0.15710499703884126}
2024-05-04 13:15:37,788 [INFO] Step[500/1020]: training loss : 0.15557752639055253 TRAIN  loss dict:  {'mse_loss': 0.15557752639055253}
2024-05-04 13:16:17,252 [INFO] Step[550/1020]: training loss : 0.16035595074295997 TRAIN  loss dict:  {'mse_loss': 0.16035595074295997}
2024-05-04 13:16:59,255 [INFO] Step[600/1020]: training loss : 0.16404105693101884 TRAIN  loss dict:  {'mse_loss': 0.16404105693101884}
2024-05-04 13:17:41,573 [INFO] Step[650/1020]: training loss : 0.16037378951907158 TRAIN  loss dict:  {'mse_loss': 0.16037378951907158}
2024-05-04 13:18:21,039 [INFO] Step[700/1020]: training loss : 0.1594841480255127 TRAIN  loss dict:  {'mse_loss': 0.1594841480255127}
2024-05-04 13:19:02,223 [INFO] Step[750/1020]: training loss : 0.16537402883172037 TRAIN  loss dict:  {'mse_loss': 0.16537402883172037}
2024-05-04 13:19:41,140 [INFO] Step[800/1020]: training loss : 0.16333698332309723 TRAIN  loss dict:  {'mse_loss': 0.16333698332309723}
2024-05-04 13:20:23,821 [INFO] Step[850/1020]: training loss : 0.15490217104554177 TRAIN  loss dict:  {'mse_loss': 0.15490217104554177}
2024-05-04 13:21:06,620 [INFO] Step[900/1020]: training loss : 0.16462164118885994 TRAIN  loss dict:  {'mse_loss': 0.16462164118885994}
2024-05-04 13:21:47,226 [INFO] Step[950/1020]: training loss : 0.16018555283546448 TRAIN  loss dict:  {'mse_loss': 0.16018555283546448}
2024-05-04 13:22:27,148 [INFO] Step[1000/1020]: training loss : 0.160622780919075 TRAIN  loss dict:  {'mse_loss': 0.160622780919075}
2024-05-04 13:25:33,323 [INFO] Label accuracies statistics:
2024-05-04 13:25:33,332 [INFO] {0: 1.0, 1: 0.75, 2: 0.25, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.5, 7: 1.0, 8: 0.5, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.5, 13: 0.75, 14: 0.5, 15: 0.75, 16: 0.75, 17: 0.5, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.5, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.75, 27: 0.75, 28: 0.5, 29: 0.75, 30: 0.75, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.5, 50: 1.0, 51: 0.5, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 1.0, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.5, 65: 1.0, 66: 0.5, 67: 0.75, 68: 1.0, 69: 1.0, 70: 0.75, 71: 1.0, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 0.75, 79: 1.0, 80: 0.75, 81: 0.75, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.5, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 0.75, 112: 1.0, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.5, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.75, 151: 0.75, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.75, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 0.75, 183: 0.75, 184: 0.75, 185: 0.75, 186: 1.0, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 0.75}

2024-05-04 13:25:33,358 [INFO] [23] TRAIN  loss: 0.16063079492864654 acc: 0.0
2024-05-04 13:25:33,358 [INFO] [23] TRAIN  loss dict: {'mse_loss': 0.16063079492864654}
2024-05-04 13:25:33,359 [INFO] [23] VALIDATION loss: 0.8886135396632281 VALIDATION  acc: 0.827020202020202
2024-05-04 13:25:33,359 [INFO] [23] VALIDATION  loss dict: {'mse_loss': 0.19005469059703325, 'classification_loss': 0.6985588507724436}
2024-05-04 13:25:33,360 [INFO] 
2024-05-04 13:26:47,089 [INFO] Step[50/1020]: training loss : 0.16382420018315316 TRAIN  loss dict:  {'mse_loss': 0.16382420018315316}
2024-05-04 13:27:27,546 [INFO] Step[100/1020]: training loss : 0.1557309930026531 TRAIN  loss dict:  {'mse_loss': 0.1557309930026531}
2024-05-04 13:28:08,889 [INFO] Step[150/1020]: training loss : 0.1580531032383442 TRAIN  loss dict:  {'mse_loss': 0.1580531032383442}
2024-05-04 13:28:53,990 [INFO] Step[200/1020]: training loss : 0.15285348236560822 TRAIN  loss dict:  {'mse_loss': 0.15285348236560822}
2024-05-04 13:29:34,710 [INFO] Step[250/1020]: training loss : 0.15272339060902596 TRAIN  loss dict:  {'mse_loss': 0.15272339060902596}
2024-05-04 13:30:15,178 [INFO] Step[300/1020]: training loss : 0.15640126660466194 TRAIN  loss dict:  {'mse_loss': 0.15640126660466194}
2024-05-04 13:30:56,779 [INFO] Step[350/1020]: training loss : 0.15162733748555182 TRAIN  loss dict:  {'mse_loss': 0.15162733748555182}
2024-05-04 13:31:38,440 [INFO] Step[400/1020]: training loss : 0.16073085069656373 TRAIN  loss dict:  {'mse_loss': 0.16073085069656373}
2024-05-04 13:32:22,268 [INFO] Step[450/1020]: training loss : 0.16586712032556533 TRAIN  loss dict:  {'mse_loss': 0.16586712032556533}
2024-05-04 13:33:02,918 [INFO] Step[500/1020]: training loss : 0.15352917969226837 TRAIN  loss dict:  {'mse_loss': 0.15352917969226837}
2024-05-04 13:33:44,750 [INFO] Step[550/1020]: training loss : 0.1611118033528328 TRAIN  loss dict:  {'mse_loss': 0.1611118033528328}
2024-05-04 13:34:26,503 [INFO] Step[600/1020]: training loss : 0.16198151901364327 TRAIN  loss dict:  {'mse_loss': 0.16198151901364327}
2024-05-04 13:35:09,110 [INFO] Step[650/1020]: training loss : 0.15839791864156724 TRAIN  loss dict:  {'mse_loss': 0.15839791864156724}
2024-05-04 13:35:51,230 [INFO] Step[700/1020]: training loss : 0.15858218923211098 TRAIN  loss dict:  {'mse_loss': 0.15858218923211098}
2024-05-04 13:36:33,236 [INFO] Step[750/1020]: training loss : 0.15789379805326462 TRAIN  loss dict:  {'mse_loss': 0.15789379805326462}
2024-05-04 13:37:24,888 [INFO] Step[800/1020]: training loss : 0.1701882615685463 TRAIN  loss dict:  {'mse_loss': 0.1701882615685463}
2024-05-04 13:38:09,806 [INFO] Step[850/1020]: training loss : 0.16135246977210044 TRAIN  loss dict:  {'mse_loss': 0.16135246977210044}
2024-05-04 13:38:55,464 [INFO] Step[900/1020]: training loss : 0.14879738345742224 TRAIN  loss dict:  {'mse_loss': 0.14879738345742224}
2024-05-04 13:39:40,096 [INFO] Step[950/1020]: training loss : 0.15695019498467444 TRAIN  loss dict:  {'mse_loss': 0.15695019498467444}
2024-05-04 13:40:26,285 [INFO] Step[1000/1020]: training loss : 0.15873491659760475 TRAIN  loss dict:  {'mse_loss': 0.15873491659760475}
2024-05-04 13:43:41,497 [INFO] Label accuracies statistics:
2024-05-04 13:43:41,497 [INFO] {0: 0.5, 1: 1.0, 2: 0.25, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.5, 7: 1.0, 8: 0.25, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.5, 15: 0.75, 16: 1.0, 17: 0.75, 18: 1.0, 19: 0.5, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.5, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 1.0, 35: 0.75, 36: 1.0, 37: 1.0, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 0.75, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 0.75, 53: 1.0, 54: 0.25, 55: 0.75, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 1.0, 66: 0.5, 67: 1.0, 68: 0.75, 69: 1.0, 70: 1.0, 71: 1.0, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.75, 95: 1.0, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.5, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 0.75, 112: 0.75, 113: 0.25, 114: 1.0, 115: 1.0, 116: 0.75, 117: 1.0, 118: 0.75, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.25, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 1.0, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.25, 154: 1.0, 155: 1.0, 156: 1.0, 157: 1.0, 158: 0.5, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 0.75, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.5, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-04 13:43:41,524 [INFO] [24] TRAIN  loss: 0.15816384465524963 acc: 0.0
2024-05-04 13:43:41,524 [INFO] [24] TRAIN  loss dict: {'mse_loss': 0.15816384465524963}
2024-05-04 13:43:41,524 [INFO] [24] VALIDATION loss: 0.8292323495026188 VALIDATION  acc: 0.8371212121212122
2024-05-04 13:43:41,524 [INFO] [24] VALIDATION  loss dict: {'mse_loss': 0.18736112783804085, 'classification_loss': 0.6418712174248261}
2024-05-04 13:43:41,524 [INFO] 
2024-05-04 13:44:53,162 [INFO] Step[50/1020]: training loss : 0.15048016011714935 TRAIN  loss dict:  {'mse_loss': 0.15048016011714935}
2024-05-04 13:45:38,779 [INFO] Step[100/1020]: training loss : 0.1563848966360092 TRAIN  loss dict:  {'mse_loss': 0.1563848966360092}
2024-05-04 13:46:29,190 [INFO] Step[150/1020]: training loss : 0.1615874770283699 TRAIN  loss dict:  {'mse_loss': 0.1615874770283699}
2024-05-04 13:47:14,183 [INFO] Step[200/1020]: training loss : 0.15917174860835076 TRAIN  loss dict:  {'mse_loss': 0.15917174860835076}
2024-05-04 13:47:56,657 [INFO] Step[250/1020]: training loss : 0.1576670803129673 TRAIN  loss dict:  {'mse_loss': 0.1576670803129673}
2024-05-04 13:48:38,984 [INFO] Step[300/1020]: training loss : 0.15900369614362717 TRAIN  loss dict:  {'mse_loss': 0.15900369614362717}
2024-05-04 13:49:21,163 [INFO] Step[350/1020]: training loss : 0.15022196412086486 TRAIN  loss dict:  {'mse_loss': 0.15022196412086486}
2024-05-04 13:50:02,598 [INFO] Step[400/1020]: training loss : 0.15931412518024446 TRAIN  loss dict:  {'mse_loss': 0.15931412518024446}
2024-05-04 13:50:42,577 [INFO] Step[450/1020]: training loss : 0.15824976265430452 TRAIN  loss dict:  {'mse_loss': 0.15824976265430452}
2024-05-04 13:51:29,648 [INFO] Step[500/1020]: training loss : 0.1569625860452652 TRAIN  loss dict:  {'mse_loss': 0.1569625860452652}
2024-05-04 13:52:13,518 [INFO] Step[550/1020]: training loss : 0.15763072893023491 TRAIN  loss dict:  {'mse_loss': 0.15763072893023491}
2024-05-04 13:52:56,921 [INFO] Step[600/1020]: training loss : 0.16790657058358194 TRAIN  loss dict:  {'mse_loss': 0.16790657058358194}
2024-05-04 13:53:39,094 [INFO] Step[650/1020]: training loss : 0.1566831836104393 TRAIN  loss dict:  {'mse_loss': 0.1566831836104393}
2024-05-04 13:54:23,524 [INFO] Step[700/1020]: training loss : 0.15745068654417993 TRAIN  loss dict:  {'mse_loss': 0.15745068654417993}
2024-05-04 13:55:10,517 [INFO] Step[750/1020]: training loss : 0.16077285900712013 TRAIN  loss dict:  {'mse_loss': 0.16077285900712013}
2024-05-04 13:55:56,149 [INFO] Step[800/1020]: training loss : 0.1552226337790489 TRAIN  loss dict:  {'mse_loss': 0.1552226337790489}
2024-05-04 13:56:37,582 [INFO] Step[850/1020]: training loss : 0.1569090434908867 TRAIN  loss dict:  {'mse_loss': 0.1569090434908867}
2024-05-04 13:57:24,095 [INFO] Step[900/1020]: training loss : 0.15027657210826872 TRAIN  loss dict:  {'mse_loss': 0.15027657210826872}
2024-05-04 13:58:06,547 [INFO] Step[950/1020]: training loss : 0.15308732017874718 TRAIN  loss dict:  {'mse_loss': 0.15308732017874718}
2024-05-04 13:58:53,217 [INFO] Step[1000/1020]: training loss : 0.160958853662014 TRAIN  loss dict:  {'mse_loss': 0.160958853662014}
2024-05-04 14:02:10,593 [INFO] Label accuracies statistics:
2024-05-04 14:02:10,594 [INFO] {0: 1.0, 1: 0.75, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.5, 7: 1.0, 8: 0.5, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.5, 15: 0.75, 16: 1.0, 17: 0.5, 18: 1.0, 19: 0.5, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.75, 28: 0.5, 29: 0.75, 30: 1.0, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 0.75, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 1.0, 51: 1.0, 52: 1.0, 53: 1.0, 54: 0.5, 55: 0.75, 56: 1.0, 57: 1.0, 58: 0.5, 59: 1.0, 60: 1.0, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.5, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 1.0, 70: 1.0, 71: 0.75, 72: 1.0, 73: 0.5, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.75, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.25, 114: 1.0, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 0.75, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.75, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 1.0, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-04 14:02:10,614 [INFO] [25] TRAIN  loss: 0.15702616172093972 acc: 0.0
2024-05-04 14:02:10,614 [INFO] [25] TRAIN  loss dict: {'mse_loss': 0.15702616172093972}
2024-05-04 14:02:10,614 [INFO] [25] VALIDATION loss: 0.8263065950813318 VALIDATION  acc: 0.851010101010101
2024-05-04 14:02:10,614 [INFO] [25] VALIDATION  loss dict: {'mse_loss': 0.18526114974961136, 'classification_loss': 0.6410454435831388}
2024-05-04 14:02:10,614 [INFO] 
2024-05-04 14:03:31,425 [INFO] Step[50/1020]: training loss : 0.15335935935378076 TRAIN  loss dict:  {'mse_loss': 0.15335935935378076}
2024-05-04 14:04:17,001 [INFO] Step[100/1020]: training loss : 0.1582615266740322 TRAIN  loss dict:  {'mse_loss': 0.1582615266740322}
2024-05-04 14:05:02,507 [INFO] Step[150/1020]: training loss : 0.15152247548103331 TRAIN  loss dict:  {'mse_loss': 0.15152247548103331}
2024-05-04 14:05:51,060 [INFO] Step[200/1020]: training loss : 0.15401332929730416 TRAIN  loss dict:  {'mse_loss': 0.15401332929730416}
2024-05-04 14:06:36,496 [INFO] Step[250/1020]: training loss : 0.15523992285132407 TRAIN  loss dict:  {'mse_loss': 0.15523992285132407}
2024-05-04 14:07:20,498 [INFO] Step[300/1020]: training loss : 0.1516606603562832 TRAIN  loss dict:  {'mse_loss': 0.1516606603562832}
2024-05-04 14:08:06,918 [INFO] Step[350/1020]: training loss : 0.15648250460624694 TRAIN  loss dict:  {'mse_loss': 0.15648250460624694}
2024-05-04 14:08:59,598 [INFO] Step[400/1020]: training loss : 0.16249562099575995 TRAIN  loss dict:  {'mse_loss': 0.16249562099575995}
2024-05-04 14:09:44,130 [INFO] Step[450/1020]: training loss : 0.16610932648181914 TRAIN  loss dict:  {'mse_loss': 0.16610932648181914}
2024-05-04 14:10:37,212 [INFO] Step[500/1020]: training loss : 0.1585962727665901 TRAIN  loss dict:  {'mse_loss': 0.1585962727665901}
2024-05-04 14:11:29,198 [INFO] Step[550/1020]: training loss : 0.1524783544242382 TRAIN  loss dict:  {'mse_loss': 0.1524783544242382}
2024-05-04 14:12:16,371 [INFO] Step[600/1020]: training loss : 0.15139853730797767 TRAIN  loss dict:  {'mse_loss': 0.15139853730797767}
2024-05-04 14:13:00,739 [INFO] Step[650/1020]: training loss : 0.15706793397665023 TRAIN  loss dict:  {'mse_loss': 0.15706793397665023}
2024-05-04 14:13:46,430 [INFO] Step[700/1020]: training loss : 0.15168904826045038 TRAIN  loss dict:  {'mse_loss': 0.15168904826045038}
2024-05-04 14:14:34,732 [INFO] Step[750/1020]: training loss : 0.16024615049362181 TRAIN  loss dict:  {'mse_loss': 0.16024615049362181}
2024-05-04 14:15:17,955 [INFO] Step[800/1020]: training loss : 0.15252942562103272 TRAIN  loss dict:  {'mse_loss': 0.15252942562103272}
2024-05-04 14:16:02,815 [INFO] Step[850/1020]: training loss : 0.16205810785293578 TRAIN  loss dict:  {'mse_loss': 0.16205810785293578}
2024-05-04 14:16:50,655 [INFO] Step[900/1020]: training loss : 0.16359341144561768 TRAIN  loss dict:  {'mse_loss': 0.16359341144561768}
2024-05-04 14:17:35,842 [INFO] Step[950/1020]: training loss : 0.15203694820404054 TRAIN  loss dict:  {'mse_loss': 0.15203694820404054}
2024-05-04 14:18:16,502 [INFO] Step[1000/1020]: training loss : 0.15075652837753295 TRAIN  loss dict:  {'mse_loss': 0.15075652837753295}
2024-05-04 14:21:33,568 [INFO] Label accuracies statistics:
2024-05-04 14:21:33,568 [INFO] {0: 0.5, 1: 0.75, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.5, 7: 1.0, 8: 0.5, 9: 0.75, 10: 1.0, 11: 1.0, 12: 1.0, 13: 0.75, 14: 0.5, 15: 0.75, 16: 1.0, 17: 0.75, 18: 1.0, 19: 0.5, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.75, 28: 0.75, 29: 1.0, 30: 1.0, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 0.75, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.75, 50: 1.0, 51: 0.75, 52: 1.0, 53: 1.0, 54: 0.25, 55: 0.75, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 1.0, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 1.0, 66: 0.75, 67: 0.75, 68: 0.5, 69: 1.0, 70: 1.0, 71: 1.0, 72: 1.0, 73: 0.5, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 1.0, 80: 0.75, 81: 0.75, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.0, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.75, 118: 0.75, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 1.0, 157: 1.0, 158: 0.5, 159: 0.75, 160: 0.75, 161: 1.0, 162: 1.0, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 0.75, 182: 0.75, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-04 14:21:33,588 [INFO] [26] TRAIN  loss: 0.156129611853291 acc: 0.0
2024-05-04 14:21:33,588 [INFO] [26] TRAIN  loss dict: {'mse_loss': 0.156129611853291}
2024-05-04 14:21:33,588 [INFO] [26] VALIDATION loss: 0.8739827624098822 VALIDATION  acc: 0.8409090909090909
2024-05-04 14:21:33,588 [INFO] [26] VALIDATION  loss dict: {'mse_loss': 0.18942590720123714, 'classification_loss': 0.6845568526686743}
2024-05-04 14:21:33,588 [INFO] 
2024-05-04 14:22:48,566 [INFO] Step[50/1020]: training loss : 0.15238362014293672 TRAIN  loss dict:  {'mse_loss': 0.15238362014293672}
2024-05-04 14:23:32,301 [INFO] Step[100/1020]: training loss : 0.15608884036540985 TRAIN  loss dict:  {'mse_loss': 0.15608884036540985}
2024-05-04 14:24:15,985 [INFO] Step[150/1020]: training loss : 0.15442103266716004 TRAIN  loss dict:  {'mse_loss': 0.15442103266716004}
2024-05-04 14:25:00,685 [INFO] Step[200/1020]: training loss : 0.15109434723854065 TRAIN  loss dict:  {'mse_loss': 0.15109434723854065}
2024-05-04 14:25:41,194 [INFO] Step[250/1020]: training loss : 0.15347230836749076 TRAIN  loss dict:  {'mse_loss': 0.15347230836749076}
2024-05-04 14:26:26,275 [INFO] Step[300/1020]: training loss : 0.153778850287199 TRAIN  loss dict:  {'mse_loss': 0.153778850287199}
2024-05-04 14:27:13,507 [INFO] Step[350/1020]: training loss : 0.16360484674572945 TRAIN  loss dict:  {'mse_loss': 0.16360484674572945}
2024-05-04 14:27:59,014 [INFO] Step[400/1020]: training loss : 0.16273037388920783 TRAIN  loss dict:  {'mse_loss': 0.16273037388920783}
2024-05-04 14:28:47,511 [INFO] Step[450/1020]: training loss : 0.15304247200489043 TRAIN  loss dict:  {'mse_loss': 0.15304247200489043}
2024-05-04 14:29:33,151 [INFO] Step[500/1020]: training loss : 0.14903036564588545 TRAIN  loss dict:  {'mse_loss': 0.14903036564588545}
2024-05-04 14:30:19,432 [INFO] Step[550/1020]: training loss : 0.16342260897159577 TRAIN  loss dict:  {'mse_loss': 0.16342260897159577}
2024-05-04 14:31:05,680 [INFO] Step[600/1020]: training loss : 0.14988367959856988 TRAIN  loss dict:  {'mse_loss': 0.14988367959856988}
2024-05-04 14:31:50,527 [INFO] Step[650/1020]: training loss : 0.1534768357872963 TRAIN  loss dict:  {'mse_loss': 0.1534768357872963}
2024-05-04 14:32:35,261 [INFO] Step[700/1020]: training loss : 0.1519283227622509 TRAIN  loss dict:  {'mse_loss': 0.1519283227622509}
2024-05-04 14:33:16,932 [INFO] Step[750/1020]: training loss : 0.1487009672820568 TRAIN  loss dict:  {'mse_loss': 0.1487009672820568}
2024-05-04 14:33:59,531 [INFO] Step[800/1020]: training loss : 0.14957201167941092 TRAIN  loss dict:  {'mse_loss': 0.14957201167941092}
2024-05-04 14:34:43,049 [INFO] Step[850/1020]: training loss : 0.15466083839535713 TRAIN  loss dict:  {'mse_loss': 0.15466083839535713}
2024-05-04 14:35:24,520 [INFO] Step[900/1020]: training loss : 0.16171613931655884 TRAIN  loss dict:  {'mse_loss': 0.16171613931655884}
2024-05-04 14:36:03,858 [INFO] Step[950/1020]: training loss : 0.14850647926330565 TRAIN  loss dict:  {'mse_loss': 0.14850647926330565}
2024-05-04 14:36:46,175 [INFO] Step[1000/1020]: training loss : 0.1616269014775753 TRAIN  loss dict:  {'mse_loss': 0.1616269014775753}
2024-05-04 14:40:02,829 [INFO] Label accuracies statistics:
2024-05-04 14:40:02,829 [INFO] {0: 0.5, 1: 0.75, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.5, 7: 1.0, 8: 0.5, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 0.75, 14: 0.5, 15: 0.75, 16: 1.0, 17: 0.75, 18: 0.75, 19: 0.5, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 0.75, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.25, 50: 1.0, 51: 0.75, 52: 0.5, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 1.0, 58: 0.75, 59: 0.75, 60: 1.0, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 1.0, 66: 0.5, 67: 0.75, 68: 0.75, 69: 0.75, 70: 1.0, 71: 1.0, 72: 1.0, 73: 0.5, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.5, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 1.0, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 1.0, 95: 1.0, 96: 0.5, 97: 0.75, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.25, 114: 1.0, 115: 1.0, 116: 0.75, 117: 1.0, 118: 0.75, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 0.5, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.5, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 0.5, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.75, 185: 0.75, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.75}

2024-05-04 14:40:02,852 [INFO] [27] TRAIN  loss: 0.1547336102773746 acc: 0.0
2024-05-04 14:40:02,852 [INFO] [27] TRAIN  loss dict: {'mse_loss': 0.1547336102773746}
2024-05-04 14:40:02,852 [INFO] [27] VALIDATION loss: 0.925755311029427 VALIDATION  acc: 0.8257575757575758
2024-05-04 14:40:02,852 [INFO] [27] VALIDATION  loss dict: {'mse_loss': 0.19016163525256244, 'classification_loss': 0.7355936748549493}
2024-05-04 14:40:02,852 [INFO] 
2024-05-04 14:41:17,596 [INFO] Step[50/1020]: training loss : 0.1609199483692646 TRAIN  loss dict:  {'mse_loss': 0.1609199483692646}
2024-05-04 14:42:02,032 [INFO] Step[100/1020]: training loss : 0.15298067197203635 TRAIN  loss dict:  {'mse_loss': 0.15298067197203635}
2024-05-04 14:42:44,031 [INFO] Step[150/1020]: training loss : 0.15528519004583358 TRAIN  loss dict:  {'mse_loss': 0.15528519004583358}
2024-05-04 14:43:24,096 [INFO] Step[200/1020]: training loss : 0.15456745982170106 TRAIN  loss dict:  {'mse_loss': 0.15456745982170106}
2024-05-04 14:44:03,153 [INFO] Step[250/1020]: training loss : 0.1503449372947216 TRAIN  loss dict:  {'mse_loss': 0.1503449372947216}
2024-05-04 14:44:44,785 [INFO] Step[300/1020]: training loss : 0.15691599398851394 TRAIN  loss dict:  {'mse_loss': 0.15691599398851394}
2024-05-04 14:45:30,256 [INFO] Step[350/1020]: training loss : 0.15553074181079865 TRAIN  loss dict:  {'mse_loss': 0.15553074181079865}
2024-05-04 14:46:18,566 [INFO] Step[400/1020]: training loss : 0.14763543397188186 TRAIN  loss dict:  {'mse_loss': 0.14763543397188186}
2024-05-04 14:47:04,813 [INFO] Step[450/1020]: training loss : 0.15403637170791626 TRAIN  loss dict:  {'mse_loss': 0.15403637170791626}
2024-05-04 14:47:45,846 [INFO] Step[500/1020]: training loss : 0.15047805279493331 TRAIN  loss dict:  {'mse_loss': 0.15047805279493331}
2024-05-04 14:48:30,832 [INFO] Step[550/1020]: training loss : 0.1605755753815174 TRAIN  loss dict:  {'mse_loss': 0.1605755753815174}
2024-05-04 14:49:13,260 [INFO] Step[600/1020]: training loss : 0.14789871260523796 TRAIN  loss dict:  {'mse_loss': 0.14789871260523796}
2024-05-04 14:49:55,277 [INFO] Step[650/1020]: training loss : 0.15106015011668206 TRAIN  loss dict:  {'mse_loss': 0.15106015011668206}
2024-05-04 14:50:36,000 [INFO] Step[700/1020]: training loss : 0.1540120166540146 TRAIN  loss dict:  {'mse_loss': 0.1540120166540146}
2024-05-04 14:51:19,589 [INFO] Step[750/1020]: training loss : 0.15386605635285378 TRAIN  loss dict:  {'mse_loss': 0.15386605635285378}
2024-05-04 14:52:00,642 [INFO] Step[800/1020]: training loss : 0.15663923263549806 TRAIN  loss dict:  {'mse_loss': 0.15663923263549806}
2024-05-04 14:52:44,537 [INFO] Step[850/1020]: training loss : 0.15390734300017356 TRAIN  loss dict:  {'mse_loss': 0.15390734300017356}
2024-05-04 14:53:29,949 [INFO] Step[900/1020]: training loss : 0.16007453471422195 TRAIN  loss dict:  {'mse_loss': 0.16007453471422195}
2024-05-04 14:54:12,265 [INFO] Step[950/1020]: training loss : 0.1601570163667202 TRAIN  loss dict:  {'mse_loss': 0.1601570163667202}
2024-05-04 14:54:57,144 [INFO] Step[1000/1020]: training loss : 0.15686362490057945 TRAIN  loss dict:  {'mse_loss': 0.15686362490057945}
2024-05-04 14:58:16,600 [INFO] Label accuracies statistics:
2024-05-04 14:58:16,600 [INFO] {0: 1.0, 1: 0.75, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.5, 7: 1.0, 8: 0.75, 9: 0.75, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.5, 15: 0.5, 16: 0.75, 17: 0.5, 18: 1.0, 19: 0.5, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.75, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 0.75, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.25, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.25, 55: 0.75, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 1.0, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 1.0, 66: 0.75, 67: 0.75, 68: 1.0, 69: 1.0, 70: 1.0, 71: 0.75, 72: 1.0, 73: 0.5, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.5, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 0.75, 95: 1.0, 96: 0.5, 97: 1.0, 98: 0.75, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 0.75, 112: 0.5, 113: 0.0, 114: 1.0, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.25, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 0.75, 145: 1.0, 146: 0.75, 147: 1.0, 148: 1.0, 149: 0.75, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 1.0, 156: 1.0, 157: 1.0, 158: 0.5, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.75, 187: 0.75, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-05-04 14:58:16,620 [INFO] [28] TRAIN  loss: 0.15482031159541187 acc: 0.0
2024-05-04 14:58:16,621 [INFO] [28] TRAIN  loss dict: {'mse_loss': 0.15482031159541187}
2024-05-04 14:58:16,621 [INFO] [28] VALIDATION loss: 0.8764165164244295 VALIDATION  acc: 0.821969696969697
2024-05-04 14:58:16,621 [INFO] [28] VALIDATION  loss dict: {'mse_loss': 0.18742998824878174, 'classification_loss': 0.6889865273331066}
2024-05-04 14:58:16,621 [INFO] 
2024-05-04 14:59:28,029 [INFO] Step[50/1020]: training loss : 0.14713625833392144 TRAIN  loss dict:  {'mse_loss': 0.14713625833392144}
2024-05-04 15:00:12,878 [INFO] Step[100/1020]: training loss : 0.15020963102579116 TRAIN  loss dict:  {'mse_loss': 0.15020963102579116}
2024-05-04 15:00:57,204 [INFO] Step[150/1020]: training loss : 0.14454094886779786 TRAIN  loss dict:  {'mse_loss': 0.14454094886779786}
2024-05-04 15:01:40,058 [INFO] Step[200/1020]: training loss : 0.15600432187318802 TRAIN  loss dict:  {'mse_loss': 0.15600432187318802}
2024-05-04 15:02:21,853 [INFO] Step[250/1020]: training loss : 0.15207237109541893 TRAIN  loss dict:  {'mse_loss': 0.15207237109541893}
2024-05-04 15:03:04,621 [INFO] Step[300/1020]: training loss : 0.15612256705760955 TRAIN  loss dict:  {'mse_loss': 0.15612256705760955}
2024-05-04 15:03:45,319 [INFO] Step[350/1020]: training loss : 0.15915963634848596 TRAIN  loss dict:  {'mse_loss': 0.15915963634848596}
2024-05-04 15:04:36,945 [INFO] Step[400/1020]: training loss : 0.16093944355845452 TRAIN  loss dict:  {'mse_loss': 0.16093944355845452}
2024-05-04 15:05:18,845 [INFO] Step[450/1020]: training loss : 0.1500342756509781 TRAIN  loss dict:  {'mse_loss': 0.1500342756509781}
2024-05-04 15:06:05,353 [INFO] Step[500/1020]: training loss : 0.15110904350876808 TRAIN  loss dict:  {'mse_loss': 0.15110904350876808}
2024-05-04 15:06:46,815 [INFO] Step[550/1020]: training loss : 0.15497288689017297 TRAIN  loss dict:  {'mse_loss': 0.15497288689017297}
2024-05-04 15:07:26,560 [INFO] Step[600/1020]: training loss : 0.15312362298369409 TRAIN  loss dict:  {'mse_loss': 0.15312362298369409}
2024-05-04 15:08:11,169 [INFO] Step[650/1020]: training loss : 0.15122710272669793 TRAIN  loss dict:  {'mse_loss': 0.15122710272669793}
2024-05-04 15:08:54,333 [INFO] Step[700/1020]: training loss : 0.14778275310993194 TRAIN  loss dict:  {'mse_loss': 0.14778275310993194}
2024-05-04 15:09:36,959 [INFO] Step[750/1020]: training loss : 0.16326071843504905 TRAIN  loss dict:  {'mse_loss': 0.16326071843504905}
2024-05-04 15:10:17,406 [INFO] Step[800/1020]: training loss : 0.15614447936415674 TRAIN  loss dict:  {'mse_loss': 0.15614447936415674}
2024-05-04 15:10:57,774 [INFO] Step[850/1020]: training loss : 0.15671065747737883 TRAIN  loss dict:  {'mse_loss': 0.15671065747737883}
2024-05-04 15:11:40,067 [INFO] Step[900/1020]: training loss : 0.15521110862493515 TRAIN  loss dict:  {'mse_loss': 0.15521110862493515}
2024-05-04 15:12:23,146 [INFO] Step[950/1020]: training loss : 0.15466765582561492 TRAIN  loss dict:  {'mse_loss': 0.15466765582561492}
2024-05-04 15:13:10,243 [INFO] Step[1000/1020]: training loss : 0.1525573591887951 TRAIN  loss dict:  {'mse_loss': 0.1525573591887951}
2024-05-04 15:16:18,633 [INFO] Label accuracies statistics:
2024-05-04 15:16:18,634 [INFO] {0: 1.0, 1: 0.75, 2: 0.75, 3: 0.75, 4: 0.3333333333333333, 5: 1.0, 6: 0.5, 7: 1.0, 8: 0.5, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.5, 15: 0.75, 16: 0.75, 17: 0.75, 18: 1.0, 19: 0.5, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.5, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.5, 33: 1.0, 34: 1.0, 35: 0.75, 36: 1.0, 37: 1.0, 38: 0.75, 39: 0.75, 40: 1.0, 41: 0.5, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.5, 52: 1.0, 53: 0.75, 54: 0.75, 55: 0.75, 56: 1.0, 57: 1.0, 58: 0.5, 59: 0.75, 60: 1.0, 61: 1.0, 62: 1.0, 63: 0.75, 64: 0.75, 65: 1.0, 66: 0.75, 67: 1.0, 68: 0.75, 69: 0.75, 70: 0.75, 71: 1.0, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 0.75, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.5, 101: 1.0, 102: 0.5, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 0.75, 108: 0.75, 109: 1.0, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.25, 114: 1.0, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 0.75, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 0.75, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.5, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 0.75, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 0.75, 181: 1.0, 182: 0.75, 183: 1.0, 184: 1.0, 185: 0.75, 186: 0.75, 187: 1.0, 188: 1.0, 189: 0.75, 190: 0.5, 191: 0.5, 192: 0.75, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-04 15:16:18,663 [INFO] [29] TRAIN  loss: 0.15374918797729062 acc: 0.0
2024-05-04 15:16:18,665 [INFO] [29] TRAIN  loss dict: {'mse_loss': 0.15374918797729062}
2024-05-04 15:16:18,667 [INFO] [29] VALIDATION loss: 0.8731128049995562 VALIDATION  acc: 0.8308080808080808
2024-05-04 15:16:18,668 [INFO] [29] VALIDATION  loss dict: {'mse_loss': 0.1871320754665919, 'classification_loss': 0.6859807277214713}
2024-05-04 15:16:18,670 [INFO] 
2024-05-04 15:17:28,662 [INFO] Step[50/1020]: training loss : 0.15673302188515664 TRAIN  loss dict:  {'mse_loss': 0.15673302188515664}
2024-05-04 15:18:13,371 [INFO] Step[100/1020]: training loss : 0.15477587789297104 TRAIN  loss dict:  {'mse_loss': 0.15477587789297104}
2024-05-04 15:18:58,083 [INFO] Step[150/1020]: training loss : 0.1494912722706795 TRAIN  loss dict:  {'mse_loss': 0.1494912722706795}
2024-05-04 15:19:42,515 [INFO] Step[200/1020]: training loss : 0.1569787561893463 TRAIN  loss dict:  {'mse_loss': 0.1569787561893463}
2024-05-04 15:20:23,714 [INFO] Step[250/1020]: training loss : 0.14884539917111397 TRAIN  loss dict:  {'mse_loss': 0.14884539917111397}
2024-05-04 15:21:04,079 [INFO] Step[300/1020]: training loss : 0.16057502284646033 TRAIN  loss dict:  {'mse_loss': 0.16057502284646033}
2024-05-04 15:21:42,918 [INFO] Step[350/1020]: training loss : 0.149454525411129 TRAIN  loss dict:  {'mse_loss': 0.149454525411129}
2024-05-04 15:22:25,109 [INFO] Step[400/1020]: training loss : 0.14969468846917153 TRAIN  loss dict:  {'mse_loss': 0.14969468846917153}
2024-05-04 15:23:05,544 [INFO] Step[450/1020]: training loss : 0.14593869924545289 TRAIN  loss dict:  {'mse_loss': 0.14593869924545289}
2024-05-04 15:23:47,294 [INFO] Step[500/1020]: training loss : 0.1508542913198471 TRAIN  loss dict:  {'mse_loss': 0.1508542913198471}
2024-05-04 15:24:28,606 [INFO] Step[550/1020]: training loss : 0.15420220777392388 TRAIN  loss dict:  {'mse_loss': 0.15420220777392388}
2024-05-04 15:25:08,840 [INFO] Step[600/1020]: training loss : 0.14862046241760254 TRAIN  loss dict:  {'mse_loss': 0.14862046241760254}
2024-05-04 15:25:51,720 [INFO] Step[650/1020]: training loss : 0.15811737298965453 TRAIN  loss dict:  {'mse_loss': 0.15811737298965453}
2024-05-04 15:26:33,723 [INFO] Step[700/1020]: training loss : 0.1496345530450344 TRAIN  loss dict:  {'mse_loss': 0.1496345530450344}
2024-05-04 15:27:19,528 [INFO] Step[750/1020]: training loss : 0.1549025946855545 TRAIN  loss dict:  {'mse_loss': 0.1549025946855545}
2024-05-04 15:28:05,903 [INFO] Step[800/1020]: training loss : 0.15461890548467636 TRAIN  loss dict:  {'mse_loss': 0.15461890548467636}
2024-05-04 15:28:45,740 [INFO] Step[850/1020]: training loss : 0.15636789068579673 TRAIN  loss dict:  {'mse_loss': 0.15636789068579673}
2024-05-04 15:29:28,220 [INFO] Step[900/1020]: training loss : 0.15479830160737038 TRAIN  loss dict:  {'mse_loss': 0.15479830160737038}
2024-05-04 15:30:08,867 [INFO] Step[950/1020]: training loss : 0.15326904639601707 TRAIN  loss dict:  {'mse_loss': 0.15326904639601707}
2024-05-04 15:30:52,415 [INFO] Step[1000/1020]: training loss : 0.15504768937826158 TRAIN  loss dict:  {'mse_loss': 0.15504768937826158}
2024-05-04 15:34:07,950 [INFO] Label accuracies statistics:
2024-05-04 15:34:07,950 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.5, 7: 1.0, 8: 0.75, 9: 1.0, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.5, 15: 0.75, 16: 0.75, 17: 0.75, 18: 1.0, 19: 0.5, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.5, 28: 0.5, 29: 0.75, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.75, 36: 1.0, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 1.0, 51: 0.5, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 0.75, 57: 1.0, 58: 0.75, 59: 0.5, 60: 1.0, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 1.0, 66: 0.5, 67: 0.75, 68: 1.0, 69: 0.75, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.5, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.5, 117: 0.75, 118: 0.75, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 0.5, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 1.0, 146: 0.75, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.5, 159: 0.75, 160: 0.75, 161: 0.75, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 0.75, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 0.5, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 1.0, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.5, 191: 0.5, 192: 0.75, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-04 15:34:07,970 [INFO] [30] TRAIN  loss: 0.15317767877496924 acc: 0.0
2024-05-04 15:34:07,970 [INFO] [30] TRAIN  loss dict: {'mse_loss': 0.15317767877496924}
2024-05-04 15:34:07,970 [INFO] [30] VALIDATION loss: 0.8385355545189044 VALIDATION  acc: 0.8257575757575758
2024-05-04 15:34:07,970 [INFO] [30] VALIDATION  loss dict: {'mse_loss': 0.18682892880204952, 'classification_loss': 0.6517066271026675}
2024-05-04 15:34:07,971 [INFO] 
2024-05-04 15:35:18,115 [INFO] Step[50/1020]: training loss : 0.14610738128423692 TRAIN  loss dict:  {'mse_loss': 0.14610738128423692}
2024-05-04 15:36:02,775 [INFO] Step[100/1020]: training loss : 0.14517160326242448 TRAIN  loss dict:  {'mse_loss': 0.14517160326242448}
2024-05-04 15:36:45,281 [INFO] Step[150/1020]: training loss : 0.14346590414643287 TRAIN  loss dict:  {'mse_loss': 0.14346590414643287}
2024-05-04 15:37:28,736 [INFO] Step[200/1020]: training loss : 0.1537631370127201 TRAIN  loss dict:  {'mse_loss': 0.1537631370127201}
2024-05-04 15:38:11,590 [INFO] Step[250/1020]: training loss : 0.14979073092341422 TRAIN  loss dict:  {'mse_loss': 0.14979073092341422}
2024-05-04 15:38:51,733 [INFO] Step[300/1020]: training loss : 0.15243593007326126 TRAIN  loss dict:  {'mse_loss': 0.15243593007326126}
2024-05-04 15:39:33,015 [INFO] Step[350/1020]: training loss : 0.14532578498125076 TRAIN  loss dict:  {'mse_loss': 0.14532578498125076}
2024-05-04 15:40:16,902 [INFO] Step[400/1020]: training loss : 0.15054287284612655 TRAIN  loss dict:  {'mse_loss': 0.15054287284612655}
2024-05-04 15:41:00,547 [INFO] Step[450/1020]: training loss : 0.15635901987552642 TRAIN  loss dict:  {'mse_loss': 0.15635901987552642}
2024-05-04 15:41:43,171 [INFO] Step[500/1020]: training loss : 0.1522930556535721 TRAIN  loss dict:  {'mse_loss': 0.1522930556535721}
2024-05-04 15:42:23,002 [INFO] Step[550/1020]: training loss : 0.15056377038359642 TRAIN  loss dict:  {'mse_loss': 0.15056377038359642}
2024-05-04 15:43:04,606 [INFO] Step[600/1020]: training loss : 0.15217501610517503 TRAIN  loss dict:  {'mse_loss': 0.15217501610517503}
2024-05-04 15:43:46,753 [INFO] Step[650/1020]: training loss : 0.151898755133152 TRAIN  loss dict:  {'mse_loss': 0.151898755133152}
2024-05-04 15:44:34,058 [INFO] Step[700/1020]: training loss : 0.15174087315797805 TRAIN  loss dict:  {'mse_loss': 0.15174087315797805}
2024-05-04 15:45:13,765 [INFO] Step[750/1020]: training loss : 0.14869691997766496 TRAIN  loss dict:  {'mse_loss': 0.14869691997766496}
2024-05-04 15:45:53,894 [INFO] Step[800/1020]: training loss : 0.14545256942510604 TRAIN  loss dict:  {'mse_loss': 0.14545256942510604}
2024-05-04 15:46:33,690 [INFO] Step[850/1020]: training loss : 0.14621051296591758 TRAIN  loss dict:  {'mse_loss': 0.14621051296591758}
2024-05-04 15:47:12,983 [INFO] Step[900/1020]: training loss : 0.1499398420751095 TRAIN  loss dict:  {'mse_loss': 0.1499398420751095}
2024-05-04 15:47:57,677 [INFO] Step[950/1020]: training loss : 0.1478500881791115 TRAIN  loss dict:  {'mse_loss': 0.1478500881791115}
2024-05-04 15:48:38,292 [INFO] Step[1000/1020]: training loss : 0.15377243623137474 TRAIN  loss dict:  {'mse_loss': 0.15377243623137474}
2024-05-04 15:51:48,385 [INFO] Label accuracies statistics:
2024-05-04 15:51:48,386 [INFO] {0: 1.0, 1: 0.5, 2: 0.25, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.5, 7: 1.0, 8: 0.75, 9: 0.75, 10: 1.0, 11: 1.0, 12: 1.0, 13: 0.75, 14: 0.75, 15: 0.75, 16: 0.75, 17: 0.75, 18: 1.0, 19: 0.75, 20: 0.75, 21: 0.75, 22: 0.75, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.75, 29: 0.75, 30: 0.75, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 0.75, 36: 1.0, 37: 0.75, 38: 0.5, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 0.75, 51: 0.5, 52: 0.5, 53: 0.75, 54: 0.5, 55: 0.75, 56: 0.75, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.75, 65: 1.0, 66: 0.5, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.5, 71: 1.0, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 1.0, 80: 0.75, 81: 0.75, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.5, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.75, 113: 0.25, 114: 1.0, 115: 1.0, 116: 0.75, 117: 0.75, 118: 0.75, 119: 1.0, 120: 1.0, 121: 1.0, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 0.75, 130: 0.75, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 0.75, 141: 0.75, 142: 1.0, 143: 0.75, 144: 0.75, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.75, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-04 15:51:48,407 [INFO] [31] TRAIN  loss: 0.14971415224466839 acc: 0.0
2024-05-04 15:51:48,407 [INFO] [31] TRAIN  loss dict: {'mse_loss': 0.14971415224466839}
2024-05-04 15:51:48,407 [INFO] [31] VALIDATION loss: 0.8690487662273826 VALIDATION  acc: 0.8383838383838383
2024-05-04 15:51:48,407 [INFO] [31] VALIDATION  loss dict: {'mse_loss': 0.18879506639157884, 'classification_loss': 0.6802536968536901}
2024-05-04 15:51:48,407 [INFO] 
2024-05-04 15:52:59,204 [INFO] Step[50/1020]: training loss : 0.14428715869784356 TRAIN  loss dict:  {'mse_loss': 0.14428715869784356}
2024-05-04 15:53:41,572 [INFO] Step[100/1020]: training loss : 0.14746077179908754 TRAIN  loss dict:  {'mse_loss': 0.14746077179908754}
2024-05-04 15:54:27,820 [INFO] Step[150/1020]: training loss : 0.14607901737093926 TRAIN  loss dict:  {'mse_loss': 0.14607901737093926}
2024-05-04 15:55:13,415 [INFO] Step[200/1020]: training loss : 0.14787303581833838 TRAIN  loss dict:  {'mse_loss': 0.14787303581833838}
2024-05-04 15:55:55,032 [INFO] Step[250/1020]: training loss : 0.1503790408372879 TRAIN  loss dict:  {'mse_loss': 0.1503790408372879}
2024-05-04 15:56:36,025 [INFO] Step[300/1020]: training loss : 0.14275355711579324 TRAIN  loss dict:  {'mse_loss': 0.14275355711579324}
2024-05-04 15:57:18,765 [INFO] Step[350/1020]: training loss : 0.15218953371047975 TRAIN  loss dict:  {'mse_loss': 0.15218953371047975}
2024-05-04 15:58:03,857 [INFO] Step[400/1020]: training loss : 0.14734978303313256 TRAIN  loss dict:  {'mse_loss': 0.14734978303313256}
2024-05-04 15:58:49,575 [INFO] Step[450/1020]: training loss : 0.14865853294730186 TRAIN  loss dict:  {'mse_loss': 0.14865853294730186}
2024-05-04 15:59:31,371 [INFO] Step[500/1020]: training loss : 0.155584407299757 TRAIN  loss dict:  {'mse_loss': 0.155584407299757}
2024-05-04 16:00:13,792 [INFO] Step[550/1020]: training loss : 0.15347347423434257 TRAIN  loss dict:  {'mse_loss': 0.15347347423434257}
2024-05-04 16:00:55,664 [INFO] Step[600/1020]: training loss : 0.14705972880125046 TRAIN  loss dict:  {'mse_loss': 0.14705972880125046}
2024-05-04 16:01:39,349 [INFO] Step[650/1020]: training loss : 0.15173512041568757 TRAIN  loss dict:  {'mse_loss': 0.15173512041568757}
2024-05-04 16:02:21,750 [INFO] Step[700/1020]: training loss : 0.14980095595121384 TRAIN  loss dict:  {'mse_loss': 0.14980095595121384}
2024-05-04 16:03:02,596 [INFO] Step[750/1020]: training loss : 0.14855154484510422 TRAIN  loss dict:  {'mse_loss': 0.14855154484510422}
2024-05-04 16:03:43,374 [INFO] Step[800/1020]: training loss : 0.15232284098863602 TRAIN  loss dict:  {'mse_loss': 0.15232284098863602}
2024-05-04 16:04:22,718 [INFO] Step[850/1020]: training loss : 0.15041965425014495 TRAIN  loss dict:  {'mse_loss': 0.15041965425014495}
2024-05-04 16:05:04,132 [INFO] Step[900/1020]: training loss : 0.13912633389234544 TRAIN  loss dict:  {'mse_loss': 0.13912633389234544}
2024-05-04 16:05:45,275 [INFO] Step[950/1020]: training loss : 0.1533076421916485 TRAIN  loss dict:  {'mse_loss': 0.1533076421916485}
2024-05-04 16:06:26,258 [INFO] Step[1000/1020]: training loss : 0.15260173112154007 TRAIN  loss dict:  {'mse_loss': 0.15260173112154007}
2024-05-04 16:09:36,609 [INFO] Label accuracies statistics:
2024-05-04 16:09:36,610 [INFO] {0: 0.5, 1: 0.5, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.75, 9: 0.75, 10: 1.0, 11: 1.0, 12: 1.0, 13: 0.75, 14: 0.75, 15: 0.5, 16: 0.75, 17: 0.75, 18: 1.0, 19: 0.5, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.5, 29: 0.75, 30: 1.0, 31: 0.75, 32: 0.75, 33: 1.0, 34: 0.75, 35: 1.0, 36: 1.0, 37: 0.75, 38: 0.75, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.5, 55: 0.75, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.75, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.5, 65: 1.0, 66: 0.5, 67: 0.75, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.5, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 0.75, 94: 1.0, 95: 1.0, 96: 1.0, 97: 0.75, 98: 1.0, 99: 1.0, 100: 0.75, 101: 0.75, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 0.75, 111: 0.75, 112: 0.5, 113: 0.25, 114: 0.5, 115: 1.0, 116: 0.75, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.25, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 0.75, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 1.0, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.5, 158: 0.5, 159: 0.75, 160: 0.75, 161: 1.0, 162: 1.0, 163: 0.75, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.75, 185: 0.75, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-04 16:09:36,630 [INFO] [32] TRAIN  loss: 0.14900791645780498 acc: 0.0
2024-05-04 16:09:36,630 [INFO] [32] TRAIN  loss dict: {'mse_loss': 0.14900791645780498}
2024-05-04 16:09:36,630 [INFO] [32] VALIDATION loss: 0.8362503292208369 VALIDATION  acc: 0.8446969696969697
2024-05-04 16:09:36,630 [INFO] [32] VALIDATION  loss dict: {'mse_loss': 0.18455739868710738, 'classification_loss': 0.651692929505982}
2024-05-04 16:09:36,630 [INFO] 
2024-05-04 16:10:50,342 [INFO] Step[50/1020]: training loss : 0.15087080955505372 TRAIN  loss dict:  {'mse_loss': 0.15087080955505372}
2024-05-04 16:11:29,063 [INFO] Step[100/1020]: training loss : 0.1405721616744995 TRAIN  loss dict:  {'mse_loss': 0.1405721616744995}
2024-05-04 16:12:10,878 [INFO] Step[150/1020]: training loss : 0.15026225864887238 TRAIN  loss dict:  {'mse_loss': 0.15026225864887238}
2024-05-04 16:12:50,932 [INFO] Step[200/1020]: training loss : 0.1444284835457802 TRAIN  loss dict:  {'mse_loss': 0.1444284835457802}
2024-05-04 16:13:30,805 [INFO] Step[250/1020]: training loss : 0.14820515871047973 TRAIN  loss dict:  {'mse_loss': 0.14820515871047973}
2024-05-04 16:14:09,499 [INFO] Step[300/1020]: training loss : 0.14941085159778594 TRAIN  loss dict:  {'mse_loss': 0.14941085159778594}
2024-05-04 16:14:48,888 [INFO] Step[350/1020]: training loss : 0.1463356138765812 TRAIN  loss dict:  {'mse_loss': 0.1463356138765812}
2024-05-04 16:15:31,029 [INFO] Step[400/1020]: training loss : 0.14754830911755562 TRAIN  loss dict:  {'mse_loss': 0.14754830911755562}
2024-05-04 16:16:12,271 [INFO] Step[450/1020]: training loss : 0.15546547070145608 TRAIN  loss dict:  {'mse_loss': 0.15546547070145608}
2024-05-04 16:16:53,372 [INFO] Step[500/1020]: training loss : 0.1475082516670227 TRAIN  loss dict:  {'mse_loss': 0.1475082516670227}
2024-05-04 16:17:34,069 [INFO] Step[550/1020]: training loss : 0.1515261176228523 TRAIN  loss dict:  {'mse_loss': 0.1515261176228523}
2024-05-04 16:18:13,240 [INFO] Step[600/1020]: training loss : 0.13914928033947946 TRAIN  loss dict:  {'mse_loss': 0.13914928033947946}
2024-05-04 16:18:56,992 [INFO] Step[650/1020]: training loss : 0.1567234180867672 TRAIN  loss dict:  {'mse_loss': 0.1567234180867672}
2024-05-04 16:19:38,731 [INFO] Step[700/1020]: training loss : 0.15037063553929328 TRAIN  loss dict:  {'mse_loss': 0.15037063553929328}
2024-05-04 16:20:23,565 [INFO] Step[750/1020]: training loss : 0.15268829971551895 TRAIN  loss dict:  {'mse_loss': 0.15268829971551895}
2024-05-04 16:21:02,854 [INFO] Step[800/1020]: training loss : 0.14705059364438056 TRAIN  loss dict:  {'mse_loss': 0.14705059364438056}
2024-05-04 16:21:42,981 [INFO] Step[850/1020]: training loss : 0.1418818563222885 TRAIN  loss dict:  {'mse_loss': 0.1418818563222885}
2024-05-04 16:22:25,415 [INFO] Step[900/1020]: training loss : 0.14551528349518775 TRAIN  loss dict:  {'mse_loss': 0.14551528349518775}
2024-05-04 16:23:08,491 [INFO] Step[950/1020]: training loss : 0.14514389082789422 TRAIN  loss dict:  {'mse_loss': 0.14514389082789422}
2024-05-04 16:23:47,249 [INFO] Step[1000/1020]: training loss : 0.14995670214295387 TRAIN  loss dict:  {'mse_loss': 0.14995670214295387}
2024-05-04 16:27:03,049 [INFO] Label accuracies statistics:
2024-05-04 16:27:03,050 [INFO] {0: 1.0, 1: 0.5, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.5, 7: 1.0, 8: 0.75, 9: 0.75, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.5, 15: 0.75, 16: 0.75, 17: 0.5, 18: 1.0, 19: 0.5, 20: 0.75, 21: 0.75, 22: 1.0, 23: 1.0, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.75, 28: 0.5, 29: 0.75, 30: 1.0, 31: 0.75, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.75, 36: 1.0, 37: 0.75, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 1.0, 48: 0.75, 49: 0.5, 50: 1.0, 51: 0.5, 52: 0.75, 53: 0.75, 54: 0.5, 55: 0.75, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 1.0, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.5, 65: 1.0, 66: 0.5, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.75, 71: 1.0, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 1.0, 110: 0.75, 111: 0.75, 112: 1.0, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 0.75, 118: 0.75, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 0.75, 129: 1.0, 130: 0.75, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 0.75, 139: 0.75, 140: 1.0, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 1.0, 146: 0.75, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.25, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.75, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.75, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 1.0, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 1.0, 185: 0.75, 186: 0.75, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.75, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-04 16:27:03,071 [INFO] [33] TRAIN  loss: 0.1481052385752692 acc: 0.0
2024-05-04 16:27:03,071 [INFO] [33] TRAIN  loss dict: {'mse_loss': 0.1481052385752692}
2024-05-04 16:27:03,071 [INFO] [33] VALIDATION loss: 0.822833585167172 VALIDATION  acc: 0.8434343434343434
2024-05-04 16:27:03,072 [INFO] [33] VALIDATION  loss dict: {'mse_loss': 0.18173162748265748, 'classification_loss': 0.6411019577550693}
2024-05-04 16:27:03,072 [INFO] 
2024-05-04 16:27:03,072 [INFO] 

***Stop training***


2024-05-04 16:27:03,073 [INFO] 
Testing checkpointed models starting...

2024-05-04 16:32:10,177 [INFO] Label accuracies statistics:
2024-05-04 16:32:10,177 [INFO] {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0, 6: 0.75, 7: 1.0, 8: 1.0, 9: 0.75, 10: 1.0, 11: 1.0, 12: 1.0, 13: 0.75, 14: 0.75, 15: 0.25, 16: 1.0, 17: 0.3333333333333333, 18: 1.0, 19: 0.6666666666666666, 20: 0.5, 21: 0.25, 22: 1.0, 23: 1.0, 24: 1.0, 25: 0.75, 26: 0.5, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.5, 31: 1.0, 32: 1.0, 33: 1.0, 34: 1.0, 35: 1.0, 36: 0.75, 37: 1.0, 38: 1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: 0.75, 43: 0.75, 44: 1.0, 45: 1.0, 46: 1.0, 47: 0.75, 48: 0.75, 49: 0.25, 50: 0.5, 51: 1.0, 52: 0.75, 53: 0.5, 54: 0.75, 55: 1.0, 56: 0.5, 57: 0.75, 58: 0.75, 59: 0.75, 60: 1.0, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.5, 65: 0.25, 66: 0.5, 67: 0.5, 68: 0.5, 69: 1.0, 70: 1.0, 71: 0.75, 72: 0.5, 73: 0.5, 74: 1.0, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 1.0, 83: 1.0, 84: 1.0, 85: 1.0, 86: 0.75, 87: 1.0, 88: 1.0, 89: 0.75, 90: 1.0, 91: 1.0, 92: 1.0, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 1.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.5, 103: 0.75, 104: 0.75, 105: 0.25, 106: 0.75, 107: 0.75, 108: 0.75, 109: 0.75, 110: 0.5, 111: 1.0, 112: 1.0, 113: 0.25, 114: 0.75, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 0.5, 120: 0.75, 121: 0.75, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 0.5, 130: 0.25, 131: 1.0, 132: 1.0, 133: 1.0, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 0.75, 140: 0.75, 141: 0.75, 142: 0.75, 143: 1.0, 144: 0.75, 145: 1.0, 146: 0.5, 147: 1.0, 148: 0.25, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.75, 159: 0.5, 160: 0.75, 161: 0.5, 162: 0.5, 163: 0.75, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.25, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 0.75, 175: 0.75, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.5, 180: 0.5, 181: 0.75, 182: 0.75, 183: 0.75, 184: 0.5, 185: 0.75, 186: 0.75, 187: 0.75, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.5, 192: 0.75, 193: 0.75, 194: 0.75, 195: 0.5, 196: 0.75, 197: 0.75, 198: 0.75}

2024-05-04 16:32:10,190 [INFO] 
Testing accuracy: 0.7964601769911505