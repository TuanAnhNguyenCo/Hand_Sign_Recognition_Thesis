2024-05-03 14:43:13,528 [INFO] Step[50/1020]: training loss : 0.5868671977519989 TRAIN  loss dict:  {'mse_loss': 0.5868671977519989}
2024-05-03 14:44:05,809 [INFO] Step[100/1020]: training loss : 0.4915395653247833 TRAIN  loss dict:  {'mse_loss': 0.4915395653247833}
2024-05-03 14:44:56,303 [INFO] Step[150/1020]: training loss : 0.4568388342857361 TRAIN  loss dict:  {'mse_loss': 0.4568388342857361}
2024-05-03 14:45:48,365 [INFO] Step[200/1020]: training loss : 0.43542587459087373 TRAIN  loss dict:  {'mse_loss': 0.43542587459087373}
2024-05-03 14:46:40,055 [INFO] Step[250/1020]: training loss : 0.4183744943141937 TRAIN  loss dict:  {'mse_loss': 0.4183744943141937}
2024-05-03 14:47:30,159 [INFO] Step[300/1020]: training loss : 0.40816432297229766 TRAIN  loss dict:  {'mse_loss': 0.40816432297229766}
2024-05-03 14:48:20,823 [INFO] Step[350/1020]: training loss : 0.39069535076618195 TRAIN  loss dict:  {'mse_loss': 0.39069535076618195}
2024-05-03 14:49:14,022 [INFO] Step[400/1020]: training loss : 0.38378062963485715 TRAIN  loss dict:  {'mse_loss': 0.38378062963485715}
2024-05-03 14:50:08,255 [INFO] Step[450/1020]: training loss : 0.3767220997810364 TRAIN  loss dict:  {'mse_loss': 0.3767220997810364}
2024-05-03 14:50:59,065 [INFO] Step[500/1020]: training loss : 0.36900634586811065 TRAIN  loss dict:  {'mse_loss': 0.36900634586811065}
2024-05-03 14:51:50,844 [INFO] Step[550/1020]: training loss : 0.3622147125005722 TRAIN  loss dict:  {'mse_loss': 0.3622147125005722}
2024-05-03 14:52:42,177 [INFO] Step[600/1020]: training loss : 0.3557077920436859 TRAIN  loss dict:  {'mse_loss': 0.3557077920436859}
2024-05-03 14:53:32,803 [INFO] Step[650/1020]: training loss : 0.3469202584028244 TRAIN  loss dict:  {'mse_loss': 0.3469202584028244}
2024-05-03 14:54:23,984 [INFO] Step[700/1020]: training loss : 0.3465542042255402 TRAIN  loss dict:  {'mse_loss': 0.3465542042255402}
2024-05-03 14:55:17,424 [INFO] Step[750/1020]: training loss : 0.33751329183578493 TRAIN  loss dict:  {'mse_loss': 0.33751329183578493}
2024-05-03 14:56:10,432 [INFO] Step[800/1020]: training loss : 0.3375901073217392 TRAIN  loss dict:  {'mse_loss': 0.3375901073217392}
2024-05-03 14:57:00,161 [INFO] Step[850/1020]: training loss : 0.3250566428899765 TRAIN  loss dict:  {'mse_loss': 0.3250566428899765}
2024-05-03 14:57:51,267 [INFO] Step[900/1020]: training loss : 0.32724059879779815 TRAIN  loss dict:  {'mse_loss': 0.32724059879779815}
2024-05-03 14:58:40,945 [INFO] Step[950/1020]: training loss : 0.31928549528121947 TRAIN  loss dict:  {'mse_loss': 0.31928549528121947}
2024-05-03 14:59:29,783 [INFO] Step[1000/1020]: training loss : 0.3219023931026459 TRAIN  loss dict:  {'mse_loss': 0.3219023931026459}
2024-05-03 15:03:08,346 [INFO] Label accuracies statistics:
2024-05-03 15:03:08,347 [INFO] {0: 0.0, 1: 1.0, 2: 0.25, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.75, 7: 0.5, 8: 0.25, 9: 1.0, 10: 0.75, 11: 1.0, 12: 0.5, 13: 0.75, 14: 0.75, 15: 1.0, 16: 0.5, 17: 0.5, 18: 1.0, 19: 0.5, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 0.75, 29: 0.5, 30: 0.75, 31: 1.0, 32: 0.5, 33: 1.0, 34: 0.25, 35: 0.25, 36: 0.75, 37: 0.25, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 0.75, 47: 1.0, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.5, 52: 0.75, 53: 0.0, 54: 0.75, 55: 0.75, 56: 1.0, 57: 0.75, 58: 0.75, 59: 0.5, 60: 0.5, 61: 0.75, 62: 1.0, 63: 0.75, 64: 0.75, 65: 0.25, 66: 0.75, 67: 0.75, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.25, 72: 1.0, 73: 0.5, 74: 0.25, 75: 1.0, 76: 0.75, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 0.75, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.5, 88: 1.0, 89: 0.5, 90: 0.75, 91: 1.0, 92: 0.75, 93: 0.75, 94: 0.25, 95: 0.75, 96: 0.75, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.5, 104: 1.0, 105: 0.25, 106: 0.75, 107: 0.5, 108: 0.5, 109: 1.0, 110: 1.0, 111: 0.75, 112: 0.5, 113: 0.0, 114: 1.0, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 0.75, 122: 0.5, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 1.0, 129: 0.75, 130: 1.0, 131: 0.75, 132: 1.0, 133: 0.25, 134: 0.75, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.5, 139: 0.5, 140: 0.5, 141: 0.75, 142: 0.75, 143: 0.5, 144: 1.0, 145: 0.75, 146: 0.75, 147: 0.75, 148: 0.75, 149: 1.0, 150: 0.25, 151: 0.75, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.5, 156: 0.75, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.25, 163: 1.0, 164: 0.5, 165: 1.0, 166: 0.0, 167: 0.75, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.25, 172: 1.0, 173: 0.75, 174: 0.5, 175: 1.0, 176: 0.5, 177: 0.75, 178: 1.0, 179: 1.0, 180: 0.75, 181: 0.75, 182: 1.0, 183: 0.5, 184: 0.75, 185: 1.0, 186: 0.75, 187: 0.75, 188: 0.75, 189: 0.75, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.0, 194: 1.0, 195: 0.75, 196: 1.0, 197: 0.75, 198: 0.25}

2024-05-03 15:03:10,400 [INFO] [1] TRAIN  loss: 0.383509479054049 acc: 0.0
2024-05-03 15:03:10,400 [INFO] [1] TRAIN  loss dict: {'mse_loss': 0.383509479054049}
2024-05-03 15:03:10,401 [INFO] [1] VALIDATION loss: 1.4670229072522636 VALIDATION  acc: 0.7449494949494949
2024-05-03 15:03:10,401 [INFO] [1] VALIDATION  loss dict: {'mse_loss': 0.29352506664064193, 'classification_loss': 1.1734978431704068}
2024-05-03 15:03:10,401 [INFO] 
2024-05-03 15:04:40,413 [INFO] Step[50/1020]: training loss : 0.3020843973755836 TRAIN  loss dict:  {'mse_loss': 0.3020843973755836}
2024-05-03 15:05:30,396 [INFO] Step[100/1020]: training loss : 0.29970990657806396 TRAIN  loss dict:  {'mse_loss': 0.29970990657806396}
2024-05-03 15:06:20,451 [INFO] Step[150/1020]: training loss : 0.29720307677984237 TRAIN  loss dict:  {'mse_loss': 0.29720307677984237}
2024-05-03 15:07:11,469 [INFO] Step[200/1020]: training loss : 0.30067235231399536 TRAIN  loss dict:  {'mse_loss': 0.30067235231399536}
2024-05-03 15:08:03,134 [INFO] Step[250/1020]: training loss : 0.2908734002709389 TRAIN  loss dict:  {'mse_loss': 0.2908734002709389}
2024-05-03 15:08:52,161 [INFO] Step[300/1020]: training loss : 0.2853222957253456 TRAIN  loss dict:  {'mse_loss': 0.2853222957253456}
2024-05-03 15:09:41,708 [INFO] Step[350/1020]: training loss : 0.28521999150514604 TRAIN  loss dict:  {'mse_loss': 0.28521999150514604}
2024-05-03 15:10:32,695 [INFO] Step[400/1020]: training loss : 0.2827395927906036 TRAIN  loss dict:  {'mse_loss': 0.2827395927906036}
2024-05-03 15:11:23,665 [INFO] Step[450/1020]: training loss : 0.27712567925453185 TRAIN  loss dict:  {'mse_loss': 0.27712567925453185}
2024-05-03 15:12:13,316 [INFO] Step[500/1020]: training loss : 0.28111215502023695 TRAIN  loss dict:  {'mse_loss': 0.28111215502023695}
2024-05-03 15:13:04,401 [INFO] Step[550/1020]: training loss : 0.2779219999909401 TRAIN  loss dict:  {'mse_loss': 0.2779219999909401}
2024-05-03 15:13:55,953 [INFO] Step[600/1020]: training loss : 0.27618701457977296 TRAIN  loss dict:  {'mse_loss': 0.27618701457977296}
2024-05-03 15:14:48,505 [INFO] Step[650/1020]: training loss : 0.27149478286504747 TRAIN  loss dict:  {'mse_loss': 0.27149478286504747}
2024-05-03 15:15:41,844 [INFO] Step[700/1020]: training loss : 0.27189959555864335 TRAIN  loss dict:  {'mse_loss': 0.27189959555864335}
2024-05-03 15:16:33,737 [INFO] Step[750/1020]: training loss : 0.26529737263917924 TRAIN  loss dict:  {'mse_loss': 0.26529737263917924}
2024-05-03 15:17:24,879 [INFO] Step[800/1020]: training loss : 0.26999946862459184 TRAIN  loss dict:  {'mse_loss': 0.26999946862459184}
2024-05-03 15:18:16,912 [INFO] Step[850/1020]: training loss : 0.2685657232999802 TRAIN  loss dict:  {'mse_loss': 0.2685657232999802}
2024-05-03 15:19:10,852 [INFO] Step[900/1020]: training loss : 0.2667952612042427 TRAIN  loss dict:  {'mse_loss': 0.2667952612042427}
2024-05-03 15:20:04,551 [INFO] Step[950/1020]: training loss : 0.2691961845755577 TRAIN  loss dict:  {'mse_loss': 0.2691961845755577}
2024-05-03 15:20:55,873 [INFO] Step[1000/1020]: training loss : 0.2580094799399376 TRAIN  loss dict:  {'mse_loss': 0.2580094799399376}
2024-05-03 15:24:24,965 [INFO] Label accuracies statistics:
2024-05-03 15:24:24,965 [INFO] {0: 0.5, 1: 0.5, 2: 0.25, 3: 0.75, 4: 0.3333333333333333, 5: 0.75, 6: 0.75, 7: 1.0, 8: 0.25, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.25, 13: 0.5, 14: 0.75, 15: 0.75, 16: 1.0, 17: 0.75, 18: 1.0, 19: 0.25, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.5, 24: 0.75, 25: 1.0, 26: 1.0, 27: 1.0, 28: 1.0, 29: 0.75, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.25, 35: 0.5, 36: 0.75, 37: 0.5, 38: 1.0, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 0.5, 47: 1.0, 48: 1.0, 49: 0.75, 50: 0.75, 51: 0.75, 52: 0.5, 53: 0.0, 54: 0.5, 55: 1.0, 56: 0.75, 57: 1.0, 58: 0.75, 59: 1.0, 60: 0.75, 61: 0.75, 62: 1.0, 63: 0.5, 64: 0.75, 65: 0.5, 66: 0.5, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.5, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.25, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.5, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.5, 88: 1.0, 89: 1.0, 90: 0.25, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.25, 106: 0.75, 107: 1.0, 108: 0.75, 109: 1.0, 110: 1.0, 111: 0.75, 112: 0.5, 113: 0.5, 114: 0.75, 115: 1.0, 116: 1.0, 117: 1.0, 118: 0.75, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.5, 123: 0.75, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 0.75, 131: 0.75, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 0.5, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 0.75, 147: 0.5, 148: 0.5, 149: 1.0, 150: 0.25, 151: 0.75, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.25, 156: 1.0, 157: 0.5, 158: 0.5, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.5, 163: 1.0, 164: 0.5, 165: 0.75, 166: 0.5, 167: 0.75, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.25, 172: 0.5, 173: 0.75, 174: 0.75, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 0.75, 182: 1.0, 183: 1.0, 184: 0.0, 185: 0.75, 186: 1.0, 187: 0.75, 188: 0.5, 189: 0.75, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.0, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.75}

2024-05-03 15:24:29,948 [INFO] [2] TRAIN  loss: 0.2795060744618668 acc: 0.0
2024-05-03 15:24:29,949 [INFO] [2] TRAIN  loss dict: {'mse_loss': 0.2795060744618668}
2024-05-03 15:24:29,949 [INFO] [2] VALIDATION loss: 1.0952219597317956 VALIDATION  acc: 0.7689393939393939
2024-05-03 15:24:29,949 [INFO] [2] VALIDATION  loss dict: {'mse_loss': 0.24267138194556187, 'classification_loss': 0.8525505778991213}
2024-05-03 15:24:29,949 [INFO] 
2024-05-03 15:26:08,472 [INFO] Step[50/1020]: training loss : 0.2523226830363274 TRAIN  loss dict:  {'mse_loss': 0.2523226830363274}
2024-05-03 15:26:58,197 [INFO] Step[100/1020]: training loss : 0.25299555212259295 TRAIN  loss dict:  {'mse_loss': 0.25299555212259295}
2024-05-03 15:27:49,864 [INFO] Step[150/1020]: training loss : 0.24865933865308762 TRAIN  loss dict:  {'mse_loss': 0.24865933865308762}
2024-05-03 15:28:42,292 [INFO] Step[200/1020]: training loss : 0.24328844010829925 TRAIN  loss dict:  {'mse_loss': 0.24328844010829925}
2024-05-03 15:29:37,919 [INFO] Step[250/1020]: training loss : 0.24573875963687897 TRAIN  loss dict:  {'mse_loss': 0.24573875963687897}
2024-05-03 15:30:34,504 [INFO] Step[300/1020]: training loss : 0.24099811136722565 TRAIN  loss dict:  {'mse_loss': 0.24099811136722565}
2024-05-03 15:31:28,089 [INFO] Step[350/1020]: training loss : 0.24989380210638046 TRAIN  loss dict:  {'mse_loss': 0.24989380210638046}
2024-05-03 15:32:21,721 [INFO] Step[400/1020]: training loss : 0.2541162726283073 TRAIN  loss dict:  {'mse_loss': 0.2541162726283073}
2024-05-03 15:33:13,011 [INFO] Step[450/1020]: training loss : 0.23960830450057982 TRAIN  loss dict:  {'mse_loss': 0.23960830450057982}
2024-05-03 15:34:08,651 [INFO] Step[500/1020]: training loss : 0.24697164297103882 TRAIN  loss dict:  {'mse_loss': 0.24697164297103882}
2024-05-03 15:35:00,898 [INFO] Step[550/1020]: training loss : 0.22687632024288176 TRAIN  loss dict:  {'mse_loss': 0.22687632024288176}
2024-05-03 15:35:54,078 [INFO] Step[600/1020]: training loss : 0.23930274665355683 TRAIN  loss dict:  {'mse_loss': 0.23930274665355683}
2024-05-03 15:36:47,561 [INFO] Step[650/1020]: training loss : 0.22950857907533645 TRAIN  loss dict:  {'mse_loss': 0.22950857907533645}
2024-05-03 15:37:39,786 [INFO] Step[700/1020]: training loss : 0.24056948333978653 TRAIN  loss dict:  {'mse_loss': 0.24056948333978653}
2024-05-03 15:38:32,951 [INFO] Step[750/1020]: training loss : 0.23345092087984085 TRAIN  loss dict:  {'mse_loss': 0.23345092087984085}
2024-05-03 15:39:23,954 [INFO] Step[800/1020]: training loss : 0.23471323400735855 TRAIN  loss dict:  {'mse_loss': 0.23471323400735855}
2024-05-03 15:40:15,727 [INFO] Step[850/1020]: training loss : 0.22881580144166946 TRAIN  loss dict:  {'mse_loss': 0.22881580144166946}
2024-05-03 15:41:09,054 [INFO] Step[900/1020]: training loss : 0.23125117838382722 TRAIN  loss dict:  {'mse_loss': 0.23125117838382722}
2024-05-03 15:42:02,453 [INFO] Step[950/1020]: training loss : 0.2294892907142639 TRAIN  loss dict:  {'mse_loss': 0.2294892907142639}
2024-05-03 15:42:56,284 [INFO] Step[1000/1020]: training loss : 0.2247081944346428 TRAIN  loss dict:  {'mse_loss': 0.2247081944346428}
2024-05-03 15:46:33,415 [INFO] Label accuracies statistics:
2024-05-03 15:46:33,416 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.75, 9: 1.0, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.75, 15: 0.5, 16: 0.75, 17: 0.5, 18: 1.0, 19: 1.0, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 1.0, 29: 0.5, 30: 0.75, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.75, 36: 1.0, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 0.75, 47: 1.0, 48: 1.0, 49: 0.75, 50: 0.75, 51: 1.0, 52: 0.5, 53: 0.0, 54: 0.5, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.5, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.75, 66: 0.75, 67: 1.0, 68: 0.5, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 1.0, 80: 1.0, 81: 1.0, 82: 0.5, 83: 1.0, 84: 1.0, 85: 1.0, 86: 0.75, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.25, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.5, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.5, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.75, 114: 0.25, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.5, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 0.75, 147: 0.75, 148: 0.5, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.5, 158: 0.5, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.5, 163: 1.0, 164: 0.75, 165: 1.0, 166: 0.25, 167: 1.0, 168: 0.5, 169: 0.75, 170: 0.75, 171: 0.25, 172: 1.0, 173: 0.75, 174: 0.75, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 1.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-03 15:46:38,284 [INFO] [3] TRAIN  loss: 0.23948024636974521 acc: 0.0
2024-05-03 15:46:38,284 [INFO] [3] TRAIN  loss dict: {'mse_loss': 0.23948024636974521}
2024-05-03 15:46:38,285 [INFO] [3] VALIDATION loss: 0.8374412926760587 VALIDATION  acc: 0.8421717171717171
2024-05-03 15:46:38,285 [INFO] [3] VALIDATION  loss dict: {'mse_loss': 0.2137309992403695, 'classification_loss': 0.623710290218393}
2024-05-03 15:46:38,285 [INFO] 
2024-05-03 15:48:20,655 [INFO] Step[50/1020]: training loss : 0.21894340842962265 TRAIN  loss dict:  {'mse_loss': 0.21894340842962265}
2024-05-03 15:49:12,159 [INFO] Step[100/1020]: training loss : 0.2177536329627037 TRAIN  loss dict:  {'mse_loss': 0.2177536329627037}
2024-05-03 15:50:05,752 [INFO] Step[150/1020]: training loss : 0.21720900297164916 TRAIN  loss dict:  {'mse_loss': 0.21720900297164916}
2024-05-03 15:50:56,614 [INFO] Step[200/1020]: training loss : 0.21950647115707397 TRAIN  loss dict:  {'mse_loss': 0.21950647115707397}
2024-05-03 15:51:51,216 [INFO] Step[250/1020]: training loss : 0.21849822729825974 TRAIN  loss dict:  {'mse_loss': 0.21849822729825974}
2024-05-03 15:52:46,670 [INFO] Step[300/1020]: training loss : 0.21686359524726867 TRAIN  loss dict:  {'mse_loss': 0.21686359524726867}
2024-05-03 15:53:38,508 [INFO] Step[350/1020]: training loss : 0.21923913627862932 TRAIN  loss dict:  {'mse_loss': 0.21923913627862932}
2024-05-03 15:54:30,402 [INFO] Step[400/1020]: training loss : 0.22235584169626235 TRAIN  loss dict:  {'mse_loss': 0.22235584169626235}
2024-05-03 15:55:23,711 [INFO] Step[450/1020]: training loss : 0.22277723670005797 TRAIN  loss dict:  {'mse_loss': 0.22277723670005797}
2024-05-03 15:56:16,485 [INFO] Step[500/1020]: training loss : 0.21255008667707442 TRAIN  loss dict:  {'mse_loss': 0.21255008667707442}
2024-05-03 15:57:05,964 [INFO] Step[550/1020]: training loss : 0.21609276354312898 TRAIN  loss dict:  {'mse_loss': 0.21609276354312898}
2024-05-03 15:57:56,852 [INFO] Step[600/1020]: training loss : 0.21416224271059037 TRAIN  loss dict:  {'mse_loss': 0.21416224271059037}
2024-05-03 15:58:48,015 [INFO] Step[650/1020]: training loss : 0.21080477237701417 TRAIN  loss dict:  {'mse_loss': 0.21080477237701417}
2024-05-03 15:59:36,939 [INFO] Step[700/1020]: training loss : 0.21205124139785766 TRAIN  loss dict:  {'mse_loss': 0.21205124139785766}
2024-05-03 16:00:28,688 [INFO] Step[750/1020]: training loss : 0.21238950937986373 TRAIN  loss dict:  {'mse_loss': 0.21238950937986373}
2024-05-03 16:01:20,635 [INFO] Step[800/1020]: training loss : 0.21584296822547913 TRAIN  loss dict:  {'mse_loss': 0.21584296822547913}
2024-05-03 16:02:12,708 [INFO] Step[850/1020]: training loss : 0.20910533428192138 TRAIN  loss dict:  {'mse_loss': 0.20910533428192138}
2024-05-03 16:03:03,824 [INFO] Step[900/1020]: training loss : 0.21083894044160842 TRAIN  loss dict:  {'mse_loss': 0.21083894044160842}
2024-05-03 16:03:57,515 [INFO] Step[950/1020]: training loss : 0.2174109062552452 TRAIN  loss dict:  {'mse_loss': 0.2174109062552452}
2024-05-03 16:04:50,242 [INFO] Step[1000/1020]: training loss : 0.20646017014980317 TRAIN  loss dict:  {'mse_loss': 0.20646017014980317}
2024-05-03 16:08:29,527 [INFO] Label accuracies statistics:
2024-05-03 16:08:29,527 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.5, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.5, 13: 0.75, 14: 0.75, 15: 0.5, 16: 1.0, 17: 1.0, 18: 1.0, 19: 1.0, 20: 0.75, 21: 1.0, 22: 1.0, 23: 0.5, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 1.0, 29: 0.75, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.75, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 0.75, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 1.0, 52: 0.75, 53: 0.0, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 1.0, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.75, 66: 0.75, 67: 1.0, 68: 0.5, 69: 1.0, 70: 1.0, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 1.0, 83: 1.0, 84: 1.0, 85: 1.0, 86: 0.75, 87: 0.75, 88: 1.0, 89: 1.0, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 0.75, 96: 0.75, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.75, 103: 0.5, 104: 1.0, 105: 0.25, 106: 1.0, 107: 1.0, 108: 0.5, 109: 0.5, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 1.0, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.75, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.5, 163: 1.0, 164: 1.0, 165: 1.0, 166: 0.5, 167: 0.75, 168: 0.5, 169: 0.5, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 0.75, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.25, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-03 16:08:34,446 [INFO] [4] TRAIN  loss: 0.21542502358263615 acc: 0.0
2024-05-03 16:08:34,447 [INFO] [4] TRAIN  loss dict: {'mse_loss': 0.21542502358263615}
2024-05-03 16:08:34,447 [INFO] [4] VALIDATION loss: 0.7242224773373267 VALIDATION  acc: 0.8573232323232324
2024-05-03 16:08:34,447 [INFO] [4] VALIDATION  loss dict: {'mse_loss': 0.19420722300055052, 'classification_loss': 0.5300152527093135}
2024-05-03 16:08:34,447 [INFO] 
2024-05-03 16:10:14,228 [INFO] Step[50/1020]: training loss : 0.20246825873851776 TRAIN  loss dict:  {'mse_loss': 0.20246825873851776}
2024-05-03 16:11:06,851 [INFO] Step[100/1020]: training loss : 0.20313249558210372 TRAIN  loss dict:  {'mse_loss': 0.20313249558210372}
2024-05-03 16:11:57,230 [INFO] Step[150/1020]: training loss : 0.2039058157801628 TRAIN  loss dict:  {'mse_loss': 0.2039058157801628}
2024-05-03 16:12:46,316 [INFO] Step[200/1020]: training loss : 0.2031562438607216 TRAIN  loss dict:  {'mse_loss': 0.2031562438607216}
2024-05-03 16:13:37,850 [INFO] Step[250/1020]: training loss : 0.19713036507368087 TRAIN  loss dict:  {'mse_loss': 0.19713036507368087}
2024-05-03 16:14:27,458 [INFO] Step[300/1020]: training loss : 0.20382096409797668 TRAIN  loss dict:  {'mse_loss': 0.20382096409797668}
2024-05-03 16:15:18,697 [INFO] Step[350/1020]: training loss : 0.1994711998105049 TRAIN  loss dict:  {'mse_loss': 0.1994711998105049}
2024-05-03 16:16:10,024 [INFO] Step[400/1020]: training loss : 0.204828183054924 TRAIN  loss dict:  {'mse_loss': 0.204828183054924}
2024-05-03 16:17:00,381 [INFO] Step[450/1020]: training loss : 0.20162059664726256 TRAIN  loss dict:  {'mse_loss': 0.20162059664726256}
2024-05-03 16:17:50,231 [INFO] Step[500/1020]: training loss : 0.201171957552433 TRAIN  loss dict:  {'mse_loss': 0.201171957552433}
2024-05-03 16:18:42,914 [INFO] Step[550/1020]: training loss : 0.2012147855758667 TRAIN  loss dict:  {'mse_loss': 0.2012147855758667}
2024-05-03 16:19:34,664 [INFO] Step[600/1020]: training loss : 0.19737981230020524 TRAIN  loss dict:  {'mse_loss': 0.19737981230020524}
2024-05-03 16:20:26,579 [INFO] Step[650/1020]: training loss : 0.20055851042270662 TRAIN  loss dict:  {'mse_loss': 0.20055851042270662}
2024-05-03 16:21:14,672 [INFO] Step[700/1020]: training loss : 0.1856677010655403 TRAIN  loss dict:  {'mse_loss': 0.1856677010655403}
2024-05-03 16:22:03,210 [INFO] Step[750/1020]: training loss : 0.2017800170183182 TRAIN  loss dict:  {'mse_loss': 0.2017800170183182}
2024-05-03 16:22:52,743 [INFO] Step[800/1020]: training loss : 0.19724332332611083 TRAIN  loss dict:  {'mse_loss': 0.19724332332611083}
2024-05-03 16:23:42,443 [INFO] Step[850/1020]: training loss : 0.20190691977739333 TRAIN  loss dict:  {'mse_loss': 0.20190691977739333}
2024-05-03 16:24:30,738 [INFO] Step[900/1020]: training loss : 0.20716077208518982 TRAIN  loss dict:  {'mse_loss': 0.20716077208518982}
2024-05-03 16:25:22,006 [INFO] Step[950/1020]: training loss : 0.20160005152225494 TRAIN  loss dict:  {'mse_loss': 0.20160005152225494}
2024-05-03 16:26:13,848 [INFO] Step[1000/1020]: training loss : 0.19756681442260743 TRAIN  loss dict:  {'mse_loss': 0.19756681442260743}
2024-05-03 16:29:45,124 [INFO] Label accuracies statistics:
2024-05-03 16:29:45,125 [INFO] {0: 1.0, 1: 0.75, 2: 0.25, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.5, 9: 1.0, 10: 1.0, 11: 0.75, 12: 0.5, 13: 1.0, 14: 0.75, 15: 0.75, 16: 0.75, 17: 0.5, 18: 1.0, 19: 0.75, 20: 0.5, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 1.0, 29: 0.75, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.75, 36: 1.0, 37: 1.0, 38: 0.75, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.75, 65: 1.0, 66: 0.75, 67: 1.0, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.5, 77: 0.75, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.5, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.75, 88: 1.0, 89: 1.0, 90: 0.25, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.75, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.75, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.25, 113: 0.0, 114: 0.75, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.5, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 1.0, 129: 0.75, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 0.75, 145: 0.75, 146: 0.75, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.75, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.5, 163: 1.0, 164: 0.75, 165: 1.0, 166: 0.25, 167: 0.75, 168: 0.25, 169: 1.0, 170: 1.0, 171: 0.25, 172: 0.75, 173: 0.75, 174: 1.0, 175: 1.0, 176: 1.0, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 1.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.25, 192: 1.0, 193: 0.25, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-03 16:29:45,144 [INFO] [5] TRAIN  loss: 0.2005174065921821 acc: 0.0
2024-05-03 16:29:45,144 [INFO] [5] TRAIN  loss dict: {'mse_loss': 0.2005174065921821}
2024-05-03 16:29:45,145 [INFO] [5] VALIDATION loss: 0.7522391946327807 VALIDATION  acc: 0.8459595959595959
2024-05-03 16:29:45,145 [INFO] [5] VALIDATION  loss dict: {'mse_loss': 0.18791293413049043, 'classification_loss': 0.5643262640629528}
2024-05-03 16:29:45,145 [INFO] 
2024-05-03 16:31:17,406 [INFO] Step[50/1020]: training loss : 0.18475330963730813 TRAIN  loss dict:  {'mse_loss': 0.18475330963730813}
2024-05-03 16:32:07,413 [INFO] Step[100/1020]: training loss : 0.19036207661032678 TRAIN  loss dict:  {'mse_loss': 0.19036207661032678}
2024-05-03 16:32:58,216 [INFO] Step[150/1020]: training loss : 0.19163395419716836 TRAIN  loss dict:  {'mse_loss': 0.19163395419716836}
2024-05-03 16:33:48,656 [INFO] Step[200/1020]: training loss : 0.19442034572362898 TRAIN  loss dict:  {'mse_loss': 0.19442034572362898}
2024-05-03 16:34:38,210 [INFO] Step[250/1020]: training loss : 0.1944916218519211 TRAIN  loss dict:  {'mse_loss': 0.1944916218519211}
2024-05-03 16:35:30,645 [INFO] Step[300/1020]: training loss : 0.19336224660277368 TRAIN  loss dict:  {'mse_loss': 0.19336224660277368}
2024-05-03 16:36:25,368 [INFO] Step[350/1020]: training loss : 0.1875166280567646 TRAIN  loss dict:  {'mse_loss': 0.1875166280567646}
2024-05-03 16:37:16,435 [INFO] Step[400/1020]: training loss : 0.18704116523265837 TRAIN  loss dict:  {'mse_loss': 0.18704116523265837}
2024-05-03 16:38:06,308 [INFO] Step[450/1020]: training loss : 0.18738806545734404 TRAIN  loss dict:  {'mse_loss': 0.18738806545734404}
2024-05-03 16:38:54,941 [INFO] Step[500/1020]: training loss : 0.19135967701673506 TRAIN  loss dict:  {'mse_loss': 0.19135967701673506}
2024-05-03 16:39:50,057 [INFO] Step[550/1020]: training loss : 0.19370789766311647 TRAIN  loss dict:  {'mse_loss': 0.19370789766311647}
2024-05-03 16:40:41,801 [INFO] Step[600/1020]: training loss : 0.19187843292951584 TRAIN  loss dict:  {'mse_loss': 0.19187843292951584}
2024-05-03 16:41:29,700 [INFO] Step[650/1020]: training loss : 0.1957048885524273 TRAIN  loss dict:  {'mse_loss': 0.1957048885524273}
2024-05-03 16:42:20,750 [INFO] Step[700/1020]: training loss : 0.18103547796607017 TRAIN  loss dict:  {'mse_loss': 0.18103547796607017}
2024-05-03 16:43:07,614 [INFO] Step[750/1020]: training loss : 0.18780119046568872 TRAIN  loss dict:  {'mse_loss': 0.18780119046568872}
2024-05-03 16:43:57,100 [INFO] Step[800/1020]: training loss : 0.18817634969949723 TRAIN  loss dict:  {'mse_loss': 0.18817634969949723}
2024-05-03 16:44:47,463 [INFO] Step[850/1020]: training loss : 0.19082220941781997 TRAIN  loss dict:  {'mse_loss': 0.19082220941781997}
2024-05-03 16:45:35,196 [INFO] Step[900/1020]: training loss : 0.18387886121869088 TRAIN  loss dict:  {'mse_loss': 0.18387886121869088}
2024-05-03 16:46:25,040 [INFO] Step[950/1020]: training loss : 0.19177066504955292 TRAIN  loss dict:  {'mse_loss': 0.19177066504955292}
2024-05-03 16:47:12,927 [INFO] Step[1000/1020]: training loss : 0.17988445550203325 TRAIN  loss dict:  {'mse_loss': 0.17988445550203325}
2024-05-03 16:50:41,175 [INFO] Label accuracies statistics:
2024-05-03 16:50:41,176 [INFO] {0: 0.5, 1: 1.0, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 0.5, 6: 0.75, 7: 1.0, 8: 0.75, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.5, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 0.75, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.75, 28: 0.75, 29: 0.5, 30: 0.75, 31: 1.0, 32: 1.0, 33: 1.0, 34: 1.0, 35: 0.75, 36: 1.0, 37: 1.0, 38: 1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 1.0, 52: 0.75, 53: 0.5, 54: 0.5, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.75, 61: 0.75, 62: 1.0, 63: 1.0, 64: 1.0, 65: 0.75, 66: 0.75, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.5, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 1.0, 88: 1.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.5, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.75, 121: 0.5, 122: 0.5, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 0.75, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.75, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.5, 163: 1.0, 164: 0.75, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 1.0, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 1.0, 190: 0.5, 191: 0.25, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-03 16:50:46,064 [INFO] [6] TRAIN  loss: 0.18962081802972391 acc: 0.0
2024-05-03 16:50:46,065 [INFO] [6] TRAIN  loss dict: {'mse_loss': 0.18962081802972391}
2024-05-03 16:50:46,067 [INFO] [6] VALIDATION loss: 0.6757895257888418 VALIDATION  acc: 0.8661616161616161
2024-05-03 16:50:46,068 [INFO] [6] VALIDATION  loss dict: {'mse_loss': 0.1788946468796995, 'classification_loss': 0.4968948807176955}
2024-05-03 16:50:46,068 [INFO] 
2024-05-03 16:52:20,307 [INFO] Step[50/1020]: training loss : 0.18497029304504395 TRAIN  loss dict:  {'mse_loss': 0.18497029304504395}
2024-05-03 16:53:08,683 [INFO] Step[100/1020]: training loss : 0.18180855214595795 TRAIN  loss dict:  {'mse_loss': 0.18180855214595795}
2024-05-03 16:53:58,849 [INFO] Step[150/1020]: training loss : 0.17870867639780044 TRAIN  loss dict:  {'mse_loss': 0.17870867639780044}
2024-05-03 16:54:48,952 [INFO] Step[200/1020]: training loss : 0.175217644572258 TRAIN  loss dict:  {'mse_loss': 0.175217644572258}
2024-05-03 16:55:37,701 [INFO] Step[250/1020]: training loss : 0.17904605239629745 TRAIN  loss dict:  {'mse_loss': 0.17904605239629745}
2024-05-03 16:56:27,865 [INFO] Step[300/1020]: training loss : 0.18190165743231773 TRAIN  loss dict:  {'mse_loss': 0.18190165743231773}
2024-05-03 16:57:15,582 [INFO] Step[350/1020]: training loss : 0.17994904428720473 TRAIN  loss dict:  {'mse_loss': 0.17994904428720473}
2024-05-03 16:58:03,192 [INFO] Step[400/1020]: training loss : 0.17591810286045073 TRAIN  loss dict:  {'mse_loss': 0.17591810286045073}
2024-05-03 16:58:50,850 [INFO] Step[450/1020]: training loss : 0.1819698604941368 TRAIN  loss dict:  {'mse_loss': 0.1819698604941368}
2024-05-03 16:59:39,797 [INFO] Step[500/1020]: training loss : 0.17593313485383988 TRAIN  loss dict:  {'mse_loss': 0.17593313485383988}
2024-05-03 17:00:28,135 [INFO] Step[550/1020]: training loss : 0.18316758677363396 TRAIN  loss dict:  {'mse_loss': 0.18316758677363396}
2024-05-03 17:01:14,688 [INFO] Step[600/1020]: training loss : 0.1830761854350567 TRAIN  loss dict:  {'mse_loss': 0.1830761854350567}
2024-05-03 17:02:00,230 [INFO] Step[650/1020]: training loss : 0.18429022133350373 TRAIN  loss dict:  {'mse_loss': 0.18429022133350373}
2024-05-03 17:02:47,878 [INFO] Step[700/1020]: training loss : 0.17928992941975594 TRAIN  loss dict:  {'mse_loss': 0.17928992941975594}
2024-05-03 17:03:33,531 [INFO] Step[750/1020]: training loss : 0.18394361913204194 TRAIN  loss dict:  {'mse_loss': 0.18394361913204194}
2024-05-03 17:04:22,612 [INFO] Step[800/1020]: training loss : 0.17229873985052108 TRAIN  loss dict:  {'mse_loss': 0.17229873985052108}
2024-05-03 17:05:10,713 [INFO] Step[850/1020]: training loss : 0.17704130306839944 TRAIN  loss dict:  {'mse_loss': 0.17704130306839944}
2024-05-03 17:06:00,374 [INFO] Step[900/1020]: training loss : 0.18336071074008942 TRAIN  loss dict:  {'mse_loss': 0.18336071074008942}
2024-05-03 17:06:49,021 [INFO] Step[950/1020]: training loss : 0.18122100621461867 TRAIN  loss dict:  {'mse_loss': 0.18122100621461867}
2024-05-03 17:07:38,739 [INFO] Step[1000/1020]: training loss : 0.18406690120697022 TRAIN  loss dict:  {'mse_loss': 0.18406690120697022}
2024-05-03 17:11:01,741 [INFO] Label accuracies statistics:
2024-05-03 17:11:01,741 [INFO] {0: 0.5, 1: 0.75, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 1.0, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 0.75, 14: 0.75, 15: 0.25, 16: 1.0, 17: 0.5, 18: 1.0, 19: 1.0, 20: 0.5, 21: 1.0, 22: 1.0, 23: 0.75, 24: 0.75, 25: 1.0, 26: 1.0, 27: 0.75, 28: 1.0, 29: 0.75, 30: 0.5, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.5, 59: 0.5, 60: 0.75, 61: 0.75, 62: 1.0, 63: 1.0, 64: 1.0, 65: 0.75, 66: 0.75, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.5, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.25, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.75, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.25, 113: 0.25, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.5, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 0.75, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.5, 149: 1.0, 150: 1.0, 151: 1.0, 152: 0.75, 153: 1.0, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.75, 158: 0.75, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.5, 163: 1.0, 164: 0.75, 165: 1.0, 166: 1.0, 167: 0.75, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.5, 191: 0.75, 192: 1.0, 193: 0.25, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-05-03 17:11:06,584 [INFO] [7] TRAIN  loss: 0.1804137724068235 acc: 0.0
2024-05-03 17:11:06,584 [INFO] [7] TRAIN  loss dict: {'mse_loss': 0.1804137724068235}
2024-05-03 17:11:06,585 [INFO] [7] VALIDATION loss: 0.6579568297649273 VALIDATION  acc: 0.8686868686868687
2024-05-03 17:11:06,585 [INFO] [7] VALIDATION  loss dict: {'mse_loss': 0.17566166528397137, 'classification_loss': 0.48229516554868435}
2024-05-03 17:11:06,585 [INFO] 
2024-05-03 17:12:35,131 [INFO] Step[50/1020]: training loss : 0.171368760317564 TRAIN  loss dict:  {'mse_loss': 0.171368760317564}
2024-05-03 17:13:22,290 [INFO] Step[100/1020]: training loss : 0.17202006563544273 TRAIN  loss dict:  {'mse_loss': 0.17202006563544273}
2024-05-03 17:14:12,242 [INFO] Step[150/1020]: training loss : 0.16900034695863725 TRAIN  loss dict:  {'mse_loss': 0.16900034695863725}
2024-05-03 17:14:59,305 [INFO] Step[200/1020]: training loss : 0.176281977891922 TRAIN  loss dict:  {'mse_loss': 0.176281977891922}
2024-05-03 17:15:46,511 [INFO] Step[250/1020]: training loss : 0.176626728028059 TRAIN  loss dict:  {'mse_loss': 0.176626728028059}
2024-05-03 17:16:34,519 [INFO] Step[300/1020]: training loss : 0.17196946144104003 TRAIN  loss dict:  {'mse_loss': 0.17196946144104003}
2024-05-03 17:17:21,856 [INFO] Step[350/1020]: training loss : 0.17325528413057328 TRAIN  loss dict:  {'mse_loss': 0.17325528413057328}
2024-05-03 17:18:08,325 [INFO] Step[400/1020]: training loss : 0.17380813688039778 TRAIN  loss dict:  {'mse_loss': 0.17380813688039778}
2024-05-03 17:18:54,267 [INFO] Step[450/1020]: training loss : 0.17574712708592416 TRAIN  loss dict:  {'mse_loss': 0.17574712708592416}
2024-05-03 17:19:44,086 [INFO] Step[500/1020]: training loss : 0.1709708146750927 TRAIN  loss dict:  {'mse_loss': 0.1709708146750927}
2024-05-03 17:20:34,991 [INFO] Step[550/1020]: training loss : 0.16944457054138184 TRAIN  loss dict:  {'mse_loss': 0.16944457054138184}
2024-05-03 17:21:25,557 [INFO] Step[600/1020]: training loss : 0.1800610801577568 TRAIN  loss dict:  {'mse_loss': 0.1800610801577568}
2024-05-03 17:22:11,888 [INFO] Step[650/1020]: training loss : 0.17458117008209229 TRAIN  loss dict:  {'mse_loss': 0.17458117008209229}
2024-05-03 17:22:59,154 [INFO] Step[700/1020]: training loss : 0.17459351405501367 TRAIN  loss dict:  {'mse_loss': 0.17459351405501367}
2024-05-03 17:23:47,654 [INFO] Step[750/1020]: training loss : 0.16502185970544814 TRAIN  loss dict:  {'mse_loss': 0.16502185970544814}
2024-05-03 17:24:36,376 [INFO] Step[800/1020]: training loss : 0.1781897021830082 TRAIN  loss dict:  {'mse_loss': 0.1781897021830082}
2024-05-03 17:25:24,274 [INFO] Step[850/1020]: training loss : 0.17883343994617462 TRAIN  loss dict:  {'mse_loss': 0.17883343994617462}
2024-05-03 17:26:11,882 [INFO] Step[900/1020]: training loss : 0.16882336035370826 TRAIN  loss dict:  {'mse_loss': 0.16882336035370826}
2024-05-03 17:27:01,267 [INFO] Step[950/1020]: training loss : 0.16933837041258812 TRAIN  loss dict:  {'mse_loss': 0.16933837041258812}
2024-05-03 17:27:48,260 [INFO] Step[1000/1020]: training loss : 0.17327234998345376 TRAIN  loss dict:  {'mse_loss': 0.17327234998345376}
2024-05-03 17:31:06,111 [INFO] Label accuracies statistics:
2024-05-03 17:31:06,111 [INFO] {0: 0.5, 1: 0.75, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.75, 7: 0.75, 8: 0.75, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.5, 18: 1.0, 19: 0.75, 20: 0.5, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.75, 27: 1.0, 28: 1.0, 29: 0.75, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 1.0, 51: 1.0, 52: 1.0, 53: 0.0, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 1.0, 61: 0.75, 62: 1.0, 63: 0.75, 64: 1.0, 65: 0.5, 66: 0.75, 67: 1.0, 68: 1.0, 69: 1.0, 70: 1.0, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.25, 106: 1.0, 107: 1.0, 108: 0.5, 109: 0.75, 110: 1.0, 111: 1.0, 112: 1.0, 113: 0.75, 114: 0.5, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 1.0, 146: 0.75, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.0, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.75, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.75, 163: 1.0, 164: 0.75, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.25, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 0.75, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 1.0, 190: 0.25, 191: 0.25, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-05-03 17:31:06,150 [INFO] [8] TRAIN  loss: 0.17295092556114292 acc: 0.0
2024-05-03 17:31:06,150 [INFO] [8] TRAIN  loss dict: {'mse_loss': 0.17295092556114292}
2024-05-03 17:31:06,150 [INFO] [8] VALIDATION loss: 0.6767527783534142 VALIDATION  acc: 0.8724747474747475
2024-05-03 17:31:06,150 [INFO] [8] VALIDATION  loss dict: {'mse_loss': 0.173026475152283, 'classification_loss': 0.5037263015642611}
2024-05-03 17:31:06,150 [INFO] 
2024-05-03 17:32:35,407 [INFO] Step[50/1020]: training loss : 0.16853226006031036 TRAIN  loss dict:  {'mse_loss': 0.16853226006031036}
2024-05-03 17:33:23,880 [INFO] Step[100/1020]: training loss : 0.17681599631905556 TRAIN  loss dict:  {'mse_loss': 0.17681599631905556}
2024-05-03 17:34:13,250 [INFO] Step[150/1020]: training loss : 0.17567913457751275 TRAIN  loss dict:  {'mse_loss': 0.17567913457751275}
2024-05-03 17:35:01,685 [INFO] Step[200/1020]: training loss : 0.16558059126138688 TRAIN  loss dict:  {'mse_loss': 0.16558059126138688}
2024-05-03 17:35:47,137 [INFO] Step[250/1020]: training loss : 0.17121150255203246 TRAIN  loss dict:  {'mse_loss': 0.17121150255203246}
2024-05-03 17:36:34,469 [INFO] Step[300/1020]: training loss : 0.172471963763237 TRAIN  loss dict:  {'mse_loss': 0.172471963763237}
2024-05-03 17:37:22,033 [INFO] Step[350/1020]: training loss : 0.1641265307366848 TRAIN  loss dict:  {'mse_loss': 0.1641265307366848}
2024-05-03 17:38:09,349 [INFO] Step[400/1020]: training loss : 0.16936922669410706 TRAIN  loss dict:  {'mse_loss': 0.16936922669410706}
2024-05-03 17:38:56,309 [INFO] Step[450/1020]: training loss : 0.169982198625803 TRAIN  loss dict:  {'mse_loss': 0.169982198625803}
2024-05-03 17:39:44,879 [INFO] Step[500/1020]: training loss : 0.16987931475043297 TRAIN  loss dict:  {'mse_loss': 0.16987931475043297}
2024-05-03 17:40:34,384 [INFO] Step[550/1020]: training loss : 0.16480005979537965 TRAIN  loss dict:  {'mse_loss': 0.16480005979537965}
2024-05-03 17:41:24,446 [INFO] Step[600/1020]: training loss : 0.1664631800353527 TRAIN  loss dict:  {'mse_loss': 0.1664631800353527}
2024-05-03 17:42:14,993 [INFO] Step[650/1020]: training loss : 0.1698863536119461 TRAIN  loss dict:  {'mse_loss': 0.1698863536119461}
2024-05-03 17:43:02,099 [INFO] Step[700/1020]: training loss : 0.1635259310901165 TRAIN  loss dict:  {'mse_loss': 0.1635259310901165}
2024-05-03 17:43:50,946 [INFO] Step[750/1020]: training loss : 0.16816426306962967 TRAIN  loss dict:  {'mse_loss': 0.16816426306962967}
2024-05-03 17:44:40,946 [INFO] Step[800/1020]: training loss : 0.17515667036175728 TRAIN  loss dict:  {'mse_loss': 0.17515667036175728}
2024-05-03 17:45:30,072 [INFO] Step[850/1020]: training loss : 0.16439694300293922 TRAIN  loss dict:  {'mse_loss': 0.16439694300293922}
2024-05-03 17:46:18,776 [INFO] Step[900/1020]: training loss : 0.16258955761790275 TRAIN  loss dict:  {'mse_loss': 0.16258955761790275}
2024-05-03 17:47:05,504 [INFO] Step[950/1020]: training loss : 0.17746203795075416 TRAIN  loss dict:  {'mse_loss': 0.17746203795075416}
2024-05-03 17:47:53,738 [INFO] Step[1000/1020]: training loss : 0.1642964531481266 TRAIN  loss dict:  {'mse_loss': 0.1642964531481266}
2024-05-03 17:51:10,799 [INFO] Label accuracies statistics:
2024-05-03 17:51:10,799 [INFO] {0: 0.5, 1: 1.0, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.5, 7: 1.0, 8: 0.5, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 0.75, 14: 0.75, 15: 0.25, 16: 1.0, 17: 0.5, 18: 1.0, 19: 1.0, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.75, 28: 1.0, 29: 0.75, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 0.75, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 0.75, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.75, 61: 0.75, 62: 1.0, 63: 1.0, 64: 1.0, 65: 0.75, 66: 0.75, 67: 1.0, 68: 0.75, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 1.0, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.75, 88: 1.0, 89: 1.0, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.5, 109: 0.5, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.75, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 1.0, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 1.0, 146: 0.75, 147: 1.0, 148: 0.5, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.75, 159: 0.75, 160: 1.0, 161: 1.0, 162: 0.5, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.25, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-05-03 17:51:15,835 [INFO] [9] TRAIN  loss: 0.16903168772365532 acc: 0.0
2024-05-03 17:51:15,836 [INFO] [9] TRAIN  loss dict: {'mse_loss': 0.16903168772365532}
2024-05-03 17:51:15,836 [INFO] [9] VALIDATION loss: 0.6313504139808092 VALIDATION  acc: 0.8762626262626263
2024-05-03 17:51:15,836 [INFO] [9] VALIDATION  loss dict: {'mse_loss': 0.16723265408566504, 'classification_loss': 0.46411775933540983}
2024-05-03 17:51:15,836 [INFO] 
2024-05-03 17:52:51,298 [INFO] Step[50/1020]: training loss : 0.1573607437312603 TRAIN  loss dict:  {'mse_loss': 0.1573607437312603}
2024-05-03 17:53:41,360 [INFO] Step[100/1020]: training loss : 0.16837943837046623 TRAIN  loss dict:  {'mse_loss': 0.16837943837046623}
2024-05-03 17:54:28,414 [INFO] Step[150/1020]: training loss : 0.1698062562942505 TRAIN  loss dict:  {'mse_loss': 0.1698062562942505}
2024-05-03 17:55:17,793 [INFO] Step[200/1020]: training loss : 0.15974563881754875 TRAIN  loss dict:  {'mse_loss': 0.15974563881754875}
2024-05-03 17:56:05,907 [INFO] Step[250/1020]: training loss : 0.15750353932380676 TRAIN  loss dict:  {'mse_loss': 0.15750353932380676}
2024-05-03 17:56:55,282 [INFO] Step[300/1020]: training loss : 0.16915504947304727 TRAIN  loss dict:  {'mse_loss': 0.16915504947304727}
2024-05-03 17:57:46,727 [INFO] Step[350/1020]: training loss : 0.1726256950199604 TRAIN  loss dict:  {'mse_loss': 0.1726256950199604}
2024-05-03 17:58:34,027 [INFO] Step[400/1020]: training loss : 0.15859617680311203 TRAIN  loss dict:  {'mse_loss': 0.15859617680311203}
2024-05-03 17:59:24,951 [INFO] Step[450/1020]: training loss : 0.16118401154875756 TRAIN  loss dict:  {'mse_loss': 0.16118401154875756}
2024-05-03 18:00:14,480 [INFO] Step[500/1020]: training loss : 0.16038689702749254 TRAIN  loss dict:  {'mse_loss': 0.16038689702749254}
2024-05-03 18:01:07,994 [INFO] Step[550/1020]: training loss : 0.1594624787569046 TRAIN  loss dict:  {'mse_loss': 0.1594624787569046}
2024-05-03 18:01:57,870 [INFO] Step[600/1020]: training loss : 0.16285815507173537 TRAIN  loss dict:  {'mse_loss': 0.16285815507173537}
2024-05-03 18:02:47,052 [INFO] Step[650/1020]: training loss : 0.15822805359959602 TRAIN  loss dict:  {'mse_loss': 0.15822805359959602}
2024-05-03 18:03:37,670 [INFO] Step[700/1020]: training loss : 0.16473618358373643 TRAIN  loss dict:  {'mse_loss': 0.16473618358373643}
2024-05-03 18:04:26,975 [INFO] Step[750/1020]: training loss : 0.169826949685812 TRAIN  loss dict:  {'mse_loss': 0.169826949685812}
2024-05-03 18:05:15,524 [INFO] Step[800/1020]: training loss : 0.17236181378364562 TRAIN  loss dict:  {'mse_loss': 0.17236181378364562}
2024-05-03 18:06:06,572 [INFO] Step[850/1020]: training loss : 0.1608327156305313 TRAIN  loss dict:  {'mse_loss': 0.1608327156305313}
2024-05-03 18:06:56,673 [INFO] Step[900/1020]: training loss : 0.15988117352128028 TRAIN  loss dict:  {'mse_loss': 0.15988117352128028}
2024-05-03 18:07:48,075 [INFO] Step[950/1020]: training loss : 0.16379788100719453 TRAIN  loss dict:  {'mse_loss': 0.16379788100719453}
2024-05-03 18:08:41,026 [INFO] Step[1000/1020]: training loss : 0.17129921928048134 TRAIN  loss dict:  {'mse_loss': 0.17129921928048134}
2024-05-03 18:11:54,485 [INFO] Label accuracies statistics:
2024-05-03 18:11:54,486 [INFO] {0: 0.5, 1: 0.75, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 1.0, 8: 1.0, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 0.75, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 1.0, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.75, 28: 1.0, 29: 0.75, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.75, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 0.75, 53: 1.0, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.75, 61: 0.75, 62: 1.0, 63: 1.0, 64: 1.0, 65: 1.0, 66: 0.75, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.75, 88: 1.0, 89: 1.0, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.25, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.75, 121: 0.75, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.75, 153: 1.0, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.5, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 0.75, 185: 0.75, 186: 0.75, 187: 1.0, 188: 0.75, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-03 18:11:59,376 [INFO] [10] TRAIN  loss: 0.16419956584041026 acc: 0.0
2024-05-03 18:11:59,377 [INFO] [10] TRAIN  loss dict: {'mse_loss': 0.16419956584041026}
2024-05-03 18:11:59,378 [INFO] [10] VALIDATION loss: 0.5945874891347356 VALIDATION  acc: 0.8876262626262627
2024-05-03 18:11:59,378 [INFO] [10] VALIDATION  loss dict: {'mse_loss': 0.16685030059983033, 'classification_loss': 0.42773718890649354}
2024-05-03 18:11:59,378 [INFO] 
2024-05-03 18:13:39,841 [INFO] Step[50/1020]: training loss : 0.1629699069261551 TRAIN  loss dict:  {'mse_loss': 0.1629699069261551}
2024-05-03 18:14:35,323 [INFO] Step[100/1020]: training loss : 0.1590481771528721 TRAIN  loss dict:  {'mse_loss': 0.1590481771528721}
2024-05-03 18:15:25,966 [INFO] Step[150/1020]: training loss : 0.15936220735311507 TRAIN  loss dict:  {'mse_loss': 0.15936220735311507}
2024-05-03 18:16:20,920 [INFO] Step[200/1020]: training loss : 0.16345532715320588 TRAIN  loss dict:  {'mse_loss': 0.16345532715320588}
2024-05-03 18:17:13,077 [INFO] Step[250/1020]: training loss : 0.16352274984121323 TRAIN  loss dict:  {'mse_loss': 0.16352274984121323}
2024-05-03 18:18:04,564 [INFO] Step[300/1020]: training loss : 0.15283711433410643 TRAIN  loss dict:  {'mse_loss': 0.15283711433410643}
2024-05-03 18:18:55,765 [INFO] Step[350/1020]: training loss : 0.15524091616272925 TRAIN  loss dict:  {'mse_loss': 0.15524091616272925}
2024-05-03 18:19:47,489 [INFO] Step[400/1020]: training loss : 0.1605086801946163 TRAIN  loss dict:  {'mse_loss': 0.1605086801946163}
2024-05-03 18:20:38,696 [INFO] Step[450/1020]: training loss : 0.1523258000612259 TRAIN  loss dict:  {'mse_loss': 0.1523258000612259}
2024-05-03 18:21:28,920 [INFO] Step[500/1020]: training loss : 0.1609614335000515 TRAIN  loss dict:  {'mse_loss': 0.1609614335000515}
2024-05-03 18:22:23,023 [INFO] Step[550/1020]: training loss : 0.15560656934976577 TRAIN  loss dict:  {'mse_loss': 0.15560656934976577}
2024-05-03 18:23:15,362 [INFO] Step[600/1020]: training loss : 0.1566936132311821 TRAIN  loss dict:  {'mse_loss': 0.1566936132311821}
2024-05-03 18:24:08,034 [INFO] Step[650/1020]: training loss : 0.152124452739954 TRAIN  loss dict:  {'mse_loss': 0.152124452739954}
2024-05-03 18:25:00,251 [INFO] Step[700/1020]: training loss : 0.16499478712677956 TRAIN  loss dict:  {'mse_loss': 0.16499478712677956}
2024-05-03 18:25:53,250 [INFO] Step[750/1020]: training loss : 0.1632568792998791 TRAIN  loss dict:  {'mse_loss': 0.1632568792998791}
2024-05-03 18:26:43,476 [INFO] Step[800/1020]: training loss : 0.15330777078866958 TRAIN  loss dict:  {'mse_loss': 0.15330777078866958}
2024-05-03 18:27:35,886 [INFO] Step[850/1020]: training loss : 0.1509016528725624 TRAIN  loss dict:  {'mse_loss': 0.1509016528725624}
2024-05-03 18:28:31,746 [INFO] Step[900/1020]: training loss : 0.15117273971438408 TRAIN  loss dict:  {'mse_loss': 0.15117273971438408}
2024-05-03 18:29:29,259 [INFO] Step[950/1020]: training loss : 0.1570364497601986 TRAIN  loss dict:  {'mse_loss': 0.1570364497601986}
2024-05-03 18:30:19,661 [INFO] Step[1000/1020]: training loss : 0.15418049290776253 TRAIN  loss dict:  {'mse_loss': 0.15418049290776253}
2024-05-03 18:33:35,909 [INFO] Label accuracies statistics:
2024-05-03 18:33:35,909 [INFO] {0: 0.5, 1: 1.0, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.5, 7: 1.0, 8: 0.75, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 0.75, 14: 0.75, 15: 0.25, 16: 1.0, 17: 0.75, 18: 1.0, 19: 0.75, 20: 0.75, 21: 1.0, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 1.0, 29: 0.75, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 1.0, 65: 0.75, 66: 0.75, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.75, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.5, 149: 1.0, 150: 1.0, 151: 1.0, 152: 0.75, 153: 1.0, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.5, 158: 0.75, 159: 0.75, 160: 1.0, 161: 1.0, 162: 0.5, 163: 0.75, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 1.0, 191: 0.5, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 0.75, 197: 0.75, 198: 0.75}

2024-05-03 18:33:35,931 [INFO] [11] TRAIN  loss: 0.1574036874242273 acc: 0.0
2024-05-03 18:33:35,931 [INFO] [11] TRAIN  loss dict: {'mse_loss': 0.1574036874242273}
2024-05-03 18:33:35,932 [INFO] [11] VALIDATION loss: 0.6182895129301933 VALIDATION  acc: 0.8775252525252525
2024-05-03 18:33:35,932 [INFO] [11] VALIDATION  loss dict: {'mse_loss': 0.1633238253569362, 'classification_loss': 0.4549656857952777}
2024-05-03 18:33:35,932 [INFO] 
2024-05-03 18:35:17,663 [INFO] Step[50/1020]: training loss : 0.1563175316154957 TRAIN  loss dict:  {'mse_loss': 0.1563175316154957}
2024-05-03 18:36:12,217 [INFO] Step[100/1020]: training loss : 0.1519681027531624 TRAIN  loss dict:  {'mse_loss': 0.1519681027531624}
2024-05-03 18:37:06,257 [INFO] Step[150/1020]: training loss : 0.15916691660881044 TRAIN  loss dict:  {'mse_loss': 0.15916691660881044}
2024-05-03 18:37:58,058 [INFO] Step[200/1020]: training loss : 0.15301569491624833 TRAIN  loss dict:  {'mse_loss': 0.15301569491624833}
2024-05-03 18:38:52,190 [INFO] Step[250/1020]: training loss : 0.157562275826931 TRAIN  loss dict:  {'mse_loss': 0.157562275826931}
2024-05-03 18:39:46,580 [INFO] Step[300/1020]: training loss : 0.1605574394762516 TRAIN  loss dict:  {'mse_loss': 0.1605574394762516}
2024-05-03 18:40:41,872 [INFO] Step[350/1020]: training loss : 0.16412775442004204 TRAIN  loss dict:  {'mse_loss': 0.16412775442004204}
2024-05-03 18:41:30,974 [INFO] Step[400/1020]: training loss : 0.15532962188124658 TRAIN  loss dict:  {'mse_loss': 0.15532962188124658}
2024-05-03 18:42:22,085 [INFO] Step[450/1020]: training loss : 0.15707477644085885 TRAIN  loss dict:  {'mse_loss': 0.15707477644085885}
2024-05-03 18:43:14,038 [INFO] Step[500/1020]: training loss : 0.15789149612188338 TRAIN  loss dict:  {'mse_loss': 0.15789149612188338}
2024-05-03 18:44:04,293 [INFO] Step[550/1020]: training loss : 0.15736467108130456 TRAIN  loss dict:  {'mse_loss': 0.15736467108130456}
2024-05-03 18:44:54,707 [INFO] Step[600/1020]: training loss : 0.15712107524275779 TRAIN  loss dict:  {'mse_loss': 0.15712107524275779}
2024-05-03 18:45:44,600 [INFO] Step[650/1020]: training loss : 0.1504787176847458 TRAIN  loss dict:  {'mse_loss': 0.1504787176847458}
2024-05-03 18:46:36,798 [INFO] Step[700/1020]: training loss : 0.1578408448398113 TRAIN  loss dict:  {'mse_loss': 0.1578408448398113}
2024-05-03 18:47:30,604 [INFO] Step[750/1020]: training loss : 0.15054826512932779 TRAIN  loss dict:  {'mse_loss': 0.15054826512932779}
2024-05-03 18:48:20,265 [INFO] Step[800/1020]: training loss : 0.16057238072156907 TRAIN  loss dict:  {'mse_loss': 0.16057238072156907}
2024-05-03 18:49:12,273 [INFO] Step[850/1020]: training loss : 0.15519228756427764 TRAIN  loss dict:  {'mse_loss': 0.15519228756427764}
2024-05-03 18:50:04,980 [INFO] Step[900/1020]: training loss : 0.1559611539542675 TRAIN  loss dict:  {'mse_loss': 0.1559611539542675}
2024-05-03 18:50:58,063 [INFO] Step[950/1020]: training loss : 0.15369804382324218 TRAIN  loss dict:  {'mse_loss': 0.15369804382324218}
2024-05-03 18:51:50,138 [INFO] Step[1000/1020]: training loss : 0.15177108004689216 TRAIN  loss dict:  {'mse_loss': 0.15177108004689216}
2024-05-03 18:55:00,240 [INFO] Label accuracies statistics:
2024-05-03 18:55:00,240 [INFO] {0: 0.5, 1: 1.0, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.5, 9: 0.75, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.25, 16: 1.0, 17: 0.75, 18: 1.0, 19: 1.0, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.75, 28: 1.0, 29: 0.5, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 0.75, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 1.0, 52: 1.0, 53: 0.5, 54: 1.0, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 1.0, 60: 1.0, 61: 1.0, 62: 1.0, 63: 1.0, 64: 1.0, 65: 0.75, 66: 0.75, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.5, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 1.0, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 0.75, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.5, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.25, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 0.75, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.5, 189: 1.0, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-05-03 18:55:00,257 [INFO] [12] TRAIN  loss: 0.15603294093527045 acc: 0.0
2024-05-03 18:55:00,258 [INFO] [12] TRAIN  loss dict: {'mse_loss': 0.15603294093527045}
2024-05-03 18:55:00,258 [INFO] [12] VALIDATION loss: 0.619794501085775 VALIDATION  acc: 0.8674242424242424
2024-05-03 18:55:00,258 [INFO] [12] VALIDATION  loss dict: {'mse_loss': 0.15996704735990727, 'classification_loss': 0.459827453119097}
2024-05-03 18:55:00,258 [INFO] 
2024-05-03 18:56:40,645 [INFO] Step[50/1020]: training loss : 0.14600010648369788 TRAIN  loss dict:  {'mse_loss': 0.14600010648369788}
2024-05-03 18:57:32,014 [INFO] Step[100/1020]: training loss : 0.15843190148472786 TRAIN  loss dict:  {'mse_loss': 0.15843190148472786}
2024-05-03 18:58:23,489 [INFO] Step[150/1020]: training loss : 0.1513210019469261 TRAIN  loss dict:  {'mse_loss': 0.1513210019469261}
2024-05-03 18:59:18,025 [INFO] Step[200/1020]: training loss : 0.16412894621491433 TRAIN  loss dict:  {'mse_loss': 0.16412894621491433}
2024-05-03 19:00:09,345 [INFO] Step[250/1020]: training loss : 0.1506214115023613 TRAIN  loss dict:  {'mse_loss': 0.1506214115023613}
2024-05-03 19:01:03,180 [INFO] Step[300/1020]: training loss : 0.15635249227285386 TRAIN  loss dict:  {'mse_loss': 0.15635249227285386}
2024-05-03 19:01:59,123 [INFO] Step[350/1020]: training loss : 0.14745899379253388 TRAIN  loss dict:  {'mse_loss': 0.14745899379253388}
2024-05-03 19:02:52,254 [INFO] Step[400/1020]: training loss : 0.15489580646157264 TRAIN  loss dict:  {'mse_loss': 0.15489580646157264}
2024-05-03 19:03:45,906 [INFO] Step[450/1020]: training loss : 0.1497161491215229 TRAIN  loss dict:  {'mse_loss': 0.1497161491215229}
2024-05-03 19:04:38,360 [INFO] Step[500/1020]: training loss : 0.15065870940685272 TRAIN  loss dict:  {'mse_loss': 0.15065870940685272}
2024-05-03 19:05:31,416 [INFO] Step[550/1020]: training loss : 0.15632422640919685 TRAIN  loss dict:  {'mse_loss': 0.15632422640919685}
2024-05-03 19:06:21,544 [INFO] Step[600/1020]: training loss : 0.15327375560998915 TRAIN  loss dict:  {'mse_loss': 0.15327375560998915}
2024-05-03 19:07:10,706 [INFO] Step[650/1020]: training loss : 0.1502709285914898 TRAIN  loss dict:  {'mse_loss': 0.1502709285914898}
2024-05-03 19:08:03,280 [INFO] Step[700/1020]: training loss : 0.15795558899641038 TRAIN  loss dict:  {'mse_loss': 0.15795558899641038}
2024-05-03 19:08:57,085 [INFO] Step[750/1020]: training loss : 0.14785799905657768 TRAIN  loss dict:  {'mse_loss': 0.14785799905657768}
2024-05-03 19:09:49,220 [INFO] Step[800/1020]: training loss : 0.15679373428225518 TRAIN  loss dict:  {'mse_loss': 0.15679373428225518}
2024-05-03 19:10:41,040 [INFO] Step[850/1020]: training loss : 0.14849240884184836 TRAIN  loss dict:  {'mse_loss': 0.14849240884184836}
2024-05-03 19:11:33,210 [INFO] Step[900/1020]: training loss : 0.152854093760252 TRAIN  loss dict:  {'mse_loss': 0.152854093760252}
2024-05-03 19:12:23,536 [INFO] Step[950/1020]: training loss : 0.15355118811130525 TRAIN  loss dict:  {'mse_loss': 0.15355118811130525}
2024-05-03 19:13:13,496 [INFO] Step[1000/1020]: training loss : 0.15743497043848037 TRAIN  loss dict:  {'mse_loss': 0.15743497043848037}
2024-05-03 19:16:26,030 [INFO] Label accuracies statistics:
2024-05-03 19:16:26,030 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.5, 9: 0.75, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 0.75, 20: 0.5, 21: 1.0, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 1.0, 29: 0.75, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 0.75, 39: 1.0, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 0.75, 51: 1.0, 52: 1.0, 53: 0.25, 54: 1.0, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 1.0, 65: 0.75, 66: 0.75, 67: 1.0, 68: 0.75, 69: 1.0, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 0.75, 87: 0.75, 88: 1.0, 89: 1.0, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.25, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.5, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.25, 169: 0.75, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 1.0, 175: 0.75, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.75}

2024-05-03 19:16:26,048 [INFO] [13] TRAIN  loss: 0.15345777807136377 acc: 0.0
2024-05-03 19:16:26,048 [INFO] [13] TRAIN  loss dict: {'mse_loss': 0.15345777807136377}
2024-05-03 19:16:26,048 [INFO] [13] VALIDATION loss: 0.632844767260431 VALIDATION  acc: 0.8762626262626263
2024-05-03 19:16:26,048 [INFO] [13] VALIDATION  loss dict: {'mse_loss': 0.16033792593563445, 'classification_loss': 0.47250683743370264}
2024-05-03 19:16:26,048 [INFO] 
2024-05-03 19:18:06,244 [INFO] Step[50/1020]: training loss : 0.15320165783166886 TRAIN  loss dict:  {'mse_loss': 0.15320165783166886}
2024-05-03 19:18:59,015 [INFO] Step[100/1020]: training loss : 0.14919789463281632 TRAIN  loss dict:  {'mse_loss': 0.14919789463281632}
2024-05-03 19:19:53,849 [INFO] Step[150/1020]: training loss : 0.15216952309012413 TRAIN  loss dict:  {'mse_loss': 0.15216952309012413}
2024-05-03 19:20:45,080 [INFO] Step[200/1020]: training loss : 0.15495558083057404 TRAIN  loss dict:  {'mse_loss': 0.15495558083057404}
2024-05-03 19:21:43,348 [INFO] Step[250/1020]: training loss : 0.15135073244571687 TRAIN  loss dict:  {'mse_loss': 0.15135073244571687}
2024-05-03 19:22:35,658 [INFO] Step[300/1020]: training loss : 0.15178732439875603 TRAIN  loss dict:  {'mse_loss': 0.15178732439875603}
2024-05-03 19:23:25,516 [INFO] Step[350/1020]: training loss : 0.15217989936470985 TRAIN  loss dict:  {'mse_loss': 0.15217989936470985}
2024-05-03 19:24:16,481 [INFO] Step[400/1020]: training loss : 0.14654706969857215 TRAIN  loss dict:  {'mse_loss': 0.14654706969857215}
2024-05-03 19:25:09,240 [INFO] Step[450/1020]: training loss : 0.15239492803812027 TRAIN  loss dict:  {'mse_loss': 0.15239492803812027}
2024-05-03 19:26:02,541 [INFO] Step[500/1020]: training loss : 0.15875849559903144 TRAIN  loss dict:  {'mse_loss': 0.15875849559903144}
2024-05-03 19:26:55,090 [INFO] Step[550/1020]: training loss : 0.1535744160413742 TRAIN  loss dict:  {'mse_loss': 0.1535744160413742}
2024-05-03 19:27:47,133 [INFO] Step[600/1020]: training loss : 0.15452448770403862 TRAIN  loss dict:  {'mse_loss': 0.15452448770403862}
2024-05-03 19:28:38,274 [INFO] Step[650/1020]: training loss : 0.1473017440736294 TRAIN  loss dict:  {'mse_loss': 0.1473017440736294}
2024-05-03 19:29:28,542 [INFO] Step[700/1020]: training loss : 0.1462458525598049 TRAIN  loss dict:  {'mse_loss': 0.1462458525598049}
2024-05-03 19:30:22,324 [INFO] Step[750/1020]: training loss : 0.15555310383439064 TRAIN  loss dict:  {'mse_loss': 0.15555310383439064}
2024-05-03 19:31:13,248 [INFO] Step[800/1020]: training loss : 0.15433329224586487 TRAIN  loss dict:  {'mse_loss': 0.15433329224586487}
2024-05-03 19:32:04,279 [INFO] Step[850/1020]: training loss : 0.15145348995923996 TRAIN  loss dict:  {'mse_loss': 0.15145348995923996}
2024-05-03 19:32:55,058 [INFO] Step[900/1020]: training loss : 0.1533297671377659 TRAIN  loss dict:  {'mse_loss': 0.1533297671377659}
2024-05-03 19:33:51,174 [INFO] Step[950/1020]: training loss : 0.15721844181418418 TRAIN  loss dict:  {'mse_loss': 0.15721844181418418}
2024-05-03 19:34:42,614 [INFO] Step[1000/1020]: training loss : 0.14882262155413628 TRAIN  loss dict:  {'mse_loss': 0.14882262155413628}
2024-05-03 19:37:52,811 [INFO] Label accuracies statistics:
2024-05-03 19:37:52,811 [INFO] {0: 0.5, 1: 0.75, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.5, 7: 1.0, 8: 0.75, 9: 1.0, 10: 1.0, 11: 0.75, 12: 1.0, 13: 0.75, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.5, 18: 1.0, 19: 1.0, 20: 0.5, 21: 1.0, 22: 1.0, 23: 0.75, 24: 0.75, 25: 1.0, 26: 1.0, 27: 0.75, 28: 0.75, 29: 0.75, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 0.75, 39: 1.0, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 1.0, 52: 0.75, 53: 0.5, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.25, 60: 1.0, 61: 1.0, 62: 1.0, 63: 1.0, 64: 1.0, 65: 0.75, 66: 0.75, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.5, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 1.0, 88: 1.0, 89: 1.0, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.75, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.25, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 0.75, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.5, 158: 0.75, 159: 0.75, 160: 1.0, 161: 1.0, 162: 0.5, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 1.0, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-05-03 19:37:52,828 [INFO] [14] TRAIN  loss: 0.15222133435308932 acc: 0.0
2024-05-03 19:37:52,829 [INFO] [14] TRAIN  loss dict: {'mse_loss': 0.15222133435308932}
2024-05-03 19:37:52,829 [INFO] [14] VALIDATION loss: 0.5974834141782438 VALIDATION  acc: 0.8762626262626263
2024-05-03 19:37:52,829 [INFO] [14] VALIDATION  loss dict: {'mse_loss': 0.1591816498248866, 'classification_loss': 0.4383017628223193}
2024-05-03 19:37:52,829 [INFO] 
2024-05-03 19:39:32,173 [INFO] Step[50/1020]: training loss : 0.1479116651415825 TRAIN  loss dict:  {'mse_loss': 0.1479116651415825}
2024-05-03 19:40:26,160 [INFO] Step[100/1020]: training loss : 0.1481902141869068 TRAIN  loss dict:  {'mse_loss': 0.1481902141869068}
2024-05-03 19:41:18,056 [INFO] Step[150/1020]: training loss : 0.15101017981767653 TRAIN  loss dict:  {'mse_loss': 0.15101017981767653}
2024-05-03 19:42:15,175 [INFO] Step[200/1020]: training loss : 0.15046979770064353 TRAIN  loss dict:  {'mse_loss': 0.15046979770064353}
2024-05-03 19:43:07,003 [INFO] Step[250/1020]: training loss : 0.14623571783304215 TRAIN  loss dict:  {'mse_loss': 0.14623571783304215}
2024-05-03 19:43:57,131 [INFO] Step[300/1020]: training loss : 0.14958851665258407 TRAIN  loss dict:  {'mse_loss': 0.14958851665258407}
2024-05-03 19:44:50,310 [INFO] Step[350/1020]: training loss : 0.15474027752876282 TRAIN  loss dict:  {'mse_loss': 0.15474027752876282}
2024-05-03 19:45:40,736 [INFO] Step[400/1020]: training loss : 0.15655680254101753 TRAIN  loss dict:  {'mse_loss': 0.15655680254101753}
2024-05-03 19:46:34,741 [INFO] Step[450/1020]: training loss : 0.14852406397461893 TRAIN  loss dict:  {'mse_loss': 0.14852406397461893}
2024-05-03 19:47:25,665 [INFO] Step[500/1020]: training loss : 0.15034857511520386 TRAIN  loss dict:  {'mse_loss': 0.15034857511520386}
2024-05-03 19:48:18,290 [INFO] Step[550/1020]: training loss : 0.14338625267148017 TRAIN  loss dict:  {'mse_loss': 0.14338625267148017}
2024-05-03 19:49:10,547 [INFO] Step[600/1020]: training loss : 0.15265217900276185 TRAIN  loss dict:  {'mse_loss': 0.15265217900276185}
2024-05-03 19:50:02,536 [INFO] Step[650/1020]: training loss : 0.15206887751817702 TRAIN  loss dict:  {'mse_loss': 0.15206887751817702}
2024-05-03 19:50:51,548 [INFO] Step[700/1020]: training loss : 0.14577172964811325 TRAIN  loss dict:  {'mse_loss': 0.14577172964811325}
2024-05-03 19:51:46,398 [INFO] Step[750/1020]: training loss : 0.15210750490427016 TRAIN  loss dict:  {'mse_loss': 0.15210750490427016}
2024-05-03 19:52:43,325 [INFO] Step[800/1020]: training loss : 0.1521237723529339 TRAIN  loss dict:  {'mse_loss': 0.1521237723529339}
2024-05-03 19:53:33,038 [INFO] Step[850/1020]: training loss : 0.14043981358408927 TRAIN  loss dict:  {'mse_loss': 0.14043981358408927}
2024-05-03 19:54:23,368 [INFO] Step[900/1020]: training loss : 0.1509673660993576 TRAIN  loss dict:  {'mse_loss': 0.1509673660993576}
2024-05-03 19:55:15,588 [INFO] Step[950/1020]: training loss : 0.14731685683131218 TRAIN  loss dict:  {'mse_loss': 0.14731685683131218}
2024-05-03 19:56:08,835 [INFO] Step[1000/1020]: training loss : 0.15004690513014793 TRAIN  loss dict:  {'mse_loss': 0.15004690513014793}
2024-05-03 19:59:28,450 [INFO] Label accuracies statistics:
2024-05-03 19:59:28,450 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.75, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 1.0, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.75, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.5, 59: 1.0, 60: 1.0, 61: 1.0, 62: 1.0, 63: 1.0, 64: 1.0, 65: 1.0, 66: 0.5, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 0.75, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 1.0, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.75, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.75, 158: 0.75, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.5, 163: 0.75, 164: 0.75, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-05-03 19:59:28,468 [INFO] [15] TRAIN  loss: 0.14932418009083645 acc: 0.0
2024-05-03 19:59:28,468 [INFO] [15] TRAIN  loss dict: {'mse_loss': 0.14932418009083645}
2024-05-03 19:59:28,468 [INFO] [15] VALIDATION loss: 0.6010887809474059 VALIDATION  acc: 0.8888888888888888
2024-05-03 19:59:28,468 [INFO] [15] VALIDATION  loss dict: {'mse_loss': 0.15874837508255785, 'classification_loss': 0.44234040408569264}
2024-05-03 19:59:28,469 [INFO] 
2024-05-03 20:01:06,648 [INFO] Step[50/1020]: training loss : 0.14103422909975052 TRAIN  loss dict:  {'mse_loss': 0.14103422909975052}
2024-05-03 20:01:56,895 [INFO] Step[100/1020]: training loss : 0.1462486904859543 TRAIN  loss dict:  {'mse_loss': 0.1462486904859543}
2024-05-03 20:02:47,842 [INFO] Step[150/1020]: training loss : 0.14545218035578728 TRAIN  loss dict:  {'mse_loss': 0.14545218035578728}
2024-05-03 20:03:43,163 [INFO] Step[200/1020]: training loss : 0.14379951760172843 TRAIN  loss dict:  {'mse_loss': 0.14379951760172843}
2024-05-03 20:04:36,289 [INFO] Step[250/1020]: training loss : 0.14496855393052102 TRAIN  loss dict:  {'mse_loss': 0.14496855393052102}
2024-05-03 20:05:31,961 [INFO] Step[300/1020]: training loss : 0.14510161980986594 TRAIN  loss dict:  {'mse_loss': 0.14510161980986594}
2024-05-03 20:06:21,564 [INFO] Step[350/1020]: training loss : 0.1494261348247528 TRAIN  loss dict:  {'mse_loss': 0.1494261348247528}
2024-05-03 20:07:16,772 [INFO] Step[400/1020]: training loss : 0.1452040985226631 TRAIN  loss dict:  {'mse_loss': 0.1452040985226631}
2024-05-03 20:08:11,301 [INFO] Step[450/1020]: training loss : 0.14376977294683457 TRAIN  loss dict:  {'mse_loss': 0.14376977294683457}
2024-05-03 20:09:04,465 [INFO] Step[500/1020]: training loss : 0.14653285458683968 TRAIN  loss dict:  {'mse_loss': 0.14653285458683968}
2024-05-03 20:09:56,812 [INFO] Step[550/1020]: training loss : 0.1493314789235592 TRAIN  loss dict:  {'mse_loss': 0.1493314789235592}
2024-05-03 20:10:46,744 [INFO] Step[600/1020]: training loss : 0.1474413724243641 TRAIN  loss dict:  {'mse_loss': 0.1474413724243641}
2024-05-03 20:11:38,906 [INFO] Step[650/1020]: training loss : 0.1454478332400322 TRAIN  loss dict:  {'mse_loss': 0.1454478332400322}
2024-05-03 20:12:35,031 [INFO] Step[700/1020]: training loss : 0.14969498425722122 TRAIN  loss dict:  {'mse_loss': 0.14969498425722122}
2024-05-03 20:13:25,932 [INFO] Step[750/1020]: training loss : 0.15191261947155 TRAIN  loss dict:  {'mse_loss': 0.15191261947155}
2024-05-03 20:14:23,294 [INFO] Step[800/1020]: training loss : 0.149603408575058 TRAIN  loss dict:  {'mse_loss': 0.149603408575058}
2024-05-03 20:15:18,685 [INFO] Step[850/1020]: training loss : 0.15823165819048882 TRAIN  loss dict:  {'mse_loss': 0.15823165819048882}
2024-05-03 20:16:11,235 [INFO] Step[900/1020]: training loss : 0.14778705894947053 TRAIN  loss dict:  {'mse_loss': 0.14778705894947053}
2024-05-03 20:17:06,447 [INFO] Step[950/1020]: training loss : 0.1512868095934391 TRAIN  loss dict:  {'mse_loss': 0.1512868095934391}
2024-05-03 20:17:59,372 [INFO] Step[1000/1020]: training loss : 0.15358304589986801 TRAIN  loss dict:  {'mse_loss': 0.15358304589986801}
2024-05-03 20:21:20,455 [INFO] Label accuracies statistics:
2024-05-03 20:21:20,457 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.5, 9: 1.0, 10: 1.0, 11: 0.75, 12: 0.75, 13: 0.75, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 1.0, 20: 0.75, 21: 1.0, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.75, 28: 0.75, 29: 0.5, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 0.75, 38: 1.0, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 1.0, 51: 1.0, 52: 0.75, 53: 0.25, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 1.0, 60: 1.0, 61: 0.75, 62: 1.0, 63: 1.0, 64: 1.0, 65: 0.75, 66: 0.75, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 0.75, 87: 0.75, 88: 1.0, 89: 1.0, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.75, 97: 1.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.75, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 0.5, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.5, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-05-03 20:21:20,486 [INFO] [16] TRAIN  loss: 0.14779482950620793 acc: 0.0
2024-05-03 20:21:20,488 [INFO] [16] TRAIN  loss dict: {'mse_loss': 0.14779482950620793}
2024-05-03 20:21:20,490 [INFO] [16] VALIDATION loss: 0.6148757423189554 VALIDATION  acc: 0.8775252525252525
2024-05-03 20:21:20,491 [INFO] [16] VALIDATION  loss dict: {'mse_loss': 0.15624647681610754, 'classification_loss': 0.4586292678852462}
2024-05-03 20:21:20,493 [INFO] 
2024-05-03 20:23:02,242 [INFO] Step[50/1020]: training loss : 0.14267587780952454 TRAIN  loss dict:  {'mse_loss': 0.14267587780952454}
2024-05-03 20:23:53,286 [INFO] Step[100/1020]: training loss : 0.14605397313833238 TRAIN  loss dict:  {'mse_loss': 0.14605397313833238}
2024-05-03 20:24:47,368 [INFO] Step[150/1020]: training loss : 0.15029248714447022 TRAIN  loss dict:  {'mse_loss': 0.15029248714447022}
2024-05-03 20:25:44,521 [INFO] Step[200/1020]: training loss : 0.1429172068834305 TRAIN  loss dict:  {'mse_loss': 0.1429172068834305}
2024-05-03 20:26:37,041 [INFO] Step[250/1020]: training loss : 0.142629017829895 TRAIN  loss dict:  {'mse_loss': 0.142629017829895}
2024-05-03 20:27:34,295 [INFO] Step[300/1020]: training loss : 0.14302650287747384 TRAIN  loss dict:  {'mse_loss': 0.14302650287747384}
2024-05-03 20:28:31,368 [INFO] Step[350/1020]: training loss : 0.1435626505315304 TRAIN  loss dict:  {'mse_loss': 0.1435626505315304}
2024-05-03 20:29:24,917 [INFO] Step[400/1020]: training loss : 0.14611334532499312 TRAIN  loss dict:  {'mse_loss': 0.14611334532499312}
2024-05-03 20:30:16,809 [INFO] Step[450/1020]: training loss : 0.14380998373031617 TRAIN  loss dict:  {'mse_loss': 0.14380998373031617}
2024-05-03 20:31:06,948 [INFO] Step[500/1020]: training loss : 0.14533847600221633 TRAIN  loss dict:  {'mse_loss': 0.14533847600221633}
2024-05-03 20:32:01,862 [INFO] Step[550/1020]: training loss : 0.14706332579255105 TRAIN  loss dict:  {'mse_loss': 0.14706332579255105}
2024-05-03 20:32:55,163 [INFO] Step[600/1020]: training loss : 0.14464868500828743 TRAIN  loss dict:  {'mse_loss': 0.14464868500828743}
2024-05-03 20:33:50,730 [INFO] Step[650/1020]: training loss : 0.15131314769387244 TRAIN  loss dict:  {'mse_loss': 0.15131314769387244}
2024-05-03 20:34:50,948 [INFO] Step[700/1020]: training loss : 0.14379649430513383 TRAIN  loss dict:  {'mse_loss': 0.14379649430513383}
2024-05-03 20:35:42,013 [INFO] Step[750/1020]: training loss : 0.14739653408527376 TRAIN  loss dict:  {'mse_loss': 0.14739653408527376}
2024-05-03 20:36:35,347 [INFO] Step[800/1020]: training loss : 0.14924828007817267 TRAIN  loss dict:  {'mse_loss': 0.14924828007817267}
2024-05-03 20:37:29,976 [INFO] Step[850/1020]: training loss : 0.14303337648510933 TRAIN  loss dict:  {'mse_loss': 0.14303337648510933}
2024-05-03 20:38:21,263 [INFO] Step[900/1020]: training loss : 0.15289123058319093 TRAIN  loss dict:  {'mse_loss': 0.15289123058319093}
2024-05-03 20:39:14,950 [INFO] Step[950/1020]: training loss : 0.1468484127521515 TRAIN  loss dict:  {'mse_loss': 0.1468484127521515}
2024-05-03 20:40:06,709 [INFO] Step[1000/1020]: training loss : 0.14688459858298303 TRAIN  loss dict:  {'mse_loss': 0.14688459858298303}
2024-05-03 20:43:36,683 [INFO] Label accuracies statistics:
2024-05-03 20:43:36,683 [INFO] {0: 0.5, 1: 0.75, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.5, 7: 1.0, 8: 0.5, 9: 1.0, 10: 1.0, 11: 0.75, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.5, 18: 1.0, 19: 1.0, 20: 0.5, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 1.0, 26: 1.0, 27: 1.0, 28: 0.75, 29: 0.5, 30: 0.5, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 1.0, 52: 1.0, 53: 0.5, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.5, 59: 0.75, 60: 0.75, 61: 0.75, 62: 1.0, 63: 1.0, 64: 1.0, 65: 0.75, 66: 0.75, 67: 1.0, 68: 0.75, 69: 1.0, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 0.75, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 1.0, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.75, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.0, 114: 0.75, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.5, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.25, 169: 0.75, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 0.75, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.75, 185: 0.75, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-05-03 20:43:36,703 [INFO] [17] TRAIN  loss: 0.1461610594946964 acc: 0.0
2024-05-03 20:43:36,703 [INFO] [17] TRAIN  loss dict: {'mse_loss': 0.1461610594946964}
2024-05-03 20:43:36,704 [INFO] [17] VALIDATION loss: 0.6061769310347359 VALIDATION  acc: 0.8762626262626263
2024-05-03 20:43:36,704 [INFO] [17] VALIDATION  loss dict: {'mse_loss': 0.15815713869953396, 'classification_loss': 0.44801979497159744}
2024-05-03 20:43:36,704 [INFO] 
2024-05-03 20:45:17,850 [INFO] Step[50/1020]: training loss : 0.14735442340373994 TRAIN  loss dict:  {'mse_loss': 0.14735442340373994}
2024-05-03 20:46:11,286 [INFO] Step[100/1020]: training loss : 0.14478259563446044 TRAIN  loss dict:  {'mse_loss': 0.14478259563446044}
2024-05-03 20:47:06,293 [INFO] Step[150/1020]: training loss : 0.14425794839859007 TRAIN  loss dict:  {'mse_loss': 0.14425794839859007}
2024-05-03 20:48:00,257 [INFO] Step[200/1020]: training loss : 0.1508450675010681 TRAIN  loss dict:  {'mse_loss': 0.1508450675010681}
2024-05-03 20:48:55,906 [INFO] Step[250/1020]: training loss : 0.14294176399707795 TRAIN  loss dict:  {'mse_loss': 0.14294176399707795}
2024-05-03 20:49:48,949 [INFO] Step[300/1020]: training loss : 0.1411329287290573 TRAIN  loss dict:  {'mse_loss': 0.1411329287290573}
2024-05-03 20:50:43,012 [INFO] Step[350/1020]: training loss : 0.14647979378700257 TRAIN  loss dict:  {'mse_loss': 0.14647979378700257}
2024-05-03 20:51:36,374 [INFO] Step[400/1020]: training loss : 0.15295768395066262 TRAIN  loss dict:  {'mse_loss': 0.15295768395066262}
2024-05-03 20:52:28,547 [INFO] Step[450/1020]: training loss : 0.15005991742014885 TRAIN  loss dict:  {'mse_loss': 0.15005991742014885}
2024-05-03 20:53:21,092 [INFO] Step[500/1020]: training loss : 0.14695096209645273 TRAIN  loss dict:  {'mse_loss': 0.14695096209645273}
2024-05-03 20:54:16,913 [INFO] Step[550/1020]: training loss : 0.14879988357424737 TRAIN  loss dict:  {'mse_loss': 0.14879988357424737}
2024-05-03 20:55:07,802 [INFO] Step[600/1020]: training loss : 0.14419751331210137 TRAIN  loss dict:  {'mse_loss': 0.14419751331210137}
2024-05-03 20:55:59,374 [INFO] Step[650/1020]: training loss : 0.14775536507368087 TRAIN  loss dict:  {'mse_loss': 0.14775536507368087}
2024-05-03 20:56:53,264 [INFO] Step[700/1020]: training loss : 0.14836832612752915 TRAIN  loss dict:  {'mse_loss': 0.14836832612752915}
2024-05-03 20:57:46,496 [INFO] Step[750/1020]: training loss : 0.14542287528514863 TRAIN  loss dict:  {'mse_loss': 0.14542287528514863}
2024-05-03 20:58:44,345 [INFO] Step[800/1020]: training loss : 0.14947764739394187 TRAIN  loss dict:  {'mse_loss': 0.14947764739394187}
2024-05-03 20:59:47,140 [INFO] Step[850/1020]: training loss : 0.14627102240920067 TRAIN  loss dict:  {'mse_loss': 0.14627102240920067}
2024-05-03 21:00:43,070 [INFO] Step[900/1020]: training loss : 0.1458927497267723 TRAIN  loss dict:  {'mse_loss': 0.1458927497267723}
2024-05-03 21:01:36,932 [INFO] Step[950/1020]: training loss : 0.14598246678709983 TRAIN  loss dict:  {'mse_loss': 0.14598246678709983}
2024-05-03 21:02:27,314 [INFO] Step[1000/1020]: training loss : 0.1476270577311516 TRAIN  loss dict:  {'mse_loss': 0.1476270577311516}
2024-05-03 21:05:58,700 [INFO] Label accuracies statistics:
2024-05-03 21:05:58,700 [INFO] {0: 0.5, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.5, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.75, 16: 1.0, 17: 0.5, 18: 1.0, 19: 1.0, 20: 0.75, 21: 1.0, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 0.75, 27: 1.0, 28: 1.0, 29: 1.0, 30: 0.75, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 1.0, 52: 0.75, 53: 0.5, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.5, 59: 0.75, 60: 0.75, 61: 0.75, 62: 1.0, 63: 1.0, 64: 1.0, 65: 1.0, 66: 0.5, 67: 1.0, 68: 0.75, 69: 0.75, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 0.75, 87: 0.75, 88: 0.6666666666666666, 89: 1.0, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.75, 95: 1.0, 96: 1.0, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 0.5, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 1.0, 146: 0.75, 147: 1.0, 148: 0.75, 149: 1.0, 150: 1.0, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.5, 156: 1.0, 157: 0.5, 158: 0.75, 159: 0.75, 160: 1.0, 161: 1.0, 162: 0.5, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.25, 169: 0.75, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.25, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-05-03 21:06:03,455 [INFO] [18] TRAIN  loss: 0.14689096419834624 acc: 0.0
2024-05-03 21:06:03,455 [INFO] [18] TRAIN  loss dict: {'mse_loss': 0.14689096419834624}
2024-05-03 21:06:03,455 [INFO] [18] VALIDATION loss: 0.5813521181393151 VALIDATION  acc: 0.8838383838383839
2024-05-03 21:06:03,455 [INFO] [18] VALIDATION  loss dict: {'mse_loss': 0.15678295925861657, 'classification_loss': 0.4245691575307512}
2024-05-03 21:06:03,456 [INFO] 
2024-05-03 21:07:49,407 [INFO] Step[50/1020]: training loss : 0.1433557939529419 TRAIN  loss dict:  {'mse_loss': 0.1433557939529419}
2024-05-03 21:08:44,438 [INFO] Step[100/1020]: training loss : 0.14398913443088532 TRAIN  loss dict:  {'mse_loss': 0.14398913443088532}
2024-05-03 21:09:40,602 [INFO] Step[150/1020]: training loss : 0.147237369120121 TRAIN  loss dict:  {'mse_loss': 0.147237369120121}
2024-05-03 21:10:34,816 [INFO] Step[200/1020]: training loss : 0.151934175491333 TRAIN  loss dict:  {'mse_loss': 0.151934175491333}
2024-05-03 21:11:29,619 [INFO] Step[250/1020]: training loss : 0.14014523565769196 TRAIN  loss dict:  {'mse_loss': 0.14014523565769196}
2024-05-03 21:12:24,917 [INFO] Step[300/1020]: training loss : 0.1467521496117115 TRAIN  loss dict:  {'mse_loss': 0.1467521496117115}
2024-05-03 21:13:19,414 [INFO] Step[350/1020]: training loss : 0.14440279349684715 TRAIN  loss dict:  {'mse_loss': 0.14440279349684715}
2024-05-03 21:14:10,555 [INFO] Step[400/1020]: training loss : 0.14661313310265542 TRAIN  loss dict:  {'mse_loss': 0.14661313310265542}
2024-05-03 21:14:59,846 [INFO] Step[450/1020]: training loss : 0.14562128394842147 TRAIN  loss dict:  {'mse_loss': 0.14562128394842147}
2024-05-03 21:15:49,789 [INFO] Step[500/1020]: training loss : 0.14681613489985465 TRAIN  loss dict:  {'mse_loss': 0.14681613489985465}
2024-05-03 21:16:40,714 [INFO] Step[550/1020]: training loss : 0.14576561912894248 TRAIN  loss dict:  {'mse_loss': 0.14576561912894248}
2024-05-03 21:17:35,561 [INFO] Step[600/1020]: training loss : 0.14153910398483277 TRAIN  loss dict:  {'mse_loss': 0.14153910398483277}
2024-05-03 21:18:29,937 [INFO] Step[650/1020]: training loss : 0.14677806407213212 TRAIN  loss dict:  {'mse_loss': 0.14677806407213212}
2024-05-03 21:19:22,953 [INFO] Step[700/1020]: training loss : 0.1555092540383339 TRAIN  loss dict:  {'mse_loss': 0.1555092540383339}
2024-05-03 21:20:15,822 [INFO] Step[750/1020]: training loss : 0.1464339689910412 TRAIN  loss dict:  {'mse_loss': 0.1464339689910412}
2024-05-03 21:21:12,654 [INFO] Step[800/1020]: training loss : 0.14105634331703187 TRAIN  loss dict:  {'mse_loss': 0.14105634331703187}
2024-05-03 21:22:06,827 [INFO] Step[850/1020]: training loss : 0.143168333619833 TRAIN  loss dict:  {'mse_loss': 0.143168333619833}
2024-05-03 21:23:02,970 [INFO] Step[900/1020]: training loss : 0.14864468440413475 TRAIN  loss dict:  {'mse_loss': 0.14864468440413475}
2024-05-03 21:23:56,451 [INFO] Step[950/1020]: training loss : 0.14611714825034142 TRAIN  loss dict:  {'mse_loss': 0.14611714825034142}
2024-05-03 21:24:54,881 [INFO] Step[1000/1020]: training loss : 0.14560641169548036 TRAIN  loss dict:  {'mse_loss': 0.14560641169548036}
2024-05-03 21:28:27,785 [INFO] Label accuracies statistics:
2024-05-03 21:28:27,785 [INFO] {0: 0.5, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 1.0, 7: 1.0, 8: 0.75, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.5, 18: 1.0, 19: 1.0, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.5, 26: 1.0, 27: 0.75, 28: 0.75, 29: 0.75, 30: 0.75, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.75, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 1.0, 65: 1.0, 66: 0.75, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.75, 75: 1.0, 76: 0.75, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 1.0, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.75, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.5, 114: 0.75, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.5, 163: 0.75, 164: 1.0, 165: 1.0, 166: 1.0, 167: 0.75, 168: 0.25, 169: 0.75, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 0.75, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-05-03 21:28:27,823 [INFO] [19] TRAIN  loss: 0.14570120045659588 acc: 0.0
2024-05-03 21:28:27,823 [INFO] [19] TRAIN  loss dict: {'mse_loss': 0.14570120045659588}
2024-05-03 21:28:27,823 [INFO] [19] VALIDATION loss: 0.5881768927881212 VALIDATION  acc: 0.8800505050505051
2024-05-03 21:28:27,823 [INFO] [19] VALIDATION  loss dict: {'mse_loss': 0.1570775273321855, 'classification_loss': 0.43109936670945825}
2024-05-03 21:28:27,823 [INFO] 
2024-05-03 21:30:14,551 [INFO] Step[50/1020]: training loss : 0.14052956700325012 TRAIN  loss dict:  {'mse_loss': 0.14052956700325012}
2024-05-03 21:31:04,510 [INFO] Step[100/1020]: training loss : 0.1427031260728836 TRAIN  loss dict:  {'mse_loss': 0.1427031260728836}
2024-05-03 21:31:55,928 [INFO] Step[150/1020]: training loss : 0.14383986249566078 TRAIN  loss dict:  {'mse_loss': 0.14383986249566078}
2024-05-03 21:32:44,581 [INFO] Step[200/1020]: training loss : 0.14482280373573303 TRAIN  loss dict:  {'mse_loss': 0.14482280373573303}
2024-05-03 21:33:38,854 [INFO] Step[250/1020]: training loss : 0.14487996101379394 TRAIN  loss dict:  {'mse_loss': 0.14487996101379394}
2024-05-03 21:34:31,995 [INFO] Step[300/1020]: training loss : 0.14098106265068056 TRAIN  loss dict:  {'mse_loss': 0.14098106265068056}
2024-05-03 21:35:21,791 [INFO] Step[350/1020]: training loss : 0.1455429135262966 TRAIN  loss dict:  {'mse_loss': 0.1455429135262966}
2024-05-03 21:36:14,208 [INFO] Step[400/1020]: training loss : 0.13949499160051346 TRAIN  loss dict:  {'mse_loss': 0.13949499160051346}
2024-05-03 21:37:05,994 [INFO] Step[450/1020]: training loss : 0.14286564648151398 TRAIN  loss dict:  {'mse_loss': 0.14286564648151398}
2024-05-03 21:38:00,466 [INFO] Step[500/1020]: training loss : 0.1476830178499222 TRAIN  loss dict:  {'mse_loss': 0.1476830178499222}
2024-05-03 21:38:50,058 [INFO] Step[550/1020]: training loss : 0.13841477960348128 TRAIN  loss dict:  {'mse_loss': 0.13841477960348128}
2024-05-03 21:39:43,500 [INFO] Step[600/1020]: training loss : 0.14252214387059212 TRAIN  loss dict:  {'mse_loss': 0.14252214387059212}
2024-05-03 21:40:36,690 [INFO] Step[650/1020]: training loss : 0.14237835228443146 TRAIN  loss dict:  {'mse_loss': 0.14237835228443146}
2024-05-03 21:41:32,192 [INFO] Step[700/1020]: training loss : 0.14611961245536803 TRAIN  loss dict:  {'mse_loss': 0.14611961245536803}
2024-05-03 21:42:20,885 [INFO] Step[750/1020]: training loss : 0.14453447550535203 TRAIN  loss dict:  {'mse_loss': 0.14453447550535203}
2024-05-03 21:43:11,998 [INFO] Step[800/1020]: training loss : 0.1428489202260971 TRAIN  loss dict:  {'mse_loss': 0.1428489202260971}
2024-05-03 21:44:02,573 [INFO] Step[850/1020]: training loss : 0.13869186773896217 TRAIN  loss dict:  {'mse_loss': 0.13869186773896217}
2024-05-03 21:44:55,934 [INFO] Step[900/1020]: training loss : 0.14130967870354652 TRAIN  loss dict:  {'mse_loss': 0.14130967870354652}
2024-05-03 21:45:50,914 [INFO] Step[950/1020]: training loss : 0.14544957295060157 TRAIN  loss dict:  {'mse_loss': 0.14544957295060157}
2024-05-03 21:46:43,681 [INFO] Step[1000/1020]: training loss : 0.14098301842808725 TRAIN  loss dict:  {'mse_loss': 0.14098301842808725}
2024-05-03 21:50:15,663 [INFO] Label accuracies statistics:
2024-05-03 21:50:15,665 [INFO] {0: 0.5, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.6666666666666666, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.5, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 1.0, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 1.0, 29: 0.75, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.25, 54: 1.0, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.5, 61: 0.75, 62: 1.0, 63: 1.0, 64: 1.0, 65: 1.0, 66: 0.75, 67: 1.0, 68: 1.0, 69: 0.75, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.75, 88: 1.0, 89: 1.0, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.75, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.5, 114: 0.75, 115: 1.0, 116: 1.0, 117: 1.0, 118: 0.75, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 1.0, 156: 0.5, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.5, 163: 0.75, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-05-03 21:50:15,692 [INFO] [20] TRAIN  loss: 0.1429189522768937 acc: 0.0
2024-05-03 21:50:15,694 [INFO] [20] TRAIN  loss dict: {'mse_loss': 0.1429189522768937}
2024-05-03 21:50:15,696 [INFO] [20] VALIDATION loss: 0.6142566293628529 VALIDATION  acc: 0.88510101010101
2024-05-03 21:50:15,696 [INFO] [20] VALIDATION  loss dict: {'mse_loss': 0.155660070253141, 'classification_loss': 0.4585965597352972}
2024-05-03 21:50:15,697 [INFO] 
2024-05-03 21:51:54,327 [INFO] Step[50/1020]: training loss : 0.13891115605831147 TRAIN  loss dict:  {'mse_loss': 0.13891115605831147}
2024-05-03 21:52:43,485 [INFO] Step[100/1020]: training loss : 0.14576055839657784 TRAIN  loss dict:  {'mse_loss': 0.14576055839657784}
2024-05-03 21:53:34,670 [INFO] Step[150/1020]: training loss : 0.1414286758005619 TRAIN  loss dict:  {'mse_loss': 0.1414286758005619}
2024-05-03 21:54:28,936 [INFO] Step[200/1020]: training loss : 0.14014941439032555 TRAIN  loss dict:  {'mse_loss': 0.14014941439032555}
2024-05-03 21:55:19,711 [INFO] Step[250/1020]: training loss : 0.14154894545674324 TRAIN  loss dict:  {'mse_loss': 0.14154894545674324}
2024-05-03 21:56:11,631 [INFO] Step[300/1020]: training loss : 0.13143007174134255 TRAIN  loss dict:  {'mse_loss': 0.13143007174134255}
2024-05-03 21:57:05,507 [INFO] Step[350/1020]: training loss : 0.1403413200378418 TRAIN  loss dict:  {'mse_loss': 0.1403413200378418}
2024-05-03 21:57:54,970 [INFO] Step[400/1020]: training loss : 0.14172249525785446 TRAIN  loss dict:  {'mse_loss': 0.14172249525785446}
2024-05-03 21:58:44,754 [INFO] Step[450/1020]: training loss : 0.1463664199411869 TRAIN  loss dict:  {'mse_loss': 0.1463664199411869}
2024-05-03 21:59:37,996 [INFO] Step[500/1020]: training loss : 0.14010541290044784 TRAIN  loss dict:  {'mse_loss': 0.14010541290044784}
2024-05-03 22:00:30,700 [INFO] Step[550/1020]: training loss : 0.13774025574326515 TRAIN  loss dict:  {'mse_loss': 0.13774025574326515}
2024-05-03 22:01:22,734 [INFO] Step[600/1020]: training loss : 0.14267128422856332 TRAIN  loss dict:  {'mse_loss': 0.14267128422856332}
2024-05-03 22:02:14,323 [INFO] Step[650/1020]: training loss : 0.13366097658872605 TRAIN  loss dict:  {'mse_loss': 0.13366097658872605}
2024-05-03 22:03:06,219 [INFO] Step[700/1020]: training loss : 0.14171856984496117 TRAIN  loss dict:  {'mse_loss': 0.14171856984496117}
2024-05-03 22:03:57,254 [INFO] Step[750/1020]: training loss : 0.14439910665154457 TRAIN  loss dict:  {'mse_loss': 0.14439910665154457}
2024-05-03 22:04:53,577 [INFO] Step[800/1020]: training loss : 0.13966713830828667 TRAIN  loss dict:  {'mse_loss': 0.13966713830828667}
2024-05-03 22:05:45,756 [INFO] Step[850/1020]: training loss : 0.14213979005813598 TRAIN  loss dict:  {'mse_loss': 0.14213979005813598}
2024-05-03 22:06:37,783 [INFO] Step[900/1020]: training loss : 0.14028279051184656 TRAIN  loss dict:  {'mse_loss': 0.14028279051184656}
2024-05-03 22:07:31,553 [INFO] Step[950/1020]: training loss : 0.14274712800979614 TRAIN  loss dict:  {'mse_loss': 0.14274712800979614}
2024-05-03 22:08:25,012 [INFO] Step[1000/1020]: training loss : 0.13945563703775407 TRAIN  loss dict:  {'mse_loss': 0.13945563703775407}
2024-05-03 22:11:56,226 [INFO] Label accuracies statistics:
2024-05-03 22:11:56,226 [INFO] {0: 1.0, 1: 0.75, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.5, 7: 1.0, 8: 0.75, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 1.0, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.75, 28: 1.0, 29: 1.0, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.5, 54: 1.0, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 1.0, 65: 0.75, 66: 0.25, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.75, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.5, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.25, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.5, 158: 0.75, 159: 0.75, 160: 1.0, 161: 1.0, 162: 0.75, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.25, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 1.0, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-03 22:12:00,948 [INFO] [21] TRAIN  loss: 0.14044362763855972 acc: 0.0
2024-05-03 22:12:00,948 [INFO] [21] TRAIN  loss dict: {'mse_loss': 0.14044362763855972}
2024-05-03 22:12:00,949 [INFO] [21] VALIDATION loss: 0.5678731913142132 VALIDATION  acc: 0.8901515151515151
2024-05-03 22:12:00,949 [INFO] [21] VALIDATION  loss dict: {'mse_loss': 0.15336776280192413, 'classification_loss': 0.4145054287333606}
2024-05-03 22:12:00,949 [INFO] 
2024-05-03 22:13:45,676 [INFO] Step[50/1020]: training loss : 0.13749762177467345 TRAIN  loss dict:  {'mse_loss': 0.13749762177467345}
2024-05-03 22:14:42,721 [INFO] Step[100/1020]: training loss : 0.13747480258345604 TRAIN  loss dict:  {'mse_loss': 0.13747480258345604}
2024-05-03 22:15:34,495 [INFO] Step[150/1020]: training loss : 0.14555463343858718 TRAIN  loss dict:  {'mse_loss': 0.14555463343858718}
2024-05-03 22:16:25,566 [INFO] Step[200/1020]: training loss : 0.1392356587946415 TRAIN  loss dict:  {'mse_loss': 0.1392356587946415}
2024-05-03 22:17:17,532 [INFO] Step[250/1020]: training loss : 0.14155045971274377 TRAIN  loss dict:  {'mse_loss': 0.14155045971274377}
2024-05-03 22:18:09,778 [INFO] Step[300/1020]: training loss : 0.13660337463021277 TRAIN  loss dict:  {'mse_loss': 0.13660337463021277}
2024-05-03 22:19:05,034 [INFO] Step[350/1020]: training loss : 0.1417942997813225 TRAIN  loss dict:  {'mse_loss': 0.1417942997813225}
2024-05-03 22:19:59,213 [INFO] Step[400/1020]: training loss : 0.13982377365231513 TRAIN  loss dict:  {'mse_loss': 0.13982377365231513}
2024-05-03 22:20:54,533 [INFO] Step[450/1020]: training loss : 0.1426174409687519 TRAIN  loss dict:  {'mse_loss': 0.1426174409687519}
2024-05-03 22:21:47,211 [INFO] Step[500/1020]: training loss : 0.14075532540678978 TRAIN  loss dict:  {'mse_loss': 0.14075532540678978}
2024-05-03 22:22:42,965 [INFO] Step[550/1020]: training loss : 0.13797679781913758 TRAIN  loss dict:  {'mse_loss': 0.13797679781913758}
2024-05-03 22:23:43,965 [INFO] Step[600/1020]: training loss : 0.14131406530737878 TRAIN  loss dict:  {'mse_loss': 0.14131406530737878}
2024-05-03 22:24:37,322 [INFO] Step[650/1020]: training loss : 0.1420479267835617 TRAIN  loss dict:  {'mse_loss': 0.1420479267835617}
2024-05-03 22:25:30,045 [INFO] Step[700/1020]: training loss : 0.14353210732340813 TRAIN  loss dict:  {'mse_loss': 0.14353210732340813}
2024-05-03 22:26:20,871 [INFO] Step[750/1020]: training loss : 0.13977774620056152 TRAIN  loss dict:  {'mse_loss': 0.13977774620056152}
2024-05-03 22:27:18,443 [INFO] Step[800/1020]: training loss : 0.13701774999499322 TRAIN  loss dict:  {'mse_loss': 0.13701774999499322}
2024-05-03 22:28:17,305 [INFO] Step[850/1020]: training loss : 0.1421036770939827 TRAIN  loss dict:  {'mse_loss': 0.1421036770939827}
2024-05-03 22:29:11,674 [INFO] Step[900/1020]: training loss : 0.14454269737005235 TRAIN  loss dict:  {'mse_loss': 0.14454269737005235}
2024-05-03 22:30:03,136 [INFO] Step[950/1020]: training loss : 0.14190302699804305 TRAIN  loss dict:  {'mse_loss': 0.14190302699804305}
2024-05-03 22:30:56,019 [INFO] Step[1000/1020]: training loss : 0.13366358816623689 TRAIN  loss dict:  {'mse_loss': 0.13366358816623689}
2024-05-03 22:35:09,440 [INFO] Label accuracies statistics:
2024-05-03 22:35:09,440 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 0.75, 6: 0.75, 7: 1.0, 8: 0.75, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 1.0, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 1.0, 29: 0.5, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 1.0, 52: 1.0, 53: 0.5, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.5, 61: 1.0, 62: 1.0, 63: 1.0, 64: 1.0, 65: 1.0, 66: 0.75, 67: 1.0, 68: 0.75, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 0.75, 87: 0.75, 88: 1.0, 89: 1.0, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.75, 153: 1.0, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.5, 163: 0.5, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.25, 169: 0.75, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-05-03 22:35:09,468 [INFO] [22] TRAIN  loss: 0.14010195075442977 acc: 0.0
2024-05-03 22:35:09,468 [INFO] [22] TRAIN  loss dict: {'mse_loss': 0.14010195075442977}
2024-05-03 22:35:09,468 [INFO] [22] VALIDATION loss: 0.6220124869259319 VALIDATION  acc: 0.88510101010101
2024-05-03 22:35:09,468 [INFO] [22] VALIDATION  loss dict: {'mse_loss': 0.1541230236415309, 'classification_loss': 0.46788946446501695}
2024-05-03 22:35:09,469 [INFO] 
2024-05-03 22:37:00,231 [INFO] Step[50/1020]: training loss : 0.1368668769299984 TRAIN  loss dict:  {'mse_loss': 0.1368668769299984}
2024-05-03 22:37:58,890 [INFO] Step[100/1020]: training loss : 0.13603371351957322 TRAIN  loss dict:  {'mse_loss': 0.13603371351957322}
2024-05-03 22:38:53,747 [INFO] Step[150/1020]: training loss : 0.13519879654049874 TRAIN  loss dict:  {'mse_loss': 0.13519879654049874}
2024-05-03 22:39:47,272 [INFO] Step[200/1020]: training loss : 0.14463213995099067 TRAIN  loss dict:  {'mse_loss': 0.14463213995099067}
2024-05-03 22:40:45,179 [INFO] Step[250/1020]: training loss : 0.13561222866177558 TRAIN  loss dict:  {'mse_loss': 0.13561222866177558}
2024-05-03 22:41:43,365 [INFO] Step[300/1020]: training loss : 0.13426529690623284 TRAIN  loss dict:  {'mse_loss': 0.13426529690623284}
2024-05-03 22:42:39,492 [INFO] Step[350/1020]: training loss : 0.13895243525505066 TRAIN  loss dict:  {'mse_loss': 0.13895243525505066}
2024-05-03 22:43:37,003 [INFO] Step[400/1020]: training loss : 0.13715482816100122 TRAIN  loss dict:  {'mse_loss': 0.13715482816100122}
2024-05-03 22:44:31,025 [INFO] Step[450/1020]: training loss : 0.13764334112405777 TRAIN  loss dict:  {'mse_loss': 0.13764334112405777}
2024-05-03 22:45:30,297 [INFO] Step[500/1020]: training loss : 0.1370799171924591 TRAIN  loss dict:  {'mse_loss': 0.1370799171924591}
2024-05-03 22:46:32,967 [INFO] Step[550/1020]: training loss : 0.13365581080317498 TRAIN  loss dict:  {'mse_loss': 0.13365581080317498}
2024-05-03 22:47:42,197 [INFO] Step[600/1020]: training loss : 0.14075796216726302 TRAIN  loss dict:  {'mse_loss': 0.14075796216726302}
2024-05-03 22:48:43,108 [INFO] Step[650/1020]: training loss : 0.14140078961849212 TRAIN  loss dict:  {'mse_loss': 0.14140078961849212}
2024-05-03 22:49:38,201 [INFO] Step[700/1020]: training loss : 0.13488396063446997 TRAIN  loss dict:  {'mse_loss': 0.13488396063446997}
2024-05-03 22:50:33,416 [INFO] Step[750/1020]: training loss : 0.1348442779481411 TRAIN  loss dict:  {'mse_loss': 0.1348442779481411}
2024-05-03 22:51:29,880 [INFO] Step[800/1020]: training loss : 0.1352773143351078 TRAIN  loss dict:  {'mse_loss': 0.1352773143351078}
2024-05-03 22:52:25,828 [INFO] Step[850/1020]: training loss : 0.14117899551987648 TRAIN  loss dict:  {'mse_loss': 0.14117899551987648}
2024-05-03 22:53:24,701 [INFO] Step[900/1020]: training loss : 0.14111401557922362 TRAIN  loss dict:  {'mse_loss': 0.14111401557922362}
2024-05-03 22:54:22,689 [INFO] Step[950/1020]: training loss : 0.1413639937341213 TRAIN  loss dict:  {'mse_loss': 0.1413639937341213}
2024-05-03 22:55:20,088 [INFO] Step[1000/1020]: training loss : 0.1384247775375843 TRAIN  loss dict:  {'mse_loss': 0.1384247775375843}
2024-05-03 22:59:01,620 [INFO] Label accuracies statistics:
2024-05-03 22:59:01,620 [INFO] {0: 1.0, 1: 0.75, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.5, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 1.0, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.75, 28: 0.75, 29: 0.75, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.5, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 1.0, 65: 1.0, 66: 0.5, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 0.75, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 0.75, 87: 0.75, 88: 1.0, 89: 1.0, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.75, 118: 0.75, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.5, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.5, 156: 1.0, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.5, 163: 0.75, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 0.75, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-05-03 22:59:01,648 [INFO] [23] TRAIN  loss: 0.13794367192860912 acc: 0.0
2024-05-03 22:59:01,648 [INFO] [23] TRAIN  loss dict: {'mse_loss': 0.13794367192860912}
2024-05-03 22:59:01,648 [INFO] [23] VALIDATION loss: 0.6213154919972323 VALIDATION  acc: 0.8724747474747475
2024-05-03 22:59:01,648 [INFO] [23] VALIDATION  loss dict: {'mse_loss': 0.15131867925326029, 'classification_loss': 0.4699968107284583}
2024-05-03 22:59:01,648 [INFO] 
2024-05-03 23:00:50,706 [INFO] Step[50/1020]: training loss : 0.13905720978975297 TRAIN  loss dict:  {'mse_loss': 0.13905720978975297}
2024-05-03 23:01:52,267 [INFO] Step[100/1020]: training loss : 0.1345633889734745 TRAIN  loss dict:  {'mse_loss': 0.1345633889734745}
2024-05-03 23:02:51,544 [INFO] Step[150/1020]: training loss : 0.14386571645736695 TRAIN  loss dict:  {'mse_loss': 0.14386571645736695}
2024-05-03 23:03:46,082 [INFO] Step[200/1020]: training loss : 0.14240566417574882 TRAIN  loss dict:  {'mse_loss': 0.14240566417574882}
2024-05-03 23:04:39,239 [INFO] Step[250/1020]: training loss : 0.14437730386853218 TRAIN  loss dict:  {'mse_loss': 0.14437730386853218}
2024-05-03 23:05:33,960 [INFO] Step[300/1020]: training loss : 0.1381656114757061 TRAIN  loss dict:  {'mse_loss': 0.1381656114757061}
2024-05-03 23:06:29,976 [INFO] Step[350/1020]: training loss : 0.1394156923890114 TRAIN  loss dict:  {'mse_loss': 0.1394156923890114}
2024-05-03 23:07:19,928 [INFO] Step[400/1020]: training loss : 0.14008684933185578 TRAIN  loss dict:  {'mse_loss': 0.14008684933185578}
2024-05-03 23:08:16,387 [INFO] Step[450/1020]: training loss : 0.14208642676472663 TRAIN  loss dict:  {'mse_loss': 0.14208642676472663}
2024-05-03 23:10:35,720 [INFO] Step[500/1020]: training loss : 0.13613918483257292 TRAIN  loss dict:  {'mse_loss': 0.13613918483257292}
2024-05-03 23:11:25,453 [INFO] Step[550/1020]: training loss : 0.13594219520688056 TRAIN  loss dict:  {'mse_loss': 0.13594219520688056}
2024-05-03 23:12:17,771 [INFO] Step[600/1020]: training loss : 0.13417447835206986 TRAIN  loss dict:  {'mse_loss': 0.13417447835206986}
2024-05-03 23:13:11,132 [INFO] Step[650/1020]: training loss : 0.13258804395794868 TRAIN  loss dict:  {'mse_loss': 0.13258804395794868}
2024-05-03 23:14:03,768 [INFO] Step[700/1020]: training loss : 0.14069706663489343 TRAIN  loss dict:  {'mse_loss': 0.14069706663489343}
2024-05-03 23:14:57,441 [INFO] Step[750/1020]: training loss : 0.1350836381316185 TRAIN  loss dict:  {'mse_loss': 0.1350836381316185}
2024-05-03 23:15:48,664 [INFO] Step[800/1020]: training loss : 0.13574078395962716 TRAIN  loss dict:  {'mse_loss': 0.13574078395962716}
2024-05-03 23:16:42,532 [INFO] Step[850/1020]: training loss : 0.14047784328460694 TRAIN  loss dict:  {'mse_loss': 0.14047784328460694}
2024-05-03 23:17:35,872 [INFO] Step[900/1020]: training loss : 0.13737295985221862 TRAIN  loss dict:  {'mse_loss': 0.13737295985221862}
2024-05-03 23:18:30,092 [INFO] Step[950/1020]: training loss : 0.1358396042883396 TRAIN  loss dict:  {'mse_loss': 0.1358396042883396}
2024-05-03 23:19:26,671 [INFO] Step[1000/1020]: training loss : 0.13396002247929573 TRAIN  loss dict:  {'mse_loss': 0.13396002247929573}
2024-05-03 23:23:24,665 [INFO] Label accuracies statistics:
2024-05-03 23:23:24,674 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.5, 9: 1.0, 10: 1.0, 11: 0.75, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.5, 18: 1.0, 19: 1.0, 20: 0.75, 21: 1.0, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 1.0, 29: 0.5, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 1.0, 35: 0.5, 36: 1.0, 37: 0.75, 38: 1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 1.0, 52: 1.0, 53: 0.5, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.5, 59: 1.0, 60: 1.0, 61: 1.0, 62: 1.0, 63: 1.0, 64: 1.0, 65: 1.0, 66: 0.75, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 0.75, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.5, 163: 1.0, 164: 0.75, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-05-03 23:23:24,695 [INFO] [24] TRAIN  loss: 0.1380645172633961 acc: 0.0
2024-05-03 23:23:24,695 [INFO] [24] TRAIN  loss dict: {'mse_loss': 0.1380645172633961}
2024-05-03 23:23:24,696 [INFO] [24] VALIDATION loss: 0.601942521303591 VALIDATION  acc: 0.8863636363636364
2024-05-03 23:23:24,696 [INFO] [24] VALIDATION  loss dict: {'mse_loss': 0.15218741902046734, 'classification_loss': 0.44975509892589405}
2024-05-03 23:23:24,696 [INFO] 
2024-05-03 23:25:05,469 [INFO] Step[50/1020]: training loss : 0.13505466997623444 TRAIN  loss dict:  {'mse_loss': 0.13505466997623444}
2024-05-03 23:26:06,005 [INFO] Step[100/1020]: training loss : 0.14007801443338394 TRAIN  loss dict:  {'mse_loss': 0.14007801443338394}
2024-05-03 23:27:06,777 [INFO] Step[150/1020]: training loss : 0.13520358979701996 TRAIN  loss dict:  {'mse_loss': 0.13520358979701996}
2024-05-03 23:28:01,054 [INFO] Step[200/1020]: training loss : 0.1388462010025978 TRAIN  loss dict:  {'mse_loss': 0.1388462010025978}
2024-05-03 23:28:59,318 [INFO] Step[250/1020]: training loss : 0.13806467846035958 TRAIN  loss dict:  {'mse_loss': 0.13806467846035958}
2024-05-03 23:29:53,068 [INFO] Step[300/1020]: training loss : 0.1337954594194889 TRAIN  loss dict:  {'mse_loss': 0.1337954594194889}
2024-05-03 23:30:48,049 [INFO] Step[350/1020]: training loss : 0.1360934829711914 TRAIN  loss dict:  {'mse_loss': 0.1360934829711914}
2024-05-03 23:31:48,156 [INFO] Step[400/1020]: training loss : 0.13197820916771888 TRAIN  loss dict:  {'mse_loss': 0.13197820916771888}
2024-05-03 23:32:43,341 [INFO] Step[450/1020]: training loss : 0.13639370054006578 TRAIN  loss dict:  {'mse_loss': 0.13639370054006578}
2024-05-03 23:33:37,046 [INFO] Step[500/1020]: training loss : 0.14490243166685104 TRAIN  loss dict:  {'mse_loss': 0.14490243166685104}
2024-05-03 23:34:28,335 [INFO] Step[550/1020]: training loss : 0.13575827106833457 TRAIN  loss dict:  {'mse_loss': 0.13575827106833457}
2024-05-03 23:35:20,551 [INFO] Step[600/1020]: training loss : 0.13888773515820504 TRAIN  loss dict:  {'mse_loss': 0.13888773515820504}
2024-05-03 23:36:16,452 [INFO] Step[650/1020]: training loss : 0.13753461599349975 TRAIN  loss dict:  {'mse_loss': 0.13753461599349975}
2024-05-03 23:37:11,940 [INFO] Step[700/1020]: training loss : 0.13488577887415887 TRAIN  loss dict:  {'mse_loss': 0.13488577887415887}
2024-05-03 23:38:05,886 [INFO] Step[750/1020]: training loss : 0.1344671368598938 TRAIN  loss dict:  {'mse_loss': 0.1344671368598938}
2024-05-03 23:39:00,630 [INFO] Step[800/1020]: training loss : 0.14146134674549102 TRAIN  loss dict:  {'mse_loss': 0.14146134674549102}
2024-05-03 23:39:51,904 [INFO] Step[850/1020]: training loss : 0.1371748523414135 TRAIN  loss dict:  {'mse_loss': 0.1371748523414135}
2024-05-03 23:40:46,683 [INFO] Step[900/1020]: training loss : 0.13624030157923697 TRAIN  loss dict:  {'mse_loss': 0.13624030157923697}
2024-05-03 23:41:38,674 [INFO] Step[950/1020]: training loss : 0.1393439416587353 TRAIN  loss dict:  {'mse_loss': 0.1393439416587353}
2024-05-03 23:42:33,063 [INFO] Step[1000/1020]: training loss : 0.13954819038510322 TRAIN  loss dict:  {'mse_loss': 0.13954819038510322}
2024-05-03 23:46:25,266 [INFO] Label accuracies statistics:
2024-05-03 23:46:25,283 [INFO] {0: 1.0, 1: 0.75, 2: 0.25, 3: 0.75, 4: 0.6666666666666666, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.75, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 1.0, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 1.0, 29: 0.75, 30: 0.75, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 1.0, 52: 0.75, 53: 1.0, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.5, 59: 0.75, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 1.0, 65: 1.0, 66: 0.75, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 0.75, 87: 0.75, 88: 1.0, 89: 1.0, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.25, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.75, 118: 0.75, 119: 1.0, 120: 0.75, 121: 1.0, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.5, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.75, 153: 1.0, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.5, 163: 0.75, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.25, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 0.75, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-03 23:46:25,308 [INFO] [25] TRAIN  loss: 0.13717770364646817 acc: 0.0
2024-05-03 23:46:25,308 [INFO] [25] TRAIN  loss dict: {'mse_loss': 0.13717770364646817}
2024-05-03 23:46:25,308 [INFO] [25] VALIDATION loss: 0.5844205976887182 VALIDATION  acc: 0.8813131313131313
2024-05-03 23:46:25,308 [INFO] [25] VALIDATION  loss dict: {'mse_loss': 0.15095197548619424, 'classification_loss': 0.4334686222289821}
2024-05-03 23:46:25,309 [INFO] 
2024-05-03 23:48:11,525 [INFO] Step[50/1020]: training loss : 0.13904843509197234 TRAIN  loss dict:  {'mse_loss': 0.13904843509197234}
2024-05-03 23:49:04,795 [INFO] Step[100/1020]: training loss : 0.13154136642813682 TRAIN  loss dict:  {'mse_loss': 0.13154136642813682}
2024-05-03 23:50:03,992 [INFO] Step[150/1020]: training loss : 0.12971780225634574 TRAIN  loss dict:  {'mse_loss': 0.12971780225634574}
2024-05-03 23:51:02,403 [INFO] Step[200/1020]: training loss : 0.13811792135238649 TRAIN  loss dict:  {'mse_loss': 0.13811792135238649}
2024-05-03 23:52:03,066 [INFO] Step[250/1020]: training loss : 0.13562715604901313 TRAIN  loss dict:  {'mse_loss': 0.13562715604901313}
2024-05-03 23:53:03,738 [INFO] Step[300/1020]: training loss : 0.13468395546078682 TRAIN  loss dict:  {'mse_loss': 0.13468395546078682}
2024-05-03 23:53:59,172 [INFO] Step[350/1020]: training loss : 0.1379276604950428 TRAIN  loss dict:  {'mse_loss': 0.1379276604950428}
2024-05-03 23:54:55,712 [INFO] Step[400/1020]: training loss : 0.13835109159350395 TRAIN  loss dict:  {'mse_loss': 0.13835109159350395}
2024-05-03 23:55:50,462 [INFO] Step[450/1020]: training loss : 0.14002458825707437 TRAIN  loss dict:  {'mse_loss': 0.14002458825707437}
2024-05-03 23:56:50,234 [INFO] Step[500/1020]: training loss : 0.1324835877120495 TRAIN  loss dict:  {'mse_loss': 0.1324835877120495}
2024-05-03 23:57:41,888 [INFO] Step[550/1020]: training loss : 0.1345616476237774 TRAIN  loss dict:  {'mse_loss': 0.1345616476237774}
2024-05-03 23:58:35,206 [INFO] Step[600/1020]: training loss : 0.14060238093137742 TRAIN  loss dict:  {'mse_loss': 0.14060238093137742}
2024-05-03 23:59:34,555 [INFO] Step[650/1020]: training loss : 0.130373115837574 TRAIN  loss dict:  {'mse_loss': 0.130373115837574}
2024-05-04 00:00:31,653 [INFO] Step[700/1020]: training loss : 0.14372840911149978 TRAIN  loss dict:  {'mse_loss': 0.14372840911149978}
2024-05-04 00:01:25,665 [INFO] Step[750/1020]: training loss : 0.13250715911388397 TRAIN  loss dict:  {'mse_loss': 0.13250715911388397}
2024-05-04 00:02:18,389 [INFO] Step[800/1020]: training loss : 0.1416095355153084 TRAIN  loss dict:  {'mse_loss': 0.1416095355153084}
2024-05-04 00:03:15,383 [INFO] Step[850/1020]: training loss : 0.14066632330417633 TRAIN  loss dict:  {'mse_loss': 0.14066632330417633}
2024-05-04 00:04:14,050 [INFO] Step[900/1020]: training loss : 0.14228698953986169 TRAIN  loss dict:  {'mse_loss': 0.14228698953986169}
2024-05-04 00:05:12,861 [INFO] Step[950/1020]: training loss : 0.13425264969468118 TRAIN  loss dict:  {'mse_loss': 0.13425264969468118}
2024-05-04 00:06:09,288 [INFO] Step[1000/1020]: training loss : 0.13717592850327492 TRAIN  loss dict:  {'mse_loss': 0.13717592850327492}
2024-05-04 00:09:44,107 [INFO] Label accuracies statistics:
2024-05-04 00:09:44,115 [INFO] {0: 1.0, 1: 0.75, 2: 0.5, 3: 0.75, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.5, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.75, 16: 1.0, 17: 0.75, 18: 1.0, 19: 1.0, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.75, 28: 0.75, 29: 0.5, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.75, 36: 0.75, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 1.0, 51: 1.0, 52: 1.0, 53: 0.5, 54: 1.0, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 1.0, 65: 0.75, 66: 0.75, 67: 1.0, 68: 1.0, 69: 1.0, 70: 1.0, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 1.0, 88: 1.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.5, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.75, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.5, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 0.75, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-05-04 00:09:44,146 [INFO] [26] TRAIN  loss: 0.1367421144436972 acc: 0.0
2024-05-04 00:09:44,149 [INFO] [26] TRAIN  loss dict: {'mse_loss': 0.1367421144436972}
2024-05-04 00:09:44,152 [INFO] [26] VALIDATION loss: 0.5894078498311115 VALIDATION  acc: 0.8813131313131313
2024-05-04 00:09:44,154 [INFO] [26] VALIDATION  loss dict: {'mse_loss': 0.1525389984099552, 'classification_loss': 0.43686884975959217}
2024-05-04 00:09:44,156 [INFO] 
2024-05-04 00:11:28,144 [INFO] Step[50/1020]: training loss : 0.1330595678091049 TRAIN  loss dict:  {'mse_loss': 0.1330595678091049}
2024-05-04 00:12:26,747 [INFO] Step[100/1020]: training loss : 0.13424348667263986 TRAIN  loss dict:  {'mse_loss': 0.13424348667263986}
2024-05-04 00:13:20,891 [INFO] Step[150/1020]: training loss : 0.1371986198425293 TRAIN  loss dict:  {'mse_loss': 0.1371986198425293}
2024-05-04 00:14:19,520 [INFO] Step[200/1020]: training loss : 0.13270745500922204 TRAIN  loss dict:  {'mse_loss': 0.13270745500922204}
2024-05-04 00:15:17,432 [INFO] Step[250/1020]: training loss : 0.1350795991718769 TRAIN  loss dict:  {'mse_loss': 0.1350795991718769}
2024-05-04 00:16:16,421 [INFO] Step[300/1020]: training loss : 0.13991995990276337 TRAIN  loss dict:  {'mse_loss': 0.13991995990276337}
2024-05-04 00:17:13,955 [INFO] Step[350/1020]: training loss : 0.14028946354985236 TRAIN  loss dict:  {'mse_loss': 0.14028946354985236}
2024-05-04 00:18:13,695 [INFO] Step[400/1020]: training loss : 0.1332149001955986 TRAIN  loss dict:  {'mse_loss': 0.1332149001955986}
2024-05-04 00:19:17,523 [INFO] Step[450/1020]: training loss : 0.13293777510523797 TRAIN  loss dict:  {'mse_loss': 0.13293777510523797}
2024-05-04 00:20:17,476 [INFO] Step[500/1020]: training loss : 0.1416541562974453 TRAIN  loss dict:  {'mse_loss': 0.1416541562974453}
2024-05-04 00:21:11,377 [INFO] Step[550/1020]: training loss : 0.1314646904170513 TRAIN  loss dict:  {'mse_loss': 0.1314646904170513}
2024-05-04 00:22:04,589 [INFO] Step[600/1020]: training loss : 0.1359135988354683 TRAIN  loss dict:  {'mse_loss': 0.1359135988354683}
2024-05-04 00:22:56,815 [INFO] Step[650/1020]: training loss : 0.13910938039422036 TRAIN  loss dict:  {'mse_loss': 0.13910938039422036}
2024-05-04 00:23:48,428 [INFO] Step[700/1020]: training loss : 0.1361487852036953 TRAIN  loss dict:  {'mse_loss': 0.1361487852036953}
2024-05-04 00:24:40,496 [INFO] Step[750/1020]: training loss : 0.13391342923045157 TRAIN  loss dict:  {'mse_loss': 0.13391342923045157}
2024-05-04 00:25:38,135 [INFO] Step[800/1020]: training loss : 0.14004198908805848 TRAIN  loss dict:  {'mse_loss': 0.14004198908805848}
2024-05-04 00:26:30,980 [INFO] Step[850/1020]: training loss : 0.13797247886657715 TRAIN  loss dict:  {'mse_loss': 0.13797247886657715}
2024-05-04 00:27:28,847 [INFO] Step[900/1020]: training loss : 0.13628844037652016 TRAIN  loss dict:  {'mse_loss': 0.13628844037652016}
2024-05-04 00:28:21,045 [INFO] Step[950/1020]: training loss : 0.13097299814224242 TRAIN  loss dict:  {'mse_loss': 0.13097299814224242}
2024-05-04 00:29:12,803 [INFO] Step[1000/1020]: training loss : 0.13206570565700532 TRAIN  loss dict:  {'mse_loss': 0.13206570565700532}
2024-05-04 00:33:01,906 [INFO] Label accuracies statistics:
2024-05-04 00:33:01,921 [INFO] {0: 0.5, 1: 1.0, 2: 0.5, 3: 1.0, 4: 0.6666666666666666, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.5, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 1.0, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 1.0, 29: 0.75, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 1.0, 52: 1.0, 53: 0.75, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 1.0, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.75, 65: 1.0, 66: 0.5, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 0.75, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 1.0, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 0.75, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.5, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 1.0, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-05-04 00:33:06,784 [INFO] [27] TRAIN  loss: 0.1356015576086208 acc: 0.0
2024-05-04 00:33:06,784 [INFO] [27] TRAIN  loss dict: {'mse_loss': 0.1356015576086208}
2024-05-04 00:33:06,785 [INFO] [27] VALIDATION loss: 0.5579193821459105 VALIDATION  acc: 0.8952020202020202
2024-05-04 00:33:06,785 [INFO] [27] VALIDATION  loss dict: {'mse_loss': 0.15111981392508805, 'classification_loss': 0.40679957028454866}
2024-05-04 00:33:06,785 [INFO] 
2024-05-04 00:34:52,663 [INFO] Step[50/1020]: training loss : 0.13575062081217765 TRAIN  loss dict:  {'mse_loss': 0.13575062081217765}
2024-05-04 00:35:47,209 [INFO] Step[100/1020]: training loss : 0.12838829353451728 TRAIN  loss dict:  {'mse_loss': 0.12838829353451728}
2024-05-04 00:36:39,630 [INFO] Step[150/1020]: training loss : 0.13720376864075662 TRAIN  loss dict:  {'mse_loss': 0.13720376864075662}
2024-05-04 00:37:39,957 [INFO] Step[200/1020]: training loss : 0.13824387684464454 TRAIN  loss dict:  {'mse_loss': 0.13824387684464454}
2024-05-04 00:38:44,228 [INFO] Step[250/1020]: training loss : 0.13294952258467674 TRAIN  loss dict:  {'mse_loss': 0.13294952258467674}
2024-05-04 00:39:41,892 [INFO] Step[300/1020]: training loss : 0.1349300940334797 TRAIN  loss dict:  {'mse_loss': 0.1349300940334797}
2024-05-04 00:40:37,935 [INFO] Step[350/1020]: training loss : 0.13609135687351226 TRAIN  loss dict:  {'mse_loss': 0.13609135687351226}
2024-05-04 00:41:28,343 [INFO] Step[400/1020]: training loss : 0.1289981260895729 TRAIN  loss dict:  {'mse_loss': 0.1289981260895729}
2024-05-04 00:42:16,956 [INFO] Step[450/1020]: training loss : 0.1329833622276783 TRAIN  loss dict:  {'mse_loss': 0.1329833622276783}
2024-05-04 00:43:09,973 [INFO] Step[500/1020]: training loss : 0.134175892919302 TRAIN  loss dict:  {'mse_loss': 0.134175892919302}
2024-05-04 00:44:02,119 [INFO] Step[550/1020]: training loss : 0.13336296454072 TRAIN  loss dict:  {'mse_loss': 0.13336296454072}
2024-05-04 00:44:57,478 [INFO] Step[600/1020]: training loss : 0.1308252254128456 TRAIN  loss dict:  {'mse_loss': 0.1308252254128456}
2024-05-04 00:45:49,906 [INFO] Step[650/1020]: training loss : 0.14076999977231025 TRAIN  loss dict:  {'mse_loss': 0.14076999977231025}
2024-05-04 00:46:41,062 [INFO] Step[700/1020]: training loss : 0.1315799857676029 TRAIN  loss dict:  {'mse_loss': 0.1315799857676029}
2024-05-04 00:47:32,978 [INFO] Step[750/1020]: training loss : 0.13410831362009049 TRAIN  loss dict:  {'mse_loss': 0.13410831362009049}
2024-05-04 00:48:20,170 [INFO] Step[800/1020]: training loss : 0.1339197850227356 TRAIN  loss dict:  {'mse_loss': 0.1339197850227356}
2024-05-04 00:49:09,702 [INFO] Step[850/1020]: training loss : 0.13545358225703238 TRAIN  loss dict:  {'mse_loss': 0.13545358225703238}
2024-05-04 00:49:59,714 [INFO] Step[900/1020]: training loss : 0.1399659049510956 TRAIN  loss dict:  {'mse_loss': 0.1399659049510956}
2024-05-04 00:50:51,411 [INFO] Step[950/1020]: training loss : 0.13535547524690628 TRAIN  loss dict:  {'mse_loss': 0.13535547524690628}
2024-05-04 00:51:44,724 [INFO] Step[1000/1020]: training loss : 0.13539889961481094 TRAIN  loss dict:  {'mse_loss': 0.13539889961481094}
2024-05-04 00:55:13,257 [INFO] Label accuracies statistics:
2024-05-04 00:55:13,274 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 0.75, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.5, 9: 1.0, 10: 1.0, 11: 0.75, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.5, 18: 1.0, 19: 1.0, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 1.0, 29: 0.75, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 0.75, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 1.0, 52: 1.0, 53: 0.5, 54: 1.0, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.5, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.75, 65: 1.0, 66: 0.75, 67: 1.0, 68: 0.75, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.75, 88: 1.0, 89: 1.0, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.75, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 0.5, 111: 1.0, 112: 0.5, 113: 0.25, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 0.75, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.25, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 0.75, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.75, 163: 0.75, 164: 1.0, 165: 0.75, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 1.0, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 0.75}

2024-05-04 00:55:13,297 [INFO] [28] TRAIN  loss: 0.13447385368978276 acc: 0.0
2024-05-04 00:55:13,297 [INFO] [28] TRAIN  loss dict: {'mse_loss': 0.13447385368978276}
2024-05-04 00:55:13,298 [INFO] [28] VALIDATION loss: 0.6093251494446186 VALIDATION  acc: 0.8737373737373737
2024-05-04 00:55:13,298 [INFO] [28] VALIDATION  loss dict: {'mse_loss': 0.15152561002307469, 'classification_loss': 0.45779953730725353}
2024-05-04 00:55:13,298 [INFO] 
2024-05-04 00:56:53,321 [INFO] Step[50/1020]: training loss : 0.12872928202152253 TRAIN  loss dict:  {'mse_loss': 0.12872928202152253}
2024-05-04 00:57:44,594 [INFO] Step[100/1020]: training loss : 0.13680509120225906 TRAIN  loss dict:  {'mse_loss': 0.13680509120225906}
2024-05-04 00:58:37,957 [INFO] Step[150/1020]: training loss : 0.14185916125774384 TRAIN  loss dict:  {'mse_loss': 0.14185916125774384}
2024-05-04 00:59:31,052 [INFO] Step[200/1020]: training loss : 0.12539948403835297 TRAIN  loss dict:  {'mse_loss': 0.12539948403835297}
2024-05-04 01:00:25,299 [INFO] Step[250/1020]: training loss : 0.13745766803622245 TRAIN  loss dict:  {'mse_loss': 0.13745766803622245}
2024-05-04 01:01:18,710 [INFO] Step[300/1020]: training loss : 0.13240567445755005 TRAIN  loss dict:  {'mse_loss': 0.13240567445755005}
2024-05-04 01:02:11,727 [INFO] Step[350/1020]: training loss : 0.13156750038266182 TRAIN  loss dict:  {'mse_loss': 0.13156750038266182}
2024-05-04 01:03:01,866 [INFO] Step[400/1020]: training loss : 0.13609590321779252 TRAIN  loss dict:  {'mse_loss': 0.13609590321779252}
2024-05-04 01:03:53,182 [INFO] Step[450/1020]: training loss : 0.13558101177215576 TRAIN  loss dict:  {'mse_loss': 0.13558101177215576}
2024-05-04 01:04:41,825 [INFO] Step[500/1020]: training loss : 0.13486288547515868 TRAIN  loss dict:  {'mse_loss': 0.13486288547515868}
2024-05-04 01:05:36,178 [INFO] Step[550/1020]: training loss : 0.13476503819227217 TRAIN  loss dict:  {'mse_loss': 0.13476503819227217}
2024-05-04 01:06:29,387 [INFO] Step[600/1020]: training loss : 0.1310272866487503 TRAIN  loss dict:  {'mse_loss': 0.1310272866487503}
2024-05-04 01:07:20,975 [INFO] Step[650/1020]: training loss : 0.13564893320202828 TRAIN  loss dict:  {'mse_loss': 0.13564893320202828}
2024-05-04 01:08:11,059 [INFO] Step[700/1020]: training loss : 0.12991018176078797 TRAIN  loss dict:  {'mse_loss': 0.12991018176078797}
2024-05-04 01:09:02,099 [INFO] Step[750/1020]: training loss : 0.13519373297691345 TRAIN  loss dict:  {'mse_loss': 0.13519373297691345}
2024-05-04 01:09:53,394 [INFO] Step[800/1020]: training loss : 0.12765071660280228 TRAIN  loss dict:  {'mse_loss': 0.12765071660280228}
2024-05-04 01:10:45,452 [INFO] Step[850/1020]: training loss : 0.1351160280406475 TRAIN  loss dict:  {'mse_loss': 0.1351160280406475}
2024-05-04 01:11:38,029 [INFO] Step[900/1020]: training loss : 0.13820893973112106 TRAIN  loss dict:  {'mse_loss': 0.13820893973112106}
2024-05-04 01:12:30,236 [INFO] Step[950/1020]: training loss : 0.13732344299554824 TRAIN  loss dict:  {'mse_loss': 0.13732344299554824}
2024-05-04 01:13:21,662 [INFO] Step[1000/1020]: training loss : 0.13387880355119705 TRAIN  loss dict:  {'mse_loss': 0.13387880355119705}
2024-05-04 01:16:45,276 [INFO] Label accuracies statistics:
2024-05-04 01:16:45,282 [INFO] {0: 1.0, 1: 0.75, 2: 0.75, 3: 0.75, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.5, 9: 1.0, 10: 1.0, 11: 0.75, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 1.0, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.75, 28: 1.0, 29: 0.75, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 1.0, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.75, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.5, 59: 0.75, 60: 0.75, 61: 0.75, 62: 1.0, 63: 1.0, 64: 1.0, 65: 1.0, 66: 0.75, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.75, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 1.0, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.5, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 0.75, 168: 0.25, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-05-04 01:16:45,300 [INFO] [29] TRAIN  loss: 0.13398685328224125 acc: 0.0
2024-05-04 01:16:45,300 [INFO] [29] TRAIN  loss dict: {'mse_loss': 0.13398685328224125}
2024-05-04 01:16:45,300 [INFO] [29] VALIDATION loss: 0.5896280212610057 VALIDATION  acc: 0.8914141414141414
2024-05-04 01:16:45,300 [INFO] [29] VALIDATION  loss dict: {'mse_loss': 0.15068740770220757, 'classification_loss': 0.43894061681548735}
2024-05-04 01:16:45,300 [INFO] 
2024-05-04 01:18:28,313 [INFO] Step[50/1020]: training loss : 0.13470327153801917 TRAIN  loss dict:  {'mse_loss': 0.13470327153801917}
2024-05-04 01:19:19,548 [INFO] Step[100/1020]: training loss : 0.12800355151295661 TRAIN  loss dict:  {'mse_loss': 0.12800355151295661}
2024-05-04 01:20:10,272 [INFO] Step[150/1020]: training loss : 0.13393754363059998 TRAIN  loss dict:  {'mse_loss': 0.13393754363059998}
2024-05-04 01:21:00,712 [INFO] Step[200/1020]: training loss : 0.13988464057445527 TRAIN  loss dict:  {'mse_loss': 0.13988464057445527}
2024-05-04 01:21:52,879 [INFO] Step[250/1020]: training loss : 0.136344463378191 TRAIN  loss dict:  {'mse_loss': 0.136344463378191}
2024-05-04 01:22:43,079 [INFO] Step[300/1020]: training loss : 0.13394130542874336 TRAIN  loss dict:  {'mse_loss': 0.13394130542874336}
2024-05-04 01:23:33,976 [INFO] Step[350/1020]: training loss : 0.13472068458795547 TRAIN  loss dict:  {'mse_loss': 0.13472068458795547}
2024-05-04 01:24:26,569 [INFO] Step[400/1020]: training loss : 0.13561187893152238 TRAIN  loss dict:  {'mse_loss': 0.13561187893152238}
2024-05-04 01:25:21,325 [INFO] Step[450/1020]: training loss : 0.13321406170725822 TRAIN  loss dict:  {'mse_loss': 0.13321406170725822}
2024-05-04 01:26:13,530 [INFO] Step[500/1020]: training loss : 0.13187461242079734 TRAIN  loss dict:  {'mse_loss': 0.13187461242079734}
2024-05-04 01:27:05,137 [INFO] Step[550/1020]: training loss : 0.1367287401854992 TRAIN  loss dict:  {'mse_loss': 0.1367287401854992}
2024-05-04 01:27:56,388 [INFO] Step[600/1020]: training loss : 0.13370255663990974 TRAIN  loss dict:  {'mse_loss': 0.13370255663990974}
2024-05-04 01:28:49,558 [INFO] Step[650/1020]: training loss : 0.1340661020576954 TRAIN  loss dict:  {'mse_loss': 0.1340661020576954}
2024-05-04 01:29:42,235 [INFO] Step[700/1020]: training loss : 0.13364864736795426 TRAIN  loss dict:  {'mse_loss': 0.13364864736795426}
2024-05-04 01:30:32,588 [INFO] Step[750/1020]: training loss : 0.13260482832789422 TRAIN  loss dict:  {'mse_loss': 0.13260482832789422}
2024-05-04 01:31:25,441 [INFO] Step[800/1020]: training loss : 0.13047459334135056 TRAIN  loss dict:  {'mse_loss': 0.13047459334135056}
2024-05-04 01:32:17,830 [INFO] Step[850/1020]: training loss : 0.13181050568819047 TRAIN  loss dict:  {'mse_loss': 0.13181050568819047}
2024-05-04 01:33:09,175 [INFO] Step[900/1020]: training loss : 0.1337733644247055 TRAIN  loss dict:  {'mse_loss': 0.1337733644247055}
2024-05-04 01:33:59,267 [INFO] Step[950/1020]: training loss : 0.1336390970647335 TRAIN  loss dict:  {'mse_loss': 0.1336390970647335}
2024-05-04 01:34:49,922 [INFO] Step[1000/1020]: training loss : 0.13741644397377967 TRAIN  loss dict:  {'mse_loss': 0.13741644397377967}
2024-05-04 01:38:12,727 [INFO] Label accuracies statistics:
2024-05-04 01:38:12,728 [INFO] {0: 0.5, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.5, 7: 1.0, 8: 0.5, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.75, 16: 1.0, 17: 0.75, 18: 1.0, 19: 1.0, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 1.0, 26: 1.0, 27: 1.0, 28: 1.0, 29: 0.75, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.5, 54: 1.0, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 1.0, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 1.0, 65: 0.75, 66: 0.75, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.5, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 0.75, 77: 1.0, 78: 1.0, 79: 0.75, 80: 0.75, 81: 0.75, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 0.75, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 0.75, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 1.0, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.5, 156: 0.75, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.5, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-05-04 01:38:12,749 [INFO] [30] TRAIN  loss: 0.13394782576052583 acc: 0.0
2024-05-04 01:38:12,749 [INFO] [30] TRAIN  loss dict: {'mse_loss': 0.13394782576052583}
2024-05-04 01:38:12,749 [INFO] [30] VALIDATION loss: 0.6182962861852814 VALIDATION  acc: 0.8787878787878788
2024-05-04 01:38:12,749 [INFO] [30] VALIDATION  loss dict: {'mse_loss': 0.1533052682349778, 'classification_loss': 0.46499101668737375}
2024-05-04 01:38:12,750 [INFO] 
2024-05-04 01:39:59,231 [INFO] Step[50/1020]: training loss : 0.13735064789652823 TRAIN  loss dict:  {'mse_loss': 0.13735064789652823}
2024-05-04 01:40:53,765 [INFO] Step[100/1020]: training loss : 0.12894311308860779 TRAIN  loss dict:  {'mse_loss': 0.12894311308860779}
2024-05-04 01:41:45,383 [INFO] Step[150/1020]: training loss : 0.13105307132005692 TRAIN  loss dict:  {'mse_loss': 0.13105307132005692}
2024-05-04 01:42:34,232 [INFO] Step[200/1020]: training loss : 0.13909594252705573 TRAIN  loss dict:  {'mse_loss': 0.13909594252705573}
2024-05-04 01:43:25,377 [INFO] Step[250/1020]: training loss : 0.1297680288553238 TRAIN  loss dict:  {'mse_loss': 0.1297680288553238}
2024-05-04 01:44:19,364 [INFO] Step[300/1020]: training loss : 0.13074360892176629 TRAIN  loss dict:  {'mse_loss': 0.13074360892176629}
2024-05-04 01:45:12,510 [INFO] Step[350/1020]: training loss : 0.12536668159067632 TRAIN  loss dict:  {'mse_loss': 0.12536668159067632}
2024-05-04 01:46:01,579 [INFO] Step[400/1020]: training loss : 0.12702196776866914 TRAIN  loss dict:  {'mse_loss': 0.12702196776866914}
2024-05-04 01:46:50,347 [INFO] Step[450/1020]: training loss : 0.12680383667349815 TRAIN  loss dict:  {'mse_loss': 0.12680383667349815}
2024-05-04 01:47:40,304 [INFO] Step[500/1020]: training loss : 0.12842487663030625 TRAIN  loss dict:  {'mse_loss': 0.12842487663030625}
2024-05-04 01:48:28,986 [INFO] Step[550/1020]: training loss : 0.12963524028658868 TRAIN  loss dict:  {'mse_loss': 0.12963524028658868}
2024-05-04 01:49:20,133 [INFO] Step[600/1020]: training loss : 0.12835799872875214 TRAIN  loss dict:  {'mse_loss': 0.12835799872875214}
2024-05-04 01:50:09,641 [INFO] Step[650/1020]: training loss : 0.13119481906294822 TRAIN  loss dict:  {'mse_loss': 0.13119481906294822}
2024-05-04 01:51:01,698 [INFO] Step[700/1020]: training loss : 0.12521459579467772 TRAIN  loss dict:  {'mse_loss': 0.12521459579467772}
2024-05-04 01:51:56,758 [INFO] Step[750/1020]: training loss : 0.1351308871805668 TRAIN  loss dict:  {'mse_loss': 0.1351308871805668}
2024-05-04 01:52:50,253 [INFO] Step[800/1020]: training loss : 0.13280555233359337 TRAIN  loss dict:  {'mse_loss': 0.13280555233359337}
2024-05-04 01:53:42,425 [INFO] Step[850/1020]: training loss : 0.13598671540617943 TRAIN  loss dict:  {'mse_loss': 0.13598671540617943}
2024-05-04 01:54:32,849 [INFO] Step[900/1020]: training loss : 0.12937780737876892 TRAIN  loss dict:  {'mse_loss': 0.12937780737876892}
2024-05-04 01:55:25,274 [INFO] Step[950/1020]: training loss : 0.1308937841653824 TRAIN  loss dict:  {'mse_loss': 0.1308937841653824}
2024-05-04 01:56:17,081 [INFO] Step[1000/1020]: training loss : 0.13032442972064018 TRAIN  loss dict:  {'mse_loss': 0.13032442972064018}
2024-05-04 01:59:44,716 [INFO] Label accuracies statistics:
2024-05-04 01:59:44,717 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.75, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.5, 18: 1.0, 19: 1.0, 20: 0.5, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 1.0, 29: 1.0, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 1.0, 35: 0.75, 36: 1.0, 37: 1.0, 38: 1.0, 39: 1.0, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 1.0, 52: 1.0, 53: 0.5, 54: 0.5, 55: 1.0, 56: 0.75, 57: 1.0, 58: 0.25, 59: 0.75, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 1.0, 65: 0.75, 66: 0.75, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 0.75, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 0.75, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.75, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.75, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.25, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.5, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.75, 158: 0.75, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.5, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-04 01:59:44,740 [INFO] [31] TRAIN  loss: 0.1306733512374408 acc: 0.0
2024-05-04 01:59:44,740 [INFO] [31] TRAIN  loss dict: {'mse_loss': 0.1306733512374408}
2024-05-04 01:59:44,741 [INFO] [31] VALIDATION loss: 0.5906049388677183 VALIDATION  acc: 0.8863636363636364
2024-05-04 01:59:44,741 [INFO] [31] VALIDATION  loss dict: {'mse_loss': 0.1489258740812239, 'classification_loss': 0.44167906698545045}
2024-05-04 01:59:44,741 [INFO] 
2024-05-04 02:01:24,493 [INFO] Step[50/1020]: training loss : 0.12423571333289146 TRAIN  loss dict:  {'mse_loss': 0.12423571333289146}
2024-05-04 02:02:15,693 [INFO] Step[100/1020]: training loss : 0.12701752170920372 TRAIN  loss dict:  {'mse_loss': 0.12701752170920372}
2024-05-04 02:03:12,376 [INFO] Step[150/1020]: training loss : 0.1262023015320301 TRAIN  loss dict:  {'mse_loss': 0.1262023015320301}
2024-05-04 02:04:02,902 [INFO] Step[200/1020]: training loss : 0.13404746398329734 TRAIN  loss dict:  {'mse_loss': 0.13404746398329734}
2024-05-04 02:04:54,037 [INFO] Step[250/1020]: training loss : 0.13041253328323366 TRAIN  loss dict:  {'mse_loss': 0.13041253328323366}
2024-05-04 02:05:45,378 [INFO] Step[300/1020]: training loss : 0.12948952972888947 TRAIN  loss dict:  {'mse_loss': 0.12948952972888947}
2024-05-04 02:06:39,486 [INFO] Step[350/1020]: training loss : 0.13320158571004867 TRAIN  loss dict:  {'mse_loss': 0.13320158571004867}
2024-05-04 02:07:30,733 [INFO] Step[400/1020]: training loss : 0.13180848211050034 TRAIN  loss dict:  {'mse_loss': 0.13180848211050034}
2024-05-04 02:08:23,115 [INFO] Step[450/1020]: training loss : 0.13437244579195975 TRAIN  loss dict:  {'mse_loss': 0.13437244579195975}
2024-05-04 02:09:15,117 [INFO] Step[500/1020]: training loss : 0.13010523468255997 TRAIN  loss dict:  {'mse_loss': 0.13010523468255997}
2024-05-04 02:10:04,968 [INFO] Step[550/1020]: training loss : 0.1316663272678852 TRAIN  loss dict:  {'mse_loss': 0.1316663272678852}
2024-05-04 02:10:58,515 [INFO] Step[600/1020]: training loss : 0.1250317521393299 TRAIN  loss dict:  {'mse_loss': 0.1250317521393299}
2024-05-04 02:11:49,981 [INFO] Step[650/1020]: training loss : 0.13323553442955016 TRAIN  loss dict:  {'mse_loss': 0.13323553442955016}
2024-05-04 02:12:40,094 [INFO] Step[700/1020]: training loss : 0.12956508085131646 TRAIN  loss dict:  {'mse_loss': 0.12956508085131646}
2024-05-04 02:13:33,318 [INFO] Step[750/1020]: training loss : 0.1295686000585556 TRAIN  loss dict:  {'mse_loss': 0.1295686000585556}
2024-05-04 02:14:26,342 [INFO] Step[800/1020]: training loss : 0.12893663644790648 TRAIN  loss dict:  {'mse_loss': 0.12893663644790648}
2024-05-04 02:15:16,799 [INFO] Step[850/1020]: training loss : 0.1314972522854805 TRAIN  loss dict:  {'mse_loss': 0.1314972522854805}
2024-05-04 02:16:07,618 [INFO] Step[900/1020]: training loss : 0.13430730402469634 TRAIN  loss dict:  {'mse_loss': 0.13430730402469634}
2024-05-04 02:17:00,083 [INFO] Step[950/1020]: training loss : 0.13411265581846238 TRAIN  loss dict:  {'mse_loss': 0.13411265581846238}
2024-05-04 02:17:49,677 [INFO] Step[1000/1020]: training loss : 0.12941238716244696 TRAIN  loss dict:  {'mse_loss': 0.12941238716244696}
2024-05-04 02:21:18,604 [INFO] Label accuracies statistics:
2024-05-04 02:21:18,605 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.5, 9: 1.0, 10: 1.0, 11: 0.75, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 1.0, 20: 0.75, 21: 1.0, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.75, 28: 1.0, 29: 0.75, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 1.0, 52: 1.0, 53: 0.25, 54: 1.0, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 1.0, 65: 1.0, 66: 0.75, 67: 1.0, 68: 0.75, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.75, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 0.75, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.75, 163: 0.75, 164: 1.0, 165: 1.0, 166: 1.0, 167: 0.75, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-04 02:21:18,654 [INFO] [32] TRAIN  loss: 0.1303860689568169 acc: 0.0
2024-05-04 02:21:18,654 [INFO] [32] TRAIN  loss dict: {'mse_loss': 0.1303860689568169}
2024-05-04 02:21:18,654 [INFO] [32] VALIDATION loss: 0.5936301898098353 VALIDATION  acc: 0.8914141414141414
2024-05-04 02:21:18,654 [INFO] [32] VALIDATION  loss dict: {'mse_loss': 0.14770984175530347, 'classification_loss': 0.4459203438923901}
2024-05-04 02:21:18,655 [INFO] 
2024-05-04 02:22:59,200 [INFO] Step[50/1020]: training loss : 0.12678477942943572 TRAIN  loss dict:  {'mse_loss': 0.12678477942943572}
2024-05-04 02:23:51,903 [INFO] Step[100/1020]: training loss : 0.13233987599611283 TRAIN  loss dict:  {'mse_loss': 0.13233987599611283}
2024-05-04 02:24:45,662 [INFO] Step[150/1020]: training loss : 0.13380104571580886 TRAIN  loss dict:  {'mse_loss': 0.13380104571580886}
2024-05-04 02:25:36,769 [INFO] Step[200/1020]: training loss : 0.1330696450173855 TRAIN  loss dict:  {'mse_loss': 0.1330696450173855}
2024-05-04 02:26:29,965 [INFO] Step[250/1020]: training loss : 0.12621488377451898 TRAIN  loss dict:  {'mse_loss': 0.12621488377451898}
2024-05-04 02:27:19,247 [INFO] Step[300/1020]: training loss : 0.1273365119099617 TRAIN  loss dict:  {'mse_loss': 0.1273365119099617}
2024-05-04 02:28:09,019 [INFO] Step[350/1020]: training loss : 0.13051823705434798 TRAIN  loss dict:  {'mse_loss': 0.13051823705434798}
2024-05-04 02:29:00,506 [INFO] Step[400/1020]: training loss : 0.12295348435640335 TRAIN  loss dict:  {'mse_loss': 0.12295348435640335}
2024-05-04 02:29:51,067 [INFO] Step[450/1020]: training loss : 0.1297088645398617 TRAIN  loss dict:  {'mse_loss': 0.1297088645398617}
2024-05-04 02:30:45,857 [INFO] Step[500/1020]: training loss : 0.12916916266083717 TRAIN  loss dict:  {'mse_loss': 0.12916916266083717}
2024-05-04 02:31:36,661 [INFO] Step[550/1020]: training loss : 0.13437284141778946 TRAIN  loss dict:  {'mse_loss': 0.13437284141778946}
2024-05-04 02:32:30,034 [INFO] Step[600/1020]: training loss : 0.13097804054617881 TRAIN  loss dict:  {'mse_loss': 0.13097804054617881}
2024-05-04 02:33:20,154 [INFO] Step[650/1020]: training loss : 0.12601226136088373 TRAIN  loss dict:  {'mse_loss': 0.12601226136088373}
2024-05-04 02:34:13,485 [INFO] Step[700/1020]: training loss : 0.13226718604564666 TRAIN  loss dict:  {'mse_loss': 0.13226718604564666}
2024-05-04 02:35:04,786 [INFO] Step[750/1020]: training loss : 0.1316556888818741 TRAIN  loss dict:  {'mse_loss': 0.1316556888818741}
2024-05-04 02:35:57,698 [INFO] Step[800/1020]: training loss : 0.1265195205807686 TRAIN  loss dict:  {'mse_loss': 0.1265195205807686}
2024-05-04 02:36:49,899 [INFO] Step[850/1020]: training loss : 0.12458364441990852 TRAIN  loss dict:  {'mse_loss': 0.12458364441990852}
2024-05-04 02:37:42,393 [INFO] Step[900/1020]: training loss : 0.13340442553162574 TRAIN  loss dict:  {'mse_loss': 0.13340442553162574}
2024-05-04 02:38:35,818 [INFO] Step[950/1020]: training loss : 0.1284460112452507 TRAIN  loss dict:  {'mse_loss': 0.1284460112452507}
2024-05-04 02:39:26,737 [INFO] Step[1000/1020]: training loss : 0.13668026477098466 TRAIN  loss dict:  {'mse_loss': 0.13668026477098466}
2024-05-04 02:42:52,083 [INFO] Label accuracies statistics:
2024-05-04 02:42:52,084 [INFO] {0: 1.0, 1: 0.75, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.5, 9: 1.0, 10: 1.0, 11: 0.75, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 1.0, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 1.0, 29: 0.5, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.75, 61: 0.75, 62: 1.0, 63: 1.0, 64: 1.0, 65: 0.75, 66: 0.75, 67: 1.0, 68: 0.75, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 1.0, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.75, 113: 0.25, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 0.75, 119: 1.0, 120: 0.75, 121: 1.0, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.5, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 0.75, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-05-04 02:42:52,103 [INFO] [33] TRAIN  loss: 0.12991283557870809 acc: 0.0
2024-05-04 02:42:52,103 [INFO] [33] TRAIN  loss dict: {'mse_loss': 0.12991283557870809}
2024-05-04 02:42:52,104 [INFO] [33] VALIDATION loss: 0.5827123702249744 VALIDATION  acc: 0.8838383838383839
2024-05-04 02:42:52,104 [INFO] [33] VALIDATION  loss dict: {'mse_loss': 0.14883512247240904, 'classification_loss': 0.4338772446998969}
2024-05-04 02:42:52,104 [INFO] 
2024-05-04 02:44:34,085 [INFO] Step[50/1020]: training loss : 0.12801172763109206 TRAIN  loss dict:  {'mse_loss': 0.12801172763109206}
2024-05-04 02:45:28,236 [INFO] Step[100/1020]: training loss : 0.13546182870864867 TRAIN  loss dict:  {'mse_loss': 0.13546182870864867}
2024-05-04 02:46:24,086 [INFO] Step[150/1020]: training loss : 0.1303235575556755 TRAIN  loss dict:  {'mse_loss': 0.1303235575556755}
2024-05-04 02:47:17,497 [INFO] Step[200/1020]: training loss : 0.13176852971315384 TRAIN  loss dict:  {'mse_loss': 0.13176852971315384}
2024-05-04 02:48:10,056 [INFO] Step[250/1020]: training loss : 0.12499533474445343 TRAIN  loss dict:  {'mse_loss': 0.12499533474445343}
2024-05-04 02:49:01,698 [INFO] Step[300/1020]: training loss : 0.12727928683161735 TRAIN  loss dict:  {'mse_loss': 0.12727928683161735}
2024-05-04 02:49:52,537 [INFO] Step[350/1020]: training loss : 0.12949879735708236 TRAIN  loss dict:  {'mse_loss': 0.12949879735708236}
2024-05-04 02:50:44,873 [INFO] Step[400/1020]: training loss : 0.12914979055523873 TRAIN  loss dict:  {'mse_loss': 0.12914979055523873}
2024-05-04 02:51:36,844 [INFO] Step[450/1020]: training loss : 0.13312071740627288 TRAIN  loss dict:  {'mse_loss': 0.13312071740627288}
2024-05-04 02:52:28,339 [INFO] Step[500/1020]: training loss : 0.12051941990852356 TRAIN  loss dict:  {'mse_loss': 0.12051941990852356}
2024-05-04 02:53:19,448 [INFO] Step[550/1020]: training loss : 0.13158925250172615 TRAIN  loss dict:  {'mse_loss': 0.13158925250172615}
2024-05-04 02:54:14,454 [INFO] Step[600/1020]: training loss : 0.13297677502036095 TRAIN  loss dict:  {'mse_loss': 0.13297677502036095}
2024-05-04 02:55:05,383 [INFO] Step[650/1020]: training loss : 0.131594385355711 TRAIN  loss dict:  {'mse_loss': 0.131594385355711}
2024-05-04 02:55:59,105 [INFO] Step[700/1020]: training loss : 0.12311525359749793 TRAIN  loss dict:  {'mse_loss': 0.12311525359749793}
2024-05-04 02:56:52,738 [INFO] Step[750/1020]: training loss : 0.1316273884475231 TRAIN  loss dict:  {'mse_loss': 0.1316273884475231}
2024-05-04 02:57:46,879 [INFO] Step[800/1020]: training loss : 0.12989581555128096 TRAIN  loss dict:  {'mse_loss': 0.12989581555128096}
2024-05-04 02:58:41,814 [INFO] Step[850/1020]: training loss : 0.13183721125125886 TRAIN  loss dict:  {'mse_loss': 0.13183721125125886}
2024-05-04 02:59:34,582 [INFO] Step[900/1020]: training loss : 0.13112285926938058 TRAIN  loss dict:  {'mse_loss': 0.13112285926938058}
2024-05-04 03:00:25,953 [INFO] Step[950/1020]: training loss : 0.1329873940348625 TRAIN  loss dict:  {'mse_loss': 0.1329873940348625}
2024-05-04 03:01:15,607 [INFO] Step[1000/1020]: training loss : 0.1300061509013176 TRAIN  loss dict:  {'mse_loss': 0.1300061509013176}
2024-05-04 03:04:42,494 [INFO] Label accuracies statistics:
2024-05-04 03:04:42,495 [INFO] {0: 0.5, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.75, 9: 1.0, 10: 1.0, 11: 0.75, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 1.0, 20: 0.75, 21: 1.0, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.75, 28: 1.0, 29: 0.75, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 1.0, 35: 0.5, 36: 1.0, 37: 1.0, 38: 0.75, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.5, 59: 0.75, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 0.75, 65: 1.0, 66: 0.75, 67: 1.0, 68: 1.0, 69: 0.75, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 1.0, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.75, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.25, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 0.75, 119: 1.0, 120: 0.75, 121: 1.0, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.5, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.5, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 0.75, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.75, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-05-04 03:04:42,511 [INFO] [34] TRAIN  loss: 0.12981897558213448 acc: 0.0
2024-05-04 03:04:42,511 [INFO] [34] TRAIN  loss dict: {'mse_loss': 0.12981897558213448}
2024-05-04 03:04:42,511 [INFO] [34] VALIDATION loss: 0.5706879939470026 VALIDATION  acc: 0.8863636363636364
2024-05-04 03:04:42,511 [INFO] [34] VALIDATION  loss dict: {'mse_loss': 0.14880178251651802, 'classification_loss': 0.4218862114104941}
2024-05-04 03:04:42,512 [INFO] 
2024-05-04 03:06:23,426 [INFO] Step[50/1020]: training loss : 0.12791745975613594 TRAIN  loss dict:  {'mse_loss': 0.12791745975613594}
2024-05-04 03:07:13,629 [INFO] Step[100/1020]: training loss : 0.13081220149993897 TRAIN  loss dict:  {'mse_loss': 0.13081220149993897}
2024-05-04 03:08:03,971 [INFO] Step[150/1020]: training loss : 0.12416179418563843 TRAIN  loss dict:  {'mse_loss': 0.12416179418563843}
2024-05-04 03:08:57,698 [INFO] Step[200/1020]: training loss : 0.12639709874987604 TRAIN  loss dict:  {'mse_loss': 0.12639709874987604}
2024-05-04 03:09:53,754 [INFO] Step[250/1020]: training loss : 0.1298392279446125 TRAIN  loss dict:  {'mse_loss': 0.1298392279446125}
2024-05-04 03:10:51,917 [INFO] Step[300/1020]: training loss : 0.12940912187099457 TRAIN  loss dict:  {'mse_loss': 0.12940912187099457}
2024-05-04 03:11:43,171 [INFO] Step[350/1020]: training loss : 0.12974197193980216 TRAIN  loss dict:  {'mse_loss': 0.12974197193980216}
2024-05-04 03:12:33,200 [INFO] Step[400/1020]: training loss : 0.131548935174942 TRAIN  loss dict:  {'mse_loss': 0.131548935174942}
2024-05-04 03:13:25,961 [INFO] Step[450/1020]: training loss : 0.13355525612831115 TRAIN  loss dict:  {'mse_loss': 0.13355525612831115}
2024-05-04 03:14:18,933 [INFO] Step[500/1020]: training loss : 0.12334918186068534 TRAIN  loss dict:  {'mse_loss': 0.12334918186068534}
2024-05-04 03:15:11,736 [INFO] Step[550/1020]: training loss : 0.1313687838613987 TRAIN  loss dict:  {'mse_loss': 0.1313687838613987}
2024-05-04 03:16:06,079 [INFO] Step[600/1020]: training loss : 0.1261366556584835 TRAIN  loss dict:  {'mse_loss': 0.1261366556584835}
2024-05-04 03:17:02,002 [INFO] Step[650/1020]: training loss : 0.13645601972937585 TRAIN  loss dict:  {'mse_loss': 0.13645601972937585}
2024-05-04 03:17:54,655 [INFO] Step[700/1020]: training loss : 0.12440350726246834 TRAIN  loss dict:  {'mse_loss': 0.12440350726246834}
2024-05-04 03:18:45,976 [INFO] Step[750/1020]: training loss : 0.13203989058732987 TRAIN  loss dict:  {'mse_loss': 0.13203989058732987}
2024-05-04 03:19:38,107 [INFO] Step[800/1020]: training loss : 0.13196970403194427 TRAIN  loss dict:  {'mse_loss': 0.13196970403194427}
2024-05-04 03:20:32,454 [INFO] Step[850/1020]: training loss : 0.12665272429585456 TRAIN  loss dict:  {'mse_loss': 0.12665272429585456}
2024-05-04 03:21:27,192 [INFO] Step[900/1020]: training loss : 0.13332584157586097 TRAIN  loss dict:  {'mse_loss': 0.13332584157586097}
2024-05-04 03:22:19,690 [INFO] Step[950/1020]: training loss : 0.1268547470867634 TRAIN  loss dict:  {'mse_loss': 0.1268547470867634}
2024-05-04 03:23:12,032 [INFO] Step[1000/1020]: training loss : 0.12799597576260566 TRAIN  loss dict:  {'mse_loss': 0.12799597576260566}
2024-05-04 03:26:32,713 [INFO] Label accuracies statistics:
2024-05-04 03:26:32,714 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.6666666666666666, 5: 1.0, 6: 0.5, 7: 1.0, 8: 0.5, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 1.0, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.75, 28: 0.75, 29: 1.0, 30: 0.75, 31: 0.75, 32: 1.0, 33: 1.0, 34: 1.0, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.5, 54: 1.0, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 1.0, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 1.0, 65: 1.0, 66: 0.75, 67: 1.0, 68: 1.0, 69: 0.75, 70: 0.75, 71: 0.75, 72: 0.75, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 0.75, 82: 0.75, 83: 1.0, 84: 1.0, 85: 0.75, 86: 1.0, 87: 0.75, 88: 1.0, 89: 1.0, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.75, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 0.75, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.25, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.75, 118: 0.75, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.5, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 0.75, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-05-04 03:26:32,734 [INFO] [35] TRAIN  loss: 0.12938334458306724 acc: 0.0
2024-05-04 03:26:32,738 [INFO] [35] TRAIN  loss dict: {'mse_loss': 0.12938334458306724}
2024-05-04 03:26:32,738 [INFO] [35] VALIDATION loss: 0.563246038413108 VALIDATION  acc: 0.8876262626262627
2024-05-04 03:26:32,738 [INFO] [35] VALIDATION  loss dict: {'mse_loss': 0.1489160747991668, 'classification_loss': 0.41432996334642114}
2024-05-04 03:26:32,738 [INFO] 
2024-05-04 03:28:12,025 [INFO] Step[50/1020]: training loss : 0.12770650669932365 TRAIN  loss dict:  {'mse_loss': 0.12770650669932365}
2024-05-04 03:29:03,773 [INFO] Step[100/1020]: training loss : 0.11643470510840416 TRAIN  loss dict:  {'mse_loss': 0.11643470510840416}
2024-05-04 03:29:58,121 [INFO] Step[150/1020]: training loss : 0.12516586259007453 TRAIN  loss dict:  {'mse_loss': 0.12516586259007453}
2024-05-04 03:30:54,945 [INFO] Step[200/1020]: training loss : 0.12816341400146483 TRAIN  loss dict:  {'mse_loss': 0.12816341400146483}
2024-05-04 03:31:48,009 [INFO] Step[250/1020]: training loss : 0.12911163449287413 TRAIN  loss dict:  {'mse_loss': 0.12911163449287413}
2024-05-04 03:32:41,192 [INFO] Step[300/1020]: training loss : 0.12526335433125496 TRAIN  loss dict:  {'mse_loss': 0.12526335433125496}
2024-05-04 03:33:33,137 [INFO] Step[350/1020]: training loss : 0.1312330836057663 TRAIN  loss dict:  {'mse_loss': 0.1312330836057663}
2024-05-04 03:34:24,296 [INFO] Step[400/1020]: training loss : 0.12971155002713203 TRAIN  loss dict:  {'mse_loss': 0.12971155002713203}
2024-05-04 03:35:20,643 [INFO] Step[450/1020]: training loss : 0.13112376064062117 TRAIN  loss dict:  {'mse_loss': 0.13112376064062117}
2024-05-04 03:36:13,172 [INFO] Step[500/1020]: training loss : 0.13132703468203544 TRAIN  loss dict:  {'mse_loss': 0.13132703468203544}
2024-05-04 03:37:04,544 [INFO] Step[550/1020]: training loss : 0.1250436607003212 TRAIN  loss dict:  {'mse_loss': 0.1250436607003212}
2024-05-04 03:37:55,400 [INFO] Step[600/1020]: training loss : 0.12611744597554206 TRAIN  loss dict:  {'mse_loss': 0.12611744597554206}
2024-05-04 03:38:46,905 [INFO] Step[650/1020]: training loss : 0.13200285136699677 TRAIN  loss dict:  {'mse_loss': 0.13200285136699677}
2024-05-04 03:39:39,987 [INFO] Step[700/1020]: training loss : 0.1251279181241989 TRAIN  loss dict:  {'mse_loss': 0.1251279181241989}
2024-05-04 03:40:33,687 [INFO] Step[750/1020]: training loss : 0.12989358723163605 TRAIN  loss dict:  {'mse_loss': 0.12989358723163605}
2024-05-04 03:41:23,053 [INFO] Step[800/1020]: training loss : 0.12882687345147134 TRAIN  loss dict:  {'mse_loss': 0.12882687345147134}
2024-05-04 03:42:18,286 [INFO] Step[850/1020]: training loss : 0.13258321091532707 TRAIN  loss dict:  {'mse_loss': 0.13258321091532707}
2024-05-04 03:43:11,091 [INFO] Step[900/1020]: training loss : 0.13027261644601823 TRAIN  loss dict:  {'mse_loss': 0.13027261644601823}
2024-05-04 03:44:03,939 [INFO] Step[950/1020]: training loss : 0.12351256862282753 TRAIN  loss dict:  {'mse_loss': 0.12351256862282753}
2024-05-04 03:44:54,613 [INFO] Step[1000/1020]: training loss : 0.12637943372130395 TRAIN  loss dict:  {'mse_loss': 0.12637943372130395}
2024-05-04 03:48:18,440 [INFO] Label accuracies statistics:
2024-05-04 03:48:18,440 [INFO] {0: 0.5, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 0.75, 8: 0.75, 9: 1.0, 10: 1.0, 11: 0.75, 12: 0.75, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 1.0, 20: 0.75, 21: 1.0, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 1.0, 29: 0.75, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 0.75, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 1.0, 53: 1.0, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.5, 61: 0.75, 62: 1.0, 63: 1.0, 64: 1.0, 65: 1.0, 66: 0.75, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.75, 88: 1.0, 89: 1.0, 90: 0.5, 91: 1.0, 92: 1.0, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.75, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 0.75, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.25, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.5, 158: 0.75, 159: 0.75, 160: 1.0, 161: 1.0, 162: 0.5, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 1.0, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 0.75, 182: 1.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 0.5, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-05-04 03:48:18,460 [INFO] [36] TRAIN  loss: 0.1280302329975016 acc: 0.0
2024-05-04 03:48:18,460 [INFO] [36] TRAIN  loss dict: {'mse_loss': 0.1280302329975016}
2024-05-04 03:48:18,460 [INFO] [36] VALIDATION loss: 0.5724163282323967 VALIDATION  acc: 0.8901515151515151
2024-05-04 03:48:18,460 [INFO] [36] VALIDATION  loss dict: {'mse_loss': 0.148798924428646, 'classification_loss': 0.4236174018293939}
2024-05-04 03:48:18,461 [INFO] 
2024-05-04 03:49:56,893 [INFO] Step[50/1020]: training loss : 0.12731601044535637 TRAIN  loss dict:  {'mse_loss': 0.12731601044535637}
2024-05-04 03:50:47,938 [INFO] Step[100/1020]: training loss : 0.12841656014323236 TRAIN  loss dict:  {'mse_loss': 0.12841656014323236}
2024-05-04 03:51:42,600 [INFO] Step[150/1020]: training loss : 0.1262777628004551 TRAIN  loss dict:  {'mse_loss': 0.1262777628004551}
2024-05-04 03:52:33,199 [INFO] Step[200/1020]: training loss : 0.1317213663458824 TRAIN  loss dict:  {'mse_loss': 0.1317213663458824}
2024-05-04 03:53:27,548 [INFO] Step[250/1020]: training loss : 0.1326007379591465 TRAIN  loss dict:  {'mse_loss': 0.1326007379591465}
2024-05-04 03:54:20,772 [INFO] Step[300/1020]: training loss : 0.12743093341588974 TRAIN  loss dict:  {'mse_loss': 0.12743093341588974}
2024-05-04 03:55:12,953 [INFO] Step[350/1020]: training loss : 0.12216671347618104 TRAIN  loss dict:  {'mse_loss': 0.12216671347618104}
2024-05-04 03:56:08,646 [INFO] Step[400/1020]: training loss : 0.12644110321998597 TRAIN  loss dict:  {'mse_loss': 0.12644110321998597}
2024-05-04 03:57:02,535 [INFO] Step[450/1020]: training loss : 0.12116498365998268 TRAIN  loss dict:  {'mse_loss': 0.12116498365998268}
2024-05-04 03:57:56,041 [INFO] Step[500/1020]: training loss : 0.12873798489570618 TRAIN  loss dict:  {'mse_loss': 0.12873798489570618}
2024-05-04 03:58:46,203 [INFO] Step[550/1020]: training loss : 0.12987969934940338 TRAIN  loss dict:  {'mse_loss': 0.12987969934940338}
2024-05-04 03:59:37,960 [INFO] Step[600/1020]: training loss : 0.13025996536016465 TRAIN  loss dict:  {'mse_loss': 0.13025996536016465}
2024-05-04 04:00:33,478 [INFO] Step[650/1020]: training loss : 0.13266121298074723 TRAIN  loss dict:  {'mse_loss': 0.13266121298074723}
2024-05-04 04:01:25,777 [INFO] Step[700/1020]: training loss : 0.13128851339221 TRAIN  loss dict:  {'mse_loss': 0.13128851339221}
2024-05-04 04:02:18,853 [INFO] Step[750/1020]: training loss : 0.13289078056812287 TRAIN  loss dict:  {'mse_loss': 0.13289078056812287}
2024-05-04 04:03:10,810 [INFO] Step[800/1020]: training loss : 0.12631931021809578 TRAIN  loss dict:  {'mse_loss': 0.12631931021809578}
2024-05-04 04:04:03,550 [INFO] Step[850/1020]: training loss : 0.13369694709777832 TRAIN  loss dict:  {'mse_loss': 0.13369694709777832}
2024-05-04 04:04:57,430 [INFO] Step[900/1020]: training loss : 0.12756768822669984 TRAIN  loss dict:  {'mse_loss': 0.12756768822669984}
2024-05-04 04:05:48,039 [INFO] Step[950/1020]: training loss : 0.13558175832033156 TRAIN  loss dict:  {'mse_loss': 0.13558175832033156}
2024-05-04 04:06:40,207 [INFO] Step[1000/1020]: training loss : 0.1341477380692959 TRAIN  loss dict:  {'mse_loss': 0.1341477380692959}
2024-05-04 04:10:12,922 [INFO] Label accuracies statistics:
2024-05-04 04:10:12,922 [INFO] {0: 1.0, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.75, 9: 1.0, 10: 1.0, 11: 0.75, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 1.0, 20: 0.5, 21: 1.0, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.75, 28: 1.0, 29: 1.0, 30: 0.75, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.75, 54: 0.5, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 1.0, 65: 1.0, 66: 0.5, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.5, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.5, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 1.0, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.75, 118: 0.75, 119: 1.0, 120: 0.75, 121: 1.0, 122: 1.0, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.5, 133: 0.75, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 1.0, 146: 1.0, 147: 1.0, 148: 1.0, 149: 1.0, 150: 0.25, 151: 1.0, 152: 1.0, 153: 0.75, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.75, 158: 0.75, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.5, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 0.75, 168: 0.5, 169: 1.0, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-05-04 04:10:12,940 [INFO] [37] TRAIN  loss: 0.12926622373508473 acc: 0.0
2024-05-04 04:10:12,940 [INFO] [37] TRAIN  loss dict: {'mse_loss': 0.12926622373508473}
2024-05-04 04:10:12,940 [INFO] [37] VALIDATION loss: 0.5890096872292384 VALIDATION  acc: 0.8876262626262627
2024-05-04 04:10:12,940 [INFO] [37] VALIDATION  loss dict: {'mse_loss': 0.14956731428251122, 'classification_loss': 0.43944236945779525}
2024-05-04 04:10:12,940 [INFO] 
2024-05-04 04:11:55,113 [INFO] Step[50/1020]: training loss : 0.12012509852647782 TRAIN  loss dict:  {'mse_loss': 0.12012509852647782}
2024-05-04 04:12:46,379 [INFO] Step[100/1020]: training loss : 0.12383394554257393 TRAIN  loss dict:  {'mse_loss': 0.12383394554257393}
2024-05-04 04:13:41,391 [INFO] Step[150/1020]: training loss : 0.12070958152413368 TRAIN  loss dict:  {'mse_loss': 0.12070958152413368}
2024-05-04 04:14:34,311 [INFO] Step[200/1020]: training loss : 0.12458324730396271 TRAIN  loss dict:  {'mse_loss': 0.12458324730396271}
2024-05-04 04:15:27,084 [INFO] Step[250/1020]: training loss : 0.12554973766207694 TRAIN  loss dict:  {'mse_loss': 0.12554973766207694}
2024-05-04 04:16:19,440 [INFO] Step[300/1020]: training loss : 0.13356836020946503 TRAIN  loss dict:  {'mse_loss': 0.13356836020946503}
2024-05-04 04:17:10,836 [INFO] Step[350/1020]: training loss : 0.12781129360198976 TRAIN  loss dict:  {'mse_loss': 0.12781129360198976}
2024-05-04 04:17:59,352 [INFO] Step[400/1020]: training loss : 0.1281927978992462 TRAIN  loss dict:  {'mse_loss': 0.1281927978992462}
2024-05-04 04:18:50,440 [INFO] Step[450/1020]: training loss : 0.12667596980929374 TRAIN  loss dict:  {'mse_loss': 0.12667596980929374}
2024-05-04 04:19:43,786 [INFO] Step[500/1020]: training loss : 0.13639334127306937 TRAIN  loss dict:  {'mse_loss': 0.13639334127306937}
2024-05-04 04:20:34,819 [INFO] Step[550/1020]: training loss : 0.12870093703269958 TRAIN  loss dict:  {'mse_loss': 0.12870093703269958}
2024-05-04 04:21:32,655 [INFO] Step[600/1020]: training loss : 0.1305413529276848 TRAIN  loss dict:  {'mse_loss': 0.1305413529276848}
2024-05-04 04:22:28,674 [INFO] Step[650/1020]: training loss : 0.12670565277338028 TRAIN  loss dict:  {'mse_loss': 0.12670565277338028}
2024-05-04 04:23:20,574 [INFO] Step[700/1020]: training loss : 0.12406591072678566 TRAIN  loss dict:  {'mse_loss': 0.12406591072678566}
2024-05-04 04:24:11,958 [INFO] Step[750/1020]: training loss : 0.12270805433392525 TRAIN  loss dict:  {'mse_loss': 0.12270805433392525}
2024-05-04 04:25:03,802 [INFO] Step[800/1020]: training loss : 0.13288555473089217 TRAIN  loss dict:  {'mse_loss': 0.13288555473089217}
2024-05-04 04:25:58,109 [INFO] Step[850/1020]: training loss : 0.13051941961050034 TRAIN  loss dict:  {'mse_loss': 0.13051941961050034}
2024-05-04 04:26:53,377 [INFO] Step[900/1020]: training loss : 0.12454335764050484 TRAIN  loss dict:  {'mse_loss': 0.12454335764050484}
2024-05-04 04:27:51,258 [INFO] Step[950/1020]: training loss : 0.12806402444839476 TRAIN  loss dict:  {'mse_loss': 0.12806402444839476}
2024-05-04 04:28:45,771 [INFO] Step[1000/1020]: training loss : 0.12847501151263713 TRAIN  loss dict:  {'mse_loss': 0.12847501151263713}
2024-05-04 04:32:16,064 [INFO] Label accuracies statistics:
2024-05-04 04:32:16,064 [INFO] {0: 0.5, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.5, 7: 1.0, 8: 0.75, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 0.75, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 0.75, 28: 0.75, 29: 0.75, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 1.0, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 0.75, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.75, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 1.0, 65: 0.75, 66: 0.5, 67: 1.0, 68: 0.75, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.75, 88: 1.0, 89: 1.0, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.75, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 0.75, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 0.75, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 1.0, 146: 0.75, 147: 1.0, 148: 0.5, 149: 1.0, 150: 0.5, 151: 1.0, 152: 0.75, 153: 0.5, 154: 1.0, 155: 0.75, 156: 1.0, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.75, 161: 1.0, 162: 0.5, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 0.75}

2024-05-04 04:32:16,084 [INFO] [38] TRAIN  loss: 0.12719941625335052 acc: 0.0
2024-05-04 04:32:16,084 [INFO] [38] TRAIN  loss dict: {'mse_loss': 0.12719941625335052}
2024-05-04 04:32:16,084 [INFO] [38] VALIDATION loss: 0.5880711278454824 VALIDATION  acc: 0.8825757575757576
2024-05-04 04:32:16,085 [INFO] [38] VALIDATION  loss dict: {'mse_loss': 0.150282076061374, 'classification_loss': 0.4377890528976974}
2024-05-04 04:32:16,085 [INFO] 
2024-05-04 04:34:03,455 [INFO] Step[50/1020]: training loss : 0.12584891691803932 TRAIN  loss dict:  {'mse_loss': 0.12584891691803932}
2024-05-04 04:34:57,229 [INFO] Step[100/1020]: training loss : 0.12317681699991226 TRAIN  loss dict:  {'mse_loss': 0.12317681699991226}
2024-05-04 04:35:48,762 [INFO] Step[150/1020]: training loss : 0.12883847922086716 TRAIN  loss dict:  {'mse_loss': 0.12883847922086716}
2024-05-04 04:36:40,134 [INFO] Step[200/1020]: training loss : 0.12888532474637032 TRAIN  loss dict:  {'mse_loss': 0.12888532474637032}
2024-05-04 04:37:33,829 [INFO] Step[250/1020]: training loss : 0.1284045846760273 TRAIN  loss dict:  {'mse_loss': 0.1284045846760273}
2024-05-04 04:38:28,176 [INFO] Step[300/1020]: training loss : 0.1266198232769966 TRAIN  loss dict:  {'mse_loss': 0.1266198232769966}
2024-05-04 04:39:20,170 [INFO] Step[350/1020]: training loss : 0.12126444056630134 TRAIN  loss dict:  {'mse_loss': 0.12126444056630134}
2024-05-04 04:40:11,420 [INFO] Step[400/1020]: training loss : 0.12633819580078126 TRAIN  loss dict:  {'mse_loss': 0.12633819580078126}
2024-05-04 04:41:01,974 [INFO] Step[450/1020]: training loss : 0.12642817601561546 TRAIN  loss dict:  {'mse_loss': 0.12642817601561546}
2024-05-04 04:41:53,793 [INFO] Step[500/1020]: training loss : 0.12016918584704399 TRAIN  loss dict:  {'mse_loss': 0.12016918584704399}
2024-05-04 04:42:47,919 [INFO] Step[550/1020]: training loss : 0.12229523167014122 TRAIN  loss dict:  {'mse_loss': 0.12229523167014122}
2024-05-04 04:43:43,399 [INFO] Step[600/1020]: training loss : 0.1284810285270214 TRAIN  loss dict:  {'mse_loss': 0.1284810285270214}
2024-05-04 04:44:37,431 [INFO] Step[650/1020]: training loss : 0.13341190204024314 TRAIN  loss dict:  {'mse_loss': 0.13341190204024314}
2024-05-04 04:45:33,113 [INFO] Step[700/1020]: training loss : 0.11982649192214012 TRAIN  loss dict:  {'mse_loss': 0.11982649192214012}
2024-05-04 04:46:26,366 [INFO] Step[750/1020]: training loss : 0.11712275132536888 TRAIN  loss dict:  {'mse_loss': 0.11712275132536888}
2024-05-04 04:47:20,602 [INFO] Step[800/1020]: training loss : 0.1260303258895874 TRAIN  loss dict:  {'mse_loss': 0.1260303258895874}
2024-05-04 04:48:14,001 [INFO] Step[850/1020]: training loss : 0.1268591158092022 TRAIN  loss dict:  {'mse_loss': 0.1268591158092022}
2024-05-04 04:49:09,059 [INFO] Step[900/1020]: training loss : 0.12890252009034156 TRAIN  loss dict:  {'mse_loss': 0.12890252009034156}
2024-05-04 04:50:03,866 [INFO] Step[950/1020]: training loss : 0.1270791310071945 TRAIN  loss dict:  {'mse_loss': 0.1270791310071945}
2024-05-04 04:50:56,338 [INFO] Step[1000/1020]: training loss : 0.12773743256926537 TRAIN  loss dict:  {'mse_loss': 0.12773743256926537}
2024-05-04 04:54:28,980 [INFO] Label accuracies statistics:
2024-05-04 04:54:28,980 [INFO] {0: 0.5, 1: 1.0, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.75, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.25, 18: 1.0, 19: 1.0, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 1.0, 29: 0.75, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.5, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 1.0, 65: 0.75, 66: 0.5, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.5, 74: 0.5, 75: 1.0, 76: 1.0, 77: 0.75, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.75, 88: 1.0, 89: 1.0, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 0.75, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.5, 121: 1.0, 122: 0.5, 123: 1.0, 124: 1.0, 125: 0.75, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.75, 151: 1.0, 152: 0.75, 153: 0.75, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.5, 158: 0.75, 159: 0.75, 160: 1.0, 161: 1.0, 162: 0.5, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 0.75, 196: 1.0, 197: 1.0, 198: 1.0}

2024-05-04 04:54:29,000 [INFO] [39] TRAIN  loss: 0.12587504774770317 acc: 0.0
2024-05-04 04:54:29,000 [INFO] [39] TRAIN  loss dict: {'mse_loss': 0.12587504774770317}
2024-05-04 04:54:29,001 [INFO] [39] VALIDATION loss: 0.5915452579807754 VALIDATION  acc: 0.88510101010101
2024-05-04 04:54:29,001 [INFO] [39] VALIDATION  loss dict: {'mse_loss': 0.14910655122513722, 'classification_loss': 0.44243870299859817}
2024-05-04 04:54:29,001 [INFO] 
2024-05-04 04:56:12,075 [INFO] Step[50/1020]: training loss : 0.11892741397023202 TRAIN  loss dict:  {'mse_loss': 0.11892741397023202}
2024-05-04 04:57:05,505 [INFO] Step[100/1020]: training loss : 0.12503824427723884 TRAIN  loss dict:  {'mse_loss': 0.12503824427723884}
2024-05-04 04:58:03,118 [INFO] Step[150/1020]: training loss : 0.1207745635509491 TRAIN  loss dict:  {'mse_loss': 0.1207745635509491}
2024-05-04 04:58:56,537 [INFO] Step[200/1020]: training loss : 0.11999875351786614 TRAIN  loss dict:  {'mse_loss': 0.11999875351786614}
2024-05-04 04:59:50,524 [INFO] Step[250/1020]: training loss : 0.12581032663583755 TRAIN  loss dict:  {'mse_loss': 0.12581032663583755}
2024-05-04 05:00:45,150 [INFO] Step[300/1020]: training loss : 0.12828443706035614 TRAIN  loss dict:  {'mse_loss': 0.12828443706035614}
2024-05-04 05:01:39,683 [INFO] Step[350/1020]: training loss : 0.12521904110908508 TRAIN  loss dict:  {'mse_loss': 0.12521904110908508}
2024-05-04 05:02:36,214 [INFO] Step[400/1020]: training loss : 0.13020524486899376 TRAIN  loss dict:  {'mse_loss': 0.13020524486899376}
2024-05-04 05:03:29,041 [INFO] Step[450/1020]: training loss : 0.12522326037287712 TRAIN  loss dict:  {'mse_loss': 0.12522326037287712}
2024-05-04 05:04:21,144 [INFO] Step[500/1020]: training loss : 0.12290104568004608 TRAIN  loss dict:  {'mse_loss': 0.12290104568004608}
2024-05-04 05:05:13,129 [INFO] Step[550/1020]: training loss : 0.13369678184390069 TRAIN  loss dict:  {'mse_loss': 0.13369678184390069}
2024-05-04 05:06:07,324 [INFO] Step[600/1020]: training loss : 0.12653481245040893 TRAIN  loss dict:  {'mse_loss': 0.12653481245040893}
2024-05-04 05:06:59,983 [INFO] Step[650/1020]: training loss : 0.12593333423137665 TRAIN  loss dict:  {'mse_loss': 0.12593333423137665}
2024-05-04 05:07:57,042 [INFO] Step[700/1020]: training loss : 0.12781322866678238 TRAIN  loss dict:  {'mse_loss': 0.12781322866678238}
2024-05-04 05:08:51,592 [INFO] Step[750/1020]: training loss : 0.12211030140519143 TRAIN  loss dict:  {'mse_loss': 0.12211030140519143}
2024-05-04 05:09:45,758 [INFO] Step[800/1020]: training loss : 0.12409701079130173 TRAIN  loss dict:  {'mse_loss': 0.12409701079130173}
2024-05-04 05:10:38,958 [INFO] Step[850/1020]: training loss : 0.13152921944856644 TRAIN  loss dict:  {'mse_loss': 0.13152921944856644}
2024-05-04 05:11:35,729 [INFO] Step[900/1020]: training loss : 0.13185721665620803 TRAIN  loss dict:  {'mse_loss': 0.13185721665620803}
2024-05-04 05:12:30,145 [INFO] Step[950/1020]: training loss : 0.1294666776061058 TRAIN  loss dict:  {'mse_loss': 0.1294666776061058}
2024-05-04 05:13:23,433 [INFO] Step[1000/1020]: training loss : 0.13021350473165513 TRAIN  loss dict:  {'mse_loss': 0.13021350473165513}
2024-05-04 05:16:59,752 [INFO] Label accuracies statistics:
2024-05-04 05:16:59,752 [INFO] {0: 0.5, 1: 0.75, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.5, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 1.0, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 1.0, 29: 0.75, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 1.0, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 0.75, 53: 0.5, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.5, 59: 1.0, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 1.0, 65: 1.0, 66: 0.5, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.5, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 1.0, 88: 1.0, 89: 1.0, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.5, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 0.75, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 1.0, 144: 0.75, 145: 1.0, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 0.5, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.5, 158: 0.75, 159: 0.75, 160: 1.0, 161: 1.0, 162: 0.5, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 0.75, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 0.75, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.75, 191: 0.5, 192: 1.0, 193: 0.5, 194: 1.0, 195: 1.0, 196: 1.0, 197: 1.0, 198: 1.0}

2024-05-04 05:16:59,773 [INFO] [40] TRAIN  loss: 0.12617273907743248 acc: 0.0
2024-05-04 05:16:59,773 [INFO] [40] TRAIN  loss dict: {'mse_loss': 0.12617273907743248}
2024-05-04 05:16:59,773 [INFO] [40] VALIDATION loss: 0.5752055021849546 VALIDATION  acc: 0.8863636363636364
2024-05-04 05:16:59,773 [INFO] [40] VALIDATION  loss dict: {'mse_loss': 0.14768767891207127, 'classification_loss': 0.42751782072879696}
2024-05-04 05:16:59,774 [INFO] 
2024-05-04 05:18:40,497 [INFO] Step[50/1020]: training loss : 0.13405143961310387 TRAIN  loss dict:  {'mse_loss': 0.13405143961310387}
2024-05-04 05:19:32,478 [INFO] Step[100/1020]: training loss : 0.12604676723480224 TRAIN  loss dict:  {'mse_loss': 0.12604676723480224}
2024-05-04 05:20:28,938 [INFO] Step[150/1020]: training loss : 0.12563585698604585 TRAIN  loss dict:  {'mse_loss': 0.12563585698604585}
2024-05-04 05:21:23,990 [INFO] Step[200/1020]: training loss : 0.12402116164565086 TRAIN  loss dict:  {'mse_loss': 0.12402116164565086}
2024-05-04 05:22:21,357 [INFO] Step[250/1020]: training loss : 0.12232414081692695 TRAIN  loss dict:  {'mse_loss': 0.12232414081692695}
2024-05-04 05:23:15,804 [INFO] Step[300/1020]: training loss : 0.12529441669583322 TRAIN  loss dict:  {'mse_loss': 0.12529441669583322}
2024-05-04 05:24:10,992 [INFO] Step[350/1020]: training loss : 0.1281067843735218 TRAIN  loss dict:  {'mse_loss': 0.1281067843735218}
2024-05-04 05:25:03,440 [INFO] Step[400/1020]: training loss : 0.125797581076622 TRAIN  loss dict:  {'mse_loss': 0.125797581076622}
2024-05-04 05:25:54,905 [INFO] Step[450/1020]: training loss : 0.12992102786898613 TRAIN  loss dict:  {'mse_loss': 0.12992102786898613}
2024-05-04 05:26:45,404 [INFO] Step[500/1020]: training loss : 0.12267832607030868 TRAIN  loss dict:  {'mse_loss': 0.12267832607030868}
2024-05-04 05:27:39,979 [INFO] Step[550/1020]: training loss : 0.12225030526518822 TRAIN  loss dict:  {'mse_loss': 0.12225030526518822}
2024-05-04 05:28:35,136 [INFO] Step[600/1020]: training loss : 0.1286442543566227 TRAIN  loss dict:  {'mse_loss': 0.1286442543566227}
2024-05-04 05:29:28,482 [INFO] Step[650/1020]: training loss : 0.12709737062454224 TRAIN  loss dict:  {'mse_loss': 0.12709737062454224}
2024-05-04 05:30:19,974 [INFO] Step[700/1020]: training loss : 0.12617090195417405 TRAIN  loss dict:  {'mse_loss': 0.12617090195417405}
2024-05-04 05:31:14,242 [INFO] Step[750/1020]: training loss : 0.11922521099448204 TRAIN  loss dict:  {'mse_loss': 0.11922521099448204}
2024-05-04 05:32:06,340 [INFO] Step[800/1020]: training loss : 0.12852075904607774 TRAIN  loss dict:  {'mse_loss': 0.12852075904607774}
2024-05-04 05:33:00,080 [INFO] Step[850/1020]: training loss : 0.127512314170599 TRAIN  loss dict:  {'mse_loss': 0.127512314170599}
2024-05-04 05:33:55,838 [INFO] Step[900/1020]: training loss : 0.12375010654330254 TRAIN  loss dict:  {'mse_loss': 0.12375010654330254}
2024-05-04 05:34:53,775 [INFO] Step[950/1020]: training loss : 0.12284806534647942 TRAIN  loss dict:  {'mse_loss': 0.12284806534647942}
2024-05-04 05:35:49,013 [INFO] Step[1000/1020]: training loss : 0.12414866521954536 TRAIN  loss dict:  {'mse_loss': 0.12414866521954536}
2024-05-04 05:39:25,719 [INFO] Label accuracies statistics:
2024-05-04 05:39:25,719 [INFO] {0: 1.0, 1: 1.0, 2: 0.5, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.75, 7: 1.0, 8: 0.25, 9: 1.0, 10: 1.0, 11: 1.0, 12: 1.0, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 1.0, 20: 0.75, 21: 0.75, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 1.0, 29: 0.75, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 1.0, 53: 0.25, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.75, 59: 0.75, 60: 0.75, 61: 0.75, 62: 1.0, 63: 1.0, 64: 1.0, 65: 1.0, 66: 0.75, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.75, 88: 0.6666666666666666, 89: 0.75, 90: 0.75, 91: 1.0, 92: 0.75, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.75, 106: 1.0, 107: 1.0, 108: 0.75, 109: 1.0, 110: 1.0, 111: 1.0, 112: 0.5, 113: 0.0, 114: 1.0, 115: 1.0, 116: 1.0, 117: 0.75, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.5, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 0.75, 132: 0.5, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 138: 1.0, 139: 1.0, 140: 0.75, 141: 1.0, 142: 1.0, 143: 0.75, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.75, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 1.0, 156: 1.0, 157: 0.5, 158: 0.75, 159: 0.75, 160: 0.5, 161: 1.0, 162: 0.75, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.5, 169: 0.75, 170: 1.0, 171: 0.5, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 0.75, 185: 1.0, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-04 05:39:25,743 [INFO] [41] TRAIN  loss: 0.12566884470482667 acc: 0.0
2024-05-04 05:39:25,743 [INFO] [41] TRAIN  loss dict: {'mse_loss': 0.12566884470482667}
2024-05-04 05:39:25,743 [INFO] [41] VALIDATION loss: 0.589950952904694 VALIDATION  acc: 0.8863636363636364
2024-05-04 05:39:25,743 [INFO] [41] VALIDATION  loss dict: {'mse_loss': 0.1462048263561846, 'classification_loss': 0.4437461287980297}
2024-05-04 05:39:25,743 [INFO] 
2024-05-04 05:41:05,806 [INFO] Step[50/1020]: training loss : 0.11877998769283295 TRAIN  loss dict:  {'mse_loss': 0.11877998769283295}
2024-05-04 05:41:57,897 [INFO] Step[100/1020]: training loss : 0.12343466997146607 TRAIN  loss dict:  {'mse_loss': 0.12343466997146607}
2024-05-04 05:42:50,047 [INFO] Step[150/1020]: training loss : 0.11928689107298851 TRAIN  loss dict:  {'mse_loss': 0.11928689107298851}
2024-05-04 05:43:46,906 [INFO] Step[200/1020]: training loss : 0.12357755407691001 TRAIN  loss dict:  {'mse_loss': 0.12357755407691001}
2024-05-04 05:44:38,090 [INFO] Step[250/1020]: training loss : 0.12411885201931 TRAIN  loss dict:  {'mse_loss': 0.12411885201931}
2024-05-04 05:45:33,992 [INFO] Step[300/1020]: training loss : 0.12586753875017165 TRAIN  loss dict:  {'mse_loss': 0.12586753875017165}
2024-05-04 05:46:31,614 [INFO] Step[350/1020]: training loss : 0.12291183680295945 TRAIN  loss dict:  {'mse_loss': 0.12291183680295945}
2024-05-04 05:47:22,416 [INFO] Step[400/1020]: training loss : 0.12689969480037688 TRAIN  loss dict:  {'mse_loss': 0.12689969480037688}
2024-05-04 05:48:15,372 [INFO] Step[450/1020]: training loss : 0.12297526612877846 TRAIN  loss dict:  {'mse_loss': 0.12297526612877846}
2024-05-04 05:49:12,102 [INFO] Step[500/1020]: training loss : 0.1255425889790058 TRAIN  loss dict:  {'mse_loss': 0.1255425889790058}
2024-05-04 05:50:06,766 [INFO] Step[550/1020]: training loss : 0.12809164240956306 TRAIN  loss dict:  {'mse_loss': 0.12809164240956306}
2024-05-04 05:51:04,143 [INFO] Step[600/1020]: training loss : 0.12044187270104885 TRAIN  loss dict:  {'mse_loss': 0.12044187270104885}
2024-05-04 05:51:57,510 [INFO] Step[650/1020]: training loss : 0.12307369440793992 TRAIN  loss dict:  {'mse_loss': 0.12307369440793992}
2024-05-04 05:52:52,320 [INFO] Step[700/1020]: training loss : 0.12624629616737365 TRAIN  loss dict:  {'mse_loss': 0.12624629616737365}
2024-05-04 05:53:47,184 [INFO] Step[750/1020]: training loss : 0.1313694503903389 TRAIN  loss dict:  {'mse_loss': 0.1313694503903389}
2024-05-04 05:54:39,325 [INFO] Step[800/1020]: training loss : 0.11845263376832009 TRAIN  loss dict:  {'mse_loss': 0.11845263376832009}
2024-05-04 05:55:32,798 [INFO] Step[850/1020]: training loss : 0.12674641817808152 TRAIN  loss dict:  {'mse_loss': 0.12674641817808152}
2024-05-04 05:56:24,554 [INFO] Step[900/1020]: training loss : 0.12277775585651397 TRAIN  loss dict:  {'mse_loss': 0.12277775585651397}
2024-05-04 05:57:20,349 [INFO] Step[950/1020]: training loss : 0.12187048986554146 TRAIN  loss dict:  {'mse_loss': 0.12187048986554146}
2024-05-04 05:58:13,792 [INFO] Step[1000/1020]: training loss : 0.12450784027576446 TRAIN  loss dict:  {'mse_loss': 0.12450784027576446}
2024-05-04 06:01:49,950 [INFO] Label accuracies statistics:
2024-05-04 06:01:49,950 [INFO] {0: 0.5, 1: 0.75, 2: 0.75, 3: 1.0, 4: 0.3333333333333333, 5: 1.0, 6: 0.5, 7: 1.0, 8: 0.5, 9: 1.0, 10: 1.0, 11: 1.0, 12: 0.75, 13: 1.0, 14: 0.75, 15: 0.5, 16: 1.0, 17: 0.75, 18: 1.0, 19: 1.0, 20: 0.75, 21: 1.0, 22: 1.0, 23: 0.75, 24: 0.75, 25: 0.75, 26: 1.0, 27: 1.0, 28: 1.0, 29: 0.75, 30: 0.75, 31: 1.0, 32: 1.0, 33: 1.0, 34: 0.75, 35: 0.5, 36: 1.0, 37: 1.0, 38: 1.0, 39: 0.75, 40: 1.0, 41: 1.0, 42: 1.0, 43: 1.0, 44: 0.75, 45: 1.0, 46: 1.0, 47: 1.0, 48: 1.0, 49: 0.5, 50: 1.0, 51: 0.75, 52: 0.75, 53: 1.0, 54: 0.75, 55: 1.0, 56: 1.0, 57: 1.0, 58: 0.5, 59: 0.75, 60: 0.75, 61: 1.0, 62: 1.0, 63: 1.0, 64: 1.0, 65: 0.75, 66: 0.75, 67: 1.0, 68: 1.0, 69: 1.0, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 0.5, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 1.0, 80: 0.75, 81: 1.0, 82: 0.75, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 0.75, 88: 1.0, 89: 0.75, 90: 0.75, 91: 1.0, 92: 1.0, 93: 1.0, 94: 1.0, 95: 1.0, 96: 1.0, 97: 1.0, 98: 1.0, 99: 1.0, 100: 1.0, 101: 0.75, 102: 1.0, 103: 1.0, 104: 1.0, 105: 0.5, 106: 1.0, 107: 1.0, 108: 0.75, 109: 1.0, 110: 0.75, 111: 1.0, 112: 0.5, 113: 0.25, 114: 1.0, 115: 1.0, 116: 1.0, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 1.0, 122: 0.75, 123: 1.0, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 1.0, 130: 1.0, 131: 1.0, 132: 0.75, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 1.0, 139: 1.0, 140: 1.0, 141: 1.0, 142: 1.0, 143: 1.0, 144: 1.0, 145: 0.75, 146: 1.0, 147: 1.0, 148: 0.75, 149: 1.0, 150: 0.5, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 0.75, 156: 0.75, 157: 0.5, 158: 0.75, 159: 0.75, 160: 1.0, 161: 1.0, 162: 0.5, 163: 1.0, 164: 1.0, 165: 1.0, 166: 1.0, 167: 1.0, 168: 0.25, 169: 1.0, 170: 1.0, 171: 0.25, 172: 1.0, 173: 0.75, 174: 1.0, 175: 1.0, 176: 0.75, 177: 0.75, 178: 1.0, 179: 1.0, 180: 1.0, 181: 1.0, 182: 1.0, 183: 1.0, 184: 0.75, 185: 0.75, 186: 1.0, 187: 1.0, 188: 1.0, 189: 1.0, 190: 0.5, 191: 0.5, 192: 1.0, 193: 0.75, 194: 1.0, 195: 1.0, 196: 0.75, 197: 1.0, 198: 1.0}

2024-05-04 06:01:49,970 [INFO] [42] TRAIN  loss: 0.12394767155615138 acc: 0.0
2024-05-04 06:01:49,970 [INFO] [42] TRAIN  loss dict: {'mse_loss': 0.12394767155615138}
2024-05-04 06:01:49,970 [INFO] [42] VALIDATION loss: 0.5749533629101334 VALIDATION  acc: 0.8876262626262627
2024-05-04 06:01:49,970 [INFO] [42] VALIDATION  loss dict: {'mse_loss': 0.1479416425255212, 'classification_loss': 0.42701172193211284}
2024-05-04 06:01:49,971 [INFO] 
2024-05-04 06:01:49,971 [INFO] 

***Stop training***


2024-05-04 06:01:49,971 [INFO] 
Testing checkpointed models starting...

2024-05-04 06:05:58,265 [INFO] Label accuracies statistics:
2024-05-04 06:05:58,266 [INFO] {0: 0.75, 1: 0.75, 2: 1.0, 3: 1.0, 4: 1.0, 5: 1.0, 6: 1.0, 7: 1.0, 8: 1.0, 9: 0.75, 10: 1.0, 11: 1.0, 12: 1.0, 13: 0.75, 14: 1.0, 15: 1.0, 16: 1.0, 17: 0.6666666666666666, 18: 1.0, 19: 0.6666666666666666, 20: 1.0, 21: 0.5, 22: 1.0, 23: 1.0, 24: 0.75, 25: 1.0, 26: 1.0, 27: 1.0, 28: 1.0, 29: 0.75, 30: 1.0, 31: 1.0, 32: 1.0, 33: 1.0, 34: 1.0, 35: 0.75, 36: 0.75, 37: 1.0, 38: 1.0, 39: 1.0, 40: 1.0, 41: 0.0, 42: 1.0, 43: 1.0, 44: 1.0, 45: 1.0, 46: 1.0, 47: 0.75, 48: 1.0, 49: 0.75, 50: 0.5, 51: 0.25, 52: 0.75, 53: 0.5, 54: 1.0, 55: 1.0, 56: 0.5, 57: 1.0, 58: 0.5, 59: 0.75, 60: 1.0, 61: 0.75, 62: 1.0, 63: 1.0, 64: 0.75, 65: 0.75, 66: 0.75, 67: 0.75, 68: 1.0, 69: 0.75, 70: 0.75, 71: 0.75, 72: 1.0, 73: 0.75, 74: 1.0, 75: 1.0, 76: 1.0, 77: 1.0, 78: 1.0, 79: 0.5, 80: 1.0, 81: 1.0, 82: 1.0, 83: 1.0, 84: 1.0, 85: 1.0, 86: 1.0, 87: 1.0, 88: 1.0, 89: 1.0, 90: 1.0, 91: 1.0, 92: 1.0, 93: 1.0, 94: 0.75, 95: 1.0, 96: 0.75, 97: 1.0, 98: 0.75, 99: 1.0, 100: 1.0, 101: 1.0, 102: 0.5, 103: 0.75, 104: 0.75, 105: 0.25, 106: 0.75, 107: 0.75, 108: 0.75, 109: 0.75, 110: 0.75, 111: 1.0, 112: 0.75, 113: 0.25, 114: 0.75, 115: 1.0, 116: 0.75, 117: 1.0, 118: 1.0, 119: 1.0, 120: 0.75, 121: 0.5, 122: 1.0, 123: 0.75, 124: 1.0, 125: 1.0, 126: 1.0, 127: 1.0, 128: 1.0, 129: 0.5, 130: 1.0, 131: 1.0, 132: 1.0, 133: 1.0, 134: 1.0, 135: 1.0, 136: 1.0, 137: 0.75, 138: 0.5, 139: 1.0, 140: 0.75, 141: 1.0, 142: 0.75, 143: 1.0, 144: 1.0, 145: 1.0, 146: 0.5, 147: 1.0, 148: 0.75, 149: 1.0, 150: 1.0, 151: 1.0, 152: 1.0, 153: 1.0, 154: 1.0, 155: 1.0, 156: 0.75, 157: 0.5, 158: 0.75, 159: 0.5, 160: 0.75, 161: 0.5, 162: 0.75, 163: 0.5, 164: 0.75, 165: 0.75, 166: 0.75, 167: 0.75, 168: 0.0, 169: 0.75, 170: 0.75, 171: 0.5, 172: 0.75, 173: 0.75, 174: 0.5, 175: 0.5, 176: 0.75, 177: 0.75, 178: 0.75, 179: 0.5, 180: 0.75, 181: 0.75, 182: 0.75, 183: 0.75, 184: 0.75, 185: 0.75, 186: 0.75, 187: 0.75, 188: 0.5, 189: 0.75, 190: 0.75, 191: 0.25, 192: 0.75, 193: 0.75, 194: 0.75, 195: 0.75, 196: 0.75, 197: 0.75, 198: 0.75}

2024-05-04 06:05:58,287 [INFO] 
Testing accuracy: 0.8305941845764855
